{"fileName":"PAIP-part1.pdf","created":"Thu Sep 03 2020","content":"                    Paradigms of\n    Artificial Intelligence\n                  Programming:\nCASE            STUDIES                IN    COMMON                             LISP\n\n\n\n\n                                   Peter Norvig\n\n\n\n\nM O R G A N   K A U F M A N N   PUBLISHERS ^ SAN   F R A N C I S C O ,   C A L I F O R N I A\n\fSponsoring Editor         Michael B.     Morgan\nProduction Manager          Yonie    Overton\nCover Designer         Sandra   Popovich\nText Design/Composition             SuperScnpt    Typography\nCopyeditor      Barbara Beidler        Kendnck\nProofreaders         Lynn Meinhardt, Shanlyn      Hovind,   Gary   Morus\nPrinter     Malloy     Lithographing\n\n\nMorgan Kaufmann Publishers, Inc.\nEditorial and Sales Office:\n340 Pine Street, Sbcth Floor\nSan Francisco, CA 94104-3205\nUSA\nTelephone     415/392-2665\nFacsim�e     415/982-2665\nInternet    mkp@mkp.com\nWeb site     http://mkp.com\n\n\n� 1992 Morgan Kaufmann Publishers, Inc.\nAll rights reserved\n\nPrinted in the United States of America\n\n03 02 Ol        8 7 6\nNo part of this publication may be reproduced, stored in a retrieval system, or\ntransmitted in any form or by any means-electronic, photocopying, recording, or\notherwise--without the prior written permission of the publisher.\n\n\n                     Library of Congress Cataloging-in-Publication Data\n\nNorvig, Peter.\n                  Paradigms of artificial inteUigence programming: case studies in\n           common Lisp / Peter Norvig.\n                         p.        cm.\n                  Includes bibliographical references and index.\n                  ISBN 1-55860-191-0:\n                   1. Electronic digital computers-Programming. 2. COMMON LISP\n           (Computer program language)          3. Artificial intelligence.  I. Title.\n           QA76.6.N6871991\n           006.3-dc20                                                       91-39187\n                                                                                 CIP\n\fTo my   family,..\n\fPreface\n\n              paradigm  1 an example or pattern; esp an outstandingly clear or typical example.\n                                                -Longman's   Dictionary of the EngUsh Language,    1984\n\n\n\n\nThis book is concerned with three related topics: the field of artificial intelligence, or AI; the skill\nof computer programming; and the programming language Common Lisp. Careful readers of\nthis book can expect to come away with an appreciation of the major questions and techniques\nof AI, an understanding of some important AI programs, and an ability to read, modify, and\ncreate programs using Common Lisp. The examples in this book are designed to be clear\nexamples of good programming style--paradigms of programming. They are also paradigms\nof AI research--historically significant programs that use widely applicable techniques to solve\nimportant problems.\n     Just as a liberal arts education includes a course in \"the great books\" of a culture, so this book\nis, at one level, a course in \"the great programs\" that define the AI culture.^\n     At another level, this book is a highly technical compendium of the knowledge you will need\nto progress from being an intermediate Lisp programmer to being an expert. Parts I and II are\ndesigned to help the novice get up to speed, but the complete beginner may have a hard time\neven with this material. Fortunately, there are at least five good texts available for the beginner;\nsee page xiii for my recommendations.\n\n   ^This does not imply that the programs chosen are the best of all AI programs--just that\nthey are representative.\n\f                                                                                         PREFACE\n\n\n\n       All too often, the teaching of computer programming consists of explaining the\n   syntax of the chosen language, showing the student a 10-line program, and then\n   asking the student to write programs. In this book, we take the approach that the\n   best way to learn to write is to read (and conversely, a good way to improve reading\n   skills is to write). After the briefest of introductions to Lisp, we start right off with\n   complex programs and ask the reader to understand and make small modifications\n   to these programs.\n       The premise of this book is that you can only write something useful and inter\n   esting when you both understand what makes good writing and have something\n   interesting to say. This holds for writing programs as well as for writing prose. As\n   Kernighan and Plauger put it on the cover of Software Tools in Pascal:\n\n         Good programming     is not learned from generalities, but by seeing how signif\n         icant programs can be made clean, easy to read, easy to maintain and modify,\n         human-engineered,    efficient, and reliable, by the application of common   sense\n         and good programming practices. Careful study and imitation of good programs\n         leads to better writing.\n\n       The proud craftsman is often tempted to display only the finished work, without\n   any indication of the false starts and mistakes that are an unfortunate but unavoidable\n   part of the creative process. Unfortunately, this reluctance to unveil the process is\n   a barrier to learning; a student of mathematics who sees a beautiful 10-line proof in\n   a textbook can marvel at its conciseness but does not learn how to construct such a\n   proof. This book attempts to show the complete programming process, \"warts and\n   all.\" Each chapter starts with a simple version of a program, one that works on some\n   examples but fails on others. Each chapter shows how these failures can be analyzed\n   to build increasingly sophisticated versions of the basic program. Thus, the reader\n   can not only appreciate the final result but also see how to learn from mistakes and\n   refine an initially incomplete design. Furthermore, the reader who finds a particular\n   chapter is becoming too difficult can skip to the next chapter, having gained some\n   appreciation of the problem area, and without being overwhelmed by the details.\n       This book presents a body of knowledge loosely known as \"AI programming\n   techniques,\" but it must be recognized that there are no clear-cut boundaries on this\n   body of knowledge. To be sure, no one can be a good AI programmer without first\n   being a good programmer. Thus, this book presents topics (especially in parts III\n   and V) that are not AI per se, but are essential background for any AI practitioner.\n\n\n   Why Lisp? Why Common Lisp?\n\n   Lisp is one of the oldest programming languages still in widespread use today. There\n   have been many versions of Lisp, each sharing basic features but differing in detail.\n   In this book we use the version called Common Lisp, which is the most widely\n   accepted standard. Lisp has been chosen for three reasons.\n\fPREFACE                                                                                       IX\n\n\n\n              First, Lisp is the most popular language for AI programming, particularly in the\n          United States. If you're going to learn a language, it might as well be one with a\n          growing literature, rather than a dead tongue.\n              Second, Lisp makes it easy to capture relevant generalizations in defining new\n          objects. In particular. Lisp makes it easy to define new languages especially targeted\n          to the problem at hand. This is especially handy in AI applications, which often\n          manipulate complex information that is most easily represented in some novel form.\n          Lisp is one of the few languages that allows full flexibility in defining and manipu\n          lating programs as well as data. All programming languages, by definition, provide\n          a means of defining programs, but many other languages limit the ways in which a\n          program can be used, or limit the range of programs that can be defined, or require\n          the programmer to explicitly state irrelevant details.\n              Third, Lisp makes it very easy to develop a working program fast. Lisp programs\n          are concise and are uncluttered by low-level detail. Common Lisp offers an unusually\n          large number of useful predefined objects, including over 700 functions. The pro\n          gramming environment (such as debugging tools, incremental compilers, integrated\n          editors, and interfaces to window systems) that surround Lisp systems are usually\n          very good. And the dynamic, interactive nature of Lisp makes it easy to experiment\n          and change a program while it is being developed.\n              It must be mentioned that in Europe and Japan, Prolog has been as popular as\n          Lisp for AI work. Prolog shares most of Lisp's advantages in terms of flexibility and\n          conciseness. Recently, Lisp has gained popularity worldwide, and Prolog is becom\n          ing more well known in the United States. As a result, the average AI worker today is\n          likely to be bilingual. This book presents the key ideas behind Prolog in chapters 11\n          and 12, and uses these ideas in subsequent chapters, particularly 20 and 21.\n               The dialect of Lisp known as Scheme is also gaining in popularity, but primarily\n          for teaching and experimenting with programming language design and techniques,\n          and not so much for writing large AI programs. Scheme is presented in chapters 22\n          and 23. Other dialects of Lisp such as Franz Lisp, MacLisp, InterLisp, ZetaLisp,\n          and Standard Lisp are now considered obsolete. The only new dialect of Lisp to be\n          proposed recently is EuLisp, the European Lisp. A few dialects of Lisp live on as\n          embedded extension languages. For example, the Gnu Emacs text editor uses elisp,\n          and the AutoCad computer-aided design package uses AutoLisp, a derivative of Xlisp.\n          In the future, it is likely that Scheme will become a popular extension language, since\n          it is small but powerful and has an officially sanctioned standard definition.\n              There is a myth that Lisp (and Prolog) are \"special-purpose\" languages, while\n          languages like Pascal and C are \"general purpose.\" Actually, just the reverse is\n          true. Pascal and C are special-purpose languages for manipulating the registers and\n          memory of a von Neumann-style computer. The majority of their syntax is devoted\n          to arithmetic and Boolean expressions, and while they provide some facilities for\n          forming data structures, they have poor mechanisms for procedural abstraction\n          or control abstraction. In addition, they are designed for the state-oriented style\n\f                                                                                PREFACE\n\n\n\n of programming: computing a result by changing the value of variables through\n assignment statements.\n     Lisp, on the other hand, has no special syntax for arithmetic. Addition and\n multiplication are no more or less basic than list operations like appending, or string\n operations like converting to upper case. But Lisp provides all you will need for\n programming in general: defining data structures, functions, and the means for\n combining them.\n     The assignment-dominated, state-oriented style of programming is possible in\n Lisp, but in addition object-oriented, rule-based, and functional styles are all sup\n ported within Lisp. This flexibihty derives from two key features of Lisp: First, Lisp\n has a powerful macro facility, which can be used to extend the basic language. When\n new styles of programming were invented, other languages died out; Lisp simply\n incorporated the new styles by defining some new macros. The macro facility is\n possible because Lisp programs are composed of a simple data structure: the list.\n In the early days, when Lisp was interpreted, most manipulation of programs was\ndone through this data structure. Nowadays, Lisp is more often compiled than in\n terpreted, and programmers rely more on Lisp's second great flexible feature: the\nfunction. Of course, other languages have functions, but Lisp is rare in allowing the\n creation of new functions while a program is running.\n    Lisp's flexibility allows it to adapt as programming styles change, but more impor\ntantly. Lisp can adapt to your particular programming problem. In other languages\nyou fit your problem to the language; with Lisp you extend the language to fit your\nproblem.\n    Because of its flexibility. Lisp has been succesful as a high-level language for rapid\nprototyping in areas such as AI, graphics, and user interfaces. Lisp has also been\nthe dominant language for exploratory programming, where the problems are so\ncomplex that no clear solution is available at the start of the project. Much of AI falls\nunder this heading.\n    The size of Common Lisp can be either an advantage or a disadvantage, depending\non your outlook. In David Touretzky's (1989) fine book for beginning programmers,\nthe emphasis is on simplicity. He chooses to write some programs slightly less\nconcisely, rather than introduce an esoteric new feature (he cites pushnew as an\nexample). That approach is entirely appropriate for beginners, but this book goes\nwell past the level of beginner. This means exposing the reader to new features of\nthe language whenever they are appropriate. Most of the time, new features are\ndescribed as they are introduced, but sometimes explaining the details of a low-\nlevel function would detract from the explanation of the workings of a program.\nIn accepting the privilege of being treated as an \"adult,\" the reader also accepts a\nresponsibility--to look up unfamiliar terms in an appropriate reference source.\n\fPREFACE                                                                                       \"\n\n\n\n\n          Outline of the Book\n\n          This book is organized into five parts.\n              Part I introduces the Common Lisp programming language.\n              Chapter 1 gives a quick introduction by way of small examples that demonstrate\n          the novel features of Lisp. It can be safely skipped or skimmed by the experienced\n          programmer.\n              Chapter 2 is a more extended example showing how the Lisp primitives can be\n          put together to form a program. It should be studied carefully by the novice, and\n          even the experienced programmer will want to look through it to get a feel for my\n          programming style.\n              Chapter 3 provides an overview of the Lisp primitives. It can be skimmed on first\n          reading and used as a reference whenever an unfamiliar function is mentioned in\n          the text.\n              Part I has been kept intentionally brief, so that there is more room for presenting\n          actual AI programs. Unfortunately, that means that another text or reference book\n          (or online help) may be needed to clarify some of the more esoteric features of the\n          language. My recommendations for texts are on page xiii.\n              The reader may also want to refer to chapter 25, which offers some debugging\n          and troubleshooting hints.\n              Part II covers four early AI programs that all use rule-based pattern-matching\n          techniques. By starting with relatively simple versions of the programs and then\n          improving them and moving on to more complex programs, the reader is able to\n          gradually acquire increasingly advanced programming skills.\n              Chapter 4 presents a reconstruction of GPS, the General Problem Solver. The\n          implementation follows the STRIPS approach.\n              Chapter 5 describes ELIZA, a program that mimics human dialogue. This is\n          followed by a chapter that generalizes some of the techniques used in GPS and ELIZA\n          and makes them available as tools for use in subsequent programs.\n              Chapter 7 covers STUDENT, a program that solves high-school-level algebra word\n          problems.\n              Chapter 8 develops a small subset of the MACSYMA program for doing symbolic\n          algebra, including differential and integral calculus. It may be skipped by those who\n          shy away from heavy mathematics.\n              Part III detours from AI for a moment to present some general tools for more\n          efficient programming. The reader who masters the material in this part can be\n          considered an advanced Lisp programmer.\n              Chapter 9 is a detailed study of efficiency techniques, concentrating on caching,\n          indexing, compilation, and delaying computation. Chapter 10 covers lower-level effi\n          ciency issues such as using declarations, avoiding garbage generation, and choosing\n          the right data structure.\n\f                                                                              PREFACE\n\n\n\n       Chapter 11 presents the Prolog language. The aim is two-fold: to show how to\n   write an interpreter for another language, and to introduce the important features\n   of Prolog, so that they can be used where appropriate. Chapter 12 shows how a\n   compiler for Prolog can be 20 to 200 times faster than the interpreter.\n       Chapter 13 introduces object-oriented programming in general, then explores the\n   Common Lisp Object System (CLOS).\n       Chapter 14 discusses the advantages and limitations of both logic-oriented and\n   object-oriented programming, and develops a knowledge representation formalism\n   using all the techniques of part III.\n\n       Part IV covers some advanced AI programs.\n       Chapter 15 uses the techniques of part III to come up with a much more efficient\n   implementation of MACSYMA. It uses the idea of a canonical form, and replaces the\n   very general rewrite rule approach with a series of more specific functions.\n       Chapter 16 covers the EMYCIN expert system shell, a backward chaining rule-\n   based system based on certainty factors. The MYCIN medical expert system is also\n   covered briefly.\n       Chapter 17 covers the Waltz line-labeling algorithm for polyhedra (using Huffman-\n   Clowes labels). Different approaches to constraint propagation and backtracking\n   are discussed.\n       Chapter 18 presents a program that plays an excellent game of Othello. The\n   technique used, alpha-beta searching, is appropriate to a wide variety of two-person\n   games.\n       Chapter 19 is an introduction to natural language processing. It covers context-\n   free grammar, top-down and bottom-up parsing, chart parsing, and some semantic\n   interpretation and preferences.\n       Chapter 20 extends the linguistic coverage of the previous chapter and introduces\n   logic grammars, using the Prolog compiler developed in chapter 11.\n       Chapter 21 is a fairly comprehensive grammar of English using the logic grammar\n   formalism. The problems of going from a simple idea to a realistic, comprehensive\n   program are discussed.\n\n        Part V includes material that is peripheral to AI but important for any serious\n   Lisp programmer.\n        Chapter 22 presents the Scheme dialect of Lisp. A simple Scheme interpreter is\n   developed, then a properly tail-recursive interpreter, then an interpreter that explic\n   itly manipulates continuations and supports cal 1 / c c . Chapter 23 presents a Scheme\n   compiler.\n        Chapter 24 presents the features that are unique to American National Standards\n   Institute (ANSI) Common Lisp. This includes the 1 oop macro, as well as error\n   handling, pretty printing, series and sequences, and the package facility.\n        Chapter 25 is a guide to troubleshooting and debugging Lisp programs.\n\fPREFACE                                                                                         XIII\n\n\n\n             The bibUography Hsts over 200 sources, and there is a comprehensive index. In\n          addition, the appendix provides a directory of publicly available Lisp programs.\n\n\n          How to Use This Book\n\n          The intended audience for this book is broad: anyone who wants to become an ad\n          vanced Lisp programmer, and anyone who wants to be an advanced AI practitioner.\n          There are several recommended paths through the book:\n\n              � In an Introductory AI Course: Concentrate on parts I and II, and at least one\n                example from part IV.\n\n              � Inan Advanced AI Programming     Course: Concentrate on parts I, II and IV, skipping\n                 chapters that are of less interest and adding as much of part III as time permits.\n\n              � In an Advanced    Programming   Languages Course: Concentrate on parts I and V,\n                 with selections from part III. Cover chapters 11 and 13 if similar material is not\n                 presented with another text.\n\n              � For the Professional Lisp Programmer: Read as much of the book as possible, and\n                refer back to it often. Part III and chapter 25 are particularly important.\n\n\n          Supplementary Texts and Reference Books\n\n          The definitive reference source is Steele's Common Lisp the Language. From 1984\n          to 1990, this unambiguously defined the language Common Lisp. However, in\n          1990 the picture became more complicated by the publication of Common Lisp the\n          Language, 2d edition. This book, also by Steele, contains the recommendations of\n          ANSI subcommittee X3J13, whose charter is to define a standard for Lisp. These\n          recommendations include many minor changes and clarifications, as well as brand\n          new material on object-oriented programming, error condition handling, and the\n          loop macro. The new material doubles the size of the book from 465 to 1029 pages.\n              Until the ANSI recommendations are formally accepted. Common Lisp users\n          are in the unfortunate situation of having two distinct and incompatible standards:\n          \"original\" Common Lisp and ANSI Common Lisp. Most of the code in this book is\n          compliant with both standards. The most significant use of an ANSI function is the\n          1 oop macro. The ANSI map- i nto, compi ement, and reduce functions are also used,\n          although rarely. Definitions for all these functions are included, so even those using\n          an \"original\" Common Lisp system can still run all the code in the book.\n              While Common Lisp the Language is the definitive standard, it is sometimes terse\n          and can be difficult for a beginner. Common Lisp: the Reference, published by Franz\n          Inc., offers complete coverage of the language with many helpful examples. Common\n          LISPcraft,   by Robert Wilensky, and Artificial Intelligence Programming,   by Charniak\n\fxiv                                                                                  PREFACE\n\n\n\n      et al., also include brief summaries of the Common Lisp functions. They are not\n      as comprehensive, but that can be a blessing, because it can lead the reader more\n      directly to the functions that are important (at least in the eyes of the author).\n          It is a good idea to read this book with a computer at hand, to try out the examples\n      and experiment with examples of your own. A computer is also handy because Lisp\n      is self-documenting, through the functions apropos, descri be, and documentati on.\n      Many implementations also provide more extensive documentation through some\n      kind of 'help' command or menu.\n          The five introductory Lisp textbooks I recommend are listed below. The first is\n      more elementary than the others.\n\n         �   Common Lisp: A Gentle Introduction to Symbolic   Computation   by David Touret-\n             zky. Most appropriate for beginners, including those who are not computer\n             scientists.\n\n             A Programmer's   Guide to Common   Lisp by Deborah G. Tatar. Appropriate for\n             those with experience in another programming language, but none in Lisp.\n\n             Common LISPcraft by Robert Wilensky. More comprehensive and faster paced,\n             but still useful as an introduction as well as a reference.\n\n             Common Lisp by Wade L. Hennessey. Somewhat hit-and-miss in terms of the\n             topics it covers, but with an enlightened discussion of implementation and\n             efficiency issues that do not appear in the other texts.\n\n         � LISP (3d edition) by Patrick H. Winston and Bertold Horn. Covers the most\n           ground in terms of programming advice, but not as comprehensive as a refer\n           ence. May be difficult for beginners. Includes some AI examples.\n\n          While it may be distracting for the beginner to be continually looking at some\n      reference source, the alternative--to have this book explain every new function in\n      complete detail as it is introduced--would be even more distracting. It would interrupt\n      the description of the AI programs, which is what this book is all about.\n\n          There are a few texts that show how to write AI programs and tools, but none\n      that go into the depth of this book. Nevertheless, the expert AI programmer will\n      want to be familiar with all the following texts, listed in rough order of increasing\n      sophistication:\n\n         � LISP (3d edition). (See above.)\n\n             Programming Paradigms in Lisp by Rajeev Sangal. Presents the different styles\n             of programming that Lisp accommodates, illustrating them with some useful\n             AI tools.\n\fPREFACE                                                                                         XV\n\n\n\n                Programming for Artificial Intelligence by Wolfgang Kreutzer and Bruce McKenzie.\n                Covers some of the basics of rule-based and pattern-matching systems well,\n                but covers Lisp, Prolog, and Smalltalk, and thus has no time left for details in\n                any of the languages.\n\n             � Artificial Intelligence Programming (2d edition) by Eugene Charniak, Christo\n               pher Riesbeck, Drew McDermott, and James Meehan. Contains 150 pages of\n               Lisp overview, followed by an advanced discussion of AI tools, but no actual\n               AI programs.\n\n             � 7 in Practice: Examples in Pop-11 by Allan Ramsey and Rosalind Barrett. Ad\n               vanced, high-quality implementations of five AI programs, unfortunately using\n               a language that has not gained popularity.\n\n              The current text combines the virtues of the last two entries: it presents both actual\n          AI programs and the tools necessary to build them. Furthermore, the presentation is\n          in an incremental fashion, with simple versions presented first for clarity, followed\n          by more sophisticated versions for completeness.\n\n\n          A Note on Exercises\n\n          Sample exercises are provided throughout. Readers can test their level of under\n          standing by faithfully doing the exercises. The exercises are graded on the scale [s],\n          [m], [h], [d], which can be interpreted either as a level of difficulty or as an expected\n          time it will take to do the exercise:\n\n                                     Code     Difficulty    Tune to Do\n                                     [s]      Simple        Seconds\n                                     [m]      Medium        Minutes\n                                     [h]      Hard          Hours\n                                     [d]      Difficult     Days\n\n             The time to do the exercise is measured from the point that the concepts have\n          been well understood. If the reader is unclear on the underlying concepts, it might\n          take hours of review to understand a [m] problem. Answers to the exercises can be\n          found in a separate section at the end of each chapter.\n\n\n          Acknowledgments\n\n          A great many people contributed to this book. First of all I would like to thank my\n          students at USC and Berkeley, as well as James Martin's students at Colorado and\n          Michael Pazzani's students at Irvine, who course-tested earlier versions of this book.\n          Useful suggestions, corrections, and additions were made by:\n\fxvi                                                                                 PREFACE\n\n\n\n          Nina Amenta (Berkeley), Ray S. Babcock and John Paxton (Montana State),\n      Bryan A. Bentz (BBN), Mary P. Boelk (Johnson Controls), Michael Braverman (Berke\n      ley), R. Chandrasekar and M. Sasikumar (National Centre for Software Technology,\n      Bombay), Mike Clancy (Berkeley), Michael Covington (Georgia), Bruce D'Ambrosio\n      (Oregon State), Piew Datta (Irvine), Shawn Dettrey (USC), J. A. Durieux (AI En\n      gineering BV, Amsterdam), Joseph Faletti (ETS), Paul Fuqua (Texas Instruments),\n      Robert Goldman (Tulane), Marty Hall (Johns Hopkins), Marti Hearst (Berkeley), Jim\n      Hendler (Maryland), Phil Laird (NASA), Raymond Lang (Tulane), David D. Loef-\n      fler (MCC), George Luger (New Mexico), Rob MacLachlan (CMU), Barry Margolin\n      (Thinking Machines), James Mayf ield (UMBC), Sanjay Manchandi (Arizona), Robert\n      McCartney (Connecticut), James Meehan (DEC), Andrew L. Ressler, Robert S. Rist\n      (University of Technology, Sydney), Paul Snively (Apple), Peter Van Roy (Berkeley),\n      David Gumby Wallace (Cygnus), and Jeff Wu (Colorado).\n          Sam Dooley and Eric Wefald both wrote Othello-playing programs without which\n      I would not have written chapter 18. Eric also showed me Aristotle's quotes on means-\n      ends analysis. Tragically, Eric died in August 1989. He is sorely missed by his friends\n      and colleagues. Richard Fateman made suggestions for chapter 8, convinced me to\n      write chapter 15, and, with help from Peter Klier, wrote a substantial program from\n      which I adapted some code for that chapter. Charley Cox (Franz Inc.), Jamie Zawinski\n      (Lucid Inc.), and Paul Fuqua (Texas Instruments) explained the inner workings of\n      their respective companies' compilers. Mike Harrison, Paul Hilfinger, Marc Luria,\n      Ethan Munson, and Stephan Slade helped with MgK. Narciso Jarimillo tested all the\n      code and separated it into the files that are available to the reader (see page 897).\n          During the writing of this book I was supported by a grant from the Defense\n      Advanced Research Projects Agency (DoD), Arpa Order No. 4871, monitored by\n      Space and Naval Warfare Systems Command under Contract N00039-84-C-0089.\n      Special thanks to DARPA and to Robert Wilensky and the rest of my colleagues and\n      students at Berkeley for providing a stimulating environment for research, program\n      ming, and writing.\n          Finally, thanks to Mike Morgan and Yonie Overton for overseeing the production\n      of the book and encouraging me to finish on time.\n\fCHAPTER                   1\n\nIntroduction to Lisp\n\n                                                      You think you know when you learn, are more sure\n                                                     when you can write, even more when you can teach,\n                                                                     hut certain when you can program.\n                                                                                         --Alan Perils\n                                                                    Yale University computer scientist\n\n\n\n\n      1 his chapter is for people with little or no experience in Lisp. Readers who feel confident\n        in their Lisp programming ability can quickly skim the chapter or skip it entirely. This\n         chapter necessarily moves quickly, so those with little programming experience, or any\nreader who finds this chapter tough going, should seek out a supplementary introductory text.\nMy recommendations are in the preface.\n    Computers allow one to carry out computations. A word processing program deals with\nwords while a calculator deals with numbers, but the principles are the same. In both cases,\nyou provide the input (words or numbers) and specify the operations (such as deleting a word\nor adding two numbers) to yield a result (a completed document or calculation).\n    We will refer to anything that can be represented in the memory of a computer as a computa\ntional object, or just an object. So, words, paragraphs, and numbers can be objects. And because\nthe operations (deleting and adding) must be represented somewhere in the computer's memory,\nthey are objects, too.\n\f                                                               INTRODUCTION       TO LISP\n\n\n\n     Normally, the distinction between a computer \"user\" and a computer \"program\nmer\" is that the user provides new input, or data (words or numbers), while the\nprogrammer defines new operations, or programs, as well as new types of data. Every\nnew object, be it datum or operation, must be defined in terms of previously defined\nobjects. The bad news is that it can be quite tedious to get these definitions right.\nThe good news is that each new object can in turn be used in the definition of future\nobjects. Thus, even complex programs can be built out of smaller, simpler objects.\nThis book covers a number of typical AI problems, showing how each problem can\nbe broken down into manageable pieces, and also how each piece can be described in\nthe programming language Common Lisp. Ideally, readers will learn enough through\nstudying these examples to attack new AI problems with style, grace, and success.\n     Let's consider a simple example of a computation: finding the sum of two num\nbers, let's say 2 and 2. If we had a calculator handy, we would type \"2 - f 2 = \" and see\nthe answer displayed. On a calculator using reverse Polish notation, we would have\nto type \" 2 2 + \" to see the same answer. In Lisp, as with the calculator, the user carries\nout an interactive dialog with the computer by typing in an expression and seeing the\ncomputer print the value of that expression. This interactive mode is different from\nmany other programming languages that only offer a batch mode, wherein an entire\nprogram is compiled and run before any output can be seen.\n     We start up a pocket calculator by flipping the on/off switch. The Lisp program\nmust also be started, but the details vary from one computer to another, so I can't\nexplain how your Lisp will work. Assuming we have managed to start up Lisp, we\nare likely to see a prompt of some kind. On my computer. Lisp types \" > \" to indicate\nit is ready to accept the next computation. So we are faced with a screen that looks\nlike this:\n\n\n\n\nWe may now type in our computation and see the result displayed. It turns out that\nthe Lisp convention for arithemtic expressions is slightly different: a computation\nconsists of a parenthesized list with the operation name first, followed by any number\nof operands, or arguments. This is called prefix notation.\n\n   > (+ 2 2)\n   4\n   >\n\n\nWe see that Lisp has printed the answer, 4, and then another prompt, >, to indicate\nit is ready for the next computation. Throughout this book, all Lisp expressions will\nbe displayed in typewriter font. Text on the same line as the \" > \" prompt is input\ntyped by the user, and text following it is output printed by the computer. Usually,\ninput that is typed by the programmer will be in 1 owercase letters, while output that\n\fINTRODUCTION\n\n\n\n         is printed back by the computer will be in UPPERCASE letters. Of course, with symbols\n         like + and 4 there is no difference.\n             To save space on the page, the output will sometimes be shown on the same line\n         as the input, separated by an arrow         which can be read as \"evaluates to,\" and\n         can also be thought of as standing for the return or enter key that the user presses to\n         complete the input:\n\n               > (+ 2 2) ^   4\n\n\n         One advantage of parenthesized prefix notation is that the parentheses clearly mark\n         the beginning and end of an expression. If we want, we can give + more than two\n         arguments, and it will still add them all:\n\n               > (+ 1 2 3 4 5 6 7 8 9 10)     55\n\n\n         This time we try (9000 + 900 + 90 - f 9) - (5000 + 500 + 50 + 5):\n\n               > (- (+ 9000 900 90 9) (+ 5000 500 50 5 ) ) =^ 4444\n\n\n             This example shows that expressions can be nested. The arguments to the -\n         function are parenthesized lists, while the arguments to each + are atoms. The\n         Lisp notation may look unusual compared to standard mathematical notation, but\n         there are advantages to this notation; since Lisp expressions can consist of a function\n         followed by any number of arguments, we don't have to keep repeating the          More\n         important than the notation is the rule for evaluation. In Lisp, lists are evaluated\n         by first evaluating all the arguments, then applying the function to the arguments,\n         thereby computing the result. This rule is much simpler than the rule for evaluating\n         normal mathematical expressions, where there are many conventions to remember,\n         such as doing multiplications and divisions before sums and differences. We will see\n         below that the actual Lisp evaluation rule is a little more complicated, but not much.\n             Sometimes programmers who are familiar with other languages have preconcep\n         tions that make it difficult for them to learn Lisp. For them, three points are worth\n         stressing here. First, many other languages make a distinction between statements\n         and expressions. An expression, like 2 + 2, has a value, but a statement, like  =\n         2 + 2, does not. Statements have effects, but they do not return values. In Lisp,\n         there is no such distinction: every expression returns a value. It is true that some\n         expressions have effects, but even those expressions also return values.\n             Second, the lexical rules for Lisp are much simpler than the rules for other\n         languages. In particular, there are fewer punctuation characters: only parentheses,\n         quote marks (single, double, and backward), spaces, and the comma serve to separate\n         symbols from each other. Thus, while the statement y=a*x+3 is analyzed as seven\n         separate tokens in other languages, in Lisp it would be treated as a single symbol. To\n\f                                                                    INTRODUCTION        TO LISP\n\n\n\nget a list of tokens, we would have to insert spaces: (y = a *  + 3).^\n    Third, while many languages use semicolons to delimit statements. Lisp has no\nneed of semicolons, since expressions are delimited by parentheses. Lisp chooses\nto use semicolons for another purpose--to mark the beginning of a comment, which\nlasts until the end of the line:\n\n   > (+ 2 2) ; t h i s i s a comment\n   4\n\n\n\n\n1.1       Symbolic Computation\nAll we've done so far is manipulate numbers in the same way a simple pocket\ncalculator would. Lisp is more useful than a calculator for two main reasons. First,\nit allows us to manipulate objects other than numbers, and second, it allows us\nto define new objects that might be useful in subsequent computations. We will\nexamine these two important properties in turn.\n    Besides numbers. Lisp can represent characters (letters), strings of characters,\nand arbitrary symbols, where we are free to interpret these symbols as referring to\nthings outside the world of mathematics. Lisp can also build nonatomic objects\nby combining several objects into a list. This capability is fundamental and well\nsupported in the language; in fact, the name Lisp is short for LISt Processing.\n    Here's an example of a computation on lists:\n\n   > (append ' ( P a t Kim) ' ( R o b i n Sandy))    (PAT KIM ROBIN SANDY)\n\n\nThis expression appends together two lists of names. The rule for evaluating this\nexpression is the same as the rule for numeric calculations: apply the function (in\nthis case append) to the value of the arguments.\n    The unusual part is the quote mark ('), which serves to block the evaluation of the\nfollowing expression, returning it literally. If we just had the expression ( P a t Kim),\nit would be evaluated by considering Pat as a function and applying it to the value of\nthe expression Ki m. This is not what we had in mind. The quote mark instructs Lisp\nto treat the list as a piece of data rather than as a function call:\n\n   > ' ( P a t Kim)     (PAT KIM)\n\n\nIn other computer languages (and in English), quotes usually come in pairs: one to\nmark the beginning, and one to mark the end. In Lisp, a single quote is used to mark\n\n   ^This list of symbols is not a legal Lisp assignment statement, but it is a Lisp data object.\n\f/./ SYMBOLIC      COMPUTATION\n\n\n\n         the beginning of an expression. Since we always know how long a single expression\n         is--either to the end of an atom or to the matching parenthesis of a list--we don't need\n         an explicit punctuation mark to tell us where the expression ends. Quotes can be\n         used on hsts, as in * (Pat Ki m), on symbols as in ' Robi n, and in fact on anything else.\n         Here are some examples:\n\n               > 'John =^ JOHN\n\n               > '(John Q Public) =^ (JOHN Q PUBLIC)\n\n               > '2      2\n\n               >  => \n               > ' ( + 2 2) => (+ 2 2)\n\n               > (+ 2 2) =^ 4\n\n               > John ^ Error: ]OHN is not a bound variable\n               > (John Q Public) ^ Error: JOHN is not a function\n\n         Note that ' 2 evaluates to 2 because it is a quoted expression, and 2 evaluates to 2\n         because numbers evaluate to themselves. Same result, different reason. In contrast,\n         ' J o h n evaluates to John because it is a quoted expression, but evaluating John leads\n         to an error, because evaluating a symbol means getting the value of the symbol, and\n         no value has been assigned to John.\n               Symbolic computations can be nested and even mixed with numeric computa\n         tions. The following expression builds a list of names in a slightly different way than\n         we saw before, using the built-in function l i s t . We then see how to find the number\n         of elements in the list, using the built-in function 1 ength:\n\n               > (append ' ( P a t Kim) ( l i s t '(John Q Public)   'Sandy))\n               (PAT KIM (JOHN Q PUBLIC) SANDY)\n\n               > (length (append ' ( P a t Kim) ( l i s t   '(John Q Public)    'Sandy)))\n               4\n\n\n         There are four important points to make about symbols:\n\n               � First, it is important to remember that Lisp does not attach any external signif\n                 icance to the objects it manipulates. For example, we naturally think of ( Robi \n                 Sandy) asalistof two first names, and (John Q Publ i c ) as a list of one person's\n                 first name, middle initial, and last name. Lisp has no such preconceptions. To\n                 Lisp, both Robi  and x y z z y are perfectly good symbols.\n\n               � Second, to do the computations above, we had to know that append, 1 e n g t h ,\n                 and + are defined functions in Common Lisp. Learning a language involves\n\f8                                                                       INTRODUCTION         TO LISP\n\n\n\n           remembering vocabulary items (or knowing where to look them up) as well\n           as learning the basic rules for forming expressions and determining what they\n           mean. Common Lisp provides over 700 built-in functions. At some point the\n           reader should flip through a reference text to see what's there, but most of the\n           important functions are presented in part I of this book.\n\n       � Third, note that symbols in Common Lisp are not case sensitive. By that I\n         mean that the inputs John, John, and jOhN all refer to the same symbol, which\n         is normally printed as JOHN.^\n\n       � Fourth, note that a wide variety of characters are allowed in symbols: numbers,\n         letters, and other punctuation marks like'+' o r ' ! ' . The exact rules for what con\n         stitutes a symbol are a little complicated, but the normal convention is to use\n         symbols consisting mostly of letters, with words separated by a dash (-), and\n         perhaps with a number at the end. Some programmers are more liberal in nam\n         ing variables, and include characters like'? 1 $/<=>'. For example, a function to\n         convert dollars to yen might be named with the symbol $ - to -yen or $ ->yen in\n         Lisp, while one would use something like Dol 1 arsToYen, dol 1 ars _to _yen or\n         do! 2yen in Pascal or C. There are a few exceptions to these naming conventions,\n         which will be dealt with as they come up.\n\n\n\n    1.2       Variables\n    We have seen some of the basics of symbolic computation. Now we move on to\n    perhaps the most important characteristic of a programming language: the ability to\n    define new objects in terms of others, and to name these objects for future use. Here\n    symbols again play an important role--they are used to name variables. A variable\n    can take on a value, which can be any Lisp object. One way to give a value to a\n    variable is with s e t f :\n\n       > ( s e t f  '(John 0 P u b l i c ) ) =^ (JOHN Q PUBLIC)\n       >          (JOHN Q PUBLIC)\n       > ( s e t f X 10)    10\n       >   (+ X   x)   20\n       > ( + X (length p)) => 13\n\n\n    After assigning the value (John Q Rubi i c ) to the variable named p, we can refer to\n    the value with the name p. Similarly, after assigning a value to the variable named x,\n    we can refer to both  and p.\n        ^The variable * p r i nt - case* controls how symbols will be printed. By default, the value of\n    this variable is -.upcase, but it can be changed to rdowncaseor : c a p i t a l i z e .\n\f13 SPECIAL FORMS\n\n\n\n            Symbols are also used to name functions in Common Lisp. Every symbol can\n        be used as the name of a variable or a function, or both, although it is rare (and\n        potentially confusing) to have symbols name both. For example, append and 1 ength\n        are symbols that name functions but have no values as variables, and pi does not\n        name a function but is a variable whose value is 3.1415926535897936 (or thereabout).\n\n\n\n\n        1.3        Special Forms\n        The careful reader will note that s e t f violates the evaluation rule. We said earlier\n        that functions like +, - and append work by first evaluating all their arguments and\n        then applying the function to the result. But s e t f doesn't follow that rule, because\n        s e t f is not a function at all. Rather, it is part of the basic syntax of Lisp. Besides the\n        syntax of atoms and function calls. Lisp has a small number of syntactic expressions.\n        They are known as special forms. They serve the same purpose as statements in other\n        programming languages, and indeed have some of the same syntactic markers, such\n        as i f and 1 oop. There are two main differences between Lisp's syntax and other\n        languages. First, Lisp's syntactic forms are always lists in which the first element is\n        one of a small number of privileged symbols, s e t f is one of these symbols, so ( s e t f\n         10) is a special form. Second, special forms are expressions that return a value.\n        This is in contrast to statements in most languages, which have an effect but do not\n        return a value.\n             In evaluating an to expression like ( s e t f  (+ 1 2 ) ) , we set the variable named\n        by the symbol  to the value of ( + 1 2 ) , which is 3. If s e t f were a normal function,\n        we would evaluate both the symbol x and the expression ( + 1 2) and do something\n        with these two values, which is not what we want at all. s e t f is called a special form\n        because it does something special: if it did not exist, it would be impossible to write\n        a function that assigns a value to a variable. The philosophy of Lisp is to provide a\n        small number of special forms to do the things that could not otherwise be done, and\n        then to expect the user to write everthing else as functions.\n             The term special form is used confusingly to refer both to symbols like s e t f and\n        expressions that start with them, like ( s e t f  3 ) . In the book Common LISPcraft\n        Wilensky resolves the ambiguity by calling s e t f a special function, and reserving the\n        term special form for ( s e t f  3 ) . This terminology implies that s e t f is just another\n        function, but a special one in that its first argument is not evaluated. Such a view\n        made sense in the days when Lisp was primarily an interpreted language. The\n        modern view is that s e t f should not be considered some kind of abnormal function\n        but rather a marker of special syntax that will be handled specially by the compiler.\n        Thus, the special form ( s e t f x (+ 2 1 ) ) should be considered the equivalent of  =\n        2 + 1 in C. When there is risk of confusion, we will call s e t f a special form operator\n        and ( s e t f  3) a special form expression.\n\f10                                                                         INTRODUCTION     TO LISP\n\n\n\n         It turns out that the quote mark is just an abbreviation for another special form.\n     The expression 'x is equivalent to (quote ;c), a special form expression that evaluates\n     to X. The special form operators used in this chapter are:\n\n                  defun               define function\n                  defparameter        define special variable\n                  setf                set variable or field to new value\n                  let                 bind local variable(s)\n                  case                choose one of several alternatives\n                  if                  do one thing or another, depending on a test\n                  function ( # ' )    refer to a function\n                  quote ( ' )         introduce constant data\n\n\n\n     1.4       Lists\n     So far we have seen two functions that operate on hsts: append and 1 ength. Since\n     lists are important, let's look at some more list processing functions:\n\n        >  =^ (JOHN 0 PUBLIC)\n\n        > ( f i r s t p)     JOHN\n\n        > ( r e s t p)       (Q PUBLIC)\n\n        > (second p) ^ Q\n\n        > ( t h i r d p) =^ PUBLIC\n\n        > (fourth p) ^ NIL\n\n        > (length p)          3\n\n\n     The functions f i r s t , second, t h i r d , and f o u r t h are aptly named: f i r s t returns\n     the first element of a list, second gives you the second element, and so on. The\n     function r e s t is not as obvious; its name stands for \"the rest of the list after the first\n     element.\" The symbol n i l and the form ( ) are completely synonymous; they are\n     both representations of the empty list, ni 1 is also used to denote the \"false\" value in\n     Lisp. Thus, ( f o u r t h  ) is ni 1 because there is no fourth element of p. Note that Hsts\n     need not be composed only of atoms, but can contain sublists as elements:\n\n         > ( s e t f  ' ( ( 1 s t element) 2 (element 3) ( ( 4 ) ) 5 ) )\n         ((1ST ELEMENT) 2 (ELEMENT 3) ( ( 4 ) ) 5)\n\n        > (length x)\n\n        > ( f i r s t x) =   (1ST ELEMENT)\n\f1A LISTS                                                                                      V\\_\n\n\n\n              > (second x) => 2\n\n              > ( t h i r d X ) => (ELEMENT 3)\n\n              > (fourth X )           ((4))\n\n              > (first     (fourth x ) ) ^       (4)\n\n              > (first     (first     (fourth x ) ) ) ^   4\n\n              > (fifth X ) ^ 5\n\n              > (first X)           (1ST ELEMENT)\n\n              > (second ( f i r s t x ) ) => ELEMENT\n\n\n           So far we have seen how to access parts of lists. It is also possible to build up new\n           lists, as these examples show:\n\n              >         (JOHN Q PUBLIC)\n\n              > (cons 'Mr p) ^             (MR JOHN Q PUBLIC)\n\n              > (cons ( f i r s t p) ( r e s t p)) => (JOHN Q PUBLIC)\n\n              > ( s e t f town ( l i s t    'Anytown 'USA)) =^ (ANYTOWN USA)\n\n              > ( l i s t  O f town 'may 'have 'already 'won!) ^\n              ((JOHN Q PUBLIC) OF (ANYTOWN USA) MAY HAVE ALREADY WON!)\n\n              > (append  ' ( o f ) town '(may have already won!))\n              (JOHN Q PUBLIC OF ANYTOWN USA MAY HAVE ALREADY WON!)\n\n              >         (JOHN Q PUBLIC)\n\n\n\n               The function cons stands for \"construct.\" It takes as arguments an element and\n           a list,^ and constructs a new list whose first is the element and whose rest is the\n           original list. 1 i s t takes any number of elements as arguments and returns a new\n           hst containing those elements in order. We've already seen append, which is similar\n           to 1 i s t ; it takes as arguments any number of lists and appends them all together,\n           forming one big list. Thus, the arguments to append must be lists, while the arguments\n           to 11 S t may be lists or atoms. It is important to note that these functions create new\n           lists; they don't modify old ones. When we say (append  q ) , the effect is to create\n           a brand new list that starts with the same elements that were in p.  itself remains\n           unchanged.\n               Now let's move away from abstract functions on lists, and consider a simple\n           problem: given a person's name in the form of a list, how might we extract the family\n           name? For (JOHN Q PUBLIC) we could Justuse the function thi rd, but that wouldn't\n\n              ^ Later we will see what happens when the second argument is not a list.\n\f12                                                                  INTRODUCTION       TO LISP\n\n\n     work for someone with no middle name. There is a function called 1 a s t in Common\n     Lisp; perhaps that would work. We can experiment:\n\n        > (last p) => (PUBLIC)\n\n        > ( f i r s t (last p))   PUBLIC\n\n\n     It turns out that l a s t perversely returns a list of the last element, rather than the\n     last element itself.^ Thus we need to combine f i r s t and 1 a s t to pick out the actual\n     last element. We would like to be able to save the work we've done, and give it a\n     proper description, like 1 a st - name. We could use s e t f to save the last name of p, but\n     that wouldn't help determine any other last name. Instead we want to define a new\n     function that computes the last name of any name that is represented as a list. The\n     next section does just that.\n\n\n\n\n     1.5      Defining New Functions\n\n     The special form defun stands for \"define function.\" It is used here to define a new\n     function called 1 ast-name:\n\n         (defun last-name (name)\n           \"Select the last name from a name represented as a l i s t . \"\n           ( f i r s t (last name)))\n\n\n     We give our new function the name 1 ast-name. It has a parameter list consisting of a\n     single parameter: ( name ). This means that the function takes one argument, which\n     we will refer to as name. It also has a documentation string that states what the function\n     does. This is not used in any computation, but documentation strings are crucial\n     tools for debugging and understanding large systems. The body of the definition is\n     ( f 1 r s t ( l a s t name )), which is what we used before to pick out the last name of p.\n     The difference is that here we want to pick out the last name of any name, not just of\n     the particular name p.\n         In general, a function definition takes the following form (where the documenta\n     tion string is optional, and all other parts are required):\n\n        ^In ANSI Common Lisp, 1 ast is defined to return a list of the last  elements, where \n     defaults to 1. Thus (last p) = (last  1) = (PUBLIC), and (last  2) = (Q PUBLIC). This\n     may make the definition of 1 ast seem less perverse.\n\f1,5 DEFINING NEW FUNCTIONS                                                                         13\n\n\n\n            (defun function-name {parameter...)\n             ''documentation string''\n              function-body...)\n\n         The function name must be a symbol, the parameters are usually symbols (with some\n         complications to be explained later), and the function body consists of one or more\n         expressions that are evaluated when the function is called. The last expression is\n         returned as the value of the function call.\n             Once we have defined 1 ast-name, we can use it just like any other Lisp function:\n\n            > (last-name p)=i> PUBLIC\n\n            > (last-name '(Rear Admiral Grace Murray H o p p e r ) ) ^ HOPPER\n\n            > (last-name '(Rex Morgan MD)) ^ MD\n\n            > (last-name ' ( S p o t ) ) ^      SPOT\n\n            > (last-name ' ( A r i s t o t l e ) )     ARISTOTLE\n\n\n        The last three examples point out an inherent limitation of the programming enter\n        prise. When we say (defun last-name...) we are not really defining what it means\n        for a person to have a last name; we are just defining an operation on a representation\n        of names in terms of lists. Our intuitions--that MD is a title. Spot is the first name\n        of a dog, and Aristotle lived before the concept of last name was invented--are not\n        represented in this operation. However, we could always change the definition of\n        1 ast-name to incorporate these problematic cases.\n             We can also define the function f i r s t - n a m e . Even though the definition is trivial\n        (it is the same as the function f 1 r s t ) , it is still good practice to define f 1 rst-name\n        explicitly. Then we can use the function f i r s t - name when we are dealing with names,\n        and f i r s t when we are dealing with arbitrary lists. The computer will perform the\n        same operation in each case, but we as programmers (and readers of programs) will\n        be less confused. Another advanatge of defining specific functions like f i rst-name\n        is that if we decide to change the representation of names we will only have to change\n        the definition of f i rst -name. This is a much easier task than hunting through a large\n        program and changing the uses of f 1 r s t that refer to names, while leaving other\n        uses alone.\n\n            (defun first-name (name)\n              \"Select the f i r s t name from a name represented as a l i s t . \"\n              ( f i r s t name))\n\n            >         (JOHN Q PUBLIC)\n\n            > (first-name p)             JOHN\n\n            > (first-name '(Wilma F l i n t s t o n e ) )      WILMA\n\f14                                                                         INTRODUCTION   TO LISP\n\n\n\n        > ( s e t f names '((John Q Public) (Malcolm X)\n                             (Admiral Grace Murray Hopper) (Spot)\n                             ( A r i s t o t l e ) (A A Milne) (Z  Top)\n                             ( S i r Larry O l i v i e r ) (Miss S c a r l e t ) ) ) =^\n        ((JOHN Q PUBLIC) (MALCOLM X) (ADMIRAL GRACE MURRAY HOPPER)\n          (SPOT) (ARISTOTLE) (A A MILNE) (Z  TOP) ( S I R LARRY OLIVIER)\n          (MISS SCARLET))\n\n        > (first-name ( f i r s t names))           JOHN\n\n\n     In the last expression we used the function f i r s t to pick out the first element in\n     a list of names, and then the function f i r s t - n a m e to pick out the first name of\n     that element. We could also have said ( f i r s t ( f i r s t names)) or even ( f i r s t\n     ( f i r s t - n a m e names)) and still have gotten JOHN, but we would not be accurately\n     representing what is being considered a name and what is being considered a list\n     of names.\n\n\n\n\n     1.6       Using Functions\n     One good thing about defining a list of names, as we did above, is that it makes it\n     easier to test our functions. Consider the following expression, which can be used to\n     test the 1 ast-name function:\n\n        > (mapcar #'last-name names)\n        (PUBLIC X HOPPER SPOT ARISTOTLE MILNE TOP OLIVIER SCARLET)\n\n\n     The funny # ' notation maps from the name of a function to the function itself. This\n     is analogous to '  notation. The built-in function mapca r is passed two arguments, a\n     function and a list. It returns a list built by calling the function on every element of\n     the input list. In other words, the mapcar call above is equivalent to:\n\n         ( l i s t (last-name ( f i r s t names))\n                   (last-name (second names))\n                   (last-name ( t h i r d names))\n                   ...)\n\n\n     mapca r's name comes from the fact that it \"maps\" the function across each of the\n     arguments. The car part of the name refers to the Lisp function c a r , an old name for\n     f i r s t . cdr is the old name for r e s t . The names stand for \"contents of the address\n     register\" and \"contents of the decrement register,\" the instructions that were used in\n     the first implementation of Lisp on the IBM 704. I'm sure you'll agree that f i r s t and\n\f1.6 USING FUNCTIONS                                                                                15\n\n\n\n         r e s t are much better names, and they will be used instead of ca r and cdr whenever\n         we are talking about lists. However, we will continue to use car and cdr on occasion\n         when we are considering a pair of values that are not considered as a list. Beware\n         that some programmers still use ca r and cdr for Usts as well.\n              Here are some more examples of mapcar:\n\n            > (mapcar        ' ( 1 2 3 4 ) ) = > ( - l -2 - 3 - 4 )\n\n            > (mapcar # ' + ' ( 1 2 3 4) ' ( 1 0 20 30 4 0 ) ) ^ ( 1 1 22 33 44)\n\n\n         This last example shows that mapcar can be passed three arguments, in which case the\n         first argument should be a binary function, which will be applied to corresponding\n         elements of the other two Usts. In general, mapcar expects an n-ary function as its\n         first argument, followed by  lists. It first applies the function to the argument list\n         obtained by collecting the first element of each list. Then it applies the function to the\n         second element of each list, and so on, until one of the lists is exhausted. It returns a\n         list of all the function values it has computed.\n              Now that we understand mapcar, let's use it to test the f i rst -name function:\n\n            > (mapcar # ' f i r s t - n a m e names)\n            (JOHN MALCOLM ADMIRAL SPOT ARISTOTLE A  S I R MISS)\n\n\n         We might be disappointed with these results. Suppose we wanted a version of\n         f i rst -name which ignored titles like Admiral and Miss, and got to the \"real\" first\n         name. We could proceed as follows:\n\n            (defparameter n i t l e s *\n              '(Mr Mrs Miss Ms S i r Madam Dr Admiral Major General)\n              \"A l i s t of t i t l e s that can appear at the s t a r t of a name.\")\n\n\n         We've introduced another new special form, defparameter, which defines a para\n         meter--a variable that does not change over the course of a computation, but that\n         might change when we think of new things to add (like the French Mme or the military\n         Lt.). The def pa rameter form both gives a value to the variable and makes it possible\n         to use the variable in subsequent function definitions. In this example we have\n         exercised the option of providing a documentation string that describes the variable.\n         It is a widely used convention among Lisp programmers to mark special variables by\n         spelling their names with asterisks on either end. This is just a convention; in Lisp,\n         the asterisk is just another character that has no particular meaning.\n              We next give a new definition for f i rst -name, which supersedes the previous\n         definition.^ This definition says that if the first word of the name is a member of the\n\n            ^Just as we can change the value of a variable, we can also change the value of a function\n\f16                                                                   INTRODUCTION        TO LISP\n\n\n     list of titles, then we want to ignore that word and return the f i rst -name of the rest\n     of the words in the name. Otherwise, we use the first word, just as before. Another\n     built-in function, member, tests to see if its first argument is an element of the list\n     passed as the second argument.\n          The special form i f has the form ( i f test then-part else-part). There are many\n     special forms for performing conditional tests in Lisp; i f is the most appropriate for\n     this example. An i f form is evaluated by first evaluating the test expression. If it is\n     true, the then-part is evaluated and returned as the value of the i f form; otherwise\n     the else-part is evaluated and returned. While some languages insist that the value of\n     a conditional test must be either true or f al se. Lisp is much more forgiving. The test\n     may legally evaluate to any value at all. Only the value n i l is considered false; all\n     other values are considered true. In the definition of f i r s t - name below, the function\n     member will return a non-nil (hence true) value if the first element of the name is in the\n     list of titles, and will return  i 1 (hence false) if it is not. Although all non-nil values\n     are considered true, by convention the constant t is usually used to represent truth.\n\n         (defun first-name (name)\n           \"Select the f i r s t name from a name represented as a l i s t . \"\n           (if   (member ( f i r s t name) * t i t l e s * )\n                 (first-name ( r e s t name))\n                 ( f i r s t name)))\n\n\n     When we map the new f i rst-name over the list of names, the results are more\n     encouraging. In addition, the function gets the \"right\" result for '(Madam Major\n     General Paul a Jones ) by dropping off titles one at a time.\n\n        > (mapcar # ' f i r s t - n a m e names)\n         (JOHN MALCOLM GRACE SPOT ARISTOTLE A  LARRY SCARLET)\n\n        > (first-name '(Madam Major General Paula Jones))\n         PAULA\n\n\n     We can see how this works by tracing the execution of f 1 rst-name, and seeing the\n     values passed to and returned from the function. The special forms t r a c e and\n     untrace are used for this purpose.\n\n        > (trace first-name)\n         (FIRST-NAME)\n\n\n     in Lisp. It is not necessary to recompile everything when a change is made, as it would be in\n     other languages.\n\f1.6 USING FUNCTIONS                                                                                     17\n\n\n\n             > (first-name '(John Q P u b l i c ) )\n             (1 ENTER FIRST-NAME: (JOHN Q PUBLIC))\n             (1 EXIT FIRST-NAME: JOHN)\n             JOHN\n\n\n         When f i r s t - name is called, the definition is entered with the single argument, name,\n         taking on the value (JOHN Q PUBLIC). The value returned is JOHN. Trace prints two\n         lines indicating entry and exit from the function, and then Lisp, as usual, prints the\n         final result, JOHN.\n               The next example is more complicated. The function f i rst -name is used four\n         times. First, it is entered with name bound to (Madam Major General Paula J o n e s ) .\n         The first element of this list is Madam, and since this is a member of the list of titles,\n         the result is computed by calling f i rst -name again on the rest of the name-- (Major\n         General Paula Jones). This process repeats two more times, and we finally enter\n         f i r s t - name with name bound to ( Paul a J o n e s ) . Since Pa ul a is not a title, it becomes\n         the result of this call to f i r s t - name, and thus the result of all four calls, as trace shows.\n         Once we are happy with the workings of f i r s t - name, the special form unt race turns\n         off tracing.\n\n             > (first-name '(Madam Major General Paula Jones)) =^\n             (1 ENTER FIRST-NAME: (MADAM MAJOR GENERAL PAULA JONES))\n               (2 ENTER FIRST-NAME: (MAJOR GENERAL PAULA JONES))\n                  (3 ENTER FIRST-NAME: (GENERAL PAULA JONES))\n                    (4 ENTER FIRST-NAME: (PAULA JONES))\n                    (4 EXIT FIRST-NAME: PAULA)\n                  (3 EXIT FIRST-NAME: PAULA)\n               (2 EXIT FIRST-NAME: PAULA)\n             (1 EXIT FIRST-NAME: PAULA)\n             PAULA\n\n             > (untrace first-name)          (FIRST-NAME)\n             > (first-name ' ( M r Blue Jeans))         BLUE\n\n\n         The function f i rst -name is said to be recursive because its definition includes a call\n         to itself. Programmers who are new to the concept of recursion sometimes find it\n         mysterious. But recursive functions are really no different from nonrecursive ones.\n         Any function is required to return the correct value for the given input(s). Another\n         way to look at this requirement is to break it into two parts: a function must return\n         a value, and it must not return any incorrect values. This two-part requirement is\n         equivalent to the first one, but it makes it easier to think about and design function\n         definitions.\n             Next I show an abstract description of the f i rst -name problem, to emphasize\n         the design of the function and the fact that recursive solutions are not tied to Lisp in\n         anyway:\n\f18                                                                    INTRODUCTION   TO LISP\n\n\n        function first-name(name):\n           i f the first element of name is a title\n               then do something complicated to get the first-name\n               else return the first element of the name\n\n\n     This breaks up the problem into two cases. In the second case, we return an answer,\n     and it is in fact the correct answer. We have not yet specified what to do in the first\n     case. But we do know that it has something to do with the rest of the name after the\n     first element, and that what we want is to extract the first name out of those elements.\n     The leap of faith is to go ahead and use f 1 rst -name, even though it has not been fully\n     defined yet:\n\n        function first-name(name):\n           i f thefirstelement of name is a title\n               then return the f i rst-name of the rest of the name\n               el se return the first element of the name\n\n\n     Now the first case in f i rst -name is recursive, and the second case remains un\n     changed. We already agreed that the second case returns the correct answer, and the\n     first case only returns what f i rst -name returns. So f 1 rst -name as a whole can only\n     return correct answers. Thus, we're halfway to showing that the function is correct;\n     the other half is to show that it eventually returns some answer. But every recursive\n     call chops off the first element and looks at the rest, so for an n-element list there\n     can be at most  recursive calls. This completes the demonstration that the function\n     is correct. Programmers who learn to think this way find recursion to be a valuable\n     tool rather than a confusing mystery.\n\n\n\n\n     1.7       Higher-Order Functions\n\n     Functions in Lisp can not only be \"called,\" or applied to arguments, they can also be\n     manipulated just like any other kind of object. A function that takes another function\n     as an argument is called a higher-orderfunction, ma pea r is an example. To demonstrate\n     the higher-order-function style of programming, we will define a new function called\n     mappend. It takes two arguments, a function and a list, mappend maps the function\n     over each element of the list and appends together all the results. The first definition\n     follows immediately from the description and the fact that the function appl y can be\n     used to apply a function to a list of arguments.\n\f17 HICHER-ORDER       FUNCTIONS                                                                                19\n\n\n\n            (defun mappend (fn t h e - l i s t )\n                \"Apply fn to each element of l i s t and append the r e s u l t s . \"\n                (apply #'append (mapcar fn t h e - l i s t ) ) )\n\n\n        Now we experiment a little to see how apply and mappend work. The first example\n        applies the addition function to a list of four numbers.\n\n            > (apply # ' + ' ( 1 2 3 4 ) ) ^ 1 0\n\n\n        The next example applies append to a list of two arguments, where each argument is\n        a list. If the arguments were not lists, it would be an error.\n\n            > (apply #'append ' ( ( 1 2 3) (a b c ) ) ) = ^ ( l 2 3 A  C)\n\n\n        Now we define a new function, sel f - a n d - d o u b l e, and apply it to a variety of argu\n        ments.\n\n            > (defun self-and-double (x) ( l i s t  (+   ) ) )\n\n            > ( s e l f - a n d - d o u b l e 3)   {3 6)\n\n            > (apply # ' s e l f - a n d - d o u b l e ' ( 3 ) ) = ^ ( 3 6)\n\n\n        If we had tried to apply sel f - a n d - d o u b l e to a list of more than one argument, or to a\n        list that did not contain a number, it would be an error, just as it would be an error to\n        evaluate ( s e l f - a n d - d o u b l e 3 4) or ( s e l f - a n d - d o u b l e 'Kim). Now let's return to\n        the mapping functions:\n\n            > (mapcar # ' s e l f - a n d - d o u b l e ' ( 1 10 3 0 0 ) ) = > ( ( 1 2) (10 20) (300 600))\n\n            > (mappend # ' s e l f - a n d - d o u b l e ' ( 1 10 3 0 0 ) ) =  ( 1 2 10 20 300 600)\n\n\n        When mapcar is passed a function and a list of three arguments, it always returns a\n        list of three values. Each value is the result of calling the function on the respective\n        argument. In contrast, when mappend is called, it returns one big list, which is equal\n        to all the values that mapca r would generate appended together. It would be an error\n        to call mappend with a function that didn't return lists, because append expects to see\n        lists as its arguments.\n\n            Now consider the following problem: given a list of elements, return a list con\n        sisting of all the numbers in the original list and the negation of those numbers. For\n        example, given the list ( t e s t i n g 1 2 3 t e s t ) , return (1 - 1 2 - 2 3 - 3 ) . This\n        problem can be solved very easily using mappend as a component:\n\f20                                                                          INTRODUCTION            TO LISP\n\n\n         (defun numbers-and-negations (input)\n           \"Given a l i s t , return only the numbers and t h e i r n e g a t i o n s . \"\n           (mappend #'number-and-negation i n p u t ) )\n\n         (defun number-and-negation (x)\n           \" I f  i s a number, return a l i s t of  and - x . \"\n           ( i f (numberp x)\n                 ( l i s t  (-  ) )\n                 nil))\n\n        > (numbers-and-negations ' ( t e s t i n g 1 2 3 t e s t ) ) = ^ ( 1 - 1 2 - 2      3 -3)\n\n\n     The alternate definition of mappend shown in the following doesn't make use of\n     ma pea r; instead it builds up the list one element at a time:\n\n         (defun mappend (fn t h e - l i s t )\n           \"Apply fn to each element of l i s t and append the r e s u l t s . \"\n           ( i f (null t h e - l i s t )\n                 nil\n                 (append (funcall fn ( f i r s t t h e - l i s t ) )\n                          (mappend fn ( r e s t t h e - l i s t ) ) ) ) )\n\n\n     f unca  is similar to a ppl y; it too takes a function as its first argument and applies the\n     function to a list of arguments, but in the case of f uncal 1, the arguments are listed\n     separately:\n\n        > (funcall # ' + 2 3) =i> 5\n\n        > (apply # ' + ' ( 2 3))       5\n\n        > (funcall # ' + ' ( 2 3) )=> Error: (2 3) is not a number.\n\n     These are equivalent to (+ 2 3 ) , (+ 2 3 ) , a n d ( + ' ( 2 3 ) ) , respectively.\n         So far, every function we have used has been either predefined in Common Lisp\n     or introduced with a defun, which pairs a function with a name. It is also possible to\n     introduce a function without giving it a name, using the special syntax 1 ambda.\n         The name lambda comes from the mathematician Alonzo Church's notation for\n     functions (Church 1941). Lisp usually prefers expressive names over terse Greek\n     letters, but lambda is an exception. A better name would be ma ke - f un ct i on . Lambda\n     derives from the notation in Russell and Whitehead's Principia Mathematica, which\n     used a caret over bound variables: x{x -h x). Church wanted a one-dimensional\n     string, so he moved the caret in front: ^x{x-\\-x). The caret looked funny with nothing\n     below it, so Church switched to the closest thing, an uppercase lambda, \\x{x - f x ) .\n     The  was easily confused with other symbols, so eventually the lowercase lambda\n     was substituted: \\x{x -h x). John McCarthy was a student of Church's at Princeton,\n     so when McCarthy invented Lisp in 1958, he adopted the lambda notation. There\n\f1.7 HIGHER-ORDER    FUNCTIONS                                                                     21\n\n\n\n         were no Greek letters on the keypunches of that era, so McCarthy used (1 ambda (x)\n         (+   ) ) , and it has survived to this day. In general, the form of a lambda expression is\n\n             (lambda (parameters...) body...)\n\n         A lambda expression is just a nonatomic name for a function, just as append is an\n         atomic name for a built-in function. As such, it is appropriate for use in the first\n         position of a function call, but if we want to get at the actual function, rather than its\n         name, we still have to use the # ' notation. For example:\n\n            > ((lambda (x) (+  2 ) ) 4) =�> 6\n\n            > (funcall #'(lambda (x) (+  2 ) ) 4) =^ 6\n\n\n         To understand the distinction we have to be clear on how expressions are evaluated\n         in Lisp. The normal rule for evaluation states that symbols are evaluated by looking\n         up the value of the variable that the symbol refers to. So the x in (+  2) is evaluated\n         by looking up the value of the variable named x. A list is evaluated in one of two\n         ways. If the first element of the list is a special form operator, then the list is evaluated\n         according to the syntax rule for that special form. Otherwise, the Hst represents a\n         function call. The first element is evaluated in a unique way, as a function. This\n         means it can either be a symbol or a lambda expression. In either case, the function\n         named by the first element is applied to the values of the remaining elements in the\n         list. These values are determined by the normal evaluation rules. If we want to refer\n         to a function in a position other than the first element of a function call, we have\n         to use the # ' notation. Otherwise, the expressions will be evaluated by the normal\n         evaluation rule, and will not be treated as functions. For example:\n\n            > append ^ Error: APPEND is not a bound variable\n            > (lambda (x) i+  Z))          Error: LAMBDA is not a function\n\n         Here are some more examples of the correct use of functions:\n\n            > (mapcar #*(lambda (x) (+   ) )\n                       ' ( 1 2 3 4 5)) ^\n            ( 2 4 6 8 10)\n\n            > (mappend #'(lambda (1) ( l i s t 1 (reverse 1 ) ) )\n                         ' ( ( 1 2 3) (a b c ) ) ) =>\n            ( ( 1 2 3) (3 2 1) (A  C) (C  A))\n\n\n         Programmers who are used to other languages sometimes fail to see the point of\n         lambda expressions. There are two reasons why lambda expressions are very useful.\n\f22                                                                    INTRODUCTION        TO LISP\n\n\n     First, it can be messy to clutter up a program with superfluous names. Just as it\n     is clearer to write (a+b)*(c+cl) rather than to invent variable names like tempi and\n     temp2 to hold a+b and c+d, so it can be clearer to define a function as a lambda\n     expression rather than inventing a name for it.\n         Second, and more importantly, lambda expressions make it possible to create\n     new functions at run time. This is a powerful technique that is not possible in\n     most programming languages. These run-time functions, known as closures, will be\n     covered in section 3.16.\n\n\n\n     1.8        Other Data Types\n     So far we have seen just four kinds of Lisp objects: numbers, symbols, lists, and\n     functions. Lisp actually defines about 25 different types of objects: vectors, arrays,\n     structures, characters, streams, hash tables, and others. At this point we will intro\n     duce one more, the string. As you can see in the following, strings, like numbers,\n     evaluate to themselves. Strings are used mainly for printing out messages, while\n     symbols are used for their relationships to other objects, and to name variables. The\n     printed representation of a string has a double quote mark (\") at each end.\n\n        > \"a s t r i n g \" =4> \"a s t r i n g \"\n\n        > (length \"a s t r i n g \" ) =i>8\n\n        > (length \" \" ) = ^ 0\n\n\n\n\n     1.9        Summary: The Lisp Evaluation Rule\n     We can now summarize the evaluation rule for Lisp.\n\n        � Every expression is either a list or an atom.\n\n        � Every list to be evaluated is either a special form expression or afunction applica tion.\n\n        � A specialform expression is defined to be a lis t whose first element is a special form\n          operator. The expression is evaluated according to the operator's idiosyncratic\n          evaluation rule. For example, the evaluation rule for s e t f is to evaluate the\n          second argument according to the normal evaluation rule, set the first argument\n          to that value, and return the value as the result. The rule for defun is to define\n          a new function, and return the name of the function. The rule for quote\n          is to return the first argument unevaluated. The notation 'x is actually an\n\f1.9 SUMMARY: THE LISP EVALUATION RULE                                                          23\n\n\n               abbreviation for the special form expression (quote x ) . Similarly, the notation\n               # ' / i s an abbreviation for the special form expression ( f uncti on f).\n\n\n               �John = (quote John)           JOHN\n               ( s e t f  'John) => JOHN\n               (defun twice (x) (+  x ) ) => TWICE\n               (if   (= 2 3) ( e r r o r ) (+ 5 6 ) ) =^ 11\n\n\n\n               A function application is evaluated by first evaluating the arguments (the rest of\n               the list) and then finding the function named by the first element of the list and\n               applying it to the list of evaluated arguments.\n\n\n               ( + 2 3)    =^5\n               (- (+ 90 9) (+ 50 5 (length ' ( P a t Kim))))         =^ 42\n\n\n               Note that if ' (Pat Kim) did not have the quote, it would be treated as a function\n               application of the function pat to the value of the variable ki m.\n\n               Every atom is either a symbol or a        nonsymbol\n\n               A symbol evaluates to the most recent value that has been assigned to the\n               variable named by that symbol. Symbols are composed of letters, and possibly\n               digits and, rarely, punctuation characters. To avoid confusion, we will use\n               symbols composed mostly of the letters a-z and the     character, with a few\n               exceptions.^\n\n\n               names\n\n               \n               *print-pretty*\n\n\n\n            � A nonsymbol atom evaluates to itself. For now, numbers and strings are the\n              only such non-symbol atoms we know of. Numbers are composed of digits,\n              and possibly a decimal point and sign. There are also provisions for scientific\n              notation, rational and complex numbers, and numbers with different bases,\n              but we won't describe the details here. Strings are delimited by double quote\n              marks on both sides.\n            ^For example, symbols that denote so-called special variables usually begin and end in\n         asterisks. Also, note that I did not hesitate to use the symbol won! on page 11.\n\f24                                                                INTRODUCTION       TO LISP\n\n\n           42          42\n\n           -273.15            -273.15\n\n           \"a s t r i n g \"      \"a s t r i n g \"\n\n\n\n\n         There are some minor details of Common Lisp that complicate the evaluation\n     rules, but this definition will suffice for now.\n\n        One complication that causes confusion for beginning Lispers is the difference\n     between reading and evaluating an expression. Beginners often imagine that when\n     they type an expression, such as\n\n        > (+ (* 3 4) (* 5 6 ) )\n\n\n     the Lisp system first reads the (+, then fetches the addition function, then reads (*\n     3 4) and computes 12, then reads (* 5 6) and computes 30, and finally computes\n     42. In fact, what actually happens is that the system first reads the entire expression,\n     the list (+ (* 3 4) (* 5 6 ) ) . Only after it has been read does the system begin\n     to evaluate it. This evaluation can be done by an interpreter that looks at the list\n     directly, or it can be done by a compiler that translates the list into machine language\n     instructions and then executes those instructions.\n         We can see now that it was a little imprecise to say, \"Numbers are composed\n     of digits, and possibly a decimal point and sign.\" It would be more precise to say\n     that the printed representation of a number, as expected by the function read and\n     as produced by the function p r i n t , is composed of digits, and possibly a decimal\n     point and sign. The internal representation of a number varies from one computer\n     to another, but you can be sure that it will be a bit pattern in a particular memory\n     location, and it will no longer contain the original characters used to represent the\n     number in decimal notation. Similarly, it is the printed representation of a string\n     that is surrounded by double quote marks; the internal representation is a memory\n     location marking the beginning of a vector of characters.\n         Beginners who fail to grasp the distinction between reading and evaluating may\n     have a good model of what expressions evaluate to, but they usually have a terrible\n     model of the efficiency of evaluating expressions. One student used only one-letter\n     variable names, because he felt that it would be faster for the computer to look up\n     a one-letter name than a multiletter name. While it may be true that shorter names\n     can save a microsecond at read time, this makes no difference at all at evaluation\n     time. Every variable, regardless of its name, is just a memory location, and the time\n     to access the location does not depend on the name of the variable.\n\f1.10 WHAT MAKES LISP DIFFERENT?                                                                   25\n\n\n\n         1.10        What Makes Lisp Different?\n         What is it that sets Lisp apart from other languages? Why is it a good language for\n         AI applications? There are at least eight important factors:\n\n            � Built-in Support for Lists\n\n            � Automatic Storage Management\n\n            � Dynamic Typing\n\n            � First-Class Functions\n\n            � Uniform Syntax\n\n            � Interactive Environment\n\n            � Extensibility\n\n            � History\n\n         In sum, these factors allow a programmer to delay making decisions. In the example\n         dealing with names, we were able to use the built-in list functions to construct and\n         manipulate names without making a lot of explicit decisions about their represen\n         tation. If we decided to change the representation, it would be easy to go back and\n         alter parts of the program, leaving other parts unchanged.\n              This ability to delay decisions--or more accurately, to make temporary, nonbind-\n         ing decisions--is usually a good thing, because it means that irrelevant details can be\n         ignored. There are also some negative points of delaying decisions. First, the less we\n         tell the compiler, the greater the chance that it may have to produce inefficient code.\n         Second, the less we tell the compiler, the less chance it has of noticing inconsistencies\n         and warning us. Errors may not be detected until the program is run. Let's consider\n         each factor in more depth, weighing the advantages and disadvantages:\n\n            � Built-in Support for Lists. The list is a very versatile data structure, and while lists\n              can be implemented in any language. Lisp makes it easy to use them. Many\n              AI applications involve lists of constantly changing size, making fixed-length\n              data structures like vectors harder to use.\n                Early versions of Lisp used lists as their only aggregate data structure. Common\n                Lisp provides other types as well, because lists are not always the most efficient\n                choice.\n\n                Automatic Storage Management. The Lisp programmer needn't keep track of\n                memory allocation; it is all done automatically. This frees the programmer of a\n                lot of effort, and makes it easy to use the functional style of programming. Other\n\f26                                                                INTRODUCTION   TO LISP\n\n\n\n     languages present programmers with a choice. Variables can be allocated on\n     the stack, meaning that they are created when a procedure is entered, and\n     disappear when the procedure is done. This is an efficient use of storage, but\n     it rules out functions that return complex values. The other choice is for the\n     programmer to explicitly allocate and free storage. This makes the functional\n     style possible but can lead to errors.\n\n     For example, consider the trivial problem of computing the expression   (b +\n     c), where a, 6, and c are numbers. The code is trivial in any language; here it is\n     in Pascal and in Lisp:\n\n\n     / * Pascal * /                                 Lisp\n\n     a * (b + c)                               (* a (+ b c ) )\n\n\n\n     The only difference is that Pascal uses infix notation and Lisp uses prefix. Now\n     consider computing   (b -f c) when a, 6, and c are matrices. Assume we have\n     procedures for matrix multiplication and addition. In Lisp the form is exactly\n     the same; only the names of the functions are changed. In Pascal we have the\n     choice of approaches mentioned before. We could declare temporary variables\n     to hold intermediate results on the stack, and replace the functional expression\n     with a series of procedure calls:\n\n\n     / * Pascal * /                                 ;;;    Lisp\n\n     var temp, r e s u l t : matrix;\n\n\n     add(b,c,temp);                                 (mult a (add b c ) )\n\n     mult(a,temp,result);\n\n     return(result);\n\n\n\n     The other choice is to write Pascal functions that allocate new matrices on the\n     heap. Then one can write nice functional expressions like mul t ( a , add ( b , c ) )\n     even in Pascal. However, in practice it rarely works this nicely, because of the\n     need to manage storage explicitly:\n\n\n     / * Pascal * /                                 ;;;    Lisp\n\n     var a , b , c , x , y : matrix;\n\fhlO WHAT MAKES LISP DIFFERENT?                                                               27\n\n\n\n              X : = adcl(b,c);                             (mult a (add b c ) )\n              y := mult(a,x);\n              free(x);\n              return(y);\n\n\n              In general, deciding which structures to free is a difficult task for the Pascal\n              programmer. If the programmer misses some, then the program may run out\n              of memory. Worse, if the programmer frees a structure that is still being used,\n              then strange errors can occur when that piece of memory is reallocated. Lisp\n              automatically allocates and frees structures, so these two types of errors can\n              never occur.\n\n              Dynamic Typing. Lisp programmers don't have to provide type declarations,\n              because the language keeps track of the type of each object at run time, rather\n              than figuring out all types at compile time. This makes Lisp programs shorter\n              and hence faster to develop, and it also means that functions can often be\n              extended to work for objects to which they were not originally intended to\n              apply. In Pascal, we can write a procedure to sort an array of 100 integers, but\n              we can't use that same procedure to sort 200 integers, or 100 strings. In Lisp,\n              one s o r t fits all.\n              One way to appreciate this kind of flexibility is to see how hard it is to achieve\n              in other languages. It is impossible in Pascal; in fact, the language Modula was\n              invented primarily to fix this problem in Pascal. The language Ada was de\n              signed to allow flexible generic functions, and a book by Musser and Stepanov\n              (1989) describes an Ada package that gives some of the functionality of Com\n              mon Lisp's sequence functions. But the Ada solution is less than ideal: it\n              takes a 264-page book to duplicate only part of the functionality of the 20-page\n              chapter 14 from Steele (1990), and Musser and Stepanov went through five Ada\n              compilers before they found one that would correctly compile their package.\n              Also, their package is considerably less powerful, since it does not handle vec\n              tors or optional keyword parameters. In Common Lisp, all this functionality\n              comes for free, and it is easy to add more.\n              On the other hand, dynamic typing means that some errors will go undetected\n              until run time. The great advantage of strongly typed languages is that they are\n              able to give error messages at compile time. The great frustration with strongly\n              typed languages is that they are only able to warn about a small class of errors.\n              They can tell you that you are mistakenly passing a string to a function that\n              expects an integer, but they can't tell you that you are passing an odd number\n              to a function that expects an even number.\n\n              First-Class Functions. A first-class object is one that can be used anywhere and\n              can be manipulated in the same ways as any other kind of object. In Pascal or C,\n\f28                                                            INTRODUCTION      TO LISP\n\n\n       for example, functions can be passed as arguments to other functions, but they\n       are not first-class, because it is not possible to create new functions while the\n       program is running, nor is it possible to create an anonymous function without\n       giving it a name. In Lisp we can do both those things using 1 ambda. This is\n       explained in section 3.16, page 92.\n\n     � Uniform Syntax. The syntax of Lisp programs is simple. This makes the lan\n       guage easy to learn, and very little time is wasted correcting typos. In addition,\n       it is easy to write programs that manipulate other programs or define whole\n       new languages--a very powerful technique. The simple syntax also makes it\n       easy for text editing programs to parse Lisp. Your editor program should be\n       able to indent expressions automatically and to show matching parentheses.\n       This is harder to do for languages with complex syntax.\n       On the other hand, some people object to all the parentheses. There are two\n       answers to this objection. First, consider the alternative: in a language with\n       \"conventional\" syntax. Lisp's parentheses pairs would be replaced either by an\n       implicit operator precedence rule (in the case of arithmetic and logical expres\n       sions) or by a begin/end pair (in the case of control structures). But neither\n       of these is necessarily an advantage. Implicit precedence is notoriously error-\n       prone, and begin/end pairs clutter up the page without adding any content.\n       Many languages are moving away from begi n/end: C uses { and } , which are\n       equivalent to parentheses, and several modern functional languages (such as\n       Haskell) use horizontal blank space, with no explicit grouping at all.\n       Second, many Lisp programmers have considered the alternative. There have\n       been a number of preprocessors that translate from \"conventional\" syntax into\n       Lisp. None of these has caught on. It is not that Lisp programmers find it\n       tolerable to use all those parentheses, rather, they find it advantageous. With a\n       little experience, you may too.\n       It is also important that the syntax of Lisp data is the same as the syntax of\n       programs. Obviously, this makes it easy to convert data to program. Less\n       obvious is the time saved by having universal functions to handle input and\n       output. The Lisp functions read and pri nt will automatically handle any list,\n       structure, string, or number. This makes it trivial to test individual functions\n       while developing your program. In a traditional language like C or Pascal, you\n       would have to write special-purpose functions to read and print each data type\n       you wanted to debug, as well as a special-purpose driver to call the routines.\n       Because this is time-consuming and error-prone, the temptation is to avoid\n       testing altogether. Thus, Lisp encourages better-tested programs, and makes\n       it easier to develop them faster.\n\n     � Interactive Environment. Traditionally, a programmer would write a complete\n       program, compile it, correct any errors detected by the compiler, and then\n\f1.10 WHAT MAKES LISP DIFFERENT?                                                              29\n\n\n\n              run and debug it. This is known as the batch mode of interaction. For long\n              programs, waiting for the compiler occupied a large portion of the debugging\n              time. In Lisp one normally writes a few small functions at a time, getting\n              feedback from the Lisp system after evaluating each one. This is knovm as\n              an interactive environment. When it comes time to make a change, only the\n              changed functions need to be recompiled, so the wait is much shorter. In\n              addition, the Lisp programmer can debug by typing in arbitrary expressions\n              at any time. This is a big improvement over editing the program to introduce\n              print statements and recompiling.\n              Notice that the distinction between interactive and a batch languages is separate\n              from the distinction between interpreted and compiled languages. It has often\n              been stated, incorrectly, that Lisp has an advantage by virtue of being an\n              interpreted language. Actually, experienced Common Lisp programmers tend\n              to use the compiler almost exclusively. The important point is interaction, not\n              interpretation.\n              The idea of an interactive environment is such a good one that even traditional\n              languages like C and Pascal are starting to offer interactive versions, so this is\n              not an exclusive advantage of Lisp. However, Lisp still provides much better\n              access to the interactive features. A C interpreter may allow the progranuner\n              to type in an expression and have it evaluated immediately, but it will not allow\n              the programmer to write a program that, say, goes through the symbol table\n              and finds all the user-defined functions and prints information on them. In\n              C-even interpreted C-the symbol table is just a Cheshire-cat-like invention\n              of the interpreter's imagination that disappears when the program is run. In\n              Lisp, the symbol table is a first-class object^ that can be accessed and modified\n              with functions like read, intern and do-symbols.\n              Common Lisp offers an unusually rich set of useful tools, including over 700\n              built-in functions (ANSI Conunon Lisp has over 900). Thus, writing a new\n              program involves more gathering of existing pieces of code and less writing of\n              new code from scratch. In addition to the standard functions. Common Lisp\n              implementations usually provide extensions for interacting with the editor,\n              debugger, and window system.\n\n              Extensibility. When Lisp was invented in 1958, nobody could have foreseen the\n              advances in programming theory and language design that have taken place in\n              the last thirty years. Other early languages have been discairded, replaced by\n              ones based on newer ideas. However, Lisp has been able to survive, because\n              it has been able to adapt. Because Lisp is extensible, it has been changed to\n              incorporate the newest features as they become popular.\n\n            ^Actually, there can be several symbol tables. They are known as packages in Common\n         Lisp.\n\f30                                                                  INTRODUCTION       TO LISP\n\n\n          The easiest way to extend the language is with macros. When so-called struc\n          tured programming constructs such as case and if-then-else arose, they were\n          incorporated into Lisp as macros. But the flexibility of Lisp goes beyond\n          adding individual constructs. Brand new styles of programming can easily be\n          implemented. Many AI applications are based on the idea of rule-based pro\n          gramming. Another new style is object-oriented programming, which has been\n          incorporated with the Common Lisp Object System (CLOS),^ a set of macros,\n          functions, and data types that have been integrated into ANSI Common Lisp.\n\n         To show how far Lisp has come, here's the only sample program given in the\n     Lisp/MTS Programmer's Guide (Hafner and Wilcox 1974):\n\n        (PROG (LIST DEPTH TEMP RESTLIST)\n        (SETQ RESTLIST (LIST (CONS (READ) 0 ) ) )\n        A (COND\n        ((NOT RESTLIST) (RETURN 'DONE))\n        (T (SETQ LIST (UNCONS (UNCONS RESTLIST\n             RESTLIST ) DEPTH))\n        (COND ((ATOM LIST)\n        (MAPC 'PRINl (LIST '\"ATOM:\" LIST ' \" . \" 'DEPTH DEPTH))\n        (TERPRD)\n        (T (SETQ TEMP (UNCONS LIST L I S T ) )\n        (COND (LIST\n        (SETQ RESTLIST (CONS(CONS LIST DEPTH) RESTLIST))))\n        (SETQ RESTLIST (CONS (CONS TEMP\n             (ADDl DEPTH)) RESTLIST))\n        ))))\n        (GO A))\n\n\n     Note the use of the now-deprecated goto (GO) statement, and the lack of consistent\n     indentation conventions. The manual also gives a recursive version of the same\n     program:\n\n        (PROG NIL (\n        (LABEL ATOMPRINT (LAMBDA (RESTLIST)\n        (COND ((NOT RESTLIST) (RETURN 'DONE))\n        ((ATOM (CAAR RESTLIST)) (MAPC 'PRINl\n             (LIST '\"ATOM:\" (CAAR RESTLIST)\n                  ' \" , \" 'DEPTH (CDAR RESTLIST)))\n        (TERPRD\n        (ATOMPRINT (CDR RESTLIST)))\n        (  (ATOMPRINT (GRAFT\n        (LIST (CONS (CAAAR RESTLIST) (ADDl (CDAR RESTLIST))))\n        (AND (CDAAR RESTLIST) (LIST (CONS (CDAAR RESTLIST)\n\n       ^Pronounced \"see-loss.\" An alternate pronunciation, \"klaus,\" seems to be losing favor.\n\f1.11 EXERCISES                                                                                 31\n\n\n\n                      (CDAR RESTLIST))))\n                            (COR R E S T L I S T ) ) ) ) ) ) )\n                 (LIST (CONS (READ) 0 ) ) ) )\n\n\n           Both versions are very difficult to read. With our modern insight (and text editors\n           that automatically indent), a much simpler program is possible:\n\n                 (defun atomprint (exp &optional (depth 0 ) )\n                   \" P r i n t each atom in exp. along with i t s depth of n e s t i n g . \"\n                   ( i f (atom exp)\n                           (format t \"\"SATOM: ~ a , DEPTH \" d \" exp depth)\n                           ( d o l i s t (element exp)\n                              (atomprint element (+ depth 1 ) ) ) ) )\n\n\n\n\n           1.11            Exercises\n     @     Exercise 1.1 [m] Define a version of 1 ast-name that handles \"Rex Morgan MD,\"\n           \"Morton Downey, Jr.,\" and whatever other cases you can think of.\n\n\n     G]    Exercise 1.2 [m] Write a function to exponentiate, or raise a number to an integer\n           power. For example: (power 3 2) = 3^ = 9.\n\n\n           Exercise 1.3 [m] Write a function that counts the number of atoms in an expression.\n           For example: (count-atoms ' ( a (b) c ) ) = 3. Notice that there is something of an\n           ambiguity in this: should (a n i l c ) count as three atoms, or as two, because it is\n           equivalent to (a ( ) c ) ?\n\n\n     I�] Exercise 1.4 [m] Write a function that counts the number of times an expression\n         occurs anywhere within another expression. Example: (count-anywhere 'a *(a\n         ( ( a ) b) a ) ) 3.\n\n\n     t�J   Exercise 1.5 [m] Write a function to compute the dot product of two sequences\n           of numbers, represented as lists. The dot product is computed by multiplying\n           corresponding elements and then adding up the resulting products. Example:\n\n                 (dot-product ' (10 20) ' (3 4 ) ) = 10  3 +          20  4 = 110\n\f32                                                                             INTRODUCTION   TO LISP\n\n\n\n     1.12       Answers\n\n     Answer 1.2\n\n        (defun power (x n)\n          \"Power r a i s e s  to the nth power.  must be an integer >= 0.\n           This executes in log  time, because of the check for even n.\n          (cond ( ( =  0) 1)\n                  ((evenp n) (expt (power  ( /  2 ) ) 2 ) )\n                  (t   (*  (power  (-  1 ) ) ) ) ) )\n\n\n\n     Answer 1.3\n\n        (defun count-atoms         (exp)\n          \"Return the total         number of non-nil atoms in the e x p r e s s i o n . \"\n          (cond ( ( n u l l exp)    0)\n                ((atom exp)         1)\n                  (t   (+ (count-atoms ( f i r s t exp))\n                          (count-atoms ( r e s t     exp))))))\n\n        (defun count-all-atoms (exp �optional ( i f - n u l l 1))\n          \"Return the total number of atoms in the e x p r e s s i o n ,\n          counting nil as an atom only in n o n - t a i l p o s i t i o n . \"\n          (cond ( ( n u l l exp) i f - n u l l )\n                 ((atom exp) 1)\n                  (t   (+ (count-all-atoms        ( f i r s t exp) 1)\n                          (count-all-atoms        ( r e s t exp) 0 ) ) ) ) )\n\n\n\n     Answer 1.4\n\n        (defun count-anywhere (item tree)\n          \"Count the times item appears anywhere w i t h i n t r e e . \"\n          (cond ((eql item tree) 1)\n                ((atom tree) 0)\n                (t (+ (count-anywhere item ( f i r s t t r e e ) )\n                       (count-anywhere item ( r e s t t r e e ) ) ) ) ) )\n\f1.12 ANSWERS                                                                      33\n\n\n\n         Answer 1.5       Here are three versions:\n\n               (defun dot-product (a b)\n                 \"Compute the mathematical dot product of two v e c t o r s . \"\n                 ( i f (or (null a) (null b))\n                       0\n                       (+ (* ( f i r s t a) ( f i r s t b))\n                          (dot-product ( r e s t a) ( r e s t b ) ) ) ) )\n\n               (defun dot-product (a b)\n                 \"Compute the mathematical dot product of two v e c t o r s . \"\n                 ( l e t ((sum 0 ) )\n                      (dotimes (i (length a ) )\n                        ( i n c f sum (* ( e l t a i ) ( e l t b i ) ) ) )\n                     sum))\n\n               (defun dot-product (a b)\n                 \"Compute the mathematical dot product of two v e c t o r s . \"\n                 (apply # ' + (mapcar # ' * a b ) ) )\n\fCHAPTER                  2\n\nA Simple Lisp Program\n\n                                                                              Cerium quod factum.\n                                                         (One is certain of only what one builds.)\n                                                            -Giovanni Battista Vico (1668- 744)\n                                                                    Italian royal historiographer\n\n\n\n\n\n       ou will never become proficient in a foreign language by studying vocabulary lists.\n       Rather, you must hear and speak (or read and write) the language to gain proficiency.\n       The same is true for learning computer languages.\n\n   This chapter shows how to combine the basic functions and special forms of Lisp into a\ncomplete program. If you can learn how to do that, then acquiring the remaining vocabulary of\nLisp (as outlined in chapter 3) will be easy.\n\f2.1 A GRAMMAR   FOR A SUBSET OF ENGLISH                                                       35\n\n\n\n         2.1      A Grammar for a Subset of English\n         The program we will develop in this chapter generates random English sentences.\n         Here is a simple grammar for a tiny portion of English:\n\n            Sentence ^ Noun-Phrase-^ Verb-Phrase\n            Noun-Phrase ^ Article + Noun\n            Verb-Phrase => Verb + Noun-Phrase\n            Article ^ the, a,...\n            Noun =^ man, ball, woman, table...\n            Verb hit, took, saw, liked...\n\n         To be technical, this description is called a context-free phrase-structure grammar, and\n         the underlying paradigm is called generative syntax. The idea is that anywhere we\n         want a sentence, we can generate a noun phrase followed by a verb phrase. Anywhere\n         a noun phrase has been specified, we generate instead an article followed by a noun.\n         Anywhere an article has been specified, we generate either \"the,\" \"a,\" or some other\n         article. The formalism is \"context-free\" because the rules apply anywhere regardless\n         of the surrounding words, and the approach is \"generative\" because the rules as a\n         whole define the complete set of sentences in a language (and by contrast the set of\n         nonsentences as well). In the following we show the derivation of a single sentence\n         using the rules:\n\n            To get a Sentence, append a Noun-Phrase and a Verb-Phrase\n             To get a Noun-Phrase, append an Article and a Noun\n                Choose \"the\" for the Article\n                Choose \"man\" for the Noun\n             The resulting Noun-Phrase is \"the man\"\n             To get a Verb-Phrase, append a Verb and a Noun-Phrase\n                Choose \"hit\" for the Verb\n                To get a Noun-Phrase, append an Article and a Noun\n                  Choose \"the\" for the Article\n                  Choose \"ball\" for the Noun\n                The resulting Noun-Phrase is \"the bair\n              The resulting Verb-Phrase is \"hit the ball\"\n            The resulting Sentence is \"The man hit the ball\"\n\n\n\n\n         1.1      A Straightforward Solution\n         We will develop a program that generates random sentences from a phrase-structure\n         grammar. The most straightforward approach is to represent each grammar rule by\n         a separate Lisp function:\n\f36                                                                            A SIMPLE LISP PROGRAM\n\n\n\n         (defun   sentence ()      (append (noun-phrase) ( v e r b - p h r a s e ) ) )\n         (defun   noun-phrase () (append ( A r t i c l e ) (Noun)))\n         (defun   verb-phrase () (append (Verb) (noun-phrase)))\n         (defun   A r t i c l e () (one-of ' ( t h e a ) ) )\n         (defun   Noun ()          (one-of '(man ball woman t a b l e ) ) )\n         (defun   Verb ()          (one-of ' ( h i t took saw l i k e d ) ) )\n\n\n     Each of these function definitions has an empty parameter list, ( ) . That means the\n     functions take no arguments. This is unusual because, strictly speaking, a function\n     with no arguments would always return the same thing, so we would use a constant\n     instead. However, these functions make use of the random function (as we will see\n     shortly), and thus can return different results even with no arguments. Thus, they\n     are not functions in the mathematical sense, but they are still called functions in Lisp,\n     because they return a value.\n          All that remains now is to define the function one-of. It takes a list of possible\n     choices as an argument, chooses one of these at random, and returns a one-element\n     list of the element chosen. This last part is so that all functions in the grammar will\n     return a list of words. That way, we can freely apply append to any category.\n\n         (defun one-of ( s e t )\n           \"Pick one element of s e t , and make a l i s t of          it.\"\n           ( l i s t (random-elt s e t ) ) )\n\n         (defun random-elt (choices)\n           \"Choose an element from a l i s t at random.\"\n           ( e l t choices (random (length c h o i c e s ) ) ) )\n\n\n     There are two new functions here, el t and random, el t picks an element out of a list.\n     The first argument is the list, and the second is the position in the list. The confusing\n     part is that the positions start at 0, so ( el t choi ces 0) is the first element of the list,\n     and ( el t choi ces 1) is the second. Think of the position numbers as telling you\n     how far away you are from the front. The expression ( random  ) returns an integer\n     from 0 to n-1, so that ( random 4 ) would return either 0,1,2, or 3.\n        Now we can test the program by generating a few random sentences, along with\n     a noun phrase and a verb phrase:\n\n        > (sentence)         (THE WOMAN HIT THE BALL)\n\n        > (sentence) =4> (THE WOMAN HIT THE MAN)\n\n        > (sentence)         (THE BALL SAW THE WOMAN)\n\n        > (sentence) => (THE BALL SAW THE TABLE)\n\n        > (noun-phrase)          (THE MAN)\n\n        > (verb-phrase) ^        (LIKED THE WOMAN)\n\f2.2 A STRAIGHTFORWARD        SOLUTION                                                            37\n\n\n\n            > (trace sentence noun-phrase verb-phrase a r t i c l e noun verb)      ^\n             (SENTENCE NOUN-PHRASE VERB-PHRASE ARTICLE NOUN VERB)\n\n            > (sentence) =>\n             (1 ENTER SENTENCE)\n               (1 ENTER NOUN-PHRASE)\n                 (1 ENTER ARTICLE)\n                 (1 EXIT ARTICLE:       (THE))\n                 (1 ENTER NOUN)\n                 (1 EXIT NOUN: (MAN))\n               (1 EXIT NOUN-PHRASE: (THE MAN))\n               (1 ENTER VERB-PHRASE)\n                 (1 ENTER VERB)\n                 (1 EXIT VERB: (HIT))\n                 (1 ENTER NOUN-PHRASE)\n                    (1 ENTER ARTICLE)\n                    (1 EXIT ARTICLE:       (THE))\n                    (1 ENTER NOUN)\n                    (1 EXIT NOUN: ( B A L D )\n                 (1 EXIT NOUN-PHRASE: (THE B A L D )\n               (1 EXIT VERB-PHRASE: (HIT THE B A L D )\n             (1 EXIT SENTENCE: (THE MAN HIT THE B A L D )\n             (THE MAN HIT THE BALL)\n\n\n         The program works fine, and the trace looks just like the sample derivation above,\n         but the Lisp definitions are a bit harder to read than the original grammar rules.\n         This problem will be compounded as we consider more complex rules. Suppose we\n         wanted to allow noun phrases to be modified by an indefinite number of adjectives\n         and an indefinite number of prepositional phrases. In grammatical notation, we\n         might have the following rules:\n\n            Noun-Phrase => ArHcle + Adj* + Noun + PP*\n\n            *=>, + *\n            PP =^ Prep + Noun-Phrase\n            Ad] ^ big, little, blue, green,...\n            Prep ^ to, in, by, with,...\n\n         In this notation, 0 indicates a choice of nothing at all, a comma indicates a choice of\n         several alternatives, and the asterisk is nothing special--as in Lisp, it's just part of the\n         name of a symbol. However, the convention used here is that names ending in an\n         asterisk denote zero or more repetitions of the underlying name. That is, PP * denotes\n         zero or more repetitions of PP. This is known as \"Kleene star\" notation (pronounced\n\f38                                                                                SIMPLE LISP   PROGRAM\n\n\n\n     \"clean-E\") after the mathematician Stephen Cole Kleene.^\n         The problem is that the rules for Adj * and PP * contain choices that we would have\n     to represent as some kind of conditional in Lisp. For example:\n\n         (defun A d j * ()\n           ( i f (= (random 2) 0)\n                nil\n                (append (Adj) ( A d j * ) ) ) )\n\n         (defun PP* ()\n           ( i f (random-elt ' ( t n i l ) )\n                (append (PP) (PP*))\n                nil))\n\n         (defun noun-phrase () (append ( A r t i c l e ) (Adj*) (Noun) ( P P * ) ) )\n         (defun PP () (append (Prep) (noun-phrase)))\n        (defun Adj () (one-of ' ( b i g l i t t l e blue green a d i a b a t i c ) ) )\n        (defun Prep () (one-of ' ( t o i n by with o n ) ) )\n\n\n     I've chosen two different implementations for A d j * and PR*; either approach would\n     work in either function. We have to be careful, though; here are two approaches that\n     would not work:\n\n        (defun A d j * ()\n           \"Warning - incorrect d e f i n i t i o n of A d j e c t i v e s . \"\n           (one-of ' ( n i l (append (Adj) ( A d j * ) ) ) ) )\n\n        (defun A d j * ()\n           \"Warning - incorrect d e f i n i t i o n of A d j e c t i v e s . \"\n           (one-of ( l i s t n i l (append (Adj) ( A d j * ) ) ) ) )\n\n\n     The first definition is wrong because it could return the literal expression ( (append\n     (Adj) (Adj * ) ) ) rather than a list of words as expected. The second definition would\n     cause infinite recursion, because computing the value of ( A d j * ) always involves a\n     recursive call to ( A d j * ) . The point is that what started out as simple functions are\n     now becoming quite complex. To understand them, we need to know many Lisp\n     conventions-- defun, ( ) , case, 1 f , quote, and the rules for order of evaluation--when\n     ideally the implementation of a grammar rule should use only linguistic conventions.\n     If we wanted to develop a larger grammar, the problem could get worse, because the\n     rule-writer might have to depend more and more on Lisp.\n\n        ^We will soon see ''Kleene plus\" notation, wherein PP+ denotes one or more repetition\n     of PP.\n\f2.3 A RULE-BASED SOLUTION                                                                           39\n\n\n\n         2.3       A Rule-Based Solution\n         An alternative implementation of this program v^ould concentrate on making it easy\n         to write grammar rules and would worry later about how they will be processed.\n         Let's look again at the original grammar rules:\n\n             Sentence =^ Noun-Phrase + Verb-Phrase\n             Noun-Phrase ^ Article + Noun\n             Verb-Phrase Verb + Noun-Phrase\n             Article the, a,...\n             Noun man, ball, woman, table ...\n             Verb hit, took, saw, liked...\n\n          Each rule consists of an arrow with a symbol on the left-hand side and something on\n          the right-hand side. The complication is that there can be two kinds of right-hand\n          sides: a concatenated list of symbols, as in \"Noun-Phrase         Article+Noun,\" or a list of\n          alternate words, as in \"Noun =^ man, hall,...\" We can account for these possibilities\n          by deciding that every rule will have a list of possibilities on the right-hand side, and\n          that a concatenated list, for example \"Article+Noun,\" will be represented as a Lisp list,\n         for example \" ( A r t i cl e Noun)\". The list of rules can then be represented as follows:\n\n             (defparameter *simple-grammar*\n               '((sentence - > (noun-phrase verb-phrase))\n                  (noun-phrase - > ( A r t i c l e Noun))\n                  (verb-phrase - > (Verb noun-phrase))\n                  ( A r t i c l e - > the a)\n                  (Noun - > man ball woman table)\n                  (Verb - > h i t took saw l i k e d ) )\n               \"A grammar for a t r i v i a l subset of E n g l i s h . \" )\n\n             (defvar *grammar* *simple-grammar*\n               \"The grammar used by generate. I n i t i a l l y , t h i s i s\n               *simple-grammar*, but we can switch to other grammars.\")\n\n\n         Note that the Lisp version of the rules closely mimics the original version. In par\n         ticular, I include the symbol\" ->\", even though it serves no real purpose; it is purely\n         decorative.\n             The special forms defvar and defparameter both introduce special variables\n         and assign a value to them; the difference is that a variable, like *grammar*, is\n         routinely changed during the course of running the program. A parameter, like\n         *s imple-grammar*, on the other hand, will normally stay constant. A change to a\n         parameter is considered a change to the program, not a change by the program.\n             Once the list of rules has been defined, it can be used to find the possible rewrites\n         of a given category symbol. The function assoc is designed for just this sort of task.\n\f40                                                                             A SIMPLE LISP   PROGRAM\n\n\n\n     It takes two arguments, a \"key\" and a list of lists, and returns the first element of the\n     list of lists that starts with the key. If there is none, it returns n i l . Here is an example:\n\n        > (assoc     'noun ^grammar*)           (NOUN - > MAN BALL WOMAN TABLE)\n\n\n     Although rules are quite simply implemented as lists, it is a good idea to impose a\n     layer of abstraction by defining functions to operate on the rules. We will need three\n     functions: one to get the right-hand side of a rule, one for the left-hand side, and one\n     to look up all the possible rewrites (right-hand sides) for a category.\n\n         (defun r u l e - l h s ( r u l e )\n           \"The left-hand s i d e of a r u l e . \"\n           ( f i r s t rule))\n\n         (defun r u l e - r h s ( r u l e )\n           \"The right-hand s i d e of a r u l e . \"\n           (rest (rest rule)))\n\n         (defun rewrites (category)\n           \"Return a l i s t of the p o s s i b l e rewrites for t h i s c a t e g o r y . \"\n           ( r u l e - r h s (assoc category *graminar*)))\n\n\n     Defining these functions will make it easier to read the programs that use them,\n     and it also makes changing the representation of rules easier, should we ever decide\n     to do so.\n         We are now ready to address the main problem: defining a function that will\n     generate sentences (or noun phrases, or any other category). We will call this function\n     generate. It will have to contend with three cases: (1) In the simplest case, generate\n     is passed a symbol that has a set of rewrite rules associated with it. We choose one of\n     those at random, and then generate from that. (2) If the symbol has no possible rewrite\n     rules, it must be a terminal symbol--a word, rather than a grammatical category--and\n     we want to leave it alone. Actually, we return the list of the input word, because, as\n     in the previous program, we want all results to be lists of words. (3) In some cases,\n     when the symbol has rewrites, we will pick one that is a list of symbols, and try to\n     generate from that. Thus, generate must also accept a list as input, in which case\n     it should generate each element of the list, and then append them all together. In\n     the following, the first clause in generate handles this case, while the second clause\n     handles (1) and the third handles (2). Note that we used the mappend function from\n     section 1.7 (page 18).\n\n         (defun generate (phrase)\n           \"Generate a random sentence or phrase\"\n           (cond ( d i s t p phrase)\n                   (mappend #'generate phrase))\n\f2.3 A RULESASED    SOLUTION                                                                  41\n\n\n                        ( ( r e w r i t e s phrase)\n                          (generate (random-elt (rewrites p h r a s e ) ) ) )\n                        (t ( l i s t p h r a s e ) ) ) )\n\n\n         Like many of the programs in this book, this function is short, but dense with\n         information: the craft of programming includes knowing what not to write, as well\n         as what to write.\n              This style of programming is called data-driven programming, because the data\n         (the list of rewrites associated with a category) drives what the program does next. It\n         is a natural and easy-to-use style in Lisp, leading to concise and extensible programs,\n         because it is always possible to add a new piece of data with a new association without\n         having to modify the original program.\n              Here are some examples of generate in use:\n\n            > (generate 'sentence)                (THE TABLE SAW THE BALL)\n\n            > (generate 'sentence) => (THE WOMAN HIT A TABLE)\n\n            > (generate 'noun-phrase) => (THE MAN)\n\n            > (generate 'verb-phrase)                 (TOOK A TABLE)\n\n\n         There are many possible ways to write generate. The following version uses i f\n         instead of cond:\n\n             (defun generate (phrase)\n               \"Generate a random sentence or phrase\"\n               ( i f ( l i s t p phrase)\n                     (mappend #'generate phrase)\n                     ( l e t ((choices (rewrites p h r a s e ) ) )\n                          ( i f (null choices)\n                                ( l i s t phrase)\n                                (generate (random-elt c h o i c e s ) ) ) ) ) )\n\n\n         This version uses the special form 1 et, which introduces a new variable (in this case,\n         choi ces) and also binds the variable to a value. In this case, introducing the variable\n         saves us from calling the function rewrites twice, as was done in the cond version\n         of generate. The general form of a 1 e t form is:\n\n             (let   (ivarvalue).,.)\n               hody-containing-vars)\n\n         1 e t is the most common way of introducing variables that are not parameters of\n         functions. One must resist the temptation to use a variable without introducing it:\n\f42                                                                    A SIMPLE LISP     PROGRAM\n\n\n\n             (defun generate (phrase)\n                ( s e t f choices . . . )       ; ; wrong!\n                ...   choices . . . )\n\n\n         This is wrong because the symbol choi ces now refers to a special or global variable,\n         one that may be shared or changed by other functions. Thus, the function generate\n         is not reliable, because there is no guarantee that choi ces will retain the same value\n         from the time it is set to the time it is referenced again. With 1 et we introduce a brand\n         new variable that nobody else can access; therefore it is guaranteed to maintain the\n         proper value.\n\n\n     @   Exercise 2.1 [m]         Write a version of generate that uses cond but avoids calling\n         r e w r i t e s twice.\n\n\n     @   Exercise 2.2 [m] Write a version of generate that explicitly differentiates between\n         terminal symbols (those with no rewrite rules) and nonterminal symbols.\n\n\n\n\n         2.4          Two Paths to Follow\n\n         The two versions of the preceding program represent two alternate approaches that\n         come up time and time again in developing programs: (1) Use the most straightfor\n         ward mapping of the problem description directly into Lisp code. (2) Use the most\n         natural notation available to solve the problem, and then worry about writing an\n         interpreter for that notation.\n             Approach (2) involves an extra step, and thus is more work for small problems.\n         However, programs that use this approach are often easier to modify and expand.\n         This is especially true in a domain where there is a lot of data to account for. The\n         grammar of natural language is one such domain--in fact, most AI problems fit this\n         description. The idea behind approach (2) is to work with the problem as much as\n         possible in its own terms, and to minimize the part of the solution that is written\n         directly in Lisp.\n            Fortunately, it is very easy in Lisp to design new notations--in effect, new program\n         ming languages. Thus, Lisp encourages the construction of more robust programs.\n         Throughout this book, we will be aware of the two approaches. The reader may\n         notice that in most cases, we choose the second.\n\f2.5 CHANGING     THE GRAMMAR        WITHOUT CHANCING           THE PROGRAM                   43\n\n\n\n         2.5         Changing the Grammar without Changing\n                     the Program\n         We show the utility of approach (2) by defining a new grammar that includes adjec\n         tives, prepositional phrases, proper names, and pronouns. We can then apply the\n         generate function without modification to this new grammar.\n\n               (defparameter *bigger-grammar*\n                 '((sentence - > (noun-phrase verb-phrase))\n                    (noun-phrase - > ( A r t i c l e A d j * Noun PP*) (Name) (Pronoun))\n                    (verb-phrase - > (Verb noun-phrase P P * ) )\n                    (PP* - > () (PP P P * ) )\n                    (Adj* - > () (Adj A d j * ) )\n                    (PP - > (Prep noun-phrase))\n                    (Prep - > to in by with on)\n                    (Adj - > big l i t t l e blue green a d i a b a t i c )\n                    ( A r t i c l e - > the a)\n                    (Name - > Pat Kim Lee Terry Robin)\n                    (Noun - > man ball woman t a b l e )\n                    (Verb - > h i t took saw l i k e d )\n                    (Pronoun - > he she i t these those t h a t ) ) )\n\n               ( s e t f *grammar* *bigger-grammar*)\n\n               > (generate 'sentence)\n               (A TABLE ON A TABLE IN THE BLUE ADIABATIC MAN SAW ROBIN\n                WITH A LITTLE WOMAN)\n\n               > (generate 'sentence)\n               (TERRY SAW A ADIABATIC TABLE ON THE GREEN BALL BY THAT WITH KIM\n                 IN THESE BY A GREEN WOMAN BY A LITTLE ADIABATIC TABLE IN ROBIN\n                ON LEE)\n\n               > (generate 'sentence)\n               (THE GREEN TABLE HIT IT WITH HE)\n\n\n         Notice the problem with case agreement for pronouns: the program generated \"with\n         he,\" although \"with him\" is the proper grammatical form. Also, it is clear that the\n         program does not distinguish sensible from silly output.\n\n\n\n         2.6         Using the Same Data for Several Programs\n         Another advantage of representing information in a declarative form-as rules or\n         facts rather than as Lisp functions-is that it can be easier to use the information for\n         multiple purposes. Suppose we wanted a function that would generate not just the\n\f44                                                                                A SIMPLE LISP      PROGRAM\n\n\n     list of words in a sentence but a representation of the complete syntax of a sentence.\n     For example, instead of the list (a woman took a b a l l ) , we want to get the nested list:\n\n         (SENTENCE (NOUN-PHRASE (ARTICLE A) (NOUN WOMAN))\n                   (VERB-PHRASE (VERB TOOK)\n                                (NOUN-PHRASE (ARTICLE A) (NOUN BALL))))\n\n\n     This corresponds to the tree that linguists draw as in figure 2.1.\n\n\n                                                           sentence\n\n\n\n\n                                       art      noun      verb      art    noun\n\n                                        I          I        I         I I\n                                        a      woman      took       a     ball\n\n\n                                       Figure 2.1: Sentence Parse Tree\n\n        Using the \"straightforward functions\" approach we would be stuck; we'd have to\n     rewrite every function to generate the additional structure. With the \"new notation\"\n     approach we could keep the grammar as it is and just write one new function: a\n     version of generate that produces nested lists. The two changes are to cons the\n     category onto the front of each rewrite, and then not to append together the results\n     but rather just list them with mapca r:\n\n         (defun generate-tree (phrase)\n           \"Generate a random sentence or phrase,\n           with a complete parse t r e e . \"\n           (cond ( ( l i s t p phrase)\n                   (mapcar #'generate-tree phrase))\n                 ( ( r e w r i t e s phrase)\n                   (cons phrase\n                                (generate-tree (random-elt ( r e w r i t e s p h r a s e ) ) ) ) )\n                 (t ( l i s t p h r a s e ) ) ) )\n\n\n     Here are some examples:\n\f2.6 USING THE SAME DATA FOR SEVERAL PROGRAMS                                                       45\n\n\n\n            > (generate-tree 'Sentence)\n            (SENTENCE (NOUN-PHRASE (ARTICLE A)\n                                   (ADJ*)\n                                   (NOUN WOMAN)\n                                   (PP*))\n                  (VERB-PHRASE (VERB HIT)\n                                   (NOUN-PHRASE (PRONOUN HE))\n                                   (PP*)))\n\n            > (generate-tree 'Sentence)\n            (SENTENCE (NOUN-PHRASE (ARTICLE A)\n                                   (NOUN WOMAN))\n                      (VERB-PHRASE (VERB TOOK)\n                                   (NOUN-PHRASE (ARTICLE A) (NOUN BALL))))\n\n\n         A s another example of the one-data/multiple-program approach, we can develop a\n         function to generate all possible rewrites of a phrase. The function g e n e r a t e - a l 1\n         returns a list of phrases rather than just one, and we define an auxiliary function,\n         combi n e - a l 1 , to manage the combination of results. Also, there are four cases instead\n         of three, because we have to check for nil explicitly. Still, the complete program is\n         quite simple:\n\n\n            (defun generate-all (phrase)\n              \"Generate a l i s t of a l l p o s s i b l e expansions of t h i s p h r a s e . \"\n              (cond ( ( n u l l phrase) ( l i s t n i l ) )\n                    ( d i s t p phrase)\n                      (combine-all (generate-all ( f i r s t phrase))\n                                          (generate-all ( r e s t p h r a s e ) ) ) )\n                    ((rewrites phrase)\n                      (mappend #*generate-all (rewrites p h r a s e ) ) )\n                    (t ( l i s t ( l i s t p h r a s e ) ) ) ) )\n\n            (defun combine-all ( x l i s t y l i s t )\n              \"Return a l i s t of l i s t s formed by appending a y to an  .\n              E . g . , (combine-all ' ( ( a ) ( b ) ) ' ( ( 1 ) ( 2 ) ) )\n              - > ((A 1) (B 1) (A 2) (B 2 ) ) . \"\n              (mappend #*(lambda ( y )\n                               (mapcar #'(lambda ( x ) (append  y ) ) x l i s t ) )\n                           ylist))\n\n\n         We can now use generate - a 11 to test our original little grammar. Note that a serious\n         drawback of g e n e r a t e - a 11 is that it can't deal with recursive grammar rules like\n         'Adj*    Adj + Adj*' that appear in *b1 gger-grammar*, since these lead to an infinite\n         number of outputs. But it works fine for finite languages, like the language generated\n         by*simple-grammar*:\n\f46                                                                      SIMPLE LISP   PROGRAM\n\n\n\n            > (generate-all      'Article)\n            ((THE) (A))\n\n            > (generate-all 'Noun)\n            ((MAN) (BALL) (WOMAN) (TABLE))\n\n            > (generate-all 'noun-phrase)\n            ((A MAN) (A BALL) (A WOMAN) (A TABLE)\n              (THE MAN) (THE BALL) (THE WOMAN) (THE TABLE))\n\n            > (length (generate-all 'sentence))\n            256\n\n\n         There are 256 sentences because every sentence in this language has the form Article-\n         Noun-Verb-Article-Noun, and there are two articles, four nouns and four verbs\n         (2 x 4 x 4 x 2 x 4 = 256).\n\n\n\n\n         2.7      Exercises\n         Exercise 2.3 [h] Write a trivial grammar for some other language. This can be a\n         natural language other than English, or perhaps a subset of a computer language.\n\n\n     @   Exercise 2.4 [m] One way of describing combi ne - a 11 is that it calculates the cross-\n         product of the function a ppend on the argument lists. Write the higher-order function\n         c r o s s - p r o d u c t , and define combi n e - a l l in terms of it.\n         The moral is to make your code as general as possible, because you never know what\n         you may want to do with it next.\n\n\n\n\n         2.8     Answers\n         Answer 2.1\n\n            (defun generate (phrase)\n              \"Generate a random sentence or phrase\"\n              ( l e t ((choices n i l ) )\n                  (cond ( ( l i s t p phrase)\n                           (mappend #'generate phrase))\n                         ( ( s e t f choices (rewrites phrase))\n                           (generate (random-elt c h o i c e s ) ) )\n                         (t ( l i s t p h r a s e ) ) ) ) )\n\f2.8 ANSWERS                                                                                   47\n\n\n\n         Answer 2.2\n\n              (defun generate (phrase)\n                \"Generate a random sentence or phrase\"\n                (cond ( ( l i s t p phrase)\n                        (mappend #'generate phrase))\n                      ((non-terminal-p phrase)\n                        (generate (random-elt (rewrites p h r a s e ) ) ) )\n                      (t ( l i s t p h r a s e ) ) ) )\n\n              (defun non-terminal-p (category)\n                \"True i f t h i s i s a category in the grammar.\"\n                (not (null (rewrites c a t e g o r y ) ) ) )\n\n\n         Answer 2.4\n\n              (defun cross-product (fn x l i s t y l i s t )\n                \"Return a l i s t of all (fn  y ) v a l u e s . \"\n                (mappend #*(lambda (y)\n                                (mapcar #*(lambda (x) (funcall fn  y ) )\n                                        xlist))\n                         ylist))\n\n              (defun combine-all ( x l i s t y l i s t )\n                \"Return a l i s t of l i s t s formed by appending a y to an x\"\n                (cross-product #*append x l i s t y l i s t ) )\n\n\n         Now we can use the cross-product in other ways as well:\n\n              > (cross-product # * + ' ( 1 2 3) ' ( 1 0 20 30))\n              (11 12 13\n               21 22 23\n               31 32 33)\n\n              > (cross-product # ' l i s t             '(a b c d e f g       h)\n                                                       ' ( 1 2 3 4 5 6 7 8   ) )\n              ((A   1)   (B   1)   (C   1)   (D   1)     (E 1) (F 1) (G      1)    (H   1)\n               (A   2)   (B   2)   (C   2)   (D   2)     (E 2) (F 2) (G      2)    (H   2)\n               (A   3)   (B   3)   (C   3)   (D   3)     (E 3) (F 3) (G      3)    (H   3)\n               (A   4)   (B   4)   (C   4)   (D   4)     (E 4) (F 4) (G      4)    (H   4)\n               (A   5)   (B   5)   (C   5)   (D   5)     (E 5) (F 5) (G      5)    (H   5)\n               (A   6)   (B   6)   (C   6)   (D   6)     (E 6) (F 6) (G      6)    (H   6)\n               (A   7)   (B   7)   (C   7)   (D   7)     (E 7) (F 7) (G      7)    (H   7)\n               (A   8)   (B   8)   (C   8)   (D   8)     (E 8) (F 8) (G      8)    (H   8))\n\fCHAPTER                   3\n\nOverview of Lisp\n\n                                                       No doubt about it. Common Lisp is a big language.\n                                                                                    --Guy L. Steele, Jr.\n                                                                          Foreword to Koschman 1990\n\n\n\n\nr I 1 his chapter briefly covers the most important special forms and functions in Lisp. It\n      can be safely skipped or skimmed by the experienced Common Lisp programmer\n      but is required reading for the novice Lisp progranuner, or one who is new to the\nCommon Lisp dialect.\n    This chapter can be used as a reference source, but the definitive reference is Steele's Common\nLisp the Language, 2d edition, which should be consulted whenever there is any confusion. Since\nthat book is 25 times longer than this chapter, it is clear that we can only touch on the important\nhighlights here. More detailed coverage is given later in this book as each feature is used in a\nreal program.\n\f3.1 A GUIDE TO LISP SLE                                                                                    49\n\n\n\n         3.1         A Guide to Lisp Style\n         The beginning Common Lisp programmer is often overwhelmed by the number of\n         options that the language provides. In this chapter we show fourteen different ways\n         to find the length of a list. How is the programmer to choose between them? One\n         answer is by reading examples of good programs--as illustrated in this book--and\n         copying that style. In general, there are six maxims that every programmer should\n         follow:\n\n              � Be specific.\n\n             � Use abstractions.\n\n             � Be concise.\n\n             � Use the provided tools.\n\n             � Don't be obscure.\n\n             � Be consistent.\n\n             These require some explanation.\n             Using the most specific form possible makes it easier for your reader to understand\n         your intent. For example, the conditional special form when is more specific than i f.\n         The reader who sees a when knows to look for only one thing: the clause to consider\n         when the test is true. The reader who sees an i f can rightfully expect two clauses:\n         one for when the test is true, and one for when it is false. Even though it is possible\n         to use i f when there is only one clause, it is preferable to use when, because when is\n         more specific.\n             One important way of being specific is using abstractions. Lisp provides very\n         general data structures, such as lists and arrays. These can be used to implement\n         specific data structures that your program will use, but you should not make the\n         mistake of invoking primitive functions directly. If you define a list of names:\n\n              (defvar *names* ' ( ( R o b e r t E. Lee) . . . ) )\n\n\n         then you should also define functions to get at the components of each name. To get\n         at Lee, use ( l a s t - n a m e ( f i r s t * n a m e s * ) ) , n o t (caddar * n a m e s * ) .\n            Often the maxims are in concord. For example, if your code is trying to find an\n         element in a list, you should use f 1 nd (or maybe f 1 nd-1 f), not 1 oop or do. f i nd is\n         more specific than the general constructs 1 oop or do, it is an abstraction, it is more\n         concise, it is a built-in tool, and it is simple to understand.\n\f50                                                                                  OVERVIEW OF LISP\n\n\n\n         Sometimes, however, the maxims are in confUct, and experience will tell you\n     which one to prefer. Consider the following two ways of placing a new key/value\n     pair on an association list:^\n\n         (push (cons key v a l ) a - l i s t )\n         ( s e t f a - l i s t (aeons key val a - l i s t ) )\n\n\n     The first is more concise. But the second is more specific, as it uses the aeons\n     function, which is designed specifically for association lists. The decision between\n     them probably hinges on obscurity: those who find aeons to be a familiar function\n     would prefer the second, and those who find it obscure would prefer the first.\n        A similar choice arises in the question of setting a variable to a value. Some prefer\n     (setq X v a l ) because it is most specific; others use ( s e t f  v a l ) , feeling that it is\n     more consistent to use a single form, s e t f , for all updating. Whichever choice you\n     make on such issues, remember the sixth maxim: be consistent.\n\n\n\n\n     3.2        Special Forms\n     As noted in chapter 1, \"special form\" is the term used to refer both to Common Lisp's\n     syntactic constructs and the reserved words that mark these constructs. The most\n     commonly used special forms are:\n\n\n                 definitions            conditional         variables   iteration   other\n                 defun                  and                 let         do          declare\n                 defstruct              case                let*        do*         function\n                 defvar                 cond                pop         dolist      progn\n                 defparameter           if                  push        dotimes     quote\n                 defconstant            or                  setf        loop        return\n                 defmacro               unless              incf                    trace\n                 labels                 when                decf                    untrace\n\n\n         To be precise, only declare, function. I f , l a b e l s , l e t , l e t * , progn and quote\n     are true special forms. The others are actually defined as macros that expand into\n     calls to more primitive special forms and functions. There is no real difference to the\n     programmer, and Common Lisp implementations are free to implement macros as\n     special forms and vice versa, so for simplicity we will continue to use \"special form\"\n     as a blanket term for both true special forms and built-in macros.\n\n        ^Association lists are covered in section 3.6.\n\f3.2   SPECIAL FORMS                                                                                        51\n\n\n\n            Special Forms for Definitions\n\n            In this section we survey the special forms that can be used to introduce new global\n            functions, macros, variables, and structures. We have already seen the defun form\n            for defining functions; the def macro form is similar and is covered on page 66.\n\n                (defun function-name (parameter...) \" optional documentation\" body...)\n                i�efmdiCro macro-name (parameter...) \"optional documentation\" body...)\n\n            There are three forms for introducing special variables, defvar defines a special\n            variable and can optionally be used to supply an initial value and a documentation\n            string. The initial value is evaluated and assigned only if the variable does not yet\n            have any value, def pa rameter is similar, except that the value is required, and it will\n            be used to change any existing value, def constant is used to declare that a symbol\n            will always stand for a particular value.\n\n                (defvar vanable-name initial-value \"optional documentation\")\n                (defparameter vanable-name value \"optional documentation\")\n                (def constant variable-name value \"optional documentation\")\n\n            All the def - forms define global objects. It is also possible to define local variables\n            with 1 et, and to define local functions with 1 abel s, as we shall see.\n\n                Most programming languages provide a way to group related data together into\n            a structure. Common Lisp is no exception. The def s t r u c t special form defines a\n            structure type (known as a record type in Pascal) and automatically defines functions\n            to get at components of the structure. The general syntax is:\n\n                (def struct structure-name \"optional documentation\" slot...)\n\n            As an example, we could define a structure for names:\n\n                (defstruct name\n                  first\n                  (middle n i l )\n                  last)\n\n\n            This automatically defines the constructor function make-name, the recognizer pred\n            icate name-p, and the accessor functions n a m e - f i r s t , name-middle and n a m e - l a s t .\n            The (middle n i l ) means that each new name built by make-name will have a middle\n            name of ni 1 by default. Here we create, access, and modify a structure:\n\f52                                                                             OVERVIEW OF LISP\n\n\n         > ( s e t f b (make-name : f i r s t 'Barney : l a s t 'Rubble)) =>\n         #S(NAME :FIRST BARNEY :LAST RUBBLE)\n\n         > (name-first b) ^      BARNEY\n\n         > (name-middle b)        NIL\n\n         > (name-last b) ^      RUBBLE\n\n         > (name-p b) = \n\n         > (name-p 'Barney) = NIL            ; only the results of make-name are names\n         > ( s e t f (name-middle b) 'Q) =^ Q\n\n         > b     #S(NAME :FIRST BARNEY .-MIDDLE Q :LAST RUBBLE)\n\n\n     The printed representation of a structure starts with a #S and is followed by a list\n     consisting of the type of the structure and alternating pairs of slot names and values.\n     Do not let this representation fool you: it is a convenient way of printing the structure,\n     but it is not an accurate picture of the way structures are represented internally.\n     Structures are actually implemented much like vectors. For the name structure, the\n     type would be in the zero element of the vector, the first name in the first element,\n     middle in the second, and last in the third. This means structures are more efficient\n     than lists: they take up less space, and any element can be accessed in a single step.\n     In a list, it takes  steps to access the nth element.\n         There are options that give more control over the structure itself and the individual\n     slots. They will be covered later as they come up.\n\n\n     Special Forms for Conditionals\n\n     We have seen the special form i f , which has the form ( i f test then-part else-part),\n     where either the then-part or the else-part is the value, depending on the success of the\n     test. Remember that only  i 1 counts as false; all other values are considered true for\n     the purpose of conditionals. However, the constant t is the conventional value used\n     to denote truth (unless there is a good reason for using some other value).\n          There are actually quite a few special forms for doing conditional evaluation.\n     Technically, i f is defined as a special form, while the other conditionals are macros,\n     so in some sense 1 f is supposed to be the most basic. Some programmers prefer to\n     use i f for most of their conditionals; others prefer cond because it has been around\n     the longest and is versatile (if not particularly pretty). Finally, some programmers opt\n     for a style more like English prose, and freely use when, unl ess, 1 f , and all the others.\n          The following table shows how each conditional can be expressed in terms of\n     1 f and cond. Actually, these translations are not quite right, because or, case, and\n     cond take care not to evaluate any expression more than once, while the translations\n     with i f can lead to multiple evaluation of some expressions. The table also has\n\f3.2 SPECIAL   FORMS                                                                                              53\n\n\n          translations to cond. The syntax of cond is a series of cond-clauses, each consisting of\n          a test expression followed by any number of result expressions:\n\n              (cond {testresult...)\n                    {test result...)\n                       ...)\n\n\n          cond goes through the cond-clauses one at a time, evaluating each test expression.\n          As soon as a test expression evaluates non-nil, the result expressions for that clause\n          are each evaluated, and the last expression in the clause is the value of the whole\n          cond. In particular, if a cond-clause consists of just a test and no result expressions,\n          then the value of the cond is the test expression itself, if it is non-nil. If all of the test\n          expressions evaluate to nil, then nil is returned as the value of the cond. A common\n          idiom is to make the last cond-clause be ( t result...).\n              The forms when and unl ess operate like a single cond clause. Both forms consist\n          of a test followed by any number of consequents, which are evaluated if the test is\n          satisfied-that is, if the test is true for when or false for unl ess.\n              The and form tests whether every one of a list of conditions is true, and or tests\n          whether any one is true. Both evaluate the arguments left to right, and stop as soon\n          as the final result can be determined. Here is a table of equivalences:\n\n              conditional                     i f form                             cond form\n              (when test ah c)                ( i f test (progn a be))             (cond {testaba))\n              (unless testxy)                 ( i f {nottest) (progn xy))          (cond {{not test) xy))\n              (and abc)                       ( i f a ( i f b c))                  (cond(fl (cond {be))))\n              (or ahc)                        ( i f a a ( i f b b c))              (cond (a) {b) (c))\n              (case a {b c) (t         x))    ( i f (eql a 'b) c x)                (cond ((eql a 'b)c)   {tx))\n\n              It is considered poor style to use and and or for anything other than testing a\n          logical condition, when, unl ess, and 1 f can all be used for taking conditional action.\n          For example:\n\n              (and    (>  100)\n                      (princ \"N i s l a r g e . \" ) )   ; Bad s t y l e !\n\n              (or (<=  100)\n                  (princ \"N i s l a r g e . \" ) )       ; Even worse s t y l e !\n\n              (cond ( ( >  100)                       ; OK. but not MY preference\n                      (princ \"N i s l a r g e . \" ) )\n\n              (when ( >  100)\n                (princ \"N i s l a r g e . \" ) )         ; Good s t y l e .\n\n\n          When the main purpose is to return a value rather than take action, cond and i f\n          (with explicit  i 1 in theelsecase)are preferred overwhenandunl ess, which implicitly\n\f54                                                                         OVERVIEW OF LISP\n\n\n     return nil in the else case, when and unl ess are preferred when there is only one\n     possibility, i f (or, for some people, cond) when there are two, and cond when there\n     are more than two:\n\n        (defun tax-bracket (income)\n          \"Determine what percent tax should be paid for this income.\"\n          (cond ((< income 10000.00) 0.00)\n                ((< income 30000.00) 0.20)\n                ( � income 50000.00) 0.25)\n                ((< income 70000.00) 0.30)\n                (t                    0.35)))\n\n     If there are several tests comparing an expression to constants, then case is appro\n     priate. A case form looks like:\n\n        (case expression\n          (matchresult..)...)\n\n     The expression is evaluated and compared to each successive match. As soon as one\n     is eql, the result expressions are evaluated and the last one is returned. Note that the\n     match expressions are not evaluated. If a match expression is a list, then case tests if\n     the expression is eql to any member of the list. If a match expression is the symbol\n     otherwi se (or the symbol t ) , then it matches anything. (It only makes sense for this\n     otherwl se clause to be the last one.)\n         There is also another special form, typecase, which compares the type of an\n     expression against several possibilities and, like case, chooses the first clause that\n     matches. In addition, the special forms ecase and etypecase are just like case and\n     typecase except that they signal an error if there is no match. You can think of the e\n     as standing for either \"exhaustive\" or \"error.\" The forms cease and etypecase also\n     signal errors, but they can be continuable errors (as opposed to fatal errors): the user\n     is offered the chance to change the expression to something that satisfies one of the\n     matches. Here are some examples of case forms and their cond equivalents:\n\n        (case                                 (cond\n          (1 10)                                ((eql  1) 10)\n          (2 20))                               ((eql  2) 20))\n        (typecase                             (cond\n          (number (abs x))                       ((typep  'number) (abs x))\n          ( l i s t (length x ) ) )             ((typep  ' l i s t ) (length x ) ) )\n         (ecase                               (cond\n           (1 10)                               ((eql  1) 10)\n           (2 20))                              ((eql  2) 20)\n                                                (t (error \"no valid case\")))\n\f3.2 SPECIAL   FORMS                                                                                           55\n\n\n              (etypecase                                 (cond\n                (number (abs  ) )                           ((typep  'number) (abs x ) )\n                ( l i s t (length x ) ) )                   ((typep  ' l i s t ) (length x ) )\n                                                            (t (error \"no v a l i d t y p e c a s e \" ) ) )\n\n\n\n\n          Special Forms for Dealing with Variables and Places\n\n\n          The special form s e t f is used to assign a new value to a variable or place, much as an\n          assignment statement with = or : = is used in other languages. A place, or generalized\n          variable is a name for a location that can have a value stored in it. Here is a table of\n          corresponding assignment forms in Lisp and Pascal:\n\n\n                  Lisp                                / * Pascal * /\n              ( s e t f  0)                            : = 0;\n              ( s e t f (aref A i j ) 0)              A [ i , j ] := 0;\n              (setf (rest l i s t ) n i l )           l i s t \\ r e s t := n i l ;\n              ( s e t f (name-middle b) 'Q)           b\\middle : = \"Q\";\n\n\n          s e t f can be used to set a component of a structure as well as to set a variable. In\n          languages like Pascal, the expressions that can appear on the left-hand side of an\n          assignment statement are limited by the syntax of the language. In Lisp, the user can\n          extend the expressions that are allowed in a s et f form using the special forms def s e t f\n          or def i ne-setf -method. These are introduced on pages 514 and 884 respectively.\n                There are also some built-in functions that modify places. For example, (rpl a cd\n          l i s t n i l ) has the same effect as ( s e t f ( r e s t l i s t ) n i l ) , except that it returns\n          l i s t instead of ni 1. Most Common Lisp programmers prefer to use the s e t f forms\n          rather than the specialized functions.\n              If you only want to set a variable, the special form setq can be used instead. In\n          this book I choose to use s e t f throughout, opting for consistency over specificity.\n              The discussion in this section makes it seem that variables (and slots of struc\n          tures) are assigned new values all the time. Actually, many Lisp programs do no\n          assignments whatsoever. It is very common to use Lisp in a functional style where\n          new variables may be introduced, but once a new variable is established, it never\n          changes. One way to introduce a new variable is as a parameter of a function. It\n          is also possible to introduce local variables using the special form 1 e t . Following\n          are the general 1 e t form, along with an example. Each variable is bound to the\n          corresponding value, and then the body is evaluated:\n\f56                                                                                 OVERVIEW OF LISP\n\n\n             (let((variablevalue)..,)           ( l e t ((x 40)\n                body...)                                 (y (+ 1 1 ) ) )\n                                                    ( + X y))    42\n\n         Defining a local variable with a 1 et form is really no different from defining param\n         eters to an anonymous function. The former is equivalent to:\n\n            ((lambdei(variable..,)          ((lambda (x y)\n                body...)                        ( + X y))\n            value..,)                       40\n                                             (+ 1 D )\n\n\n         First, all the values are evaluated. Then they are bound to the variables (the pa\n         rameters of the lambda expression), and finally the body is evaluated, using those\n         bindings.\n             The special form 1 e t * is appropriate when you want to use one of the newly\n         introduced variables in a subsequent value computation. For example:\n\n             (let* ((x 6)\n                    (y (*  )))\n               (+  y))    42\n\n         We could not have used 1 e t here, because then the variable  would be unbound\n         during the computation of y's value.\n\n\n     @   Exercise 3.1 [m] Show a 1 ambda expression that is equivalent to the above 1 e t *\n         expression. You may need more than one 1 ambda.\n             Because lists are so important to Lisp, there are special forms for adding and\n         deleting elements from the front of a list--in other words, for treating a list as a stack.\n         If 1 i s t is the name of a location that holds a list, then ( push A: 1 i s t ) will change 1 i s t\n         to have  as its first element, and (pop 1 i s t ) will return the first element and, as\n         a side-effect, change 1 i s t to no longer contain the first element, push and pop are\n         equivalent to the following expressions:\n\n             (push  l i s t ) = (setf l i s t (cons  l i s t ) )\n             (pop l i s t )   = ( l e t ((result ( f i r s t l i s t ) ) )\n                                   (setf l i s t (rest l i s t ) )\n                                   result)\n\n         Just as a Hst can be used to accumulate elements, a running sum can be used to\n         accumulate numbers. Lisp provides two more special forms, 1 ncf and decf, that can\n         be used to increment or decrement a sum. For both forms the first argument must\n\f3.2 SPECIAL   FORMS                                                                                           57\n\n\n          be a location (a variable or other setf-able form) and the second argument, which\n          is optional, is the number to increment or decrement by. For those who know C,\n          ( i n c f x) is equivalent to - H-X , and ( i n c f  2) is equivalent to x+=2. In Lisp the\n          equivalence is:\n\n              ( i n c f x) = ( i n c f  1) = ( s e t f  (+  D )\n              (decf x) = (decf  1) = ( s e t f  (-  D )\n\n\n          When the location is a complex form rather than a variable. Lisp is careful to expand\n          into code that does not evaluate any subform more than once. This holds for push,\n          pop, 1 ncf, and decf. In the following example, we have a list of players and want\n          to decide which player has the highest score, and thus has won the game. The\n          structure pi ayer has slots for the player's score and number of wins, and the function\n          determi ne -wi nner increments the winning player's w1 ns field. The expansion of the\n          i ncf form binds a temporary variable so that the sort is not done twice.\n\n              (defstruct player (score 0) (wins 0 ) )\n\n\n              (defun determine-winner ( p l a y e r s )\n                \"Increment the WINS for the player with highest s c o r e . \"\n                ( i n c f (player-wins ( f i r s t ( s o r t players # * >\n                                                             :key # ' p l a y e r - s c o r e ) ) ) ) )\n\n              (defun determine-winner ( p l a y e r s )\n                \"Increment the WINS f o r the player with highest s c o r e . \"\n                ( l e t ((temp ( f i r s t ( s o r t players # ' > :key # ' p l a y e r - s c o r e ) ) ) )\n                    ( s e t f (player-wins temp) (+ (player-wins temp) 1 ) ) ) )\n\n\n\n\n          Functions and Special Forms for Repetition\n\n          Many languages have a small number of reserved words for forn�ng iterative loops.\n          For example, Pascal has whi 1 e, repeat, and f o r statements. In contrast, Conunon\n          Lisp has an almost bewildering range of possibilities, as summarized below:\n\n                               dolist                        loop over elements of a list\n                               dot 1 mes                     loop over successive integers\n                               do, d o *                     general loop, sparse syntax\n                               loop                          general loop, verbose syntax\n                               mapc. mapcar                  loop over elements of lists(s)\n                               some, every                   loop over list until condition\n                               find,       reduce, efc.      more specific looping functions\n                               recursion                     general repetition\n\f58                                                                                      OVERVIEW OF LISP\n\n\n         To explain each possibiUty, we will present versions of the function 1 ength, which\n     returns the number of elements in a list. First, the special form dol i s t can be used\n     to iterate over the elements of a list. The syntax is:\n\n         (dol i st (variable list optional-result) body...)\n\n     This means that the body is executed once for each element of the list, with vari\n     able bound to the first element, then the second element, and so on. At the end,\n     dol i s t evaluates and returns the optional-result expression, or nil if there is no result\n     expression.\n         Below is a version of 1 ength usingdol i s t . The 1 e t form introduces anew variable,\n     1 en, which is initially bound to zero. The dol i s t form then executes the body once\n     for each element of the list, with the body incrementing 1 en by one each time. This\n     use is unusual in that the loop iteration variable, el ement, is not used in the body.\n\n        (defun lengthl ( l i s t )\n          (let ( d e n 0))                         s t a r t with LEN=0\n            ( d o l i s t (element l i s t )       and on each i t e r a t i o n\n               (incf len))                           increment LEN by 1\n            len))                                  and return LEN\n\n\n     It is also possible to use the optional result of dol i s t , as shown below. While many\n     programmers use this style, I find that it is too easy to lose track of the result, and so\n     I prefer to place the result last explictly.\n\n         (defun l e n g t h l . 1 ( l i s t )         ; alternate v e r s i o n :\n           (let ( d e n 0))                           ; (not my preference)\n             ( d o l i s t (element l i s t len)      ; uses len as r e s u l t here\n                (incf len))))\n\n\n     The function mapc performs much the same operation as the special form dol i s t . In\n     the simplest case, mapc takes two arguments, the first a function, the second a list. It\n     applies the function to each element of the list. Here is 1 ength using mapc:\n\n         (defun lengthZ ( l i s t )\n           (let ( d e n 0))                                ; s t a r t with LEN=0\n             (mapc #'dambda (element)                      ; and on each i t e r a t i o n\n                          (incf len))                      ; increment LEN by 1\n                     list)\n             len))                                         ; and return LEN\n\n\n     There are seven different mapping functions, of which the most useful are mapc and\n     mapca r. mapca r executes the same function calls as mapc, but then returns the results\n\f3.2 SPECIAL FORMS                                                                                  59\n\n\n\n         in a list.\n\n             There is also a dot i mes form, which has the syntax:\n\n             (dot i mes (variable number optional-result) body,..)\n         and executes the body with variable bound first to zero, then one, all the way up to\n         number-1 (for a total of number times). Of course, dot i mes is not appropriate for\n         implementing 1 ength, since we don't know the number of iterations ahead of time.\n             There are two very general looping forms, do and 1 oop. The syntax of do is as\n         follows:\n\n             (do ((variable initial next)...)\n                 (exit-test result)\n               body...)\n\n         Each variable is initially bound to the initial value. If exit-test is true, then result is re\n         turned. Otherwise, the body is executed and each variable is set to the corresponding\n         next value and exit-test is tried again. The loop repeats until exit-test is true. If a next\n         value is omitted, then the corresponding variable is not updated each time through\n         the loop. Rather, it is treated as if it had been bound with a 1 e t form.\n             Here is 1 ength implemented withdo,usingtwo variables, 1 en to count the number\n         of elements, and 1 to go down the list. This is often referred to as cdr-ing down a list,\n         because on each operation we apply the function cdr to the list. (Actually, here we\n         have used the more mnemonic name r e s t instead of cdr.) Note that the do loop has\n         no body! All the computation is done in the variable initialization and stepping, and\n         in the end test.\n\n             (defun lengths ( l i s t )\n               (do ( d e n 0 (+ len D )             ; s t a r t with LEN=0. increment\n                     (1 l i s t ( r e s t 1 ) ) )   ; . . . on each i t e r a t i o n\n                   ( ( n u l l 1) l e n ) ) )       ; ( u n t i l the end of the l i s t )\n\n\n         I find the do form a little confusing, because it does not clearly say that we are looping\n         through a list. To see that it is indeed iterating over the list requires looking at both\n         the variable 1 and the end test. Worse, there is no variable that stands for the current\n         element of the Ust; we would need to say ( f i r s t 1 ) to get at it. Both dol i s t and\n         mapc take care of stepping, end testing, and variable naming automatically. They are\n         examples of the \"be specific\" principle. Because it is so unspecific, do will not be\n         used much in this book. However, many good programmers use it, so it is important\n         to know how to read do loops, even if you decide never to write one.\n            The syntax of 1 oop is an entire language by itself, and a decidedly non-Lisp-like\n         language it is. Rather than list all the possibilities for 1 oop, we will just give examples\n\f60                                                                                          OVERVIEW OF LISP\n\n\n     here, and refer the reader to Common Lisp the Language, 2d edition, or chapter 24.5 for\n     more details. Here are three versions of 1 ength using 1 oop:\n\n         (defun length4 ( l i s t )\n           (loop for element i n l i s t             ; go through each element\n                 count t ) )                         ;   counting each one\n\n         (defun lengths ( 1 1 s t )\n           (loop for element i n l i s t             ; go through each element\n                 summing 1 ) )                       ;   adding 1 each time\n\n         (defun lengthe ( l i s t )\n           (loop with len = 0                        ;   s t a r t with LEN=0\n                 u n t i l (null l i s t )           ;   and ( u n t i l end of l i s t )\n                 for element = (pop l i s t )        ;   on each i t e r a t i o n\n                 do ( i n c f len)                   ;    increment LEN by 1\n                 f i n a l l y (return l e n ) ) )   ;   and return LEN\n\n\n     Every programmer learns that there are certain kinds of loops that are used again\n     and again. These are often called programming idioms or cliches. An example is going\n     through the elements of a list or array and doing some operation to each element.\n     In most languages, these idioms do not have an explicit syntactic marker. Instead,\n     they are implemented with a general loop construct, and it is up to the reader of the\n     program to recognize what the programmer is doing.\n          Lisp is unusual in that it provides ways to explicitly encapsulate such idioms, and\n     refer to them with explicit syntactic and functional forms, dol 1 s t and dotimes are\n     two examples of this-they both follow the \"be specific\" principle. Most programmers\n     prefer to use a dol i s t rather than an equivalent do, because it cries out \"this loop\n     iterates over the elements of a list.\" Of course, the corresponding do form also says\n     the same thing--but it takes more work for the reader to discover this.\n          In addition to special forms like dol 1 s t and dotimes, there are quite a few func\n     tions that are designed to handle common idioms. Two examples are c o u n t - I f ,\n     which counts the number of elements of a sequence that satisfy a predicate, and\n     p o s i t i o n - I f , which returns the index of an element satisfying a predicate. Both\n     can be used to implement 1 ength. In 1 ength7 below, count -1 f gives the number of\n     elements in 11 s t that satisfy the predicate true. Since t r u e is defined to be always\n     true, this gives the length of the list.\n\n        (defun length? ( l i s t )\n          ( c o u n t - i f #*true l i s t ) )\n\n        (defun true (x)          t)\n\n\n     In 1 engthS, the function posi t1 on -1 f finds the position of an element that satisfies\n     the predicate true, starting from the end of the list. This will be the very last element\n\f3.2 SPECIAL FORMS                                                                             61\n\n\n\n         of the list, and since indexing is zero-based, we add one to get the length. Admittedly,\n         this is not the most straightforward implementation of 1 ength.\n\n             (defun lengths ( l i s t )\n               (if (null l i s t )\n                   0\n                   (+ 1 (position-if #*true l i s t :from-end t ) ) ) )\n\n\n         A partial table of functions that implement looping idioms is given below. These\n         functions are designed to be flexible enough to handle almost all operations on\n         sequences. The flexibility comes in three forms. First, functions like mapcar can\n         apply to an arbitrary number of lists, not just one:\n\n            > (mapcar     '(1 2 3)) => (-1 -2 -3)\n            > (mapcar #'+ '(1 2) '(10 20))    (11 22)\n            > (mapcar #'+ '(1 2) '(10 20) '(100 200)) =^ (111 222)\n\n\n         Second, many of the functions accept keywords that allow the user to vary the test\n         for comparing elements, or to only consider part of the sequence.\n\n            > (remove 1 '(1 2 3 2 1 0 -1)) =4^ (2 3 2 0 -1)\n\n            > (remove 1 '(1 2 3 2 1 0 -1) :key #'abs) ^ ( 2 3 2 0 )\n\n            > (remove 1 '(1 2 3 2 1 0 -1) :test #'<) = � ( 1 1 0 -1)\n\n            > (remove 1 '(1 2 3 2 1 0 -1) rstart 4)            (1 2 3 2 0 -1)\n\n\n         Third, some have corresponding functions ending in - i f or - i f - n o t that take a\n         predicate rather than an element to match against:\n\n            > (remove-if #Oddp '(1 2 3 2 1 0 -1)) = ^ ( 2 2 0)\n\n            > (remove-if-not #'oddp ' ( 1 2 3 2 1 0 -1)) = ^ ( 1 3 1 -1)\n\n            > (find-if #'evenp ' ( 1 2 3 2 1 0 -1))        2\n\n         The following two tables assume these two values:\n\n             (setf  '(a b c ) )\n             (setf y '(1 2 3))\n\n         The first table lists functions that work on any number of lists but do not accept\n         keywords:\n\f62                                                                                   OVERVIEW OF LISP\n\n\n\n     (every # O d d p y )      =  i 1               test if every element satisfies a predicate\n     (some # O d d p y )       => t                 test if some element satisfies predicate\n     (mapcar          y)       =^(-1    -2 - 3 )    apply function to each element and return result\n     (mapc # ' p r i n t y )   prints 1 2 3         perform operation on each element\n\n             The second table lists functions that have - i f and - i f - n o t versions and also\n          accept keyword arguments:\n\n               (member 2 y )               = ^ ( 2 3)          see if element is in list\n               (count 'b x)                =>1                 count the number of matching elements\n               (delete 1 y )               = > ( 2 3)          omit matching elements\n               (find 2 y )                 ^2                  find first element that matches\n               (position ' a x)            =^0                 find index of element in sequence\n               (reduce # ' + y )                               apply function to succesive elements\n               (remove 2 y )               = > ( 1 3)          like del e t e , but makes a new copy\n               (substitute 4 2 y)          = ^ ( 1 4 3)        replace elements with new ones\n\n\n          Repetition through Recursion\n\n          Lisp has gained a reputation as a \"recursive\" language, meaning that Lisp encourages\n          programmers to write functions that call themselves. As we have seen above, there is\n          a dizzying number of functions and special forms for writing loops in Common Lisp,\n          but it is also true that many programs handle repetition through recursion rather\n          than with a syntactic loop.\n              One simple definition of 1 ength is \"the empty list has length 0, and any other list\n          has a length which is one more than the length of the rest of the list (after the first\n          element).\" This translates directly into a recursive function:\n\n               (defun length9 ( l i s t )\n                 ( i f (null l i s t )\n                       0\n                       (+ 1 (length9 (rest l i s t ) ) ) ) )\n\n          This version of 1 ength arises naturally from the recursive definition of a list: \"a list\n          is either the empty list or an element consed onto another list.\" In general, most\n          recursive functions derive from the recursive nature of the data they are operating\n          on. Some kinds of data, like binary trees, are hard to deal with in anything but a\n          recursive fashion. Others, like Hsts and integers, can be defined either recursively\n          (leading to recursive functions) or as a sequence (leading to iterative functions). In\n          this book, I tend to use the \"list-as-sequence\" view rather than the \"list-as-first-and-\n          rest\" view. The reason is that defining a hst as a first and a rest is an arbitrary and\n          artificial distinction that is based on the implementation of lists that Lisp happens to\n          use. But there are many other ways to decompose a list. We could break it into the last\n\f3.2 SPECIAL     FORMS                                                                                      63\n\n\n\n              element and all-but-the-last elements, for example, or the first half and the second\n              half. The \"list-as-sequence\" view makes no such artificial distinction. It treats all\n              elements identically.\n\n                  One objection to the use of recursive functions is that they are inefficient, because\n              the compiler has to allocate memory for each recursive call. This may be true for the\n              function 1 ength9, but it is not necessarily true for all recursive calls. Consider the\n              following definition:\n\n                  (defun lengthlO ( l i s t )\n                    (lengthlO-aux l i s t 0 ) )\n\n                  (defun lengthlO-aux ( s u b l i s t l e n - s o - f a r )\n                    ( i f (null s u b l i s t )\n                          len-so-far\n                          (lengthlO-aux ( r e s t s u b l i s t ) (+ 1 l e n - s o - f a r ) ) ) )\n\n\n              1 engthlO uses 1 engthlO - aux as an auxiliary function, passing it 0 as the length of the\n              list so far. 1 engt hlO - a ux then goes down the list to the end, adding 1 for each element.\n              The invariant relation is that the length of the sublist plus 1 en - so - f a r always equals\n              the length of the original list. Thus, when the sublist is nil, then 1 e n - s o - f ar is the\n              length of the original list. Variables like 1 en - so - fa r that keep track of partial results\n              are called accumulators. Other examples of functions that use accumulators include\n              f 1 a t t e n - a 11 on page 329; one - un known on page 237; the Prolog predicates discussed\n              on page 686; and a n o n y m o u s - v a r i a b l e s - i n on pages 400 and 433, which uses two\n              accumulators.\n                    The important difference between length9 and l e n g t h l O is when the addition\n              is done. In length9, the function calls itself, then returns, and then adds 1 . In\n              l e n g t h l O - a u x , the function adds 1 , then calls itself, then returns. There are no\n              pending operations to do after the recursive call returns, so the compiler is free to\n              release any memory allocated for the original call before making the recursive call.\n              1 engthlO-aux is called a tail-recursive function, because the recursive call appears as\n              the last thing the function does (the tail). Many compilers will optimize tail-recursive\n              calls, although not all do. (Chapter 22 treats tail-recursion in more detail, and points\n              out that Scheme compilers guarantee that tail-recursive calls will be optimized.)\n                    Some find it ugly to introduce 1 ength 10 - a ux. For them, there are two alternatives.\n              First, we could combine 1 engthlO and 1 engthlO-aux into a single function with an\n              optional parameter:\n\n                  (defun l e n g t h l l ( l i s t &optional ( l e n - s o - f a r 0 ) )\n                    ( i f (null l i s t )\n                          len-so-far\n                          ( l e n g t h l l ( r e s t l i s t ) (+ 1 l e n - s o - f a r ) ) ) )\n\f64                                                                                                OVERVIEW   OF LISP\n\n\n\n     Second, we could introduce a local function inside the definition of the main function.\n     This is done with the special form 1 abel s:\n\n        (defun lengthl2 ( t h e - l i s t )\n          (labels\n             ((lengthl3 ( l i s t len-so-far)\n                 ( i f (null l i s t )\n                       len-so-far\n                       ( l e n g t h l S ( r e s t l i s t ) (+ 1 l e n - s o - f a r ) ) ) ) )\n             (lengthlS t h e - l i s t 0)))\n\n\n     In general, a 1 abel s form (or the similar f 1 et form) can be used to introduce one or\n     more local functions. It has the following syntax:\n\n        (labels\n           ((function-name          {parameter...)function-body)...)\n           body-of-labels)\n\n\n\n\n     Other Special Forms\n\n     A few more special forms do not fit neatly into any category. We have already seen\n     the two special forms for creating constants and functions, quote and f u n c t i o n .\n     These are so common that they have abbreviations: ' x for (quote x) and # ' f for\n     (function f ) .\n         The special form progn can be used to evaluate a sequence of forms and return\n     the value of the last one:\n\n        (progn ( s e t f  0) ( s e t f  (+  D ) )                          1\n\n\n     progn is the equivalent of a b e g i n . . .end block in other languages, but it is used\n     very infrequently in Lisp. There are two reasons for this. First, programs written\n     in a functional style never need a sequence of actions, because they don't have side\n     effects. Second, even when side effects are used, many special forms allow for a\n     body which is a sequence--an implicit progn. I can only think of three places where\n     a progn is justified. First, to implement side effects in a branch of a two-branched\n     conditional, one could use either an i f with a progn, or a cond:\n\n        (if   (> X 100)                                                 (cond ( ( >  100)\n              (progn ( p r i n t \"too b i g \" )                                 ( p r i n t \"too b i g \" )\n                     ( s e t f X 100))                                          ( s e t f  100))\n              X)                                                              (t X ) )\n\f3.2 SPECIAL FORMS                                                                                     65\n\n\n\n         If the conditional had only one branch, then when or unl ess should be used, since\n         they allow an implicit progn. If there are more than two branches, then cond should\n         be used.\n             Second, progn is sometimes needed in macros that expand into more than one\n         top-level form, as in the d e f u n * macro on page 326, section 10.3. Third, a progn is\n         sometimes needed in an unwi nd - p r o t e c t , an advanced macro. An example of this is\n         the wi t h - resource macro on page 338, section 10.4.\n\n            The forms t r a c e and untrace are used to control debugging information about\n         entry and exit to a function:\n\n             > (trace length9)         (LENGTH9)\n\n             > (length9 ' ( a b c ) )\n             (1 ENTER LENGTH9: ( A B O )\n               (2 ENTER LENGTH9: ( B O )\n                  (3 ENTER LENGTH9: ( O )\n                    (4 ENTER LENGTH9: N I L )\n                    (4 EXIT LENGTH9: 0)\n                  (3 EXIT LENGTH9: 1)\n               (2 EXIT LENGTH9: 2)\n             (1 EXIT LENGTH9: 3)\n             3\n\n             > (untrace length9) =� (LENGTH9)\n\n            > (length9 ' ( a b c ) ) =^ 3\n\n\n         Finally, the special form return can be used to break out of a block of code. Blocks are\n         set up by the special form bl ock, or by the looping forms (do, d o * , dol i s t , dot i mes, or\n         loop). For example, the following function computes the product of a list of numbers,\n         but if any number is zero, then the whole product must be zero, so we immediately\n         return zero from the dol i s t loop. Note that this returns from the dol i s t only, not\n         from the function itself (although in this case, the value returned by dol i s t becomes\n         the value returned by the function, because it is the last expression in the function). I\n         have used uppercase letters in RETURN to emphasize the fact that it is an unusual step\n         to exit from a loop.\n\n             (defun product (numbers)\n               \" M u l t i p l y a l l the numbers together to compute t h e i r product.\"\n               ( l e t ((prod D )\n                   ( d o l i s t (n numbers prod)\n                      ( i f (=  0)\n                               (RETURN 0)\n                               ( s e t f prod (*  p r o d ) ) ) ) ) )\n\f66                                                                                        OVERVIEW OF LISP\n\n\n\n     Macros\n\n     The preceding discussion has been somewhat cavalier with the term \"special form.\"\n     Actually, some of these special forms are really macros, forms that the compiler\n     expands into some other code. Common Lisp provides a number of built-in macros\n     and allows the user to extend the language by defining new macros. (There is no way\n     for the user to define new special forms, however.)\n         Macros are defined with the special form def ma c ro. Suppose we wanted to define\n     a macro, whi 1 e, that would act like the whi 1 e loop statement of Pascal. Writing a\n     macro is a four-step process:\n\n         � Decide if the macro is really necessary.\n\n         � Write down the syntax of the macro.\n\n         � Figure out what the macro should expand into.\n\n         � Use def macro to implement the syntax/expansion correspondence.\n\n         The first step in writing a macro is to recognize that every time you write one,\n     you are defining a new language that is just like Lisp except for your new macro.\n     The programmer who thinks that way will rightfully be extremely frugal in defining\n     macros. (Besides, when someone asks, \"What did you get done today?\" it sounds\n     more impressive to say \"I defined a new language and wrote a compiler for it\" than\n     to say \"I just hacked up a couple of macros.\") Introducing a macro puts much more\n     memory strain on the reader of your program than does introducing a function,\n     variable or data type, so it should not be taken lightly. Introduce macros only when\n     there is a clear need, and when the macro fits in well with your existing system. As\n     C.A.R. Hoare put it, \"One thing the language designer should not do is to include\n     untried ideas of his own.\"\n         The next step is to decide what code the macro should expand into. It is a good\n     idea to follow established Lisp conventions for macro syntax whenever possible.\n     Look at the looping macros ( d o l i s t , dot i mes, do-symbols), the defi��ng macros\n     (defun, d e f v a r , defparameter, d e f s t r u c t ) , or the the I/O macros ( w i t h - o p e n - f i l e ,\n     with-open-stream, w i t h - i n p u t - f r o m - s t r i n g ) , for example. If you follow the nam\n     ing and syntax conventions for one of these instead of inventing your own conven\n     tions, you'll be doing the reader of your program a favor. For whi 1 e, a good syntax is:\n\n         (while test body...)\n\n     The third step is to write the code that you want a macro call to expand into:\n\f3.2 SPECIAL FORMS                                                                               67\n\n\n             (loop\n               (unless test (return n i l ) )\n               body)\n\n         The final step is to write the definition of the macro, using defmacro. A defmacro\n         form is similar to a defun in that it has a parameter list, optional documentation\n         string, and body. There are a few differences in what is allowed in the parameter list,\n         which will be covered later. Here is a definition of the macro whi 1 e, which takes a\n         test and a body, and builds up the 1 oop code shown previously:\n\n             (defmacro while ( t e s t &rest body)\n               \"Repeat body while t e s t i s t r u e . \"\n               (list* \n                      ( l i s t 'unless test '(return n i l ) )\n                      body))\n\n\n         (The function 1 i s t * is like 11 s t , except that the last argument is appended onto the\n         end of the list of the other arguments.) We can see what this macro expands into by\n         using macroexpand, and see how it runs by typing in an example:\n\n            > (macroexpand-1 ' ( w h i l e ( < i 10)\n                                 ( p r i n t (* i i ) )\n                                 ( s e t f i (+ i 1 ) ) ) )   ^\n            (LOOP (UNLESS � I 10) (RETURN N I L ) )\n                  (PRINT (* I I ) )\n                  (SETF I (+ I 1 ) ) )\n\n            > ( s e t f i 7) =^ 7\n\n            > (while ( < i 10)\n                ( p r i n t (* i i ) )\n                ( s e t f i (+ i 1 ) ) ) =>\n            49\n            64\n            81\n            NIL\n\n\n         Section 24.6 (page 853) describes a more complicated macro and some details on the\n         pitfalls of writing complicated macros (page 855).\n\n\n         Backquote Notation\n\n         The hardest part about defining whi 1 e is building the code that is the expansion of\n         the macro. It would be nice if there was a more immediate way of building code.\n         The following version of w h i l e following attempts to do just that. It defines the local\n\f68                                                                                     OVERVIEW OF LISP\n\n\n     variable code to be a template for the code we want, and then substitutes the real\n     values of the variables t e s t and body for the placeholders in the code. This is done\n     with the function subst; (subst new old tree) substitutes new for each occurrence of\n     old anywhere within tree.\n\n         (defmacro while ( t e s t &rest body)\n           \"Repeat body while t e s t i s t r u e . \"\n           (let   ((code ' ( l o o p (unless t e s t (return n i l ) )     . body)))\n              (subst t e s t ' t e s t (subst body 'body c o d e ) ) ) )\n\n\n     The need to build up code (and noncode data) from components is so frequent that\n     there is a special notation for it, the backquote notation. The backquote character\n     \" ' \" is similar to the quote character \" . A backquote indicates that what follows is\n     mostly a literal expression but may contain some components that are to be evaluated.\n     Anything marked by a leading c o m m a \" , \" is evaluated and inserted into the structure,\n     and anything marked with a leading \" ,@\" must evaluate to a Hst that is spliced into\n     the structure: each element of the list is inserted, without the top-level parentheses.\n     The notation is covered in more detail in section 23.5. Here we use the combination\n     of backquote and comma to rewrite whi 1 e:\n\n         (defmacro while ( t e s t &rest body)\n           \"Repeat body while t e s t i s t r u e . \"\n           ' ( l o o p (unless . t e s t (return n i l ) )\n                     .�body))\n\n\n     Here are some more examples of backquote. Note that at the end of a list,\", @\" has the\n     same effect as \" . \" followed by \" , \" . In the middle of a list, only \", @\" is a possibility.\n\n        > ( s e t f t e s t l ' ( a t e s t ) ) => (A TEST)\n\n        > ' ( t h i s i s . t e s t l ) => (THIS I S (A TEST))\n\n        > ' ( t h i s i s . � t e s t l ) =i> (THIS I S A TEST)\n\n        > '(this is . .testl)               (THIS I S A TEST)\n\n        > ' ( t h i s i s .�testl - - t h i s i s only . � t e s t l )\n         (THIS I S A TEST          THIS I S ONLY A TEST)\n\n\n     This completes the section on special forms and macros. The remaining sections of\n     this chapter give an overview of the important built-in functions in Common Lisp.\n\f3.3 FUNCTIONS    ON LISTS                                                                               69\n\n\n         3�3         Functions on Lists\n         For the sake of example, assume we have the following assignments:\n\n             ( s e t f  ' ( a b c))\n             (setf y ' ( 1 2 3))\n\n\n         The most important functions on lists are summarized here. The more complicated\n         ones are explained more thoroughly when they are used.\n\n          ( f i r s t x)         a                          first element of a list\n          (second x)           =>b                          second element of a list\n          ( t h i r d x)                                    third element of a list\n          (nth 0 x)            => a                         nth element of a list, 0-based\n          (rest x)             => (b c)                     all but the first element\n          (car x)              => a                         another name for the first element of a list\n          (cdr x)              = > ( b c)                   another name for all but the first element\n          ( l a s t x)         =i>(c)                       last cons cell in a list\n          (length x)           =^3                          number of elements in a list\n          (reverse x)          =>(c b a)                    puts list in reverse order\n          (cons 0 y)           = � ( 0 1 2 3)               add to front of list\n          (append  y)          =i>(a b c 1 2 3)             append together elements\n          ( l i s t  y)        =>i{d      b c) (1 2 3 ) )   make a new list\n          ( l i s t * 1 2 )    = � ( 1 2 a b c)             append last argument to others\n          (null n i l )        =>J                          predicate is true of the empty list\n          (null x)             =�nil                        ... and false for everything else\n          d i s t p x)         =>T                          predicate is true of any list, including  i 1\n          d i s t p 3)         =� n i l                     ... and is false for nonlists\n          (consp x)            =>t                          predicate is true of non-nil lists\n          (consp n i l )       =�nil                        ... and false for atoms, including  i 1\n          (equal  )            =^t                          true for lists that look the same\n          (equal  y)               nil                      ... and false for lists that look different\n          (sort y #'>)         = ^ ( 3 2 1)                 sort a list according to a comparison function\n          (subseq  1 2)        =� (B)                       subsequence with given start and end points\n\n                We said that (cons a b) builds a longer list by adding element a to the front of list\n         b, but what if b is not a list? This is not an error; the result is an object  such that\n         ( f i r s t j c ) =^a, ( r e s t j c ) b, and where ;c prints as ia . b). This is known as do�f^�/\n         pair notation. If i? is a list, then the usual list notation is used for output rather than\n         the dotted pair notation. But either notation can be used for input.\n\n             So far we have been thinking of lists as sequences, using phrases like \"a list of\n         three elements.\" The list is a convenient abstraction, but the actual implementation\n         of lists relies on lower-level building blocks called cons cells. A cons cell is a data\n         structure with two fields: a first and a rest. What we have been calling \"a list of\n         three elements\" can also be seen as a single cons cell, whose first field points to\n\f70                                                                            OVERVIEW OF LISP\n\n\n\n         the first element and whose rest field points to another cons cell that is a cons cell\n         representing a Ust of two elements. This second cons cell has a rest field that is a\n         third cons cell, one whose rest field is nil. All proper lists have a last cons cell whose\n         rest field is nil. Figure 3.1 shows the cons cell notation for the three-element list (one\n         two t h r e e ) , as well as for the result of (cons One 'two).\n\n\n                  (ONE   TWO THREE)                                          (ONE   . TWO)\n\n\n\n\n                   ONE                TWO              THREE                 ONE     TWO\n\n\n\n\n                                      Figure 3.1: Cons Cell Diagrams\n\n\n\n     S   Exercise 3.2 [s] The function cons can be seen as a special case of one of the other\n         functions listed previously. Which one?\n\n\n     S   Exercise 3.3 [m] Write a function that will print an expression in dotted pair nota\n         tion. Use the built-in function pri nc to print each component of the expression.\n\n\n     S   Exercise 3.4 [m] Write a function that, like the regular print function, will print an\n         expression in dotted pair notation when necessary but will use normal list notation\n         when possible.\n\n\n\n         3.4      Equality and Internal Representation\n         In Lisp there are five major equality predicates, because not all objects are created\n         equally equal. The numeric equality predicate, =, tests if two numbers are the same.\n         It is an error to apply = to non-numbers. The other equality predicates operate\n         on any kind of object, but to understand the difference between them, we need to\n         understand some of the internals of Lisp.\n             When Lisp reads a symbol in two different places, the result is guaranteed to be\n         the exact same symbol. The Lisp system maintains a symbol table that the function\n         read uses to map between characters and symbols. But when a list is read (or built)\n\f3.4 EQUALITY   AND INTERNAL      REPRESENTATION                                              71\n\n\n          in two different places, the results are not identically the same, even though the\n          corresponding elements may be. This is because read calls cons to build up the list,\n          and each call to cons returns a new cons cell. Figure 3.2 shows two lists, x and y,\n          which are both equal to (one two), but which are composed of different cons cells,\n          and hence are not identical. Figure 3.3 shows that the expression ( r e s t x) does not\n          generate new cons cells, but rather shares structure with x, and that the expression\n          (cons ' zero x) generates exactly one new cons cell, whose rest is x.\n\n\n\n                                            (setf X '(one two))\n\n\n\n\n                                             ONE                  TWO\n\n\n\n\n                                            (setf y '(one two))\n\n\n\n\n                                Figure 3.2: Equal But Nonidentical Lists\n\n\n\n\n                                 (cons 'zero x)                         (restx)\n\n\n                                   1\n                                   1\n                                 ZERO                    ONE            TWO\n\n\n\n\n                                           Figure 3.3: Parts of Lists\n\f72                                                                              OVERVIEW OF LISP\n\n\n\n          When two mathematically equal numbers are read (or computed) in two places,\n     they may or may not be the same, depending on what the designers of your implemen\n     tation felt was more efficient. In most systems, two equal fixnums will be identical,\n     but equal numbers of other types will not (except possibly short floats). Common\n     Lisp provides four equality predicates of increasing generality. All four begin with\n     the letters eq, with more letters meaning the predicate considers more objects to be\n     equal. The simplest predicate is eq, which tests for the exact same object. Next,\n     eql tests for objects that are either eq or are equivalent numbers, equal tests for\n     objects that are either eql or are lists or strings with eql elements. Finally, equal \n     is like equal except it also matches upper- and lowercase characters and numbers\n     of different types. The following table summarizes the results of applying each of\n     the four predicates to various values of  and y. The ? value means that the result\n     depends on your implementation: two integers that are eql may or may not be eq.\n\n                          X         y          eq     eql    equal     equal \n                           'x        'X                                \n                                               ?                       \n                           '()       �()       nil    nil              \n                           '\"xy\"     �\"xy\"     nil    nil              \n                           \"�Xy\"     '\"\"       nil    nil    nil       \n                           �0        .         nil    nil    nil       \n                                               nil    nil    nil       nil\n\n          In addition, there are specialized equaUty predicates such as =, t r e e - e q u a l ,\n     c h a r - e q u a l , and s t r i n g - e q u a l , which compare numbers, trees, characters, and\n     strings, respectively.\n\n\n\n\n     3.5       Functions on Sequences\n     Common Lisp is in a transitional position halfway between the Lisps of the past\n     and the Lisps of the future. Nowhere is that more apparent than in the sequence\n     functions. The earliest Lisps dealt only with symbols, numbers, and lists, and\n     provided Hst functions like append and 1 ength. More modern Lisps added support\n     for vectors, strings, and other data types, and introduced the term sequence to refer\n     to both vectors and lists. (A vector is a one-dimensional array. It can be represented\n     more compactly than a list, because there is no need to store the r e s t pointers. It\n     is also more efficient to get at the nth element of a vector, because there is no need\n     to follow a chain of pointers.) Modern Lisps also support strings that are vectors of\n     characters, and hence also a subtype of sequence.\n         With the new data types came the problem of naming functions that operated\n     on them. In some cases. Common Lisp chose to extend an old function: 1 ength can\n\f3.6 FUNCTIONS   FOR MAINTAINING          TABLES                                                   73\n\n\n         apply to vectors as well as lists. In other cases, the old names were reserved for the\n         list functions, and new names were invented for generic sequence functions. For\n         example, append and mapcar only work on lists, but concatenate and map work on\n         any kind of sequence. In still other cases, new functions were invented for specific\n         data types. For example, there are seven functions to pick the nth element out of a\n         sequence. The most general is e 11, which works on any kind of sequence, but there are\n         specific functions for lists, arrays, strings, bit vectors, simple bit vectors, and simple\n         vectors. Confusingly, nth is the only one that takes the index as the first argument:\n\n             (nth  list)\n             ieM sequence n)\n             {aref array n)\n             {char string n)\n             (bit bit vector n)\n             (s b i t simple-hit vector )\n             (s V ref simple-vector )\n\n         The most important sequence functions are listed elsewhere in this chapter, depend\n         ing on their particular purpose.\n\n\n\n         3.6       Functions for Maintaining Tables\n         Lisp lists can be used to represent a one-dimensional sequence of objects. Because\n         they are so versatile, they have been put to other purposes, such as representing\n         tables of information. The association list is a type of list used to implement tables.\n         An association list is a list of dotted pairs, where each pair consists of a key and a value.\n         Together, the list of pairs form a table: given a key, we can retrieve the corresponding\n         value from the table, or verify that there is no such key stored in the table. Here's\n         an example for looking up the names of states by their two-letter abbreviation. The\n         function a s s oc is used. It returns the key/value pair (if there is one). To get the value,\n         we just take the cdr of the result returned by assoc.\n\n             (setf state-table\n               '((AL . Alabama) (AK . Alaska) (AZ . Arizona) (AR . A r k a n s a s ) ) )\n\n            > (assoc   s t a t e - t a b l e ) ^   (AK . ALASKA)\n\n            > (cdr (assoc *AK s t a t e - t a b l e ) ) ^   ALASKA\n            > (assoc 'TX s t a t e - t a b l e ) => NIL\n\n\n         If we want to search the table by value rather than by key, we can use rassoc:\n\n            > (rassoc 'Arizona table)              (AZ . ARIZONA)\n\f74                                                                     OVERVIEW OF LISP\n\n\n\n        > (car (rassoc 'Arizona t a b l e ) ) => AZ\n\n\n     Managing a table with assoc is simple, but there is one drawback: we have to search\n     through the whole list one element at a time. If the list is very long, this may take\n     a while.\n         Another way to manage tables is with hash tables. These are designed to han\n     dle large amounts of data efficiently but have a degree of overhead that can make\n     them inappropriate for small tables. The function gethash works much like get--it\n     takes two arguments, a key and a table. The table itself is initialized with a call to\n     make-hash-tab! e and modified with a s e t f of gethash:\n\n        ( s e t f table (make-hash-table))\n\n        ( s e t f (gethash 'AL table)       'Alabama)\n        ( s e t f (gethash   t a b l e )    'Alaska)\n        ( s e t f (gethash   table)         'Arizona)\n        ( s e t f (gethash 'AR table)       'Arkansas)\n\n\n     Here we retrieve values from the table:\n\n        > (gethash   table) ^              ALASKA\n        > (gethash 'TX t a b l e ) => NIL\n\n\n     The function remhash removes a key/value pair from a hash table, cl rhash removes\n     all pairs, and maphash can be used to map over the key/value pairs. The keys to hash\n     tables are not restricted; they can be any Lisp object. There are many more details\n     on the implementation of hash tables in Common Lisp, and an extensive Uterature\n     on their theory.\n         A third way to represent table is with property lists. A property list is a Hst of\n     alternating key/value pairs. Property lists (sometimes called p-lists or plists) and\n     association lists (sometimes called a-lists or alists) are similar:\n\n        a - l i s t ; iikeyi . vah) {keyi . vali) ... {keyn . vain))\n        p - l i s t : {key I val\\ key 2 vah ... key  vain)\n\n     Given this representation, there is little to choose between a-Hsts and p-lists. They\n     are slightly different permutations of the same information. The difference is in how\n     they are normally used. Every symbol has a property list associated with it. That\n     means we can associate a property/value pair directly with a symbol. Most programs\n     use only a few different properties but have many instances of property/value pairs\n     for each property. Thus, each symbol's p-list wiH likely be short. In our example,\n     we are only interested in one property: the state associated with each abbreviation.\n\f3.6 FUNCTIONS   FOR MAINTAINING                TABLES                                        75\n\n\n\n         That means that the property lists will be very short indeed: one property for each\n         abbreviation, instead of a list of 50 pairs in the association list implementation.\n            Property values are retrieved with the function g e t , which takes two arguments:\n         the first is a symbol for which we are seeking information, and the second is the\n         property of that symbol that we are interested in. get returns the value of that\n         property, if one has been stored. Property/value pairs can be stored under a symbol\n         with a s e t f form. A table would be built as follows:\n\n            (setf     (get    'AL    'state)      'Alabama)\n            (setf     (get           'state)      'Alaska)\n            (setf     (get           'state)      'Arizona)\n            (setf     (get    'AR    'state)      'Arkansas)\n\n\n         Now we can retrieve values with get:\n\n            > (get   ' s t a t e ) =^ ALASKA\n            > (get 'TX ' s t a t e ) => NIL\n\n\n         This will be faster because we can go immediately from a symbol to its lone property\n         value, regardless of the number of symbols that have properties. However, if a given\n         symbol has more than one property, then we still have to search linearly through the\n         property list. As Abraham Lincoln might have said, you can make some of the table\n         lookups faster some of the time, but you can't make all the table lookups faster all\n         of the time. Notice that there is no equivalent of rassoc using property lists; if you\n         want to get from a state to its abbreviation, you could store the abbreviation under a\n         property of the state, but that would be a separate s e t f form, as in:\n\n            ( s e t f (get 'Arizona 'abbrev) *AZ)\n\n\n         In fact, when source, property, and value are all symbols, there are quite a few\n         possibilities for how to use properties. We could have mimicked the a-list approach,\n         and Usted all the properties under a single symbol, using s e t f on the function\n         symbol - pi i s t (which gives a symbol's complete property list):\n\n            (setf (symbol-piist 'state-table)\n                      '(AL Alabama AK Alaska AZ Arizona AR Arkansas))\n\n            > (get ' s t a t e - t a b l e ' A D =^ ALASKA\n\n            > (get ' s t a t e - t a b l e ' A l a s k a )   NIL\n\n         Property lists have a long history in Lisp, but they are falling out of favor as new\n         alternatives such as hash tables are introduced. There are two main reasons why\n         property lists are avoided. First, because symbols and their property lists are global.\n\f76                                                                                    OVERVIEW      OF LISP\n\n\n\n     it is easy to get conflicts when trying to put together two programs that use property\n     lists. If two programs use the same property for different purposes, they cannot be\n     used together. Even if two programs use different properties on the same symbols,\n     they will slow each other down. Second, property lists are messy. There is no way to\n     remove quickly every element of a table implemented with property Hsts. In contrast,\n     this can be done trivially with cl rhash on hash tables, or by setting an association\n     Hst to nil.\n\n\n\n\n     3.7        Functions on Trees\n     Many Common Lisp functions treat the expression ((a b) ( ( c ) ) (d e ) ) a s a\n     sequence of three elements, but there are a few functions that treat it as a tree with\n     five non-null leaves. The function copy - t r e e creates a copy of a tree, and t r e e - equa 1\n     tests if two trees are equal by traversing cons cells, but not other complex data like\n     vectors or strings. In that respect, tree-equal is similar to equal, but tree-equal is\n     more powerful because it allows a : t e s t keyword:\n\n         > ( s e t f tree ' ( ( a b) ( ( c ) ) (d e ) ) )\n\n         > (tree-equal tree (copy-tree t r e e ) )           \n\n         (defun same-shape-tree (a b)\n           \"Are two trees the same except for the l e a v e s ? \"\n           (tree-equal a b : t e s t # * t r u e ) )\n\n         (defun true (&rest ignore)            t)\n\n        > (same-shape-tree tree ' ( ( 1 2) ( ( 3 ) ) (4 5 ) ) ) ^        \n\n        > (same-shape-tree tree ' ( ( 1 2) (3) (4 5 ) ) ) => NIL\n\n\n     Figure3.4shows thetree ( ( a b) ( ( c ) ) (d e ) ) as a cons ceU diagram.\n         There are also two functions for substituting a new expression for an old one\n     anywhere within a tree, subst substitutes a single value for another, while sub! i s\n     takes a list of substitutions in the form of an association Hst of (old . new) pairs.\n     Note that the order of old and new in the a-Hst for subl i s is reversed from the order\n     of arguments to subst. The name subl i s is uncharacteristically short and confusing;\n     a better name would be subst - 1 i S t .\n\n        > (subst 'new ' o l d ' ( o l d ((very o l d ) ) ) ^    (NEW ((VERY NEW)))\n\n        > ( s u b l i s ' ( ( o l d . new)) ' ( o l d ((very o l d ) ) ) ) = ^ (NEW ((VERY NEW)))\n\n        > (subst 'new ' o l d O l d ) => 'NEW\n\f3.7 FUNCTIONS    ON TREES                                                                                  77\n\n\n            (defun e n g l i s h - > f r e n c h (words)\n              ( s u b l i s ' ( ( a r e . va) (book . l i b r e ) ( f r i e n d . ami)\n                                 ( h e l l o . bonjour) (how . comment) (my . mon)\n                                 (red . rouge) (you . t u ) )\n                            words))\n\n            > ( e n g l i s h - > f r e n c h ' ( h e l l o my f r i e n d - how are you t o d a y ? ) )\n            (BONJOUR MON AMI - COMMENT VA TU TODAY?)\n\n\n\n\n                ((ab) ((c)) (de))\n\n\n\n\n                                       Figure 3.4: Cons Cell Diagram of a Tree\n\f78                                                                                OVERVIEW      OF LISP\n\n\n\n     3.8        Functions on Numbers\n     The most commonly used functions on numbers are listed here. There are quite a\n     few other numeric functions that have been omitted.\n\n           ( + 4 2)             =>6         add\n           (- 4 2)              =^Z         subtract\n           ( * 4 2)             ^ 8         multiply\n           (/   4 2)            =>2         divide\n           ( > 100 99)                      greater than (also >=, greater than or equal to)\n           ( = 100 100)                     equal (also / = , not equal)\n           ( < 99 100)                      less than (also <=, less than or equal to)\n           (random 100)         =^42        random integer from 0 to 99\n           (expt 4 2)           =i>16       exponentiation (also exp,             and 1 eg)\n           (sin   pi)           ^0.0        sine function (also c o s , t a n , etc.)\n           ( a s i n 0)         =>0.0       arcsine or sin~^ function (also acos, atan, etc.)\n           (min 2 3 4)          =>2         minimum (also max)\n           (abs   -3)           =>3         absolute value\n           ( s q r t 4)                     square root\n           (round 4 . 1 )                   round off (also t r u n c a t e , f 1 cor, cei 1 i ng)\n           (rem 11 5)                       remainder (also mod)\n\n\n\n     3.9        Functions on Sets\n     One of the important uses of lists is to represent sets. Common Lisp provides\n     functions that treat lists in just that way. For example, to see what elements the sets\n     r = { a , 6, c, d} and s = { c , d, e} have in common, we could use:\n\n        > (setf  ' ( a b c d ) )               (A  C D)\n        > ( s e t f s ' ( c d e ) ) = (C D E)\n        > ( i n t e r s e c t i o n r s ) = > (C D)\n\n\n     This implementation returned (C D) as the answer, but another might return ( D C ) .\n     They are equivalent sets, so either is valid, and your program should not depend on\n     the order of elements in the result. Here are the main functions on sets:\n\n        (intersection r s)             =^ (c d)           find common elements of two sets\n        (union r s)                       (a b c d e)     find all elements in either of two sets\n        (set -difference r s)          =>(a b)            find elements in one but not other set\n        (member *d r)                  ^(d)               check if an element is a member of a set\n        (subsetp s r)                  =>nil              see if all elements of one set are in another\n        (adjoin 'b s)                  = ^ ( b c d e)     add an element to a set\n        (adjoin 'c s)                  =>{c � e)          . . . but don't add duplicates\n\f3.10 DESTRUCTIVE    FUNCTIONS                                                                    79\n\n\n             It is also possible to represent a set with a sequence of bits, given a particular\n         universe of discourse. For example, if every set we are interested in must be a subset\n         of(a b c d e ) , then we can use the bit sequence 111 10 to represent (a b c d ) , 00000\n         to represent the empty set, and 11001 to represent (a b e ) . The bit sequence can be\n         represented in Common Lisp as a bit vector, or as an integer in binary notation. For\n         example, (a b e ) would be the bit vector #* 11001 or the integer 25, which can also\n         be written as #bllOOL\n             The advantage of using bit sequences is that it takes less space to encode a set,\n         assuming a small universe. Computation will be faster, because the computer's\n         underlying instruction set will typically process 32 elements at a time.\n             Common Lisp provides a full complement of functions on both bit vectors and\n         integers. The following table lists some, their correspondence to the list functions.\n\n                               lists                integers     bit vectors\n                                intersection        logand        bit-and\n                                union               logior        bit-ior\n                                set-difference      logandc2      bit-andc2\n                               member               logbitp       bit\n                                length              logcount\n\n\n             For example,\n\n             (intersection '(a b e d ) '(a b e))        (A B)\n             (bit-and      #*11110     #*11001)         #*11000\n             (logand       #bllllO     #bll001)         24 = #bll000\n\n\n\n\n         3.10       Destructive Functions\n         In mathematics, a function is something that computes an output value given some\n         input arguments. Functions do not \"do\" anything, they just compute results. For\n         example, if I tell you that  = 4 and y = 5 and ask you to apply the function \"plus\" to\n         X and y, I expect you to tell me 9. If I then ask, \"Now what is the value of x?\" it would\n         be surprising if  had changed. In mathematics, applying an operator to  can have\n         no effect on the value of x .\n             In Lisp, some functions are able to take effect beyond just computing the result.\n         These \"functions\" are not functions in the mathematical sense,^ and in other lan\n         guages they are known as \"procedures.\" Of course, most of the Lisp functions are true\n         mathematical functions, but the few that are not can cause great problems. They can\n\n            ^In mathematics, a function must associate a unique output value with each input value.\n\f80                                                                                        OVERVIEW OF LISP\n\n\n\n         also be quite useful in certain situations. For both reasons, they are worth knowing\n         about.\n             Consider the following:\n\n             > (setf X '(a b c ) )      (A  C)\n             > (setf y ' ( 1 2 3 ) ) => ( 1 2 3)\n             > (append  y) =^ (A  C 1 2 3)\n\n\n         append is a pure function, so after evaluating the call to append, we can rightfully\n         expect that  and y retain their values. Now consider this:\n\n             > (nconc X y)  (A  C 1 2 3)\n             >  =^ (A  C 1 2 3)\n             > y    (1 2 3)\n\n\n         The function nconc computes the same result as append, but it has the side effect\n         of altering its first argument. It is called a destructive function, because it destroys\n         existing structures, replacing them with new ones. This means that there is quite\n         a conceptual load on the programmer who dares to use nconc. He or she must be\n         aware that the first argument may be altered, and plan accordingly. This is far more\n         complicated than the case with nondestructive functions, where the programmer\n         need worry only about the results of a function call.\n             The advantage of nconc is that it doesn't use any storage. While append must\n         make a complete copy of x and then have that copy end with y, nconc does not need\n         to copy anything. Instead, it just changes the r e s t field of the last element of x to\n         point to y. So use destructive functions when you need to conserve storage, but be\n         aware of the consequences.\n             Besides nconc, many of the destructive functions have names that start with\n         n, including nreverse, n i n t e r s e c t i o n , nunion, n s e t - d i f f e r e n c e , and nsubst. An\n         important exception is del e t e , which is the name used for the destructive version of\n         remove. Of course, the s e t f special form can also be used to alter structures, but it\n         is the destructive functions that are most dangerous, because it is easier to overlook\n         their effects.\n\n\n     @   Exercise 3.5 [h] (Exercise in altering structure.) Write a program that will play the\n         role of the guesser in the game Twenty Questions. The user of the program will have\n         in mind any type of thing. The program will ask questions of the user, which must\n         be answered yes or no, or \"it\" when the program has guessed it. If the program runs\n         out of guesses, it gives up and asks the user what \"it\" was. At first the program will\n         not play well, but each time it plays, it will remember the user's replies and use them\n         for subsequent guesses.\n\f3.11 OVERVIEW OF DATATYPES                                                                     81\n\n\n         3.11        Overview of Data Types\n        This chapter has been organized around functions, with similar functions grouped\n        together. But there is another way of organizing the Common Lisp world: by con\n        sidering the different data types. This is useful for two reasons. First, it gives an\n        alternative way of seeing the variety of available functionality. Second, the data types\n        themselves are objects in the Common Lisp language, and as we shall see, there are\n        functions that manipulate data types. These are useful mainly for testing objects (as\n        with the typecase macro) and for making declarations.\n            Here is a table of the most commonly used data types:\n\n        Type         Example           Explanation\n        character    #\\c               A single letter, number, or punctuation mark.\n        number       42                The most common numbers are floats and integers.\n        float        3.14159           A number with a decimal point.\n        integer      42                A whole number, of either fixed or indefinite size:\n        fixnum       123               An integer that fits in a single word of storage.\n        bignum       123456789         An integer of unbounded size.\n        function     #'sin             A function can be applied to an argument list.\n        symbol       sin               Symbols can name fns and vars, and are themselves objects.\n        null         nil               The object ni 1 is the only object of type null.\n        keyword       :key             Keywords are a subtype of symbol.\n        sequence     (a b c)           Sequences include lists and vectors.\n        list         (a b c)           A list is either a cons or nul 1.\n        vector       #(a b c)          A vector is a subtype of sequence.\n        cons         (a b c)           A cons is a non-nil list.\n        atom         t                 An atom is anything that is not a cons.\n        string       \"abc\"             A string is a type of vector of characters.\n        array        #lA(a b c)        Arrays include vectors and higher-dimensional arrays.\n        structure    #S(type . . . )   Structures are defined by defstruct.\n        hash-table                     Hash tables are created by make-hash-tabl e.\n\n            Almost every data type has a recognizer predicate--a function that returns true\n        for only elements of that type. In general, a predicate is a function that always\n        returns one of two values: true or false. In Lisp, the false value is ni 1 , and every\n        other value is considered true, although the most common true value is t. In most\n        cases, the recognizer predicate's name is composed of the type name followed by\n        p: characterp recognizes characters, numberp recognizes numbers, and so on. For\n        example, (numberp 3) returns t because 3 is a number, but (numberp \"x\") returns\n         i 1 because \"\" is a string, not a number.\n            Unfortunately, Common Lisp is not completely regular. There are no recognizers\n        for fixnums, bignums, sequences, and structures. Two recognizers, nul 1 and atom,\n        do not end in p. Also note that there is a hyphen before the  in hash-table-p,\n        because the type has a hyphen in it. In addition, all the recognizers generated by\n        defstruct have a hyphen before the p.\n\f82                                                                                     OVERVIEW     OF LISP\n\n\n\n               The function type - of returns the type of its argument, and typep tests if an object\n           is of a specified type. The function subtypep tests if one type can be determined to\n           be a subtype of another. For example:\n\n               > (type-of 123) ^       FIXNUM\n\n               > (typep 123 'fixnum)          \n\n               > (typep 123 'number)          \n\n               > (typep 123 ' i n t e g e r ) => \n\n               > (typep 123.0 ' i n t e g e r ) ^ NIL\n\n               > (subtypep 'fixnum 'number) => \n\n\n            The hierarchy of types is rather complicated in Common Lisp. As the prior example\n            shows, there are many different numeric types, and a number like 123 is considered\n            to be of type fixnum, i n t e g e r , and number. We will see later that it is also of type\n            rational andt.\n               The type hierarchy forms a graph, not just a tree. For example, a vector is both\n           a sequence and an array, although neither array nor sequence are subtypes of each\n           other. Similarly, nul 1 is a subtype of both symbol and 1 i s t .\n               The following table shows a number of more specialized data types that are not\n           used as often:\n\n     Type              Example                      Explanation\n     t                 42                           Every object is of type t.\n     nil                                            No object is of type n i l .\n     complex           #C(0 1)                      Imaginary numbers.\n     bit               0                            Zero or one.\n     rational          2/3                          Rationals include integers and ratios.\n     ratio             2/3                          Exact fractional numbers.\n     simple-array       #lA(x y )                   An array that is not displaced or adjustable.\n     readtable                                      A mapping from characters to their meanings to read.\n     package                                        A collection of symbols that form a module.\n     pathname           #P'7usr/spool/mail\"         A file or directory name.\n     stream                                         A pointer to an open file; used for reading or printing.\n     random-state                                   A state used as a seed by random.\n\n               In addition, there are even more specialized types, such as s ho r t - f 1 oa t, comp i 1 ed -\n           f uncti on, and bi t - v e c t o r . It is also possible to construct more exact types, such as\n           (vector ( i n t e g e r 0 3) 100), which represents a vector of 100 elements, each of\n           which is an integer from 0 to 3, inclusive. Section 10.1 gives more information on\n           types and their use.\n                While almost every type has a predicate, it is also true that there are predicates\n            that are not type recognizers but rather recognize some more general condition. For\n\f3.12 INPUT/OUTPUT                                                                                83\n\n\n\n          example, oddp is true only of odd integers, and s t r i ng-greaterp is true if one string\n          is alphabetically greater than another.\n\n\n\n\n          3.12 Input/Output\n\n          Input in Lisp is incredibly easy because a complete lexical and syntactic parser is\n          available to the user. The parser is called read. It is used to read and return a single\n          Lisp expression. If you can design your application so that it reads Lisp expressions,\n          then your input worries are over. Note that the expression parsed by read need not\n          be a legal evaluable Lisp expression. That is, you can read ( \" h e l l o \" cons zzz) just\n          as well as (+ 2 2 ) . In cases where Lisp expressions are not adequate, the function\n          read-char reads a single character, and read-1 i ne reads everything up to the next\n          newline and returns it as a string.\n             To read from the terminal, the functions read, read-char, or read-line (with\n          no arguments) return an expression, a character, and a string up to the end of line,\n          respectively. It is also possible to read from a file. The function open or the macro\n          with-open-stream can be used to open a file and associate it with a stream, Lisp's\n          name for a descriptor of an input/output source. All three read functions take three\n          optional arguments. The first is the stream to read from. The second, if true, causes\n          an error to be signaled at end of file. If the second argument is nil, then the third\n          argument indicates the value to return at end of file.\n              Output in Lisp is similar to output in other languages, such as C. There are a\n          few low-level functions to do specific kinds of output, and there is a very general\n          function to do formatted output. The function print prints any object on a new line,\n          with a space following it. pr i nl will print any object without the new line and space.\n          For both functions, the object is printed in a form that could be processed by read.\n          Forexample, the string \"hello there\" would print as \"hello there\". Thefunction\n           r i  c is used to print in a human-readable format. The string in question would print\n          as hel 1 o there with pri nc--the quote marks are not printed. This means that read\n          cannot recover the original form; read would interpret it as two symbols, not one\n          string. The function wri t e accepts eleven different keyword arguments that control\n          whether it acts like pri nl or pri c, among other things.\n\n               The output functions also take a stream as an optional argument. In the following,\n          we create the file \" t e s t . t e x t \" and print two expressions to it. Then we open the\n          file for reading, and try to read back the first expression, a single character, and then\n          two more expressions. Note that the read-char returns the character #\\G, so the\n          following read reads the characters OODBYE and turns them into a symbol. The final\n          read hits the end of file, and so returns the specified value, eof.\n\f84                                                                                                     OVERVIEW   OF LISP\n\n\n\n        > ( w i t h - o p e n - f i l e (stream \" t e s t . t e x t \"   i d i r e c t l o n :output)\n             ( p r i n t ' ( h e l l o there) stream)\n             (princ 'goodbye stream))\n         GOODBYE               ; and creates the file test.text\n        > ( w i t h - o p e n - f i l e (stream \" t e s t . t e x t \" i d i r e c t i o n .-input)\n             ( l i s t (read stream) (read-char stream) (read stream)\n                         (read stream nil ' e o f ) ) ) ^\n        ((HELLO THERE) #\\G OODBYE EOF)\n\n\n     The function terpri stands for \"terminate print line,\" and it skips to the next line.\n     The function fresh -1 i ne also skips to the next line, unless it can be determined that\n     the output is already at the start of a line.\n         Common Lisp also provides a very general function for doing formatted output,\n     called format. The first argument to format is always the stream to print to; use\n     t to print to the terminal. The second argument is the format string. It is printed\n     out verbatim, except for format directives, which begin with the character \" ~\". These\n     directives tell how to print out the remaining arguments. Users of C's pri n t f func\n     tion or FORTRAN 'S format statement should be familiar with this idea. Here's\n     an example:\n\n        > (format t \" h e l l o , world\")\n        h e l l o , world\n        NIL\n\n\n     Things get interesting when we put in additional arguments and include format\n     directives:\n\n        > (format t \" ~ r a plus -^s i s ~f\"                   \"two\" \"two\" 4)\n        two plus \"two\" i s 4.0\n        NIL\n\n\n     Thedirective \"~&\" moves to a fresh line, \"~a\" printsthenextargumentas pri no would,\n     \" ~ s\" prints the next argument as  r i  1 would, and \" ~ f\" prints a number in floating\n     point format. If the argument is not a number, then princ is used, format always\n     returns nil. There are 26 different format directives. Here's a more complex example:\n\n        > ( l e t ((numbers ' ( 1 2 3 4 5 ) ) )\n              (format t \"~&~{~r~\" plus \" } i s ~@r\"\n                       numbers (apply # ' + numbers)))\n        one plus two plus three plus four plus f i v e i s XV\n        NIL\n\n\n     The directive \"~r\" prints the next argument, which should be a number, in English,\n\f3.13 DEBUGGING     TOOLS                                                                          85\n\n\n\n          and \" ~�\" prints a number as a roman numeral. The compound directive \" ~ { . . . \" } \"\n          takes the next argument, which must be a list, and formats each element of the list\n          according to the format string inside the braces. Finally, the directive               exits\n          from the enclosing \" ' ' i . . . \" } \" loop if there are no more arguments. You can see that\n          format, like 1 oop, comprises almost an entire programming language, which, also\n          like 1 oop, is not a very Lisplike language.\n\n\n\n          3.13          Debugging Tools\n          In many languages, there are two strategies for debugging: (1) edit the program to\n          insert print statements, recompile, and try again, or (2) use a debugging program to\n          investigate (and perhaps alter) the internal state of the running program.\n               Common Lisp admits both these strategies, but it also offers a third: (3) add\n          annotations that are not part of the program but have the effect of automatically\n          altering the running program. The advantage of the third strategy is that once\n          you are done you don't have to go back and undo the changes you would have\n          introduced in the first strategy. In addition, Common Lisp provides functions that\n          display information about the program. You need not rely solely on looking at the\n          source code.\n               We have already seen how t r a c e and untrace can be used to provide debugging\n          information (page 65). Another useful tool is s t e p, which can be used to halt execution\n          before each subform is evaluated. The form (step expression) will evaluate and return\n          expression, but pauses at certain points to allow the user to inspect the computation,\n          and possibly change things before proceeding to the next step. The commands\n          available to the user are implementation-dependent, but typing a ? should give you\n          a list of commands. As an example, here we step through an expression twice, the\n          first time giving commands to stop at each subevaluation, and the second time giving\n          commands to skip to the next function call. In this implementation, the commands\n          are control characters, so they do not show up in the output. All output, including\n          the symbols <= and => are printed by the stepper itself; I have added no annotation.\n\n             > (step (+ 3 4 ( * 5 6 ( / 7 8 ) ) ) )\n             <i= (+ 3   4 (* 5 6 ( / 7 8 ) ) )\n\n                 <i= 4 =i> 4\n                 <^ (* 5 6 (/ 7 8 ) )\n                    <^ 5 ^ 5\n\n                   <^ ( / 7 8)\n                         7     7\n                         8 =^ 8\n                   ^ (/ 7 8)        7/8\n\f86                                                                                           OVERVIEW OF LISP\n\n\n\n           ^ (* 5 6 ( / 7 8 ) ) 105/4\n         <^ (+ 3 4 ( * 5 6 ( / 7 8 ) ) ) ^ 133/4\n         133/4\n\n         > (step (+ 3 4 (* 5 6 ( / 7 8 ) ) ) )\n         ^ (+ 3 4 (* 5 6 (/ 7 8 ) ) )\n           / : 7 8 =^ 7 / 8\n           *: 5 6 7/8      105/4\n           + : 3 4 105/4     133/4\n              (+ 3 4 (* 5 6 ( / 7 8 ) ) ) =^ 133/4\n         133/4\n\n\n     The functions d e s c r i be, i n s p e c t , documentati on, and a p r o p o s provide information\n     about the state of the current program, a p r o p o s prints information about all symbols\n     w h o s e name matches the argument:\n\n\n         > (apropos ' s t r i n g )\n         MAKE-STRING                         function      (LENGTH &KEY INITIAL-ELEMENT)\n         PRINl-TO-STRING                     function      (OBJECT)\n         PRINC-TO-STRING                     function      (OBJECT)\n         STRING                              function     (X)\n\n\n\n     Once you know what obj ect you are interested in, des c r i be can give more information\n     on it:\n\n\n         > (describe ' m a k e - s t r i n g )\n         Symbol MAKE-STRING i s i n LISP package.\n         The function d e f i n i t i o n i s #<FUNCTION MAKE-STRING -42524322>:\n              NAME:          MAKE-STRING\n             ARGLIST:         (LENGTH &KEY INITIAL-ELEMENT)\n             DOCUMENTATION: \"Creates and returns a s t r i n g of LENGTH elements,\n         a l l set to INITIAL-ELEMENT.\"\n              DEFINITION:     (LAMBDA (LENGTH &KEY INITIAL-ELEMENT)\n                                   (MAKE-ARRAY LENGTH :ELEMENT-TYPE 'CHARACTER\n                                                  :INITIAL-ELEMENT (OR INITIAL-ELEMENT\n                                                                       #\\SPACE)))\n         MAKE-STRING has property INLINE: INLINE\n         MAKE-STRING has property :SOURCE-FILE: #P\"SYS:KERNEL; STRINGS\"\n\n         > (describe 1234.56)\n         1234.56 i s a s i n g l e - p r e c i s i o n f l o a t i n g - p o i n t number.\n           Sign 0 , exponent #o211. 2 3 - b i t f r a c t i o n #06450754\n\n\n     If all you want is a symbol's documentation string, the function d o c u m e n t a t i on will\n     do the trick:\n\f3,14   ANTIBUGGING      TOOLS                                                                                      87\n\n\n\n                > (documentation ' f i r s t ' f u n c t i o n ) =^ \"Return the f i r s t element of L I S T . '\n                > (documentation ' p i ' v a r i a b l e ) =^ \" p i \"\n\n\n\n\n                 If you want to look at and possibly alter components of a complex structure,\n            then i nspect is the tool. In some implementations it invokes a fancy, window-based\n            browser.\n                 Common Lisp also provides a debugger that is entered automatically when an\n            error is signalled, either by an inadvertant error or by deliberate action on the part\n            of the program. The details of the debugger vary between implementations, but\n            there are standard ways of entering it. The function break enters the debugger\n            after printing an optional message. It is intended as the primary method for setting\n            debugging break points, break is intended only for debugging purposes; when a\n            program is deemed to be working, all calls to break should be removed. However,\n            it is still a good idea to check for unusual conditions with e r r o r , c e r r o r , a s s e r t , or\n            check - ty pe, which will be described in the following section.\n\n\n\n\n            3.14         Antibugging Tools\n            It is a good idea to include antibugging checks in your code, in addition to doing normal\n            debugging. Antibugging code checks for errors and possibly takes corrective action.\n                  The functions e r r o r and c e r r o r are used to signal an error condition. These are\n            intended to remain in the program even after it has been debugged. The function\n            e r r o r takes a format string and optional arguments. It signals a fatal error; that is, it\n            stops the program and does not offer the user any way of restarting it. For example:\n\n                (defun average (numbers)\n                  ( i f (null numbers)\n                        ( e r r o r \"Average of the empty l i s t i s undefined.\")\n                        ( / (reduce # ' + numbers)\n                              (length numbers))))\n\n\n            In many cases, a fatal error is a little drastic. The function c e r r o r stands for con-\n            tinuable error, c e r r o r takes two format strings; the first prints a message indicating\n            what happens if we continue, and the second prints the error message itself, c e r r o r\n            does not actually take any action to repair the error, it just allows the user to signal\n            that continuing is alright. In the following implementation, the user continues by\n            typing : conti nue. In ANSI Common Lisp, there are additional ways of specifying\n            options for continuing.\n\f88                                                                               OVERVIEW   OF LISP\n\n\n\n        (defun average (numbers)\n          ( i f (null numbers)\n                (progn\n                   (cerror \"Use 0 as the average.\"\n                            \"Average of the empty l i s t i s undefined.\")\n                   0)\n                ( / (reduce # ' + numbers)\n                     (length numbers))))\n\n        > (average ' ( ) )\n        E r r o r : Average of the empty l i s t i s undefined.\n        Error s i g n a l e d by function AVERAGE.\n        I f continued: Use 0 as the average.\n        �     :continue\n        0\n\n\n     In this example, adding error checking nearly doubled the length of the code. This\n     is not unusual; there is a big difference between code that works on the expected\n     input and code that covers all possible errors. Common Lisp tries to make it easier\n     to do error checking by providing a few special forms. The form ecase stands for\n     \"exhaustive case\" or \"error case.\" It is like a normal case form, except that if none\n     of the cases are satisfied, an error message is generated. The form cease stands for\n     \"continuable case.\" It is like ecase, except that the error is continuable. The system\n     will ask for a new value for the test object until the user supplies one that matches\n     one of the programmed cases.\n\n         To make it easier to include error checks without inflating the length of the code\n     too much. Common Lisp provides the special forms check-type and a s s e r t . As\n     the name implies, check-type is used to check the type of an argument. It signals a\n     continuable error if the argument has the wrong type. For example:\n\n        (defun sqr (x)\n          \" M u l t i p l y  by i t s e l f . \"\n          (check-type  number)\n           (*   X X))\n\n\n\n     If s q r is called with a non-number argument, an appropriate error message is printed:\n\n        > (sqr \" h e l l o \" )\n        E r r o r : the argument X was \" h e l l o \" , which i s not a NUMBER.\n        I f continued: replace X with new value\n        � :continue 4\n        16\n\n\n     a s s e r t is more general than check-type. In the simplest form, a s s e r t tests an\n\f3.14   ANTIBUCCING         TOOLS                                                                    89\n\n\n\n            expression and signals an error if it is false. For example:\n\n\n                (defun sqr (x)\n                     \" M u l t i p l y X by i t s e l f . \"\n                     ( a s s e r t (numberp x ) )\n                     (*   X X))\n\n\n\n            There is no possibility of continuing from this kind of assertion. It is also possible to\n            give a s s e r t a list of places that can be modified in an attempt to make the assertion\n            true. In this example, the variable  is the only thing that can be changed:\n\n\n                (defun sqr (x)\n                     \" M u l t i p l y X by i t s e l f . \"\n                     ( a s s e r t (numberp x) ( x ) )\n                     (*   X X))\n\n\n\n            If the assertion is violated, an error message will be printed and the user will be given\n            the option of continuing by altering x. If  is given a value that satisfies the assertion,\n            then the program continues, a s s e r t always returns nil.\n                 Finally, the user who wants more control over the error message can provide\n            a format control string and optional arguments. So the most complex syntax for\n            a s s e r t is:\n\n\n                (assert test-form (place...) format-ctl-string format-arg...)\n\n\n            Here is another example. The assertion tests that the temperature of the bear's\n            porridge is neither too hot nor too cold.\n\n                (defun eat-porridge (bear)\n                     ( a s s e r t ( < too-cold (temperature (bear-porridge bear)) too-hot)\n                                  (bear (bear-porridge bear))\n                                  \" ~ a ' s porridge i s not j u s t r i g h t : ~a\"\n                                  bear (hotness (bear-porridge b e a r ) ) )\n                     (eat (bear-porridge b e a r ) ) )\n\n\n            In the interaction below, the assertion failed, and the programmer's error message\n            was printed, along with two possibilities for continuing. The user selected one, typed\n            in a call to ma ke - por r i dge for the new value, and the function succesfully continued.\n\f90                                                                             OVERVIEW OF LISP\n\n\n\n        > (eat-porridge momma-bear)\n        E r r o r : #<MOMMA BEAR>*s porridge i s not j u s t r i g h t : 39\n        Restart actions ( s e l e c t using : c o n t i n u e ) :\n         0: Supply a new value for BEAR\n         1 : Supply a new value for (BEAR-PORRIDGE BEAR)\n        � :continue 1\n        Form to evaluate and use to replace (BEAR-PORRIDGE BEAR):\n         (make-porridge :temperature            just-right)\n         nil\n\n\n     It may seem like wasted effort to spend time writing assertions that (if all goes well)\n     will never be used. However, for all but the perfect programmer, bugs do occur, and\n     the time spent antibugging will more than pay for itself in saving debugging time.\n          Whenever you develop a complex data structure, such as some kind of data base,\n     it is a good idea to develop a corresponding consistency checker. A consistency\n     checker is a function that will look over a data structure and test for all possible\n     errors. When a new error is discovered, a check for it should be incorporated into\n     the consistency checker. Calling the consistency checker is the fastest way to help\n     isolate bugs in the data structiu-e.\n          In addition, it is a good idea to keep a list of difficult test cases on hand. That\n     way, when the program is changed, it will be easy to see if the change reintroduces\n     a bug that had been previously removed. This is called regression testing, and Waters\n     (1991) presents an interesting tool for maintaining a suite of regression tests. But it\n     is simple enough to maintain an informal test suite with a function that calls a s s e r t\n     on a series of examples:\n\n         (defun t e s t - e x ()\n           \"Test the program EX on a s e r i e s of examples.\"\n           (i n i t - e x ) ; I n i t i a l i z e the EX program f i r s t ,\n           ( a s s e r t (equal (ex 3 4)              5))\n           ( a s s e r t (equal (ex 5 0)              0))\n           ( a s s e r t (equal (ex *x 0) 0 ) ) )\n\n\n\n\n     Timing Tools\n\n     A program is not complete just because it gives the right output. It must also deliver\n     the output in a timely fashion. The form ( t i me expression) can be used to see how\n     long it takes to execute expression. Some implementations also print statistics on the\n     amount of storage required. For example:\n\n        > (defun f (n) (dotimes (i n) n i l ) )            =^ F\n\f3.15 EVALUATION                                                                                 91\n\n\n\n             > (time (f 10000)) => NIL\n             Evaluation of (F 10000) took 4.347272 Seconds of elapsed time,\n             including 0.0 seconds of paging time for 0 f a u l t s , Consed 27 words.\n\n             > (compile ' f ) => F\n\n             > (time ( f 10000))         NIL\n             Evaluation of (F 10000) took 0.011518 Seconds of elapsed time,\n             i n c l u d i n g 0.0 seconds of paging time for 0 f a u l t s , Consed 0 words.\n\n\n         This shows that the compiled version is over 300 times faster and uses less storage\n         to boot. Most serious Common Lisp programmers work exclusively with compiled\n         functions. However, it is usually a bad idea to worry too much about efficiency details\n         while starting to develop a program. It is better to design a flexible program, get it to\n         work, and then modify the most frequently used parts to be more efficient. In other\n         words, separate the development stage from the fine-tuning stage. Chapters 9 and\n         10 give more details on efficiency consideration, and chapter 25 gives more advice\n         on debugging and antibugging techniques.\n\n\n\n\n          3.15       Evaluation\n         There are three functions for doing evaluation in Lisp: f uncal 1 , apply, and e v a l .\n         f uncal 1 is used to apply a function to individual arguments, while apply is used\n         to apply a function to a list of arguments. Actually, apply can be given one or\n         more individual arguments before the final argument, which is always a Ust. eval\n         is passed a single argument, which should be an entire form-a function or special\n         form followed by its arguments, or perhaps an atom. The following five forms are\n         equivalent:\n\n             > (+ 1 2 3 4)                         10\n             > (funcall # ' + 1 2 3 4)         ^   10\n             > (apply # ' + ' ( 1 2 3 4 ) ) = ^ 10\n             > (apply #�+ 1 2 ' ( 3 4 ) ) =^ 10\n             > (eval ' ( + 1 2 3 4 ) )         =^ 10\n\n\n         In the past, eval was seen as the key to Lisp's flexibility. In modern Lisps with lexical\n         scoping, such as Common Lisp, eval is used less often (in fact, in Scheme there is\n         no eval at all). Instead, programmers are expected to use 1 ambda to create a new\n         function, and then apply or f uncal 1 the function. In general, if you find yourself\n         using eval, you are probably doing the wrong thing.\n\f92                                                                        OVERVIEW     OF LISP\n\n\n\n\n     3.16       Closures\n     What does it mean to create a new function? Certainly every time a f uncti on (or # ' )\n     special form is evaluated, a function is returned. But in the examples we have seen\n     and in the following one, it is always the same function that is returned.\n\n        > (mapcar #'(1ambda (x) (+   ) ) ' ( 1 3 10)) =4>(2 6 20)\n\n\n     Every time we evaluate the # * ( 1 ambda . . . ) form, it returns the function that doubles\n     its argument. However, in the general case, a function consists of the body of the\n     function coupled with any free lexical vanables that the function references. Such a\n     pairing is called a lexical closure, or just a closure, because the lexical variables are\n     enclosed within the function. Consider this example:\n\n        (defun adder (c)\n          \"Return a function that adds c to i t s argument.\"\n          #'(lambda (x) (+  c ) ) )\n\n        > (mapcar (adder 3) ' ( 1 3 10)) = ^ ( 4 6 13)\n\n        > (mapcar (adder 10) ' ( 1 3 10)) ^     (11 13 20)\n\n\n     Each time we call adder with a different value for c, it creates a different function,\n     the function that adds c to its argument. Since each call to adder creates a new local\n     variable named c, each function returned by adder is a unique function.\n         Here is another example. The function bank-account returns a closure that can\n     be used as a representation of a bank account. The closure captures the local variable\n     balance. The body of the closure provides code to access and modify the local\n     variable.\n\n        (defun bank-account (balance)\n          \"Open a bank account s t a r t i n g with the given balance.\"\n          #'(lambda (action amount)\n               (case action\n                 (deposit ( s e t f balance (-�� balance amount)))\n                 (withdraw ( s e t f balance (- balance amount))))))\n\n\n     In the following, two calls to bank-account create two different closures, each with\n     a separate value for the lexical variable bal a nee. The subsequent calls to the two\n     closures change their respective balances, but there is no confusion between the two\n     accounts.\n\n        > ( s e t f my-account (bank-account 500.00)) =^ #<CLOSURE 52330407>\n\f3.17   SPECIAL   VARIABLES                                                                         93\n\n\n\n                 > ( s e t f your-account (bank-account 250.00)) ^           #<CLOSURE 52331203>\n\n                 > (funcall my-account 'withdraw 75.00)              425.0\n\n                 > (funcall your-account ' d e p o s i t 250.00) ^     500.0\n\n                 > (funcall your-account 'withdraw 100.00)              400.0\n\n                 > (funcall my-account 'withdraw 25.00) => 400.0\n\n\n             This style of programming will be considered in more detail in chapter 13.\n\n\n\n             3.17        Special Variables\n             Common Lisp provides for two kinds of variables: lexical and special variables. For\n             the beginner, it is tempting to equate the special variables in Common Lisp with\n             global variables in other languages. Unfortunately, this is not quite correct and can\n             lead to problems. It is best to understand Common Lisp variables on their own terms.\n                 By default. Common Lisp variables are lexical variables. Lexical variables are\n             introduced by some syntactic construct like 1 e t or defun and get their name from the\n             fact that they may only be referred to by code that appears lexically within the body\n             of the syntactic construct. The body is called the scope of the variable.\n                 So far, there is no difference between Common Lisp and other languages. The\n             interesting part is when we consider the extent, or lifetime, of a variable. In other\n             languages, the extent is the same as the scope: a new local variable is created when a\n             block is entered, and the variable goes away when the block is exited. But because it\n             is possible to create new functions--closures--in Lisp, it is therefore possible for code\n             that references a variable to live on after the scope of the variable has been exited.\n             Consider again the bank-account function, which creates a closure representing a\n             bank account:\n\n                  (defun bank-account (balance)\n                    \"Open a bank account s t a r t i n g with the given balance.\"\n                    #'(lambda (action amount)\n                         (case action\n                           (deposit ( s e t f balance (+ balance amount)))\n                           (withdraw ( s e t f balance (- balance amount))))))\n\n\n             The function introduces the lexical variable bal anee. The scope of bal anee is the\n             body of the function, and therefore references to bal anee can occur only within this\n             scope. What happens when ba  k - a ccount is called and exited? Once the body of the\n             function has been left, no other code can refer to that instance of bal anee. The scope\n             has been exited, but the extent of bal anee lives on. We can call the closure, and it\n\f94                                                                      OVERVIEW OF LISP\n\n\n\n     can reference bal anee, because the code that created the closure appeared lexically\n     within the scope of bal anee.\n        In summary. Common Lisp lexical variables are different because they can be\n     captured inside closures and referred to even after the flow of control has left their\n     scope.\n\n        Now we will consider special variables. A variable is made special by a def va r or\n     defparameter form. For example, if we say\n\n         (defvar *counter* 0)\n\n\n     then we can refer to the special variable ^counter* anywhere in our program. This\n     is just like a familiar global variable. The tricky part is that the global binding of\n     *counter* can be shadowed by a local binding for that variable. In most languages,\n     the local binding would introduce a local lexical variable, but in Common Lisp, special\n     variables can be bound both locally and globally. Here is an example:\n\n        (defun report ()\n          (format t \"Counter = '^d \" * c o u n t e r * ) )\n\n        > (report)\n        Counter = 0\n        NIL\n\n        > ( l e t ( ( * c o u n t e r * 100))\n              (report))\n        Counter = 100\n        NIL\n\n        > (report)\n        Counter = 0\n        NIL\n\n\n     There are three calls to report here. In the first and third, report prints the global\n     value of the special variable ^counter*. In the second call, the 1 e t form introduces\n     a new binding for the special variable ^counter*, which is again printed by report.\n     Once the scope of the 1 e t is exited, the new binding is disestablished, so the final\n     call to report uses the global value again.\n         In summary. Common Lisp special variables are different because they have\n     global scope but admit the possibility of local (dynamic) shadowing. Remember:\n     A lexical variable has lexical scope and indefinite extent. A special variable has\n     indefinite scope and dynamic extent.\n         The function call (symbol - value var), where var evaluates to a symbol, can be\n     used to get at the current value of a special variable. To set a special variable, the\n     following two forms are completely equivalent:\n\f3.18   MULTIPLE    VALUES                                                                          95\n\n\n\n                  (setf    (symbol-value Pflr)        t7fl/Me)\n                  (set var value)\n\n            where both var and value are evaluated. There are no corresponding forms for\n            accessing and setting lexical variables. Special variables set up a mapping between\n            symbols and values that is accessible to the running program. This is unlike lexical\n            variables (and all variables in traditional languages) where symbols (identifiers)\n            have significance only while the program is being compiled. Once the program is\n            running, the identifiers have been compiled away and cannot be used to access the\n            variables; only code that appears within the scope of a lexical variable can reference\n            that variable.\n\n\n        @   Exercise 3.6 [s] Given the following initialization for the lexical variable a and the\n            special variable *b*, what will be the value of the 1 e t form?\n\n                  (setf a 'global-a)\n                  (defvar * b * ' g l o b a l - b )\n\n                  (defun fn () * b * )\n\n                  (let      ((a ' l o c a l - a )\n                             (*b* ' l o c a l - b ) )\n                     ( l i s t a * b * (fn) (symbol-value ' a )   (symbol-value'*b*)))\n\n\n\n\n            3.18            Multiple Values\n            Throughout this book we have spoken of \"the value returned by a function.\" Histor\n            ically, Lisp was designed so that every function returns a value, even those functions\n            that are more like procedures than like functions. But sometimes we want a single\n            function to return more than one piece of information. Of course, we can do that by\n            making up a list or structure to hold the information, but then we have to go to the\n            trouble of defining the structure, building an instance each time, and then taking that\n            instance apart to look at the pieces. Consider the function round. One way it can be\n            used is to round off a floating-point number to the nearest integer. So ( round 5 . 1 ) is\n            5. Sometimes, though not always, the programmer is also interested in the fractional\n            part. The function round serves both interested and disinterested programmers by\n            returning two values: the rounded integer and the remaining fraction:\n\n                  > (round 5.1)            5 .1\n\n\n            There are two values after the =^ because round returns two values. Most of the time.\n\f96                                                                            OVERVIEW OF LISP\n\n\n\n     multiple values are ignored, and only the first value is used. So (* 2 (round 5 . 1 ) )\n     is 10, just as if round had only returned a single value. If you want to get at multiple\n     values, you have to use a special form, such as mul t i pi e-val ue-bi nd:\n\n\n         (defun show-both (x)\n           ( m u l t i p l e - v a l u e - b i n d ( i n t rem)\n                  (round x)\n              (format t \"~f = ~d + ~f\"  i n t rem)))\n\n\n        > (show-both 5 . 1 )\n        5.1 = 5 + 0.1\n\n\n     You can write functions of your own that return multiple values using the function\n     val ues, which returns its arguments as multiple values:\n\n\n        > (values 1 2 3) =i> 1 2 3\n\n\n     Multiple values are a good solution because they are unobtrusive until they are\n     needed. Most of the time when we are using round, we are only interested in the\n     integer value. If round did not use multiple values, if it packaged the two values up\n     into a list or structure, then it would be harder to use in the normal cases.\n        It is also possible to return no values from a function with ( v a l u e s ) . This is\n     sometimes used by procedures that are called for effect, such as printing. For\n     example, descri be is defined to print information and then return no values:\n\n\n        > (describe '  )\n        Symbol X i s i n the USER package.\n        I t has no v a l u e , d e f i n i t i o n or p r o p e r t i e s .\n\n\n     However, when (val ues ) or any other expression returning no values is nested in\n     a context where a value is expected, it still obeys the Lisp rule of one-value-per-\n     expression and returns n i l . In the following example, descri be returns no values,\n     but then 1 i s t in effect asks for the first value and gets n i l .\n\n\n        > ( l i s t (describe ' x ) )\n        Symbol X i s i n A I LP package.\n        I t has no value, d e f i n i t i o n or p r o p e r t i e s .\n        (NIL)\n\f3.19   MORE   ABOUT       PARAMETERS                                                                     97\n\n\n\n\n              3.19          More about Parameters\n\n              Common Lisp provides the user with a lot of flexibility in specifying the parameters\n              to a function, and hence the arguments that the function accepts. Following is a\n              program that gives practice in arithmetic. It asks the user a series of  problems,\n              where each problem tests the arithmetic operator op (which can be +, -, *, or / , or\n              perhaps another binary operator). The arguments to the operator will be random\n              integers from 0 to range. Here is the program:\n\n\n                 (defun math-quiz (op range n)\n                    \"Ask the user a s e r i e s of math problems.\"\n                    (dotimes (i )\n                       (problem (random range) op (random r a n g e ) ) ) )\n\n\n                 (defun problem (x op y )\n                    \"Ask a math problem, read a r e p l y , and say i f              it   is correct.\"\n                    (format t \"~&How much i s ~d ~a ~ d ? \"  op y )\n                    (if   (eql (read) (funcall op  y ) )\n                          (princ \"Correct!\")\n\n\n                          (princ \" S o r r y , t h a t ' s not r i g h t . \" ) ) )\n\n\n              and here is an example of its use:\n                 > (math-quiz ' + 100 2)\n                 How much i s 32 + 60? 92\n                 Correct!\n                 How much i s 91 + 19? 100\n                 S o r r y , t h a t ' s not r i g h t .\n\n\n              One problem with the function math-qui  is that it requires the user to type three\n              arguments: the operator, a range, and the number of iterations. The user must\n              remember the order of the arguments, and remember to quote the operator. This is\n              quite a lot to expect from a user who presumably is just learning to add!\n                 Common Lisp provides two ways of dealing with this problem. First, a program\n              mer can specify that certain arguments are optional, and provide default values for\n              those arguments. For example, in math - qui  we can arrange to make be the default\n              operator, 100 be the default number range, and 10 be the default number of examples\n              with the following definition:\n\f98                                                                             OVERVIEW OF LISP\n\n\n\n         (defun math-quiz (&optional (op '��-) (range 100) (n 10))\n           \"Ask the user a s e r i e s of math problems.\"\n           (dotimes ( i n)\n             (problem (random range) op (random r a n g e ) ) ) )\n\n\n     Now (math-quiz) means the same as (math-quiz ' + 100 1 0 ) . If an optional\n     parameter appears alone without a default value, then the default is ni 1. Optional\n     parameters are handy; however, what if the user is happy with the operator and\n     range but wants to change the number of iterations? Optional parameters are still\n     position-dependent, so the only solution is to type in all three arguments: (ma th - qui \n         100 5 ) .\n         Common Lisp also allows for parameters that are position-independent. These\n     keyword parameters are explicitly named in the function call. They are useful when\n     there are a number of parameters that normally take default values but occasionally\n     need specific values. For example, we could have defined math - qui  as:\n\n         (defun math-quiz (&key (op ' + ) (range 100) (n 10))\n           \"Ask the user a s e r i e s of math problems.\"\n           (dotimes ( i n)\n              (problem (random range) op (random r a n g e ) ) ) )\n\n\n     Now ( m a t h - q u i z :n 5) and ( m a t h - q u i z : o p ' + :n 5 -.range 100) mean the same.\n     Keyword arguments are specified by the parameter name preceded by a colon, and\n     followed by the value. The keyword/value pairs can come in any order.\n         A symbol starting with a colon is called a keyword, and can be used anywhere,\n     not just in argument lists. The term keyword is used differently in Lisp than in many\n     other languages. For example, in Pascal, keywords (or reserved words) are syntactic\n     symbols, like i f , el se, begin, and end. In Lisp we call such symbols special form\n     operators or just special forms. Lisp keywords are symbols that happen to reside in\n     the keyword package.\"^ They have no special syntactic meaning, although they do\n     have the unusual property of being self-evaluating: they are constants that evaluate\n     to themselves, unlike other symbols, which evaluate to whatever value was stored in\n     the variable named by the symbol. Keywords also happen to be used in specifying\n     &key argument lists, but that is by virtue of their value, not by virtue of some syntax\n     rule. It is important to remember that keywords are used in the function call, but\n     normal nonkeyword symbols are used as parameters in the function definition.\n        Just to make things a little more confusing, the symbols &opti o n a l , &rest, and\n     &key are called lambda-list keywords, for historical reasons. Unlike the colon in real\n     keywords, the & in lambda-list keywords has no special significance. Consider these\n     annotated examples:\n\n         A package is a symbol table: a mapping between strings and the symbols they name.\n\f3.19 MORE    ABOUT    PARAMETERS                                                                                 99\n\n\n\n               > :xyz =^ :XYZ                                         ; keywords are self-evaluating\n\n               > �optional =^                                       ; lambda-list keywords are normal symbols\n               Error: the symbol &optional has no value\n\n               > '&optional         &OPTIONAL\n\n               > (defun f (&xyz) (+ &xyz &xyz))                   F ;& has no significance\n\n               > ( f 3) = 6\n\n               > (defun f ( : x y z ) (+ :xyz : x y z ) )     ^\n               Error: the keyword :xyz appears in a variable list.\n               Keywords are constants, and so cannot be used as names of variables.\n\n               > (defun g (&key  y ) ( l i s t  y ) )             G\n\n               > ( l e t ((keys * ( : x :y : z ) ) )              ; keyword args can be computed\n                     ig (second keys) 1 ( f i r s t keys) 2 ) ) =^ (2 1)\n\n\n            Many of the functions presented in this chapter take keyword arguments that make\n            them more versatile. For example, remember the function f i nd, which can be used\n            to look for a particular element in a sequence:\n\n               > ( f i n d 3 *(1 2 3 4 - 5 6 . 0 ) ) =^ 3\n\n\n            It turns out that f i n d takes several optional keyword arguments.                        For example,\n            suppose we tried to find 6 in this sequence:\n\n               > ( f i n d 6 ' ( 1 2 3 4 -5 6 . 0 ) )       nil\n\n\n            This fails because f i nd tests for equality with eql, and 6 is not eql to 6 . 0 . However,\n            6 is equal  to 6 . 0 , so we could use the : t e s t keyword:\n\n               > ( f i n d 6 ' ( 1 2 3 4 - 5 6 . 0 ) : t e s t #'equalp) ^      6.0\n\n\n            In fact, we can specify any binary predicate for the : t e s t keyword; it doesn't have to\n            be an equality predicate. For example, we could find the first number that 4 is less\n            than:\n\n               > (find 4 ' ( 1 2 3 4 -5 6.0) :test #*<)                  6.0\n\n\n            Now suppose we don't care about the sign of the numbers; if we look for 5, we want\n            to find the - 5. We can handle this with the key keyword to take the absolute value of\n            each element of the list with the abs function:\n\f100                                                                                               OVERVIEW OF LISP\n\n\n\n          > ( f i n d 5 ' ( 1 2 3 4 -5 6 . 0 ) ikey # ' a b s )               -5\n\n\n      Keyword parameters significantly extend the usefulness of built-in functions, and\n      they can do the same for functions you define. Among the built-in functions, the most\n      common keywords fall into two main groups: : t e s t , : t e s t - not and : key, which are\n      used for matching functions, and : s t a r t , :end, and :from-end, which are used on\n      sequence functions. Some functions accept both sets of keywords. {Common Lisp the\n      Language, 2d edition, discourages the use of : t e s t - n o t ke3words, although they are\n      still a part of the language.)\n          The matching functions include sub! i s, posi t i on, s u b s t , uni on, i n t e r s e c t i on,\n      s e t - d i f f e r e n c e , remove, r e m o v e - i f , s u b s e t p , a s s o c , f i n d , and member. By default,\n      each tests if some item is eql to one or more of a series of other objects. This test can\n      be changed by supplying some other predicate as the argument to : t e s t , or it can be\n      reversed by specifying : t e s t - not. In addition, the comparison can be made against\n      some part of the object rather than the whole object by specifying a selector function\n      as the : key argument.\n          The sequence functions include remove, remove-if, p o s i t i o n , and f i n d . The\n      most common type of sequence is the list, but strings and vectors can also be used as\n      sequences. A sequence function performs some action repeatedly for some elements\n      of a sequence. The default is to go through the sequence from beginning to end, but\n      the reverse order can be specified with : from-end t , and a subsequence can be\n      specifed by supplying a number for the : s t a r t or : end keyword. The first element\n      of a sequence is numbered 0, not 1, so be careful.\n          As an example of keyword parameters, suppose we wanted to write sequence\n      functions that are similar to f i n d and f i n d - i f , except that they return a list of all\n      matching elements rather than just the first matching element. We will call the\n      new functions f i nd - a 11 and f i nd - a  - i f . Another way to look at these functions\n      is as variations of remove. Instead of removing items that match, they keep all the\n      items that match, and remove the ones that don't. Viewed this way, we can see\n      that the function f i nd - a 11 - i f is actually the same function as remove - i f - not . It is\n      sometimes useful to have two names for the same function viewed in different ways\n      (like not and nul 1). The new name could be defined with a defun, but it is easier to\n      just copy over the definition:\n\n\n          ( s e t f (symbol-function ' f i n d - a l l - i f ) # ' r e m o v e - i f - n o t )\n\n\n      Unfortunately, there is no built-in function that corresponds exactly to f i nd - a 11, so\n      we will have to define it. Fortunately, remove can do most of the work. All we have\n      to do is arrange to pass remove the complement of the : t e s t predicate. For example,\n      finding all elements that are equal to 1 in a list is equivalent to removing elements\n      that are not equal to 1:\n\f3.19   MORE   ABOUT      PARAMETERS                                                                           101^\n\n\n\n                 > ( s e t f nums ' ( 1 2 3 2 D )           ( 1 2 3 2 1)\n\n                 > ( f i n d - a l l 1 nums : t e s t # ' = ) = (remove 1 nums rtest # V = )         ( 1 1)\n\n\n              Now what we need is a higher-order function that returns the complement of a\n              function. In other words, given =, we want to return / = . This function is called\n              compl ement in ANSI Common Lisp, but it was not defined in earlier versions, so it is\n              given here:\n\n                 (defun complement ( f n )\n                    \" I f FN returns y , then (complement FN) returns (not y ) . \"\n                        This function i s b u i l t - i n i n ANSI Common L i s p ,\n                        but   i s defined here f o r those with non-ANSI compilers.\n                    #*(lambda (&rest a r g s ) (not (apply fn a r g s ) ) ) )\n\n\n              When f i n d - a l l is called with a given : t e s t predicate, all we have to do is call\n              remove with the complement as the : t e s t predicate. This is true even when the\n               : t e s t function is not specified, and therefore defaults to eql. We should also test\n              for when the user specifies the : t e s t - n o t predicate, which is used to specify that\n              the match succeeds when the predicate is false. It is an error to specify both a : t e s t\n              and : t e s t - n o t argument to the same call, so we need not test for that case. The\n              definition is:\n\n                 (defun f i n d - a l l   (item sequence &rest keyword-args\n                                          &key ( t e s t #*eql) t e s t - n o t &aHow-other-keys)\n                    \"Find a l l those elements of sequence that match item,\n                    according to the keywords.             Doesn't a l t e r sequence.\"\n                    ( i f test-not\n                          (apply #*remove item sequence\n                                     : t e s t - n o t (complement t e s t - n o t ) keyword-args)\n                          (apply #�remove item sequence\n                                     : t e s t (complement t e s t ) keyword-args)))\n\n\n              The only hard part about this definition is understanding the parameter list. The\n              &rest accumulates all the keyword/value pairs in the variable keyword-args. In\n              addition to the &rest parameter, two specific keyword parameters, r t e s t and\n              : t e s t - n o t , are specified. Any time you put a &key in a parameter Ust, you need\n              an &al 1 ow-other- keys if, in fact, other keywords are allowed. In this case we want\n              to accept keywords like : s t a r t and : key and pass them on to remove.\n                  All the keyword/value pairs will be accumulated in the Ust keyword - a rgs, includ\n              ing the r t e s t or r t e s t - n o t values. SowewiUhave:\n\f102                                                                                           OVERVIEW OF LISP\n\n\n\n             ( f i n d - a l l 1 nums ; t e s t # ' = :key #*abs)\n                  = (remove 1 nums : t e s t (complement #*=) : t e s t # ' = :key #*abs)\n                 ^ (1 1)\n\n\n          Note that the call to remove will contain two : t e s t keywords. This is not an error;\n          Common Lisp declares that the leftmost value is the one that counts.\n\n\n      @   Exercise 3.7 [s] Why do you think the leftmost of two keys is the one that counts,\n          rather than the rightmost?\n\n\n          Exercise 3.8 [m] Some versions of Kyoto Common Lisp (KCL) have a bug wherein\n          they use the rightmost value when more than one keyword/value pair is specified\n          for the same keyword. Change the definition of f i nd - a 11 so that it works in KCL.\n              There are two more lambda-list keywords that are sometimes used by advanced\n          programmers. First, within a macro definition (but not a function definition), the\n          symbol &body can be used as a synonym for &rest. The difference is that &body\n          instructs certain formatting programs to indent the rest as a body. Thus, if we\n          defined the macro:\n\n             (defmacro while2 ( t e s t &body body)\n               \"Repeat body while t e s t i s t r u e . \"\n               ' ( l o o p ( i f (not . t e s t ) (return n i l ) )\n                           . .body))\n\n\n          Then the automatic indentation of wh 11 e2 (on certain systems) is prettier than wh 11 e:\n\n             (while ( < i 10)                                         (while2 ( < i 10)\n                    ( p r i n t (* i D )                                ( p r i n t (* i i ) )\n                    ( s e t f i (+ i 1 ) ) )                            ( s e t f i (+ i 1 ) ) )\n\n\n          Finally, an &aux can be used to bind a new local variable or variables, as if bound\n          with 1 et*. Personally, I consider this an abomination, because &aux variables are\n          not parameters at all and thus have no place in a parameter list. I think they should\n          be clearly distinguished as local variables with a 1 et. But some good programmers\n          do use &aux, presumably to save space on the page or screen. Against my better\n          judgement, I show an example:\n\n              (defun lengthl4 ( l i s t &aux (len 0 ) )\n                ( d o l i s t (element l i s t l e n )\n                   (incf len)))\n\f3.20 THE REST OF LISP                                                                        103\n\n\n\n           3.20       The Rest of Lisp\n           There is a lot more to Common Lisp than what we have seen here, but this overview\n           should be enough for the reader to comprehend the programs in the chapters to\n           come. The serious Lisp programmer will further his or her education by continuing\n           to consult reference books and online documentation. You may also find part V\n           of this book to be helpful, particularly chapter 24, which covers advanced features\n           of Common Lisp (such as packages and error handling) and chapter 25, which is a\n           collection of troubleshooting hints for the perplexed Lisper.\n                While it may be distracting for the beginner to be continually looking at some\n           reference source, the alternative--to explain every new function in complete detail as\n           it is introduced--would be even more distracting. It would interrupt the description\n           of the AI programs, which is what this book is all about.\n\n\n\n\n           3.21       Exercises\n     @     Exercise 3.9 [m]   Write a version of 1 ength using the function reduce.\n\n\n     @     Exercise 3.10 [m] Use a reference manual or d e s c r i be to figure out what the func\n           tions 1 cm and  reconc do.\n\n\n     [�1   Exercise 3.11 [m] There is a built-in Common Lisp function that, given a key, a\n           value, and an association Hst, returns a new association list that is extended to\n           include the key/value pair. What is the name of this function?\n\n\n           Exercise 3.12 [m] Write a single expression using format that will take a list of\n           words and print them as a sentence, with the first word capitalized and a period after\n           the last word. You will have to consult a reference to learn new format directives.\n\n\n\n\n           3.22 Answers\n\n           Answer 3.2     (consab) =        (Mst*ab)\n\f104                                                                                                    OVERVIEW OF LISP\n\n\n\n      Answer 3.3\n\n          (defun dprint (x)\n            \" P r i n t an expression in dotted p a i r n o t a t i o n . '\n            (cond ((atom x) ( p r i n c x ) )\n                      (t ( p r i n c \" ( \" )\n                            (dprint ( f i r s t x ) )\n                            (pr-rest (rest x))\n                            (princ \" ) \" )\n                            X)))\n\n\n          (defun p r - r e s t (x)\n            (princ \" . \")\n            (dprint x ) )\n\n\n\n      Answer 3.4         Use the same dpri nt function defined in the last exercise, but change\n      pr-rest.\n\n         (defun p r - r e s t (x)\n            (cond ( ( n u l l x ) )\n                      ((atom x) ( p r i n c \" . \" ) ( p r i n c x ) )\n                      (t ( p r i n c \" \") ( d p r i n t ( f i r s t x ) ) ( p r - r e s t ( r e s t x ) ) ) ) )\n\n\n\n      Answer 3.5 We will keep a data base called *db*. The data base is organized into\n      a tree structure of nodes. Each node has three fields: the name of the object it\n      represents, a node to go to if the answer is yes, and a node for when the answer is no.\n      We traverse the nodes until we either get an \"it\" reply or have to give up. In the latter\n      case, we destructively modify the data base to contain the new information.\n\n         ( d e f s t r u c t node\n            name\n            (yes    nil)\n            (no n i l ) )\n\n          (defvar *db*\n            (make-node :name 'animal\n                               :yes   (make-node :name 'mammal)\n                               :no (make-node\n                                        :name 'vegetable\n                                        :no (make-node :name ' m i n e r a l ) ) ) )\n\f3.22 ANSWERS                                                                                       105\n\n\n\n               (defun questions (&optional (node * d b * ) )\n                 (format t \"~&Is i t a ~a? \" (node-name node))\n                 (case (read)\n                    ((y y e s ) ( i f (not (null (node-yes node)))\n                                      (questions (node-yes node))\n                                      ( s e t f (node-yes node) ( g i v e - u p ) ) ) )\n                    ((n no) ( i f (not (null (node-no node)))\n                                      (questions (node-no node))\n                                      ( s e t f (node-no node) ( g i v e - u p ) ) ) )\n                    (it 'aha!)\n                    (t (format t \"Reply with Y E S , NO, or IT i f I have guessed         it.\")\n                       (questions node))))\n\n               (defun give-up ()\n                 (format t \"~&I give up - what i s i t ?     \")\n                 (make-node :name (read)))\n\n\n          Here it is used:\n\n               > (questions)\n               I s i t a ANIMAL? yes\n               I s i t a MAMMAL? yes\n               I give up - what i s i t ? bear\n               #S(NODE :NAME BEAR)\n\n               > (questions)\n               I s i t a ANIMAL? yes\n               I s i t a MAMMAL? no\n               I give up - what i s i t ? penguin\n               #S(NODE :NAME PENGUIN)\n\n               > (questions)\n               I s i t a ANIMAL? yes\n               I s i t a MAMMAL? yes\n               I s i t a BEAR? i t\n               AHA!\n\n\n\n          Answer 3.6 The value is (LOCAL-A LOCAL-B LOCAL-B GLOBAL-A LOCAL-B).\n             The 1 e t form binds a lexically and *b* dynamically, so the references to a and\n          *b* (including the reference to *b* within f n) all get the local values. The function\n          symbol - v a l u e always treats its argument as a special variable, so it ignores the lexical\n          binding for a and returns the global binding instead. However, the symbol - va 1 ue of\n          *b* is the local dynamic value.\n\f106                                                                    OVERVIEW OF LISP\n\n\n\n      Answer 3.7 There are two good reasons: First, it makes it faster to search through\n      the argument list: just search until you find the key, not all the way to the end.\n      Second, in the case where you want to override an existing keyword and pass the\n      argument list on to another function, it is cheaper to cons the new keyword/value\n      pair on the front of a list than to append it to the end of a list.\n\n      Answer 3.9\n\n         (defun length-r ( l i s t )\n           (reduce #*+ (mapcar #*(lambda (x) 1) l i s t ) ) )\n\n      or more efficiently:\n\n         (defun length-r ( l i s t )\n           (reduce #'(lambda (x y) (+  D ) l i s t\n                   rinitial-value 0 ) )\n\n      or, with an ANSI-compliant Common Lisp, you can specify a : key\n\n         (defun length-r (list)\n          (reduce #'+ list :key #'(lambda (x) 1)))\n\n\n      Answer 3.12      (format t     '^@r{'^a'^^         '(this is a test))\n\fCHAPTER                  4\nGPS: The Genera\nProblem Solver\n\n                                                            There are now in the world machines that think.\n                                                                                        --Herbert Simon\n                                                                       Nobel Prize-winning Al researcher\n\n\n\n\nI I 1 he General Problem Solver, developed in 1957 by Alan Newell and Herbert Simon, em-\n  I    bodied a grandiose vision: a single computer program that could solve any problem,\n JL given a suitable description of the problem. GPS caused quite a stir when it was intro\nduced, and some people in AI felt it would sweep in a grand new era of intelligent machines.\nSimon went so far as to make this statement about his creation:\n\n     It is not my aim to surprise or shock you. ... But the simplest way I can summarize is to say\n     that there are now in the world machines that think, that learn and create. Moreover, their\n     ability to do these things is going to increase rapidly until-in a visible future-the range of\n     problems they can handle will be coextensive with the range to which the human mind has\n     been applied.\n\f110                                                    CPS: THE GENERAL PROBLEM         SOLVER\n\n\n\n          Although GPS never lived up to these exaggerated claims, it was still an important\n      program for historical reasons. It was the first program to separate its problem-\n      solving strategy from its knowledge of particular problems, and it spurred much\n      further research in problem solving. For all these reasons, it is a fitting object\n      of study.\n          The original GPS program had a number of minor features that made it quite\n      complex. In addition, it was written in an obsolete low-level language, IPL, that added\n      gratuitous complexity. In fact, the confusing nature of IPL was probably an important\n      reason for the grand claims about GPS. If the program was that complicated, it must\n      do something important. We will be ignoring some of the subtleties of the original\n      program, and we will use Common Lisp, a much more perspicuous language than\n      IPL. The result will be a version of GPS that is quite simple, yet illustrates some\n      important points about AI.\n          On one level, this chapter is about GPS. But on another level, it is about the process\n      of developing an AI computer program. We distinguish five stages in the develop\n      ment of a program. First is the problem description, which is a rough idea--usually\n      written in English prose~of what we want to do. Second is the program specification,\n      where we redescribe the problem in terms that are closer to a computable procedure.\n      The third stage is the implementation of the program in a programming language\n      such as Common Lisp, the fourth is testing, and the fifth is debugging and analysis.\n      The boundaries between these stages are fluid, and the stages need not be completed\n      in the order stated. Problems at any stage can lead to a change in the previous stage,\n      or even to complete redesign or abandonment of the project. A programmer may\n      prefer to complete only a partial description or specification, proceed directly to\n      implementation and testing, and then return to complete the specification based on\n      a better understanding.\n          We follow all five stages in the development of our versions of GPS, with the hope\n      that the reader will understand GPS better and will also come to understand better\n      how to write a program of his or her own. To summarize, the five stages of an AI\n      programming project are:\n\n\n         1. Describe the problem in vague terms\n\n\n         2. Specify the problem in algorithmic terms\n\n\n         3. Implement the problem in a programming language\n\n\n         4. Test the program on representative examples\n\n\n         5. Debug and analyze the resulting program, and repeat the process\n\f4.1 STAGE 1: DESCRIPTION                                                                               111\n\n\n\n\n           4.1      Stage 1: Description\n           As our problem description, we will start with a quote from Newell and Simon's 1972\n           book. Human Problem Solving:\n\n                 The main methods of GPS jointly embody the heunstic ofmeans-ends    analy\n                 sis. Means-ends analysis is typified by the following kind of common-sense\n                 argument:\n\n                      I want to take my son to nursery school. What's the difference\n                      between what I have and what I want? One of distance. What\n                      changes distance? My automobile. My automobile won't work.\n                      What is needed to make it work? A new battery. What has new\n                      battenes? An auto repair shop. I want the repair shop to put in a\n                      new battery; but the shop doesn't know I need one. What is the\n                      difficulty? One of communication. What allows communication?\n                      A telephone... and so on.\n\n                 The kind of analysis-classifying things in terms of the functions they serve and\n                 oscillating among ends, functions required, andmeans thatperform      them-forms\n                 the basic system of heuristic of GPS.\n\n                Of course, this kind of analysis is not exactly new. The theory of means-ends\n           analysis was laid down quite elegantly by Aristotle 2300 years earlier in the chapter\n           entitled \"The nature of deliberation and its objects\" of the Nicomachean Ethics (Book\n           III. 3,1112b):\n\n                 We deliberate not about ends, but about means. For a doctor does not deliberate\n                 whether he shall heal, nor an orator whether he shall persuade, nor a statesman\n                 whether he shall produce law and order, nor does any one else deliberate about\n                 his end. They assume the end and consider how and by what means it is attained;\n                 and if it seems to be produced by several means they consider by which it is\n                 most easily and best produced, while if it is achieved by one only they consider\n                 how it will be achieved by this and by what means this will be achieved, till\n                 they come to the first cause, which in the order of discovery is last... and what\n                 is last in the order of analysis seems to be first in the order of becoming. And if\n                 we come on an impossibility, we give up the search, e.g., if we need money and\n                 this cannot be got; but if a thing appears possible we try to do it.\n\n               Given this description of a theory of problem solving, how should we go about\n           writing a program? First, we try to understand more fully the procedure outlined in\n           the quotes. The main idea is to solve a problem using a process called means-ends\n           analysis, where the problem is stated in terms of what we want to happen. In Newell\n           and Simon's example, the problem is to get the kid to school, but in general we would\n\f112                                                    CPS; THE GENERAL PROBLEM          SOLVER\n\n\n\n      like the program to be able to solve a broad class of problems. We can solve a problem\n      if we can find some way to eliminate \"the difference between what I have and what\n      I want.\" For example, if what I have is a child at home, and what I want is a child\n      at school, then driving may be a solution, because we know that driving leads to a\n      change in location. We should be aware that using means-ends analysis is a choice:\n      it is also possible to start from the current situation and search forward to the goal,\n      or to employ a mixture of different search strategies.\n           Some actions require the solving of preconditions as subproblems. Before we can\n      drive the car, we need to solve the subproblem of getting the car in working condition.\n      It may be that the car is already working, in which case we need do nothing to solve\n      the subproblem. So a problem is solved either by taking appropriate action directly,\n      or by first solving for the preconditions of an appropriate action and then taking\n      the action. It is clear we will need some description of allowable actions, along\n      with their preconditions and effects. We will also need to develop a definition of\n      appropriateness. However, if we can define these notions better, it seems we won't\n      need any new notions. Thus, we will arbitrarily decide that the problem description\n      is complete, and move on to the problem specification.\n\n\n\n      4.2      Stage 2: Specification\n      At this point we have an idea--admittedly vague--of what it means to solve a problem\n      in GPS. We can refine these notions into representations that are closer to Lisp as\n      follows:\n\n         � We can represent the current state of the world--\"what I have\"--or the goal\n           state--\"what I want\"--as sets of conditions. Common Lisp doesn't have a data\n           type for sets, but it does have Usts, which can be used to implement sets. Each\n           condition can be represented by a symbol. Thus, a typical goal might be the list\n           of two conditions ( r i c h famous), and a typical current state might be (unknown\n           poor).\n\n         � We need a list of allowable operators. This list will be constant over the course\n           of a problem, or even a series of problems, but we want to be able to change it\n           and tackle a new problem domain.\n\n         � An operator can be represented as a structure composed of an action, a list\n           of preconditions, and a list of effects. We can place limits on the kinds of\n           possible effects by saying that an effect either adds or deletes a condition from\n           the current state. Thus, the list of effects can be split into an add-list and\n           a delete-list. This was the approach taken by the S T R I P S ^ implementation of\n\n         ^STRIPS is the Stanford Research Institute Problem Solver, designed by Richard Pikes and\n      NilsNilsson (1971).\n\f4 .3 STAGE 3: IMPLEMENTATION                                                                      113\n\n\n\n                 G P S , which we will be in effect reconstructing in this chapter. The original G P S\n                 allowed more flexibility in the specification of effects, but flexibility leads to\n                 inefficiency.\n\n              � A complete problem is described to G P S in terms of a starting state, a goal state,\n                and a set of known operators. Thus, G P S will be a function of three arguments.\n                For example, a sample call might be:\n\n\n                 (GPS '(unknown poor) ' ( r i c h famous) l i s t - o f - o p s )\n\n\n\n                 In other words, starting from the state of being poor and unknown, achieve the\n                 state of being rich and famous, using any combination of the known operators.\n                 G P S should return a true value only if it solves the problem, and it should print\n                 a record of the actions taken. The simplest approach is to go through the\n                 conditions in the goal state one at a time and try to achieve each one. If they\n                 can all be achieved, then the problem is solved.\n\n              � A single goal condition can be achieved in two ways. If it is already in the\n                current state, the goal is trivially achieved with no effort. Otherwise, we have\n                to find some appropriate operator and try to apply it.\n\n              � An operator is appropriate if one of the effects of the operator is to add the goal\n                in question to the current state; in other words, if the goal is in the operator's\n                add-list.\n\n              � We can apply an operator if we can achieve all the preconditions. But this is\n                easy, because we just defined the notion of achieving a goal in the previous\n                paragraph. Once the preconditions have been achieved, applying an operator\n                means executing the action and updating the current state in term of the oper\n                ator's add-list and delete-list. Since our program is just a simulation--it won't\n                be actually driving a car or dialing a telephone--we must be content simply to\n                print out the action, rather than taking any real action.\n\n\n\n\n           4.3       Stage 3: Implementation\n           The specification is complete enough to lead directly to a complete Common Lisp\n           program. Figure 4.1 summarizes the variables, data types, and functions that make\n           up the G P S program, along with some of the Common Lisp functions used to imple\n           ment it.\n\f114                                                                       CPS; THE GENERAL PROBLEM          SOLVER\n\n\n\n                                   Top-Level Function\n      GPS                          Solve a goal from a state using a list of operators.\n                                   Special Variables\n      *state*                      The current state: a list of conditions.\n      *ops*                        A list of available operators.\n                                   Data Types\n      op                           An operation with preconds, add-list and del-list.\n                                   Functions\n      achieve                      Achieve an individual goal.\n      appropriate-p                Decide if an operator is appropriate for a goal.\n      apply-op                     Apply operator to current state.\n                                   Selected Common Lisp Functions\n      member                       Test if an element is a member of a list. (p. 78)\n      set-difference               All elements in one set but not the other.\n      union                        All elements in either of two sets.\n      every                        Test if every element of a list passes a test. (p. 62)\n      some                         Test if any element of a list passes a test.\n                                   Previously Defined Functions\n      find-all                     A list of all matching elements, (p. 101)\n\n                                     Figure 4.1: Glossary for the GPS Program\n\n\n           Here is the complete GPS program itself:\n\n           (defvar * s t a t e * n i l   \"The current s t a t e : a l i s t of c o n d i t i o n s . \" )\n\n           (defvar * o p s * n i l    \"A l i s t of a v a i l a b l e o p e r a t o r s . \" )\n\n           (defstruct op \"An operation\"\n             (action n i l ) (preconds n i l ) ( a d d - l i s t n i l ) ( d e l - l i s t n i l ) )\n\n           (defun GPS ( * s t a t e * goals * o p s * )\n             \"General Problem S o l v e r : achieve a l l goals using * o p s * . \"\n             ( i f (every #'achieve g o a l s ) ' s o l v e d ) )\n\n           (defun achieve (goal)\n             \"A goal i s achieved i f i t already h o l d s ,\n             or i f there i s an appropriate op for i t that i s a p p l i c a b l e . \"\n             (or (member goal * s t a t e * )\n                   (some # ' a p p l y - o p\n                         ( f i n d - a l l goal * o p s * : t e s t # ' a p p r o p r i a t e - p ) ) ) )\n\n           (defun appropriate-p (goal op)\n             \"An op i s appropriate to a goal i f i t                      i s i n i t s add l i s t . \"\n             (member goal ( o p - a d d - l i s t o p ) ) )\n\f4.3 STAGE 3: IMPLEMENTATION                                                                                 115\n\n\n\n              (defun apply-op (op)\n                \" P r i n t a message and update * s t a t e * i f op i s a p p l i c a b l e . \"\n                (when (every #*achieve (op-preconds op))\n                   ( p r i n t ( l i s t 'executing (op-action o p ) ) )\n                   (setf *state* (set-difference *state* (op-del-list op)))\n                   ( s e t f * s t a t e * (union * s t a t e * ( o p - a d d - l i s t o p ) ) )\n                   t))\n\n\n          We can see the program is made up of seven definitions. These correspond to the\n          seven items in the specification above. In general, you shouldn't expect such a\n          perfect fit between specification and implementation. There are two def var forms,\n          one def s t r uct, and four defun forms. These are the Common Lisp forms for defining\n          variables, structures, and functions, respectively. They are the most common top-\n          level forms in Lisp, but there is nothing magic about them; they are just special forms\n          that have the side effect of adding new definitions to the Lisp environment.\n             The two def var forms, repeated below, declare special variables named * s t a t e *\n          and *ops*, which can then be accessed from anywhere in the program.\n\n              (defvar * s t a t e * n i l \"The current s t a t e : a l i s t of c o n d i t i o n s . \" )\n\n              (defvar * o p s * n i l \"A l i s t of a v a i l a b l e o p e r a t o r s . \" )\n\n\n          The d e f s t r u c t form defines a structure called an op, which has slots called a c t i on,\n          preconds, add - 1 i s t , and del - 1 i s t . Structures in Common Lisp are similar to struc\n          tures in C, or records in Pascal. The d e f s t r u c t automatically defines a constructor\n          function, which is called make-op, and an access function for each slot of the struc\n          ture. The access functions are called o p - a c t i o n , op -preconds, o p - a d d - l i s t , and\n          op -del -1 i s t . The d e f s t r u c t also defines a copier function, copy -op, a predicate,\n          o p - p , and s e t f definitions for changing each slot. None of those are used in the GPS\n          program. Roughly speaking, it is as if the d e f s t r u c t form\n\n              (defstruct op \"An operation\"\n                (action n i l ) (preconds n i l ) ( a d d - l i s t n i l ) ( d e l - l i s t n i l ) )\n\n\n          expanded into the following definitions:\n\n              (defun make-op (&key action precondsadd -1 ist del -1 i s t )\n                (vector 'op action preconds a d d - l i s t d e l - l i s t ) )\n\n              (defun    op-action          (op)    (elt   op   1))\n              (defun    op-preconds        (op)    (elt   op   2))\n              (defun    op-add-list        (op)    (elt   op   3))\n              (defun    op-del-list        (op)    (elt   op   4))\n\n              (defun copy-op (op) (copy-seq op))\n\f116                                                           CPS; THE GENERAL PROBLEM     SOLVER\n\n\n\n          (defun op-p (op)\n            (and (vectorp op) (eq ( e l t op 0) O p ) ) )\n\n          ( s e t f (documentation 'op ' s t r u c t u r e ) \"An operation\")\n\n\n      Next in tlie GPS program are four function definitions. The main function, GPS, is\n      passed three arguments. The first is the current state of the world, the second the\n      goal state, and the third a list of allowable operators. The body of the function says\n      simply that if we can achieve every one of the goals we have been given, then the\n      problem is solved. The unstated alternative is that otherwise, the problem is not\n      solved.\n           The function a ch i eve is given as an argument a single goal. The function succeeds\n      if that goal is already true in the current state (in which case we don't have to do\n      anything) or if we can apply an appropriate operator. This is accomplished by first\n      building the list of appropriate operators and then testing each in turn until one can\n      be applied, achieve calls f i n d - a l 1, which we defined on page 101. In this use,\n      f i n d - a l 1 returns a list of operators that match the current goal, according to the\n      predicate a p p r o p r i a t e - p .\n           The function a p p r o p r i a t e - p tests if an operator is appropriate for achieving a\n      goal. (It follows the Lisp naming convention that predicates end in - p.)\n           Finally, the function a p p l y - o p says that if we can achieve all the preconditions\n      for an appropriate operator, then we can apply the operator. This involves printing\n      a message to that effect and changing the state of the world by deleting what was in\n      the delete-list and adding what was in the add-Hst. a p p l y - o p is also a predicate; it\n      returns t only when the operator can be applied.\n\n\n\n\n      4.4       Stage 4: Test\n      This section will define a list of operators applicable to the \"driving to nursery school\"\n      domain and will show how to pose and solve some problems in that domain. First,\n      we need to construct the list of operators for the domain. The d e f s t r u c t form for the\n      type op automatically defines the function ma ke - op, which can be used as follows:\n\n          (make-op :action ' d r i v e - s o n - t o - s c h o o l\n                   ipreconds *(son-at-home car-works)\n                   :add-list '(son-at-school)\n                   : d e l - l i s t '(son-at-home))\n\n\n      This expression returns an operator whose action is the symbol drive-son-to-school\n      and whose preconditions, add-list and delete-list are the specified lists. The intent\n\f4.4 STAGE 4: TEST                                                                                  117\n\n\n\n          of this operator is that whenever the son is at home and the car works, dri v e - s o n -\n          to-school can be appHed, changing the state by deleting the fact that the son is at\n          home, and adding the fact that he is at school.\n              It should be noted that using long hyphenated atoms like son - a t - home is a useful\n          approach only for very simple examples like this one. A better representation would\n          break the atom into its components: perhaps ( a t son home). The problem with\n          the atom-based approach is one of combinatorics. If there are 10 predicates (such\n          as at) and 10 people or objects, then there will be 10  10  10 = 1000 possible\n          hyphenated atoms, but only 20 components. Clearly, it would be easier to describe\n          the components. In this chapter we stick with the hyphenated atoms because it is\n          simpler, and we do not need to describe the whole world. Subsequent chapters take\n          knowledge representation more seriously.\n              With this operator as a model, we can define other operators corresponding to\n          Newell and Simon's quote on page 109. There will be an operator for installing a\n          battery, telling the repair shop the problem, and telephoning the shop. We can fill in\n          the \"and so on\" by adding operators for looking up the shop's phone number and for\n          giving the shop money:\n\n              (defparameter * s c h o o l - o p s *\n                (list\n                   (make-op taction ' d r i v e - s o n - t o - s c h o o l\n                      :preconds '(son-at-home car-works)\n                      :add-list '(son-at-school)\n                      : d e l - l i s t '(son-at-home))\n                   (make-op taction ' s h o p - i n s t a l l s - b a t t e r y\n                      ipreconds '(car-needs-battery shop-knows-problem shop-has-money)\n                      :add-list '(car-works))\n                   (make-op taction 'tell-shop-problem\n                      :preconds           '(in-communication-with-shop)\n                      : a d d - l i s t '(shop-knows-problem))\n                   (make-op raction 'telephone-shop\n                      rpreconds '(know-phone-number)\n                      :add-list           '(in-communication-with-shop))\n                   (make-op .-action 'look-up-number\n                      ipreconds '(have-phone-book)\n                      : a d d - l i s t '(know-phone-number))\n                   (make-op taction 'give-shop-money\n                      ipreconds '(have-money)\n                      : a d d - l i s t '(shop-has-money)\n                      : d e l - l i s t '(have-money))))\n\n\n          The next step is to pose some problems to GPS and examine the solutions. Following\n          are three sample problems. In each case, the goal is the same: to achieve the single\n          condition s o n - a t - s c h o o l . The Hst of available operators is also the same in each\n\f118                                                                        CPS: THE GENERAL PROBLEM                        SOLVER\n\n\n\n      problem; the difference is in the initial state. Each of the three examples consists of\n      the prompt, \">\", which is printed by the Lisp system, followed by a call to G P S , \" (gps\n      . . . w h i c h is typed by the user, then the output from the program, \"(EXECUTING\n      . . . ) \" , and finally the result of the function call, which can be either SOLVED or NI L.\n\n\n          > (gps '(son-at-home car-needs-battery have-money                                  have-phone-book)\n                      '(son-at-school)\n                      *school-ops*)\n           (EXECUTING LOOK-UP-NUMBER)\n           (EXECUTING TELEPHONE-SHOP)\n           (EXECUTING TELL-SHOP-PROBLEM)\n           (EXECUTING GIVE-SHOP-MONEY)\n           (EXECUTING SHOP-INSTALLS-BATTERY)\n           (EXECUTING DRIVE-SON-TO-SCHOOL)\n           SOLVED\n\n          > (gps '(son-at-home car-needs-battery have-money)\n                      '(son-at-schoo1)\n                      *school-ops*)\n           NIL\n\n           > (gps '(son-at-home               car-works)\n                      '(son-at-school)\n                      *school-ops*)\n           (EXECUTING DRIVE-SON-TO-SCHOOL)\n           SOLVED\n\n\n      In all three examples the goal is to have the son at school. The only operator that\n      has s o n - a t - s c h o o l in its add-list is d r i v e - s o n - t o - s c h o o l , so G P S selects that op\n      erator initially. Before it can execute the operator, G P S has to solve for the pre\n      conditions. In the first example, the program ends up working backward through\n      the operators s h o p - i n s t a l 1 s - b a t t e r y , g i v e - s h o p - m o n e y , t e l 1 - s h o p - p r o b l e m , and\n      telephone-shop to look-up-number, whichhasnooutstandingpreconditions. Thus,\n      the 1 ook -up-number action can be executed, and the program moves on to the other\n      actions. As Aristotle said, \"What is the last in the order of analysis seems to be first\n      in the order of becoming.\"\n          The second example starts out exactly the same, but the 1 ook - up - umbe r operator\n      fails because its precondition, have-phone -book, cannot be achieved. Knowing the\n      phone number is a precondition, directly or indirectly, of all the operators, so no\n      action is taken and G P S returns NIL.\n          Finally, the third example is much more direct; the initial state specifies that the\n      car works, so the driving operator can be applied immediately.\n\f4.5 STAGE 5: ANALYSIS, OR ''WE LIED ABOUT     THE C\"                                       VI9\n\n\n\n          4.5      Stage 5: Analysis, or ''We Lied about the C\n          In the sections that follow, we examine the question of just how general this General\n          Problem Solver is. The next four sections point out limitations of our version of GPS,\n          and we will show how to correct these limitations in a second version of the program.\n              One might ask if \"limitations\" is just a euphemism for \"bugs.\" Are we \"enhancing\"\n          the program, or are we \"correcting\" it? There are no clear answers on this point,\n          because we never insisted on an unambiguous problem description or specification.\n          AI programn�ng is largely exploratory programming; the aim is often to discover\n          more about the problem area rather than to meet a clearly defined specification. This\n          is in contrast to a more traditional notion of programming, where the problem is\n          completely specified before the first line of code is written.\n\n\n\n\n          4.6      The Running Around the Block Problem\n          Representing the operator \"driving from home to school\" is easy: the precondition\n          and delete-list includes being at home, and the add-list includes being at school. But\n          suppose we wanted to represent \"running around the block.\" There would be no\n          net change of location, so does that mean there would be no add- or delete-list? If\n          so, there would be no reason ever to apply the operator. Perhaps the add-list should\n          contain something like \"got some exercise\" or \"feel tired,\" or something more general\n          like \"experience running around the block.\" We will return to this question later.\n\n\n\n\n          4.7      The Clobbered Sibling Goal Problem\n          Consider the problem of not only getting the child to school but also having some\n          money left over to use for the rest of the day. GPS can easily solve this problem from\n          the following initial condition:\n\n             > (gps *(son-at-home have-money car-works)\n                     '(have-money s o n - a t - s c h o o l )\n                    *school-ops*)\n             (EXECUTING DRIVE-SON-TO-SCHOOL)\n             SOLVED\n\n\n          However, in the next example GPS incorrectly reports success, when in fact it has\n          spent the money on the battery.\n\f120                                                           CPS: THE GENERAL PROBLEM SOLVER\n\n\n         > (gps '(son-at-home car-needs-battery have-money have-phone-book)\n                   '(have-money s o n - a t - s c h o o l )\n                   ^school-ops*)\n          (EXECUTING LOOK-UP-NUMBER)\n          (EXECUTING TELEPHONE-SHOP)\n          (EXECUTING TELL-SHOP-PROBLEM)\n          (EXECUTING GIVE-SHOP-MONEY)\n          (EXECUTING SHOP-INSTALLS-BATTERY)\n          (EXECUTING DRIVE-SON-TO-SCHOOL)\n          SOLVED\n\n\n      The \"bug\" is that G P S uses the expression (every # ' a c h i e v e g o a l s ) to achieve\n      a set of goals. If this expression returns true, it means that every one of the\n      goals has been achieved in sequence, but it doesn't mean they are all still true\n      at the end. In other words, the goal (have-money s o n - a t - s c h o o l ) , which we in\n      tended to mean \"end up in a state where both have-money and s o n - a t - s c h o o l are\n      true,\" was interpreted by G P S to mean \"first achieve have-money, and then achieve\n      s o n - a t - s c h o o l . \" Sometimes achieving one goal can undo another, previously\n      achieved goal. We will call this the \"prerequisite clobbers sibling goal\" problem.^\n      That is, have-money and s o n - a t - s c h o o l are sibling goals, one of the prerequisites\n      for the plan for s o n - a t - s c h o o l is car -works, and achieving that goal clobbers the\n      have-money goal.\n           Modifying the program to recognize the \"prerequisite clobbers sibling goal\" prob\n      lem is straightforward. First note that we call (every # ' a c h i e v e something) twice\n      within the program, so let's replace those two forms with ( achi eve - al 1 something).\n      We can then define achi eve -al 1 as follows:\n\n          (defun achieve-all ( g o a l s )\n            \"Try to achieve each g o a l , then make sure they s t i l l h o l d . \"\n            (and (every #'achieve g o a l s ) (subsetp goals * s t a t e * ) ) )\n\n\n      The Common Lisp function subsetp returns true if its first argument is a subset of its\n      second. In achi eve -al 1 , it returns true if every one of the goals is still in the current\n      state after achieving all the goals. This is just what we wanted to test.\n          The introduction of achi eve-al 1 prevents G P S from returning true when one of\n      the goals gets clobbered, but it doesn't force G P S to replan and try to recover from a\n      clobbered goal. We won't consider that possibility now, but we will take it up again\n      in the section on the blocks world domain, which was Sussman's primary example.\n\n         ^Gerald Sussman, in his book A Computer Model of Skill Acquisition, uses the term \"prereq\n      uisite clobbers brother goal\" or PCBG. I prefer to be gender neutral, even at the risk of being\n      labeled a historical revisionist.\n\f4.8   THE LEAPING     BEFORE   YOU LOOK          PROBLEM                                                    121\n\n\n\n            4 �8        The Leaping before You Look Problem\n\n            Another way to address the \"prerequisite clobbers sibling goal\" problem is just to be\n            more careful about the order of goals in a goal list. If we want to get the kid to school\n            and still have some money left, why not just specify the goal as (son-at-school\n            have-money) rather than (have-money s o n - a t - s c h o o l ) ? Let's see what happens\n            when we try that:\n\n                > (gps '(son-at-home car-needs-battery have-money have-phone-book)\n                         ' ( s o n - a t - s c h o o l have-money)\n                         *school-ops*)\n                (EXECUTING LOOK-UP-NUMBER)\n                (EXECUTING TELEPHONE-SHOP)\n                (EXECUTING TELL-SHOP-PROBLEM)\n                (EXECUTING GIVE-SHOP-MONEY)\n                (EXECUTING SHOP-INSTALLS-BATTERY)\n                (EXECUTING DRIVE-SON-TO-SCHOOL)\n                NIL\n\n\n            G P S returns nil, reflecting the fact that the goal cannot be achieved, but only after\n            executing all actions up to and including driving to school. I call this the \"leaping\n            before you look\" problem, because if you asked the program to solve for the two goals\n            ( j ump - of f - c 1 i f f 1 a nd - s a f e 1 y) it would happily jump first, only to discover that it\n            had no operator to land safely. This is less than prudent behavior.\n                The problem arises because planning and execution are interleaved. Once the\n            preconditions for an operator are achieved, the action is taken--and *sta te* is irrevo\n            cably changed--even if this action may eventually lead to a dead end. An alternative\n            would be to replace the single global * s t a t e * with distinct local state variables, such\n            that a new variable is created for each new state. This alternative is a good one for\n            another, independent reason, as we shall see in the next section.\n\n\n\n\n            4.9        The Recursive Subgoal Problem\n\n            In our simulated nursery school world there is only one way to find out a phone\n            number: to look it up in the phone book. Suppose we want to add an operator for\n            finding out a phone number by asking someone. Of course, in order to ask someone\n            something, you need to be in communication with him or her. The asking-for-a-\n            phone-number operator could be implemented as follows:\n\f122                                                      CPS: THE GENERAL PROBLEM SOLVER\n\n\n\n          (push (make-op :action 'ask-phone-number\n                         :preconds           '(in-communication-with-shop)\n                         ; a d d - l i s t '(know-phone-number))\n                *school-ops*)\n\n\n      (The special form ( p u s h item list) puts the item on the front of the list; it is equiv\n      alent to ( s e t f list ( c o n s item /fsO) in the simple case.) Unfortunately, something\n      unexpected happens when we attempt to solve seemingly simple problems with this\n      new set of operators. Consider the following:\n\n\n         > (gps *(son-at-home car-needs-battery         have-money)\n                '(son-at-school)\n                *school-ops*)\n\n         � T R A P 14877 (SYSTEM:PDL-OVERFLOW EH::REGULAR)\n         The regular push-down l i s t has overflown.\n         While i n the function ACHIEVE < - EVERY < - REMOVE\n\n\n      The error message (which will vary from one implementation of Common Lisp to\n      another) means that too many recursively nested function calls were made. This\n      indicates either a very complex problem or, more commonly, a bug in the program\n      leading to infinite recursion. One way to try to see the cause of the bug is to trace a\n      relevant function, such as a c h i eve:\n\n\n         > (trace achieve) =^ (ACHIEVE)\n\n         > (gps '(son-at-home car-needs-battery have-money)\n                 '(son-at-school)\n                *school-ops*)\n         (1 ENTER ACHIEVE: SON-AT-SCHOOL)\n           (2 ENTER ACHIEVE: SON-AT-HOME)\n           (2 EXIT ACHIEVE: (SON-AT-HOME CAR-NEEDS-BATTERY HAVE-MONEY))\n           (2 ENTER ACHIEVE: CAR-WORKS)\n             (3 ENTER ACHIEVE: CAR-NEEDS-BATTERY)\n             (3 EXIT ACHIEVE: (CAR-NEEDS-BATTERY HAVE-MONEY))\n             (3 ENTER ACHIEVE: SHOP-KNOWS-PROBLEM)\n               (4 ENTER ACHIEVE: IN-COMMUNICATION-WITH-SHOP)\n                  (5 ENTER ACHIEVE: KNOW-PHONE-NUMBER)\n                    (6 ENTER ACHIEVE: IN-COMMUNICATION-WITH-SHOP)\n                      (7 ENTER ACHIEVE: KNOW-PHONE-NUMBER)\n                        (8 ENTER ACHIEVE: IN-COMMUNICATION-WITH-SHOP)\n                           (9 ENTER ACHIEVE: KNOW-PHONE-NUMBER)\n\f4.10   THE LACK OF INTERMEDIATE       INFORMATION       PROBLEM                                       123\n\n\n\n            The output from t r a c e gives us the necessary clues. Newell and Simon talk of\n            \"oscillating among ends, functions required, and means that perform them.\" Here\n            it seems we have an infinite oscillation between being in communication with the\n            shop (levels 4, 6, 8 , . . . ) and knowing the shop's phone number (levels 5, 7, 9 , . . . ) .\n            The reasoning is as follows: we want the shop to know about the problem with the\n            battery, and this requires being in communication with him or her. One way to get in\n            communication is to phone, but we don't have a phone book to look up the number.\n            We could ask them their phone number, but this requires being in communication\n            with them. As Aristotle put it, \"If we are to be always deliberating, we shall have to\n            go on to infinity.\" We will call this the \"recursive subgoal\" problem: trying to solve\n            a problem in terms of itself. One way to avoid the problem is to have achi eve keep\n            track of all the goals that are being worked on and give up if it sees a loop in the\n            goal stack.\n\n\n\n            4.10         The Lack of Intermediate Information\n                         Problem\n            When GPS fails to find a solution, it just returns n i l . This is annoying in cases where\n            the user expected a solution to be found, because it gives no information about the\n            cause of failure. The user could always trace some function, as we traced achi eve\n            above, but the output from trace is rarely exactly the information desired. It would\n            be nice to have a general debugging output tool where the programmer could insert\n            print statements into his code and have them selectively printed, depending on the\n            information desired.\n                 The function dbg provides this capability, dbg prints output in the same way as\n            format, but it will only print when debugging output is desired. Each call to dbg is\n            accompanied by an identifer that is used to specify a class of debugging messages.\n            The functions debug and undebug are used to add or remove message classes to the\n            list of classes that should be printed. In this chapter, all the debugging output will\n            use the identifier : g p s . Other programs will use other identifiers, and a complex\n            program will use many identifiers.\n                 A call to dbg will result in output if the first argument to dbg, the identifier, is one\n            that was specified in a call to debug. The other arguments to dbg are a format string\n            followed by a list of arguments to be printed according to the format string. In other\n            words, we will write functions that include calls to dbg like:\n\n                (dbg   :gps \"The current goal i s : ~a\" goal)\n\n\n            If we have turned on debugging with (debug : g p s ) , then calls to dbg with the\n            identifier : g p s will print output. The output is turned off with (undebug : g p s ) .\n\f124                                                                        CPS; THE GENERAL PROBLEM SOLVER\n\n\n\n      debug and undebug are designed to be similar to t r a c e and untrace, in that they turn\n      diagnostic output on and off. They also follow the convention that debug with no\n      arguments returns the current list of identifiers, and that undebug with no arguments\n      turns all debugging off. However, they differ from t r a c e and untrace in that they\n      are functions, not macros. If you use only keywords and integers for identifiers, then\n      you won't notice the difference.\n          Two new built-in features are introduced here. First, * d e b u g - i o * is the stream\n      normally used for debugging input/output. In all previous calls to format we have\n      used t as the stream argument, which causes output to go to the * s t a n d a rd - o u t p u t *\n      stream. Sending different types of output to different streams allows the user some\n      flexibility. For example, debugging output could be directed to a separate window,\n      or it could be copied to a file. Second, the function fresh - 1 i ne advances to the next\n      line of output, unless the output stream is already at the start of the line.\n\n          (defvar * d b g - i d s * n i l     \" I d e n t i f i e r s used by dbg\")\n\n          (defun dbg ( i d f o r m a t - s t r i n g &rest a r g s )\n             \" P r i n t debugging i n f o i f        (DEBUG ID) has been s p e c i f i e d . \"\n             (when (member i d * d b g - i d s * )\n                (fresh-line *debug-io*)\n                (apply #'format * d e b u g - i o * f o r m a t - s t r i n g a r g s ) ) )\n\n          (defun debug (&rest i d s )\n             \" S t a r t dbg output on the given i d s . \"\n             ( s e t f * d b g - i d s * (union i d s * d b g - i d s * ) ) )\n\n          (defun undebug (&rest i d s )\n             \"Stop dbg on the i d s .             With no i d s . stop dbg a l t o g e t h e r . \"\n             (setf *dbg-ids* ( i f            (null i d s ) n i l\n                                              (set-difference *dbg-ids* i d s ) ) ) )\n\n\n      Sometimes it is easier to view debugging output if it is indented according to some\n      pattern, such as the depth of nested calls to a function. To generate indented output,\n      the function dbg -1 ndent is defined:\n\n          (defun dbg-indent ( i d indent f o r m a t - s t r i n g &rest a r g s )\n             \" P r i n t indented debugging i n f o i f              (DEBUG I D ) has been s p e c i f i e d . \"\n             (when (member id * d b g - i d s * )\n                (fresh-line *debug-io*)\n                (dotimes (i indent) ( p r i n c \"                 \" *debug-io*))\n                (apply #*format * d e b u g - i o * f o r m a t - s t r i n g a r g s ) ) )\n\f4.11   GPS VERSION    2: A MORE   GENERAL   PROBLEM     SOLVER                              125\n\n\n            4.11         GPS Version 2: A More General\n                         Problem Solver\n            At this point we are ready to put together a new version of GPS with solutions for\n            the \"running around the block,\" \"prerequisite clobbers sibling goal,\" \"leaping before\n            you look,\" and \"recursive subgoal\" problems. The glossary for the new version is in\n            figure 4.2.\n\n                                  Top-Level Function\n             GPS                  Solve a goal from a state using a list of operators.\n                                  Special Variables\n             *ops*                A list of available operators.\n                                  Data Types\n              op                  An operation with preconds, add-list and del-Hst.\n                                  Major Functions\n              achieve-all         Achieve a list of goals.\n             achieve              Achieve an individual goal.\n              appropriate-p       Decide if an operator is appropriate for a goal.\n              apply-op            Apply operator to current state.\n                                  Auxiliary Functions\n             executing-p          Is a condition an executi ng form?\n              starts-with         Is the argument a list that starts with a given atom?\n              convert-op          Convert an operator to use the executi ng convention.\n             op                   Create an operator.\n              use                 Use a list of operators.\n             member-equal         Test if an element is equal to a member of a list.\n                                  Selected Common Lisp Functions\n             member               Test if an element is a member of a list. (p. 78)\n             set-difference       All elements in one set but not the other.\n              subsetp             Is one set wholly contained in another?\n              union               All elements in either of two sets.\n             every                Test if every element of a list passes a test. (p. 62)\n              some                Test if any element of a list passes a test.\n              remove-if           Remove all items satisfying a test.\n                                  Previously Defined Functions\n             find-all             A list of all matching elements, (p. 101)\n              find-all-if         A list of all elements satisfying a predicate.\n\n                                   Figure 4.2: Glossary for Version 2 of GPS\n\n               The most important change is that, instead of printing a message when each\n            operator is applied, we will instead have GPS return the resulting state. A list of\n\f126                                                            CPS: THE GENERAL PROBLEM SOLVER\n\n\n\n      \"messages\" in each state indicates what actions have been taken. Each message is\n      actuallyacondition,aHstof the form (executing operator). This solves the \"running\n      around the block\" problem: we could call GPS with an initial goal of ((executing\n      run - a round - bl o c k ) ) , and it would execute the run - a round - bl ock operator, thereby\n      satisfying the goal. The following code defines a new function, op, which builds\n      operators that include the message in their add-list.\n\n          (defun executing-p (x)\n            \" I s X of the form: (executing . . . ) ? \"\n            ( s t a r t s - w i t h  'executing))\n\n          (defun s t a r t s - w i t h ( l i s t x)\n            \" I s t h i s a l i s t whose f i r s t element i s x ? \"\n            (and (consp l i s t ) (eql ( f i r s t l i s t ) x ) ) )\n\n          (defun convert-op (op)\n            \"Make op conform to the (EXECUTING op) convention.\"\n            (unless (some #'executing-p ( o p - a d d - l i s t op))\n               (push ( l i s t 'executing (op-action op)) ( o p - a d d - l i s t o p ) ) )\n            op)\n\n          (defun op (action &key preconds a d d - l i s t d e l - l i s t )\n            \"Make a new operator that obeys the (EXECUTING op) convention.\"\n            (convert-op\n              (make-op :action action :preconds preconds\n                        :add-list add-list :del-list d e l - l i s t ) ) )\n\n\n      Operators built by op will be correct, but we can convert existing operators using\n      convert -op directly:\n\n          (mapc #'convert-op ^ s c h o o l - o p s * )\n\n\n      This is an example of exploratory programming: instead of starting all over when\n      we discover a limitation of the first version, we can use Lisp to alter existing data\n      structures for the new version of the program.\n\n           The definition of the variable * o p s * and the structure op are exactly the same as\n      before, and the rest of the program consists of five functions we have already seen:\n      GPS, a c h i e v e - a l l , achieve, appropriate -p, and apply-op. At the top level, the\n      function GPS calls achieve -al 1, which returns either nil or a valid state. From this\n      we remove all the atoms, which leaves only the elements of the final state that are\n      lists--in other words, the actions of the form (executi ng operator). Thus, the value\n      of GPS itself is the Hst of actions taken to arrive at the final state. GPS no longer returns\n      SOLVED when it finds a solution, but it still obeys the convention of returning nil for\n      failure, and non-nil for success. In general, it is a good idea to have a program return\n\f4.11   GPS VERSION    2: A MORE       GENERAL       PROBLEM          SOLVER                                       127\n\n\n\n            a meaningful value rather than print that value, if there is the possibility that some\n            other program might ever want to use the value.\n\n                (defvar * o p s * nil    \"A l i s t of a v a i l a b l e o p e r a t o r s . \" )\n\n                (defstruct op \"An operation\"\n                  (action n i l ) (preconds n i l )          (add-list nil)           (del-list    nil))\n\n                (defun GPS (state goals &optional ( * o p s * * o p s * ) )\n                  \"General Problem S o l v e r : from s t a t e , achieve goals using * o p s * . \"\n                  (remove-if #'atom ( a c h i e v e - a l l (cons ' ( s t a r t ) s t a t e ) goals n i l ) ) )\n\n\n            The first major change in version 2 is evident from the first line of the program: there\n            is no * s t a t e * variable. Instead, the program keeps track of local state variables.\n            This is to solve the \"leaping before you look\" problem, as outlined before. The\n            functions achieve, achieve -al 1, and apply-op all take an extra argument which is\n            the current state, and all return a new state as their value. They also must still obey\n            the convention of returning nil when they fail.\n                 Thus we have a potential ambiguity: does nil represent failure, or does it rep\n            resent a valid state that happens to have no conditions? We resolve the ambiguity\n            by adopting the convention that all states must have at least one condition. This\n            convention is enforced by the function GPS. Instead of calling (achieve -al 1 s t a t e\n            goals nil), GPS calls ( a c h i e v e - a l l (cons ' ( s t a r t ) s t a t e ) goals nil). Soeven\n            if the user passes GPS a null initial state, it will pass on a state containing ( s t a r t )\n            to achieve -al 1. From then on, we are guaranteed that no state will ever become\n            nil, because the only function that builds a new state is a ppl y - op, and we can see by\n            looking at the last line of appl y - op that it always appends something onto the state it\n            is returning. (An add-list can never be nil, because if it were, the operator would not\n            be appropriate. Besides, every operator includes the (executi ng . . . ) condition.)\n                Note that the final value we return from GPS has all the atoms removed, so we end\n            up reporting only the actions performed, since they are represented by conditions\n            of the form (executi ng action). Adding the ( s t a r t ) condition at the beginning also\n            serves to differentiate between a problem that cannot be solved and one that is solved\n            without executing any actions. Failure returns nil, while a solution with no steps will\n            at least include the ( s t a r t ) condition, if nothing else.\n                Functions that return nil as an indication of failure and return some useful value\n            otherwise are known as semipredicates.            They are error prone in just these cases\n            where nil might be construed as a useful value. Be careful when defining and using\n            semipredicates: (1) Decide if nil could ever be a meaningful value. (2) Insure that\n            the user can't corrupt the program by supplying nil as a value. In this program, GPS\n            is the only function the user should call, so once we have accounted for it, we're\n            covered. (3) Insure that the program can't supply nil as a value. We did this by seeing\n            that there was only one place in the program where new states were constructed,\n            and that this new state was formed by appending a one-element list onto another\n\f128                                                                  CPS; THE GENERAL PROBLEM SOLVER\n\n\n\n      state. By following this three-step procedure, we have an informal proof that the\n      semipredicates involving states will function properly. This kind of informal proof\n      procedure is a common element of good program design.\n\n           The other big change in version 2 is the introduction of a goal stack to solve the\n      recursive subgoal problem. The program keeps track of the goals it is working on\n      and immediately fails if a goal appears as a subgoal of itself. This test is made in the\n      second clause of achi eve.\n           The function a ch i eve - a 11 tries to achieve each one of the goals in turn, setting the\n      variable s t a t e 2 to be the value returned from each successive call to achi eve. If all\n      goals are achieved in turn, and if all the goals still hold at the end (as subsetp checks\n      for), then the final state is returned; otherwise the function fails, returning nil.\n           Most of the work is done by achieve, which gets passed a state, a single goal\n      condition, and the stack of goals worked on so far. If the condition is already in the\n      state, then achieve succeeds and returns the state. On the other hand, if the goal\n      condition is already in the goal stack, then there is no sense continuing--we will be\n      stuck in an endless loop--so achi eve returns nil. Otherwise, achi eve looks through\n      the list of operators, trying to find one appropriate to apply.\n\n          (defun achieve-all ( s t a t e goals g o a l - s t a c k )\n            \"Achieve each g o a l , and make sure they s t i l l hold at the e n d . \"\n            (let ((current-state state))\n              ( i f (and (every #'(lambda (g)\n                                       (setf current-state\n                                             (achieve c u r r e n t - s t a t e g g o a l - s t a c k ) ) )\n                                  goals)\n                         (subsetp goals c u r r e n t - s t a t e rtest # ' e q u a l ) )\n                    current-state)))\n\n          (defun achieve ( s t a t e goal g o a l - s t a c k )\n            \"A goal i s achieved i f i t already h o l d s ,\n            or i f there i s an appropriate op f o r i t that i s a p p l i c a b l e . \"\n            (dbg-indent :gps (length g o a l - s t a c k ) \"Goal: \" a \" goal)\n            (cond ((member-equal goal s t a t e ) s t a t e )\n                   ((member-equal goal g o a l - s t a c k ) n i l )\n                   (t (some #'(lambda (op) (apply-op s t a t e goal op g o a l - s t a c k ) )\n                             ( f i n d - a l l goal * o p s * : t e s t # * a p p r o p r i a t e - p ) ) ) ) )\n\n\n      The goal ( ( e x e c u t i n g r u n - a r o u n d - b l o c k ) ) is a list of one condition, where the\n      condition happens to be a two-element list. Allowing lists as conditions gives us\n      more flexibility, but we also have to be careful. The problem is that not all Usts that\n      look alike actually are the same. The predicate equal essentially tests to see if its two\n      arguments look alike, while the predicate eql tests to see if its two arguments actually\n      are identical. Since functions like member use eql by default, we have to specify with\n      a : t e s t keyword that we want equal instead. Since this is done several times, we\n\f4.11 CPS VERSION      2: A MORE      GENERAL       PROBLEM       SOLVER                                      1 29\n\n\n\n          introduce the function member -equal . In fact, we could have carried the abstraction\n          one step further and defined member-situation, a function to test if a condition is\n          true in a situation. This would allow the user to change the matching function from\n          eql to equal , and to anything else that might be useful.\n\n\n              (defun member-equal (item l i s t )\n                   (member item l i s t : t e s t #*equal))\n\n\n          The function a p p l y - o p , which used to change the state irrevocably and print a mes\n          sage reflecting this, now returns the new state instead of printing anything. It first\n          computes the state that would result from achieving all the preconditions of the\n          operator. If it is possible to arrive at such a state, then a p p l y - o p returns a new state\n          derived from this state by adding what's in the add-list and removing everything in\n          the delete-list.\n\n\n              (defun apply-op (state goal op g o a l - s t a c k )\n                   \"Return a new, transformed state i f op i s a p p l i c a b l e . \"\n                   (dbg-indent :gps (length g o a l - s t a c k ) \"Consider: ~a\" (op-action op))\n                   ( l e t ( ( s t a t e 2 (achieve-all state (op-preconds op)\n                                                         (cons goal g o a l - s t a c k ) ) ) )\n                     (unless (null state2)\n                        ; ; Return an updated state\n                        (dbg-indent :gps (length g o a l - s t a c k ) \" A c t i o n : ~a\" (op-action op))\n                        (append (remove-if #*(lambda (x)\n                                                         (member-equal  ( o p - d e l - l i s t o p ) ) )\n                                                   stateZ)\n                                   (op-add-list op)))))\n\n              (defun appropriate-p (goal op)\n                   \"An op i s appropriate to a goal i f i t i s i n i t s a d d - l i s t . \"\n                   (member-equal goal ( o p - a d d - l i s t o p ) ) )\n\n\n          There is one last complication in the way we compute the new state. In version\n          1 of GPS, states were (conceptually) unordered sets of conditions, so we could use\n          uni on and s e t - d i f f erence to operate on them. In version 2, states become ordered\n          lists, because we need to preserve the ordering of actions. Thus, we have to use the\n          functions append and remove-if, since these are defined to preserve order, while\n          union and s e t - d i f f e r e n c e are not.\n              Finally, the last difference in version 2 is that it introduces a new function: use.\n          This function is intended to be used as a sort of declaration that a given list of operators\n          is to be used for a series of problems.\n\f130                                                                 CPS; THE GENERAL PROBLEM                SOLVER\n\n\n\n          (defun use ( o p l i s t )\n            \"Use o p l i s t as the default l i s t of o p e r a t o r s . \"\n                 Return something u s e f u l , but not too verbose:\n                 the   number of o p e r a t o r s ,\n            (length ( s e t f * o p s * o p l i s t ) ) )\n\n\n      Calling use sets the parameter * o p s * , so that it need not be specified on each call\n      to GPS. Accordingly, in the definition of GPS itself the third argument, * o p s * , is now\n      optional; if it is not supplied, a default will be used. The default value for * o p s * is\n      given as * o p s * . This may seem redundant or superfluous--how could a variable be\n      its own default? The answer is that the two occurrences of * o p s * look alike, but they\n      actually refer to two completely separate bindings of the special variable * o p s * . Most\n      of the time, variables in parameter lists are local variables, but there is no rule against\n      binding a special variable as a parameter. Remember that the effect of binding a\n      special Vciriable is that all references to the special variable that occur anywhere in\n      the program--even outside the lexical scope of the function--refer to the new binding\n      of the special variable. So after a sequence of calls we eventually reach achieve,\n      which references * o p s * , and it will see the newly bound value of * o p s * .\n          The definition of GPS is repeated here, along with an alternate version that binds\n      a local variable and explicitly sets and resets the special variable *ops*. Clearly,\n      the idiom of binding a special variable is more concise, and while it can be initially\n      confusing, it is useful once understood.\n\n          (defun GPS ( s t a t e goals �optional ( * o p s * * o p s * ) )\n            \"General Problem S o l v e r : from s t a t e , achieve goals using * o p s * . \"\n            (remove-if #'atom ( a c h i e v e - a l l (cons ' ( s t a r t ) s t a t e ) goals n i l ) ) )\n\n          (defun GPS ( s t a t e goals �optional (ops * o p s * ) )\n            \"General Problem S o l v e r : from s t a t e , achieve goals using * o p s * . \"\n            (let ((old-ops *ops*))\n               ( s e t f * o p s * ops)\n               ( l e t ( ( r e s u l t (remove-if #'atom ( a c h i e v e - a l l\n                                                                 (cons ' ( s t a r t ) s t a t e )\n                                                                 goalsnil))))\n                   (setf *ops* old-ops)\n                  result)))\n\n\n      Now let's see how version 2 performs. We use the list of operators that includes the\n      \"asking the shop their phone number\" operator. First we make sure it will still do the\n      examples version 1 did:\n\n         > (use * s c h o o l - o p s * )     7\n\f4.11 CPS VERSION    2: A MORE   GENERAL     PROBLEM   SOLVER                      131\n\n\n\n             > (gps '(son-at-home car-needs-battery have-money have-phone-book)\n                     '(son-at-school))\n             ((START)\n               (EXECUTING LOOK-UP-NUMBER)\n               (EXECUTING TELEPHONE-SHOP)\n               (EXECUTING TELL-SHOP-PROBLEM)\n               (EXECUTING GIVE-SHOP-MONEY)\n               (EXECUTING SHOP-INSTALLS-BATTERY)\n               (EXECUTING DRIVE-SON-TO-SCHOOL))\n\n             > (debug : g p s ) => (:GPS)\n\n             > (gps '(son-at-home car-needs-battery have-money have-phone-book)\n                     '(son-at-school))\n             Goal: SON-AT-SCHOOL\n             Consider: DRIVE-SON-TO-SCHOOL\n               Goal: SON-AT-HOME\n               Goal: CAR-WORKS\n               Consider: SHOP-INSTALLS-BATTERY\n                 Goal: CAR-NEEDS-BATTERY\n                 Goal: SHOP-KNOWS-PROBLEM\n                 Consider: TELL-SHOP-PROBLEM\n                   Goal: IN-COMMUNICATION-WITH-SHOP\n                   Consider: TELEPHONE-SHOP\n                      Goal: KNOW-PHONE-NUMBER\n                      Consider: ASK-PHONE-NUMBER\n                               Goal: IN-COMMUNICATION-WITH-SHOP\n                           Consider: LOOK-UP-NUMBER\n                               Goal: HAVE-PHONE-BOOK\n                           A c t i o n : LOOK-UP-NUMBER\n                      A c t i o n : TELEPHONE-SHOP\n                   A c t i o n : TELL-SHOP-PROBLEM\n                   Goal: SHOP-HAS-MONEY\n                   Consider: GIVE-SHOP-MONEY\n                         Goal: HAVE-MONEY\n                     A c t i o n : GIVE-SHOP-MONEY\n                A c t i o n : SHOP-INSTALLS-BATTERY\n             A c t i o n : DRIVE-SON-TO-SCHOOL\n             ((START)\n               (EXECUTING LOOK-UP-NUMBER)\n               (EXECUTING TELEPHONE-SHOP)\n               (EXECUTING TELL-SHOP-PROBLEM)\n               (EXECUTING GIVE-SHOP-MONEY)\n               (EXECUTING SHOP-INSTALLS-BATTERY)\n               (EXECUTING DRIVE-SON-TO-SCHOOL))\n\n             > (undebug)        NIL\n\f132                                                          CPS: THE GENERAL   PROBLEM    SOLVER\n\n\n\n         > (gps *(son-at-home car-works)\n                 '(son-at-school))\n         ((START)\n           (EXECUTING DRIVE-SON-TO-SCHOOL))\n\n\n      Now we see that version 2 can also handle the three cases that version 1 got wrong.\n      In each case, the program avoids an infinite loop, and also avoids leaping before\n      it looks.\n\n         > (gps '(son-at-home car-needs-battery              have-money have-phone-book)\n                '(have-money s o n - a t - s c h o o l ) )\n         NIL\n\n         > (gps '(son-at-home car-needs-battery              have-money have-phone-book)\n                ' ( s o n - a t - s c h o o l have-money))\n         NIL\n\n         > (gps '(son-at-home car-needs-battery              have-money)\n                '(son-at-school))\n         NIL\n\n\n      Finally, we see that this version of G P S also works on trivial problems requiring no\n      action:\n\n         > (gps '(son-at-home)        '(son-at-home)) =^ ((START))\n\n\n\n\n      4.12        The New Domain Problem: Monkey\n                  and Bananas\n      To show that G P S is at all general, we have to make it work in different domains. We\n      will start with a \"classic\" AI problem.^ Imagine the following scenario: a hungry\n      monkey is standing at the doorway to a room. In the middle of the room is a bunch\n      of bananas suspended from the ceiling by a rope, well out of the monkey's reach.\n      There is a chair near the door, which is light enough for the monkey to push and tall\n      enough to reach almost to the bananas. Just to make things complicated, assume the\n      monkey is holding a toy ball and can only hold one thing at a time.\n          In trying to represent this scenario, we have some flexibility in choosing what to\n      put in the current state and what to put in with the operators. For now, assume we\n      define the operators as follows:\n\n         ^Originally posed by Saul Amarel (1968).\n\f4.12   THE NEW DOMAIN         PROBLEM:         MONKEY         AND BANANAS                                   133\n\n\n\n               (defparameter *banana-ops*\n                 (list\n                   (op ' c l i m b - o n - c h a i r\n                         ipreconds '(chair-at-middle-room at-middle-room o n - f l o o r )\n                         : a d d - l i s t '(at-bananas o n - c h a i r )\n                         : d e l - l i s t '(at-middle-room o n - f l o o r ) )\n                     (op 'push-chair-from-door-to-middle-room\n                         :preconds ' ( c h a i r - a t - d o o r at-door)\n                         : a d d - l i s t '(chair-at-middle-room at-middle-room)\n                         : d e l - l i s t '(chair-at-door at-door))\n                     (op 'walk-from-door-to-middle-room\n                         ipreconds ' ( a t - d o o r o n - f l o o r )\n                         ; a d d - l i s t '(at-middle-room)\n                         :del-list '(at-door))\n                     (op 'grasp-bananas\n                         rpreconds '(at-bananas empty-handed)\n                         : a d d - l i s t '(has-bananas)\n                         : d e l - l i s t '(empty-handed))\n                    (op 'drop-ball\n                         ipreconds ' ( h a s - b a l l )\n                         l a d d - l i s t '(empty-handed)\n                         idel-list '(has-balD)\n                    (op 'eat-bananas\n                         ipreconds '(has-bananas)\n                         l a d d - l i s t '(empty-handed not-hungry)\n                         i d e l - l i s t '(has-bananas h u n g r y ) ) ) )\n\n\n           Using these operators, we could pose the problem of becoming not-hungry, given\n           the initial state of being at the door, standing on the floor, holding the ball, hungry,\n           and with the chair at the door. GPS can find a solution to this problem:\n\n              > (use *banana-ops*) => 6\n\n              > (GPS ' ( a t - d o o r o n - f l o o r h a s - b a l l hungry c h a i r - a t - d o o r )\n                      '(not-hungry))\n              ((START)\n                (EXECUTING PUSH-CHAIR-FROM-DOOR-TO-MIDDLE-ROOM)\n                (EXECUTING CLIMB-ON-CHAIR)\n                (EXECUTING DROP-BALL)\n                (EXECUTING GRASP-BANANAS)\n                (EXECUTING EAT-BANANAS))\n\n\n           Notice we did not need to make any changes at all to the GPS program. We just used\n           a different set of operators.\n\f134                                                           CPS: THE GENERAL   PROBLEM   SOLVER\n\n\n\n\n      4.13         The Maze Searching Domain\n\n      Now we will consider another \"classic\" problem, maze searching. We will assume a\n      particular maze, diagrammed here.\n\n\n                                             1     2     3     4       5\n                                           6       7     8     9      10\n                                           11    12    13      14     15\n                                           16    17    18       19    20\n                                           21    22     23     24     25\n\n\n         It is much easier to define some functions to help build the operators for this\n      domain than it would be to type in all the operators directly. The following code\n      defines a set of operators for mazes in general, and for this maze in particular:\n\n         (defun make-maze-ops ( p a i r )\n           \"Make maze ops in both d i r e c t i o n s \"\n           (list   (make-maze-op ( f i r s t p a i r ) (second p a i r ) )\n                   (make-maze-op (second p a i r ) ( f i r s t p a i r ) ) ) )\n\n         (defun make-maze-op (here there)\n           \"Make an operator to move between two places\"\n           (op '(move from ,here to .there)\n                ipreconds ' ( ( a t   .here))\n                :add-list '((at       .there))\n                : d e l - l i s t '((at .here))))\n\n         (defparameter *maze-ops*\n           (mappend #'make-maze-ops\n               ' ( ( 1 2) (2 3) (3 4) (4 9) (9 14) (9 8) (8 7) (7 12) (12 13)\n                   (12 11) (11 6) (11 16) (16 17) (17 22) (21 22) (22 23)\n                   (23 18) (23 24) (24 19) (19 20) (20 15) (15 10) (10 5) (20 2 5 ) ) ) )\n\n\n      Note the backquote notation, ( I t is covered in section 3.2, page 67.\n          We can now use this list of operators to solve several problems with this maze.\n      And we could easily create another maze by giving another list of connections. Note\n      that there is nothing that says the places in the maze are arranged in a five-by-five\n      layout--that is just one way of visualizing the connectivity.\n\n         > (use *maze-ops*)           48\n\f4.13   THE MAZE SEARCHING        DOMAIN                                                                          135\n\n\n\n               > (gps ' ( ( a t D ) � ( ( a t 25)))\n                ((START)\n                 (EXECUTING (MOVE FROM 1 TO 2 ) )\n                 (EXECUTING (MOVE FROM 2 TO 3 ) )\n                 (EXECUTING (MOVE FROM 3 TO 4 ) )\n                 (EXECUTING (MOVE FROM 4 TO 9 ) )\n                 (EXECUTING (MOVE FROM 9 TO 8 ) )\n                 (EXECUTING (MOVE FROM 8 TO 7 ) )\n                 (EXECUTING (MOVE FROM 7 TO 12))\n                 (EXECUTING (MOVE FROM 12 TO I D )\n                 (EXECUTING (MOVE FROM 11 TO 16))\n                (EXECUTING (MOVE FROM 16 TO 17))\n                (EXECUTING (MOVE FROM 17 TO 22))\n                (EXECUTING (MOVE FROM 22 TO 23))\n                (EXECUTING (MOVE FROM 23 TO 24))\n                (EXECUTING (MOVE FROM 24 TO 19))\n                (EXECUTING (MOVE FROM 19 TO 20))\n                (EXECUTING (MOVE FROM 20 TO 25))\n                (AT 25))\n\n\n            There is one subtle bug that the maze domain points out. We wanted GPS to return\n            a list of the actions executed. However, in order to account for the case where the\n            goal can be achieved with no action, I included (START) in the value returned by\n            GPS. These examples include the START and EXECUTING forms but also a list of the\n            form (AT n ) , for some n. This is the bug. If we go back and look at the function\n            GPS, we find that it reports the result by removing all atoms from the state returned\n            by achieve-al 1 . This is a \"pun\"--we said remove atoms, when we really meant\n            to remove all conditions except the (START) and (EXECUTING action) forms. Up to\n            now, all these conditions were atoms, so this approach worked. The maze domain\n            introduced conditions of the form (AT n), so for the first time there was a problem.\n            The moral is that when a programmer uses puns--saying what's convenient instead\n            of what's really happening--there's bound to be trouble. What we really want to do\n            is not to remove atoms but to find all elements that denote actions. The code below\n            says what we mean:\n\n\n               (defun GPS ( s t a t e goals �optional ( * o p s * * o p s * ) )\n                 \"General Problem S o l v e r : from s t a t e , achieve goals using * o p s * . \"\n                 (find-all-if      #*action-p\n                                   ( a c h i e v e - a l l (cons ' ( s t a r t ) s t a t e ) goals n i l ) ) )\n\f136                                                                       CPS; THE GENERAL         PROBLEM   SOLVER\n\n\n\n         (defun a c t i o n - p (x)\n           \" I s  something that i s ( s t a r t ) or (executing . . . ) ? \"\n           (or (equal  ' ( s t a r t ) ) (executing-p x ) ) )\n\n\n      The domain of maze solving also points out an advantage of version 2: that it returns\n      a representation of the actions taken rather than just printing them out. The reason\n      this is an advantage is that we may want to use the results for something, rather than\n      just look at them. Suppose we wanted a function that gives us a path through a maze\n      as a list of locations to visit in turn. We could do this by calling GPS as a subfunction\n      and then manipulating the results:\n\n          (defun f i n d - p a t h ( s t a r t end)\n            \"Search a maze for a path from s t a r t to e n d . \"\n            ( l e t ( ( r e s u l t s (GPS ' ( ( a t . s t a r t ) ) ' ( ( a t . e n d ) ) ) ) )\n                 (unless (null r e s u l t s )\n                   (cons s t a r t (mapcar # ' d e s t i n a t i o n\n                                                   (remove ' ( s t a r t ) r e s u l t s\n                                                                  :test #'equal))))))\n\n          (defun d e s t i n a t i o n ( a c t i o n )\n            \"Find the Y i n (executing (move from X to Y ) ) \"\n            ( f i f t h (second a c t i o n ) ) )\n\n\n      The function f i nd - path calls GPS to get the resul t s . If this is ni 1, there is no answer,\n      but if it is not, then take the r e s t of r e s u l t s (in other words, ignore the (START) part).\n      Pick out the destination,!/, from each (EXECUTING (MOVE FROM  TO y ) ) form, and\n      remember to include the starting point.\n\n          > (use *maze-ops*) => 48\n\n          > ( f i n d - p a t h 1 25) ^\n          (1 2 3 4 9 8 7 12 11 16 17 22 23 24 19 20 25)\n\n          > ( f i n d - p a t h 1 1)         (1)\n\n          > (equal ( f i n d - p a t h 1 25) (reverse ( f i n d - p a t h 25 1 ) ) ) =^ \n\n\n\n\n      4�14            The Blocks World Domain\n       Another domain that has attracted more than its share of attention in AI circles is\n       the blocks world domain. Imagine a child's set of building blocks on a table top.\n       The problem is to move the blocks from their starting configuration into some goal\n       configuration. We will assume that each block can have only one other block directly\n\f4.14 THE BLOCKS   WORLD         DOMAIN                                                        137\n\n\n          on top of it, although they can be stacked to arbitrary height. The only action that\n          can be taken in this world is to move a single block that has nothing on top of it either\n          to the top of another block or onto the table that represents the block world. We will\n          create an operator for each possible block move.\n\n             (defun make-block-ops (blocks)\n               ( l e t ((ops n i l ) )\n                    ( d o l i s t (a blocks)\n                       ( d o l i s t (b blocks)\n                            (unless (equal a b)\n                                ( d o l i s t (c blocks)\n                                   (unless (or (equal c a) (equal c b))\n                                        (push (move-op a b c ) o p s ) ) )\n                                (push (move-op a ' t a b l e b) ops)\n                                (push (move-op a b ' t a b l e ) o p s ) ) ) )\n                   ops))\n\n             (defun move-op (a b c)\n               \"Make an operator to move A from  to C . \"\n               (op '(move .a from .b to , c )\n                   ipreconds ' ( ( s p a c e on ,a) (space on , c ) (,a on . b ) )\n                   l a d d - l i s t (move-ons a b c )\n                   i d e l - l i s t (move-ons a c b ) ) )\n\n             (defun move-ons (a b c)\n               ( i f (eq b ' t a b l e )\n                     * ( ( , a on , c ) )\n                     * ( ( . a on , c ) (space on , b ) ) ) )\n\n\n          Now we try these operators out on some problems. The simplest possible problem\n          is stacking one block on another:\n\n\n\n\n                                                            \n                                                  start                    goal\n\n\n             > (use (make-block-ops          ' ( a b ) ) ) =^ 4\n\n             > (gps ' ( ( a on table) (b on table) (space on a) (space on b)\n                          (space on t a b l e ) )\n                     ' ( ( a on b) (b on t a b l e ) ) )\n             ((START)\n               (EXECUTING (MOVE A FROM TABLE TO B ) ) )\n\f138                                                        CPS; THE GENERAL   PROBLEM    SOLVER\n\n\n\n      Here is a slightly more complex problem: inverting a stack of two blocks. This time\n      we show the debugging output.\n\n\n\n\n                                             start         goa\n\n\n         > (debug : g p s )         (:GPS)\n         > (gps *((a on b) (b on table) (space on a) (space on t a b l e ) )\n                      ' ( ( b on a ) ) )\n         Goal: (B ON A)\n         Consider: (MOVE  FROM TABLE TO A)\n            Goal: (SPACE ON B)\n            Consider: (MOVE A FROM  TO TABLE)\n                 Goal: (SPACE ON A)\n                 Goal: (SPACE ON TABLE)\n                 Goal: (A ON B)\n            A c t i o n : (MOVE A FROM  TO TABLE)\n            Goal: (SPACE ON A)\n            Goal: (B ON TABLE)\n         A c t i o n : (MOVE  FROM TABLE TO A)\n         ((START)\n           (EXECUTING (MOVE A FROM  TO TABLE))\n           (EXECUTING (MOVE  FROM TABLE TO A ) ) )\n\n         > (undebug)          NIL\n\n\n      Sometimes it matters what order you try the conjuncts in. For example, you can't\n      have your cake and eat it too, but you can take a picture of your cake and eat it too, as\n      long as you take the picture before eating it. In the blocks world, we have:\n\n                                               A             C\n                                              _B_           _B_\n                                               C            A\n                                             start         goal\n\n\n         > (use (make-block-ops ' ( a b c ) ) )       18\n         > (gps ' ( ( a   on b) (b on c) (c on table) (space on a) (space on t a b l e ) )\n                 '((b     on a) (c on b ) ) )\n         ((START)\n           (EXECUTING     (MOVE A FROM  TO TABLE))\n           (EXECUTING     (MOVE  FROM C TO A ) )\n           (EXECUTING     (MOVE C FROM TABLE TO B ) ) )\n\f4.14   THE BLOCKS   WORLD      DOMAIN                                                                              139\n\n\n\n               > (gps ' ( ( a on b) (b on c) (c on table) (space on a) (space on t a b l e ) )\n                      ' ( ( c on b) (b on a ) ) )\n               NIL\n\n\n\n            In the first case, the tower was built by putting  on A first, and then C on B . In\n            the second case, the program gets C on  first, but clobbers that goal while getting \n            on A. The \"prerequisite clobbers sibling goal\" situation is recognized, but the program\n            doesn't do anything about it. One thing we could do is try to vary the order of the\n            conjunct goals. That is, we could change a c h i e v e - a l 1 as follows:\n\n               (defun a c h i e v e - a l l ( s t a t e goals g o a l - s t a c k )\n                 \"Achieve each g o a l , t r y i n g several o r d e r i n g s . \"\n                 (some #'(lambda ( g o a l s ) (achieve-each s t a t e goals g o a l - s t a c k ) )\n                       (orderings g o a l s ) ) )\n\n               (defun achieve-each ( s t a t e goals g o a l - s t a c k )\n                 \"Achieve each g o a l , and make sure they s t i l l hold at the e n d . \"\n                 (let ((current-state state))\n                   ( i f (and (every #'(lambda (g)\n                                           (setf current-state\n                                                  (achieve c u r r e n t - s t a t e g g o a l - s t a c k ) ) )\n                                       goals)\n                              (subsetp goals c u r r e n t - s t a t e : t e s t #*equal))\n                         current-state)))\n\n               (defun orderings (1)\n                 ( i f ( > (length 1) 1)\n                       (1 i s t 1 (reverse 1))\n                       ( l i s t 1)))\n\n\n            Now we can represent the goal either way, and we'll still get an answer. Notice that\n            we only consider two orderings: the order given and the reversed order. Obviously,\n            for goal sets of one or two conjuncts this is all the orderings. In general, if there\n            is only one interaction per goal set, then one of these two orders will work. Thus,\n            we are assuming that \"prerequisite clobbers sibling goal\" interactions are rare, and\n            that there will seldom be more than one interaction per goal set. Another possibility\n            would be to consider all possible permutations of the goals, but that could take a long\n            time with large goal sets.\n                Another consideration is the efficiency of solutions. Consider the simple task of\n            getting block C on the table in the following diagram:\n\n\n\n\n                                 A]            \\B]                [A]            [B]\n                                       start                                    goal\n\f140                                                        GPS: THE GENERAL        PROBLEM   SOLVER\n\n\n\n         > (gps ' ( ( c on a) (a on t a b l e ) (b on t a b l e )\n                       (space on c) (space on b) (space on t a b l e ) )\n                 ' ( ( c on t a b l e ) ) )\n         ((START)\n           (EXECUTING (MOVE C FROM A TO B))\n           (EXECUTING (MOVE C FROM  TO TABLE)))\n\n\n      The solution is correct, but there is an easier solution that moves C directly to the\n      table. The simpler solution was not found because of an accident: it happens that\n      make-bl ock-ops defines the operators so that moving C from  to the table comes\n      before moving C from A to the table. So the first operator is tried, and it succeeds\n      provided C is on B. Thus, the two-step solution is found before the one-step solution is\n      ever considered. The following example takes four steps when it could be done in two:\n\n\n\n\n                                             \n                                     start                         goal\n\n\n         > (gps ' ( ( c on a) (a on t a b l e ) (b on t a b l e )\n                       (space on c) (space on b) (space on t a b l e ) )\n                 ' ( ( c on table) (a on b ) ) )\n         ((START)\n           (EXECUTING (MOVE C FROM A TO B))\n           (EXECUTING (MOVE C FROM  TO TABLE))\n           (EXECUTING (MOVE A FROM TABLE TO O )\n           (EXECUTING (MOVE A FROM C TO B ) ) )\n\n\n      How could we find shorter solutions? One way would be to do a full-fledged search:\n      shorter solutions are tried first, temporarily abandoned when something else looks\n      more promising, and then reconsidered later on. This approach is taken up in\n      chapter 6, using a general searching function. A less drastic solution is to do a limited\n      rearrangement of the order in which operators are searched: the ones with fewer\n      unfulfilled preconditions are tried first. In particular, this means that operators with\n      all preconditions filled would always be tried before other operators. To implement\n      this approach, we change achi eve:\n\n          (defun achieve ( s t a t e goal g o a l - s t a c k )\n            \"A goal i s achieved i f i t already h o l d s ,\n            or i f there i s an appropriate op for i t that i s a p p l i c a b l e . \"\n            (dbg-indent :gps (length g o a l - s t a c k ) \" G o a l : ~ a \" goal)\n            (cond ((member-equal goal s t a t e ) s t a t e )\n                   ((member-equal goal g o a l - s t a c k ) n i l )\n\f4,14   THE BLOCKS   WORLD              DOMAIN                                                                                       141\n\n\n                            (t   (some #'(lambda (op) (apply-op state goal op g o a l - s t a c k ) )\n                                       (appropriate-ops goal s t a t e ) ) ) ) )\n               (defun appropriate-ops (goal state)\n                 \"Return a l i s t of appropriate operators,\n                 sorted by the number of u n f u l f i l l e d p r e c o n d i t i o n s . \"\n                 ( s o r t ( c o p y - l i s t ( f i n d - a l l goal * o p s * : t e s t # ' a p p r o p r i a t e - p ) ) # ' <\n                           :key #*(lambda (op)\n                                              ( c o u n t - i f #'(lambda (precond)\n                                                                     (not (member-equal precond s t a t e ) ) )\n                                                                (op-preconds o p ) ) ) ) )\n\n\n            Now we get the solutions we wanted:\n\n\n\n\n                                                    start                                   goal\n\n\n               > (gps ' ( ( c on a) (a on table) (b on table)\n                            (space on c) (space on b) (space on t a b l e ) )\n                       ' ( ( c on table) (a on b ) ) )\n               ((START)\n                 (EXECUTING (MOVE C FROM A TO TABLE))\n                 (EXECUTING (MOVE A FROM TABLE TO B ) ) )\n\n\n\n\n                                                             start                 goal\n\n\n               > (gps ' ( ( a     on b) (b on c) (c on table)                     (space on a) (space on t a b l e ) )\n                       '((b       on a) (c on b ) ) )\n               ((START)\n                 (EXECUTING       (MOVE A FROM  TO TABLE))\n                 (EXECUTING       (MOVE  FROM C TO A))\n                 (EXECUTING       (MOVE C FROM TABLE TO B ) ) )\n               > (gps ' ( ( a     on b) (b on c) (c on table)                     (space on a) (space on t a b l e ) )\n                       '((c       on b) (b on a ) ) )\n               ((START)\n                 (EXECUTING       (MOVE A FROM  TO TABLE))\n                 (EXECUTING       (MOVE  FROM C TO A))\n                 (EXECUTING       (MOVE C FROM TABLE TO B ) ) )\n\f142                                                    CPS; THE GENERAL     PROBLEM      SOLVER\n\n\n\n      The Sussman Anomaly\n\n      Surprisingly, there are problems that can't be solved by any reordering of goals.\n      Consider:\n\n\n\n\n                                                 A\n                                         Start                goal\n\n      This doesn't look too hard, so let's see how our GPS handles it:\n\n         > (setf start ' ( ( c on a) (a on table) (b on table) (space on c)\n                           (space on b) (space on table)))\n         ((C ON A) (A ON TABLE) (B ON TABLE) (SPACE ON C)\n          (SPACE ON B) (SPACE ON TABLE))\n\n         > (gps start ' ( ( a on b) (b on c ) ) )    NIL\n\n         > (gps start *((b on c) (a on b ) ) ) =^ NIL\n\n\n      There is a \"prerequisite clobbers sibling goal\" problem regardless of which way we\n      order the conjuncts! In other words, no combination of plans for the two individual\n      goals can solve the conjunction of the two goals. This is a surprising fact, and the\n      example has come to be known as \"the Sussman anomaly.\"^ We will return to this\n      problem in chapter 6.\n\n\n\n\n      4.15       Stage 5 Repeated: Analysis of Version 2\n\n      We have shown that GPS is extensible to multiple domains. The main point is that\n      we didn't need to change the program itself to get the new domains to work; we\n      just changed the list of operators passed to GPS. Experience in different domains\n      did suggest changes that could be made, and we showed how to incorporate a few\n      changes. Although version 2 is a big improvement over version 1, it still leaves much\n      to be desired. Now we will discover a few of the most troubling problems.\n\n        ^ A footnote in Waldinger 1977 says, 'This problem was proposed by Allen Brown. Perhaps\n      many children thought of it earlier but did not recognize that it was hard.\" The problem is\n      named after Gerald Sussman because he popularized it in Sussman 1973.\n\f4.16 THE NOT LOOKING       AFTER YOU               LEAP PROBLEM                                 143\n\n\n\n          4.16        The Not Looking after You Don^t\n                      Leap Problem\n         We solved the \"leaping before you look\" problem by introducing variables to hold a\n         representation of possible future states, rather than just a single variable representing\n         the current state. This prevents GPS from taking an ill-advised action, but we shall\n         see that even with all the repair strategies introduced in the last section, it doesn't\n         guarantee that a solution will be found whenever one is possible.\n             To see the problem, add another operator to the front of the ^school - ops* Hst\n         and turn the debugging output back on:\n\n             (use(push (op ' t a x i - s o n - t o - s c h o o l\n                            :preconds *(son-at-home have-money)\n                            :add-list '(son-at-school)\n                            : d e l - l i s t '(son-at-home have-money))\n                        *school-ops*))\n\n             (debug : g p s )\n\n\n          Now, consider the problem of getting the child to school without using any money:\n\n             > (gps '(son-at-home have-money car-works)\n                          ' ( s o n - a t - s c h o o l have-money))\n             Goal: SON-AT-SCHOOL\n             Consider: TAXI-SON-TO-SCHOOL\n                Goal: SON-AT-HOME\n                Goal: HAVE-MONEY\n             A c t i o n : TAXI-SON-TO-SCHOOL\n             Goal: HAVE-MONEY\n             Goal: HAVE-MONEY\n             Goal: SON-AT-SCHOOL\n             Consider: TAXI-SON-TO-SCHOOL\n                Goal: SON-AT-HOME\n                Goal: HAVE-MONEY\n             A c t i o n : TAXI-SON-TO-SCHOOL\n             NIL\n\n\n          The first five lines of output succesfully solve the son-at-school goal with the\n          TAX I - SON - TO - SCHOO L action. The next line shows an unsuccesf ul attempt to solve the\n          have - money goal. The next step is to try the other ordering. This time, the have - money\n          goal is tried first, and succeeds. Then, the son-at-school goal is achieved again by\n          the TAX I - SON - TO - SCHOO L action. But the check for consistency in achi eve-each fails,\n          and there are no repairs available. The goal fails, even though there is a valid solution:\n          driving to school.\n\f144                                                      CPS; THE GENERAL       PROBLEM      SOLVER\n\n\n\n          The problem is that achi eve uses some to look at the appropri a t e - o p s . Thus, if\n      there is some appropriate operator, achi eve succeeds. If there is only one goal, this\n      will yield a correct solution. However, if there are multiple goals, as in this case,\n      achi eve will still only find one way to fulfill the first goal. If the first solution is a bad\n      one, the only recourse is to try to repair it. In domains like the block world and maze\n      world, repair often works, because all steps are reversible. But in the taxi example, no\n      amount of plan repair can get the money back once it is spent, so the whole plan fails.\n          There are two ways around this problem. The first approach is to examine all\n      possible solutions, not just the first solution that achieves each subgoal. The language\n      Prolog, to be discussed in chapter 11, does just that. The second approach is to have\n      achi eve and achi eve-al 1 keep track of a list of goals that must be protected. In the\n      taxi example, we would trivially achieve the have-money goal and then try to achieve\n      s o n - a t - s c h o o l , while protecting the goal have-money. An operator would only\n      be appropriate if it didn't delete any protected goals. This approach still requires\n      some kind of repair or search through multiple solution paths. If we tried only\n      one ordering-achieving son - a t - school and then trying to protect it while achieving\n      have - money--then we would not find the solution. David Warren's WARPLAN planner\n      makes good use of the idea of protected goals.\n\n\n\n      4.17        The Lack of Descriptive Power Problem\n      It would be a lot more economical, in the maze domain, to have one operator that\n      says we can move from here to there if we are at \"here,\" and if there is a connection\n      from \"here\" to \"there.\" Then the input to a particular problem could list the valid\n      connections, and we could solve any maze with this single operator. Similarly, we\n      have defined an operator where the monkey pushes the chair from the door to the\n      middle of the room, but it would be better to have an operator where the monkey\n      can push the chair from wherever it is to any other nearby location, or better yet, an\n      operator to push any \"pushable\" object from one location to a nearby one, as long\n      as there is no intervening obstacle. The conclusion is that we would like to have\n      variables in the operators, so we could say something like:\n\n          (op ' ( p u s h X from A to B)\n            :preconds '((monkey at A) (X at A) (pushable X) (path A B ) )\n            : a d d - l i s t '((monkey at B) (X at B ) )\n            : d e l - l i s t '((monkey at A) (X at A ) ) )\n\n\n      Often we want to characterize a state in terms of something more abstract than a\n      list of conditions. For example, in solving a chess problem, the goal is to have the\n      opponent in checkmate, a situation that cannot be economically described in terms\n      of primitives like (bl ack ki ng on A 4 ) , so we need to be able to state some kind\n\f4.18   THE PERFECT INFORMATION      PROBLEM                                                     145\n\n\n\n            of constraint on the goal state, rather than just listing its components. We might\n            want to be able to achieve a disjunction or negation of conditions, where the current\n            formalism allows only a conjunction.\n                It also is important, in many domains, to be able to state problems dealing with\n            time: we want to achieve X before time To, and then achieve Y before time T2, but\n            not before Ti. Scheduling work on a factory floor or building a house are examples\n            of planning where time plays an important role.\n                Often there are costs associated with actions, and we want to find a solution\n            with minimal, or near-minimal costs. The cost might be as simple as the number of\n            operators required for a solution--we saw in the blocks world domain that sometimes\n            an operator that could be applied immediately was ignored, and an operator that\n            needed several preconditions satisfied was chosen instead. Or we may be satisfied\n            with a partial solution, if a complete solution is impossible or too expensive. We may\n            also want to take the cost (and time) of computation into account.\n\n\n\n            4.18       The Perfect Information Problem\n            All the operators we have seen so far have unambiguous results; they add or delete\n            certain things from the current state, and GPS always knows exactly what they are\n            going to do. In the real world, things are rarely so cut and dried. Going back to the\n            problem of becoming rich, one relevant operator would be playing the lottery. This\n            operator has the effect of consuming a few dollars, and once in a while paying off a\n            large sum. But we have no way to represent a payoff \"once in a while.\" Similarly,\n            we have no way to represent unexpected difficulties of any kind. In the nursery\n            school problem, we could represent the problem with the car battery by having GPS\n            explicitly check to see if the car was working, or if it needed a battery, every time\n            the program considered the driving operator. In the real world, we are seldom this\n            careful; we get in the car, and only when it doesn't start do we consider the possibility\n            of a dead battery.\n\n\n\n            4.19       The Interacting Goals Problem\n            People tend to have multiple goals, rather than working on one at a time. Not only do\n            I want to get the kid to nursery school, but I want to avoid getting hit by another car,\n            get to my job on time, get my work done, meet my friends, have some fun, continue\n            breathing, and so on. I also have to discover goals on my own, rather than work on\n            a set of predefined goals passed to me by someone else. Some goals I can keep in\n            the background for years, and then work on them when the opportunity presents\n            itself. There is never a notion of satisfying all possible goals. Rather, there is a\n\f146                                                    CPS; THE GENERAL     PROBLEM      SOLVER\n\n\n\n      continual process of achieving some goals, partially achieving others, and deferring\n      or abandoning still others.\n          In addition to having active goals, people also are aware of undesirable situations\n      that they are trying to avoid. For example, suppose I have a goal of visiting a friend\n      in the hospital. This requires being at the hospital. One appHcable operator might\n      be to walk to the hospital, while another would be to severly injure myself and wait\n      for the ambulance to take me there. The second operator achieves the goal just as\n      well (perhaps faster), but it has an undesirable side effect. This could be addressed\n      either with a notion of solution cost, as outlined in the last section, or with a list of\n      background goals that every solution attempts to protect.\n          Herb Simon coined the term \"satisficing\" to describe the strategy of satisfying a\n      reasonable number of goals to a reasonable degree, while abandoning or postponing\n      other goals. GPS only knows success and failure, and thus has no way of maximizing\n      partial success.\n\n\n\n      4.20       The End of GPS\n      These last four sections give a hint as to the scope of the limitations of GPS. In fact, it\n      is not a very general problem solver at all. It is general in the sense that the algorithm\n      is not tied to a particular domain; we can change domain by changing the operators.\n      But GPS fails to be general in that it can't solve many interesting problems. It is\n      confined to small tricks and games.\n           There is an important yet subtle reason why GPS was destined to fail, a reason\n      that was not widely appreciated in 1957 but now is at the core of computer science.\n      It is now recognized that there are problems that computers can't solve--not because\n      a theoretically correct program can't be written, but because the execution of the\n      program will take too long. A large number of problems can be shown to fall into\n      the class of \"NP-hard\" problems. Computing a solution to these problems takes\n      time that grows exponentially as the size of the problem grows. This is a property\n      of the problems themselves, and holds no matter how clever the programmer is.\n      Exponential growth means that problems that can be solved in seconds for, say, a\n      five-input case may take trillions of years when there are 100 inputs. Buying a faster\n      computer won't help much. After all, if a problem would take a trillion years to solve\n      on your computer, it won't help much to buy 1000 computers each 1000 times faster\n      than the one you have: you're still left with a million years wait. For a theoretical\n      computer scientist, discovering that a problem is NP-hard is an end in itself. But for\n      an AI worker, it means that the wrong question is being asked. Many problems are\n      NP-hard when we insist on the optimal solution but are much easier when we accept\n      a solution that might not be the best.\n           The input to GPS is essentially a program, and the execution of GPS is the execution\n      of that program. If GPS's input language is general enough to express any program.\n\f4.21   HISTORY   AND REFERENCES                                                                        147\n\n\n\n\n            then there will be problems that can't be solved, either because they take too long\n            to execute or because they have no solution. Modern problem-solving programs\n            recognize this fundamental limitation, and either limit the class of problems they try\n            to solve or consider ways of finding approximate or partial solutions. Some problem\n            solvers also monitor their own execution time and know enough to give up when a\n            problem is too hard.\n                The following quote from Drew McDermott's article \"Artificial Intelligence Meets\n            Natural Stupidity\" sums up the current feeling about GPS. Keep it in mind the next\n            time you have to name a program.\n\n                   Remember G P S ? By now, \"GPS\" is a colorless term denoting a particularly stupid\n                   program to solve puzzles. But it originally meant ''General Problem Solver,\"\n                   which caused everybody a lot of needless excitement and distraction. It should\n                   have been called LFGNS-\"Loca/ Feature-Guided Network Searcher.\"\n\n                Nonetheless, GPS has been a useful vehicle for exploring programn�ng in general,\n            and AI programming in particular. More importantly, it has been a useful vehicle\n            for exploring \"the nature of deliberation.\" Surely we'll admit that Aristotle was\n            a smarter person than you or me, yet with the aid of the computational model of\n            mind as a guiding metaphor, and the further aid of a working computer program\n            to help explore the metaphor, we have been led to a more thorough appreciation of\n            means-ends analysis--at least within the computational model. We must resist the\n            temptation to believe that all thinking follows this model.\n                The appeal of AI can be seen as a split between means and ends. The end of a\n            successful AI project can be a program that accomplishes some useful task better,\n            faster, or cheaper than it could be before. By that measure, GPS is a mostly a failure,\n            as it doesn't solve many problems particularly well. But the means toward that end\n            involved an investigation and formalization of the problem-solving process. By that\n            measure, our reconstruction of GPS is a success to the degree in which it leads the\n            reader to a better understanding of the issues.\n\n\n\n            4.21        History and References\n            The original GPS is documented in Newell and Simon's 1963 paper and in their 1972\n            book. Human Problem Solving, as well as in Ernst and Newell 1969. The implementa\n            tion in this chapter is based on the STRIPS program (Fikes and Nilsson 1971).\n                 There are other important planning programs. Earl Sacerdoti's ABSTRIPS program\n            was a modification of STRIPS that allowed for hierarchical planning. The idea was to\n            sketch out a skeletal plan that solved the entire program at an abstract level, and then\n            fill in the details. David Warren's WARPLAN planner is covered in Warren 1974a,b\n            and in a section of Coelho and Cotta 1988. Austin Tate's NONLIN system (Tate 1977)\n\f148                                                       CPS; THE GENERAL     PROBLEM      SOLVER\n\n\n\n           achieved greater efficiency by considering a plan as a partially ordered sequence of\n           operations rather than as a strictly ordered sequence of situations. David Chapman's\n           TWEAK synthesizes and formalizes the state of the art in planning as of 1987.\n              All of these papers-and quite a few other important planning papers-are\n           reprinted in Allen, Hendler, and Tate 1990.\n\n\n\n\n           4.22 Exercises\n      t�3 Exercise 4.1 [m] It is possible to implement dbg using a single call to format. Can\n          you figure out the format directives to do this?\n\n\n      t�3 Exercise 4.2 [m]    Write a function that generates all permutations of its input.\n\n\n      13   Exercise 4.3 [h] GPS does not recognize the situation where a goal is accidentally\n           solved as part of achieving another goal. Consider the goal of eating dessert. Assume\n           that there are two operators available: eating ice cream (which requires having the\n           ice cream) and eating cake (which requires having the cake). Assume that we can\n           buy a cake, and that the bakery has a deal where it gives out free ice cream to each\n           customer who purchases and eats a cake. (1) Design a list of operators to represent\n           this situation. (2) Give gps the goal of eating dessert. Show that, with the right list\n           of operators, gps will decide to eat ice cream, then decide to buy and eat the cake in\n           order to get the free ice cream, and then go ahead and eat the ice cream, even though\n           the goal of eating dessert has already been achieved by eating the cake. (3) Fix gps so\n           that it does not manifest this problem.\n               The following exercises address the problems in version 2 of the program.\n\n\n      SI   Exercise 4.4 [h] The Not Looking after You Don't Leap Problem. Write a program that\n           keeps track of the remaining goals so that it does not get stuck considering only one\n           possible operation when others will eventually lead to the goal. Hint: have achi eve\n           take an extra argument indicating the goals that remain to be achieved after the\n           current goal is achieved, achi eve should succeed only if it can achieve the current\n           goal and also achi e v e - a l l the remaining goals.\n\n\n      @    Exercise 4.5 [d] Write a planning program that, like Warren's WARPLAN, keeps\n           track of the list of goals that remain to be done as well as the list of goals that have\n           been achieved and should not be undone. The program should never undo a goal\n           that has been achieved, but it should allow for the possibility of reordering steps that\n\f4.23   ANSWERS                                                                                                       149\n\n\n\n            have already been taken. In this way, the program will solve the Sussman anomaly\n            and sin�lar problems.\n\n\n       @    Exercise 4.6 [d] The Lack of Descriptive Power Problem. Read chapters 5 and 6 to learn\n            about pattern matching. Write a version of GPS that uses the pattern matching tools,\n            and thus allows variables in the operators. Apply it to the maze and blocks world\n            domains. Your program will be more efficient if, like Chapman's TWEAK program,\n            you allow for the possibility of variables that remain unbound as long as possible.\n\n\n       E�] Exercise 4.7 [d] Speculate on the design of a planner that can address the Perfect\n           Information and Interacting Goals problems.\n\n\n\n\n            4.23          Answers\n\n            Answer 4.1 In this version, the format string \" ~&~V�T~?\" breaks down as follows:\n                 means go to a fresh line; \"~V�T\" means insert spaces (�T) but use the next\n            argument (V) to get the number of spaces. The \" ~?\" is the indirection operator: use\n            the next argument as a format string, and the argument following that as the list of\n            arguments for the format string.\n\n                 (defun dbg-indent ( i d indent f o r m a t - s t r i n g &rest args)\n                   \" P r i n t indented debugging i n f o i f       (DEBUG ID) has been s p e c i f i e d . \"\n                   (when (member id * d b g - i d s * )\n                      (format * d e b u g - i o * \"~&~v�T~?\" ( * 2 indent) f o r m a t - s t r i n g a r g s ) ) )\n\f150                                                           CPS; THE GENERAL         PROBLEM     SOLVER\n\n\n\n      Answer 4.2 Here is one solution. The sophisticated Lisp programmer should also\n      see the exercise on page 680.\n\n         (defun permutations (bag)\n           \"Return a l i s t of a l l the permutations of the i n p u t . \"\n                I f the input i s n i l , there i s only one permutation:\n                nil i t s e l f\n           ( i f (null bag)\n                   '(())\n                      Otherwise, take an element, e, out of the bag.\n                      Generate a l l permutations of the remaining elements.\n                      And add e to the f r o n t of each of these.\n                      Do t h i s for a l l p o s s i b l e e to generate a l l permutations,\n                  (mapcan #'(lambda (e)\n                                  (mapcar #*(lambda (p) (cons e p))\n                                             (permutations\n                                                (remove e bag :count 1 : t e s t # ' e q ) ) ) )\n                             bag)))\n\fCHAPTER                    5\n\nELIZA : Dialog with a Machine\n\n                                                               It is said that to explain is to explain away.\n                                                                                  --Joseph Weizenbaum\n                                                                                  MIT computer scientist\n\n\n\n\nI I 1 his chapter and the rest of part I will examine three more well-known AI programs of\n   I    the 1960s. ELIZA held a conversation with the user in which it simulated a psychother-\n        apist. STUDENT solved word problems of the kind found in high school algebra books,\nand MACSYMA solved a variety of symbolic mathematical problems, including differential and\nintegral calculus. We will develop versions of the first two programs that duplicate most of\nthe essential features, but for the third we will implement only a tiny fraction of the original\nprogram's capabilities.\n   All three programs make heavy use of a technique called pattern matching. Part I serves to\nshow the versatility--and also the limitations--of this technique.\n    Of the three programs, the first two process input in plain English, and the last two solve non-\ntrivial problems in mathematics, so there is some basis for describing them as being \"intelligent.\"\nOn the other hand, we shall see that this intelligence is largely an illusion, and that ELIZA in\nparticular was actually designed to demonstrate this illusion, not to be a \"serious\" AI program.\n\f152                                                          ELIZA; DIALOG      WITH A      MACHINE\n\n\n\n         ELIZA was one of the first programs to feature English output as well as input.\n      The program was named after the heroine of Pygmalion, who was taught to speak\n      proper English by a dedicated teacher. ELIZA'S principal developer, MIT professor\n      Joseph Weizenbaum, published a paper on ELIZA in the January 1966 issue of the\n      Communications of the Association for Computing Machinery. The introduction to that\n      paper is reproduced in its entirety here:\n\n           It is said that to explain is to explain away. This maxim is nowhere so well\n           fulfilled as in the area of computer programming, especially in what is called\n            heuristic programming and artificial intelligence. For in those realms machines\n            are made to behave in wondrous ways, often sufficient to dazzle even the most\n            experienced observer. But once a particular program is unmasked, once its inner\n            workings are explained in language sufficiently plain to induce understanding\n            its magic crumbles away; it stands revealed as a mere collection of procedures,\n            each quite comprehensible. The observer says to himself, \"I could have written\n            that.\" With that thought he moves the program in question from the shelf\n            marked \"intelligent,\" to that reserved for curios, fit to be discussed only with\n           people less enlightened than he.\n            The object of this paper is to cause just such a re-evaluation of the program about\n            to be \"explained.\" Few programs ever needed it more.\n\n          Let me point out in passing that the main object of this book is to cause the reader\n      to say to him or herself, \"I could have written that.\" It is hoped that in some cases\n      this will be because the reader has gained something, and not solely because the\n      programs in question have lost their ability to dazzle.\n          Let's start our investigation of ELIZA by looking at a sample dialog from the\n      Weizenbaum article. ELIZA was designed to be instructed by a variety of scripts, or\n      patterns of interaction. In fact it had several scripts, including ones in German and\n      Welsh. But the only script that was used to any extent was in English, and it made\n      ELIZA emulate a Rogerian psychoanalyst. Rogerians are \"nondirective\"--they try to\n      let the patient reveal himself. This is an easy script for ELIZA to follow, because it\n      involves being passive and reacting, rather than volunteering new information. In\n      the listing that follows, the user's input is in mixed case, and ELIZA'S response is in\n      capitals:\n\n         Men are all a l i k e .\n         IN WHAT WAY\n         They're always bugging us about something or another.\n         CAN YOU BE MORE SPECIFIC\n         Well, my boyfriend made me come here.\n         YOUR BOYFRIEND MADE YOU COME HERE\n         He says I'm depressed much of the time.\n         I AM SORRY TO HEAR YOU ARE DEPRESSED\n\fINTRODUCTION                                                                                 153\n\n\n\n               I t ' s true. I am unhappy.\n               DO YOU THINK COMING HERE WILL HELP YOU NOT TO BE UNHAPPY\n               I need some help, that much seems c e r t a i n .\n               WHAT WOULD IT MEAN TO YOU IF YOU GOT SOME HELP\n               Perhaps I could learn to get along with my mother.\n               TELL ME MORE ABOUT YOUR FAMILY\n\n\n          This seems quite impressive; the program is responding reasonably to a variety of\n          inputs and appears to be exhibiting true \"understanding.\" But, as Weizenbaum\n          explains, this appearance is an illusion, and the program has finessed the difficult\n          task of understanding by carefully recognizing, transforming, and echoing pieces\n          of the input. The procedure is to look for specific patterns, based on a key word\n          or words in the input. For example, whenever the program sees the words \"alike\"\n          or \"same,\" it prints a message asking about similarity, in this case, \"IN W     HAT WAY.\"\n          Other patterns are more complicated. In the next to last exchange, ELIZA first throws\n          away everything after the comma, and then uses a pattern that looks for input of\n          the form \"I need X\" and transforms it to the output \"What would it mean to you if\n          you got X,\" where X is the phrase \"some help\" in this case. The great advantage of\n          this approach is that the response will make sense for a variety of inputs: \"I need\n          a vacation\" will elicit \"What would it mean to you if you got a vacation.\" This will\n          work automatically, without having to tell the program the difference between \"some\n          help\" and \"a vacation.\" The disadvantage is that the program will sometimes make\n          silly responses: \"I need this like a hole in the head\" will be answered with \"What\n          would it mean to you if you got this like a hole in the head.\" In fact, the program only\n          makes any sense at all if it is receiving input from someone who makes sense--and\n          someone who interprets its answers charitably. When given \"I need gibble plix zzq,\"\n          ELIZA would reply \" What would it mean to you if you got gibble plix zzq,\" without any\n          inkling that something is wrong. Another example of the original ELIZA program has\n          it communicating with another program, PARRY, which was written by Dr. Kenneth\n          Colby to mimic paranoid behavior. Part of the conversation follows, with ELIZA again\n          in capitals and PARRY in mixed case:\n\n               I d o n ' t understand your motives.\n               WHY DON'T YOU UNDERSTAND MY MOTIVES?\n               S h o u l d n ' t I be?\n               WHY DO YOU SAY THAT JUST NOW?\n               T h a t ' s j u s t the way i t i s .\n               SUPPOSE THAT'S JUST THE WAY IT WERE NOT.\n               So?\n               I AM NOT SURE I UNDERSTAND YOU FULLY.\n               You harp on the same questions too much.\n               WHAT DOES THAT SIMILARITY SUGGEST TO YOU?\n               I d o n ' t get y o u .\n               DO YOU WISH THAT YOU DID GET I ?\n\f154                                                       E L I Z A ; DIALOG   WITH A   MACHINE\n\n\n\n      This suggests that neither ELIZA nor PARRY had a deep understanding of the dialog.\n      When there is a human to take on most of the burden of carrying forth the conver\n      sation, these programs can be convincing, but when the human is taken out of the\n      conversation, the weaknesses of the programs are revealed.\n\n\n\n\n      5.1      Describing and Specifying                           ELIZA\n\n      Now that we have an idea of what ELIZA is like, we can begin the description and spec\n      ification of the program, and eventually move to the implementation and debugging.\n          The ELIZA algorithm can be described simply as: (1) read an input, (2) find a\n      pattern that matches the input, (3) transform the input into a response, and (4) print\n      the response. These four steps are repeated for each input.\n          The specification and implementation of steps (1) and (4) are trivial: for (1), use\n      the built-in read function to read a list of words, and for (4) use print to print the list\n      of words in the response.\n          Of course, there are some drawbacks to this specification. The user will have\n      to type a real list--using parentheses--and the user can't use characters that are\n      special to read, like quotation marks, commas, and periods. So our input won't\n      be as unconstrained as in the sample dialog, but that's a small price to pay for the\n      convenience of having half of the problem neatly solved.\n\n\n\n\n      5.2      Pattern Matching\n      The hard part comes with steps (2) and (3)--this notion of pattern matching and\n      transformation. There are four things to be concerned with: a general pattern and\n      response, and a specific input and transformation of that input. Since we have agreed\n      to represent the input as a list, it makes sense for the other components to be lists\n      too. For example, we might have:\n\n         Pattern: ( i need a X)\n\n         Response: (what would i t mean to you i f you got a X ? )\n\n         Input: ( i need a vacation)\n         Transformation: (what would i t mean to you i f you got a vacation ? )\n\n      The pattern matcher must match the literals i with i, need with need, and a with a,\n      as well as match the variable X with va cat i on. This presupposes that there is some\n      way of deciding that X is a variable and that need is not. We must then arrange to\n      substitute vacation for X within the response, in order to get the final transformation.\n\f5.2   PAnERN MATCHING                                                                                    155\n\n\n              Ignoring for a moment the problem of transforming the pattern into the response,\n           we can see that this notion of pattern matching is just a generalization of the Lisp\n           function equa 1. Below we show the function s i mpl e - equa 1, which is like the built-in\n           function equal, ^ and the function pat-match, which is extended to handle pattern-\n           matching variables:\n\n               (defun simple-equal (x y )\n                 \"Are  and y equal? (Don't check i n s i d e s t r i n g s . ) \"\n                 ( i f (or (atom x) (atom y ) )\n                       (eql  y )\n                       (and (simple-equal ( f i r s t x) ( f i r s t y ) )\n                            (simple-equal ( r e s t x) ( r e s t y ) ) ) ) )\n\n               (defun pat-match (pattern input)\n                 \"Does pattern match input? Any v a r i a b l e can match a n y t h i n g . \"\n                 ( i f ( v a r i a b l e - p pattern)\n                       t\n                       ( i f (or (atom pattern) (atom i n p u t ) )\n                               (eql pattern input)\n                               (and (pat-match ( f i r s t pattern) ( f i r s t i n p u t ) )\n                                         (pat-match ( r e s t pattern) ( r e s t i n p u t ) ) ) ) ) )\n\n\n\n\n       @   Exercise 5.1 [s]       Would it be a good idea to replace the complex and form in\n           pat-match with the simpler (every # ' p a t - m a t c h p a t t e r n i n p u t ) ?\n                 Before we can go on, we need to decide on an implementation for pattern-\n           matching variables. We could, for instance, say that only a certain set of symbols,\n           such as {,,}, are variables. Alternately, we could define a structure of type\n           v a r i abl e, but then we'd have to type something verbose like (make-vari abl e : name\n            * X) every time we wanted one. Another choice would be to use symbols, but to dis\n           tinguish variables from constants by the name of the symbol. For example, in Prolog,\n           variables start with capital letters and constants with lowercase. But Common Lisp\n           is case-insensitive, so that won't work. Instead, there is a tradition in Lisp-based AI\n           programs to have variables be symbols that start with the question mark character.\n                 So far we have dealt with symbols as atoms--objects with no internal structure.\n           But things are always more compHcated than they first appear and, as in Lisp as\n           in physics, it turns out that even atoms have components. In particular, symbols\n           have names, which are strings and are accessible through the symbol - name function.\n           Strings in turn have elements that are characters, accessible through the function\n           char. The character ' ? ' is denoted by the self-evaluating escape sequence # \\ ? . So\n           the predicate vari ab1 e -p can be defined as follows, and we now have a complete\n           pattern matcher:\n\n              ^The difference is that simpl e-equal does not handle strings.\n\f156                                                                      ELIZA- DIALOG           WITH A   MACHINE\n\n\n\n          (defun variab1e-p (x)\n            \" I s X a v a r i a b l e (a symbol beginning with * ? * ) ? \"\n            (and (symbolp x) (equal (char (symbol-name x) 0) # \\ ? ) ) )\n\n          > (pat-match ' ( I need a ? X ) ' ( I need a v a c a t i o n ) )\n          \n\n          > (pat-match * ( I need a ? X ) ' ( I r e a l l y need a v a c a t i o n ) )\n          NIL\n\n\n      In each case we get the right answer, but we don't get any indication of what ?X is, so\n      we couldn't substitute it into the response. We need to modify pat-match to return\n      some kind of table of variables and corresponding values. In making this choice, the\n      experienced Common Lisp programmer can save some time by being opportunistic:\n      recognizing when there is an existing function that will do a large part of the task at\n      hand. What we want is to substitute values for variables throughout the response.\n      The alert programmer could refer to the index of this book or the Common Lisp\n      reference manual and find the functions s u b s t i t u t e , s u b s t , and subl i s. All of these\n      substitute some new expression for an old one within an expression. It turns out that\n      subl i s is most appropriate because it is the only one that allows us to make several\n      substitutions all at once, subl 1 s takes two arguments, the first a list of old-new pairs,\n      and the second an expression in which to make the substitutions. For each one of\n      the pairs, the car is replaced by the cdr. In other words, we would form each pair\n      with something like ( cons ol d new) . (Such a list of pairs is known as an association\n      Ust, or a-list, because it associates keys with values. See section 3.6.) In terms of the\n      example above, we would use:\n\n          > (sublis ' ( ( ? X . vacation))\n                    '(what would i t mean to you i f you got a ?X ? ) )\n          (WHAT WOULD IT MEAN TO YOU I F YOU GOT A VACATION ? )\n\n\n      Now we need to arrange for pat-match to return an a-Iist, rather than just  for\n      success. Here's a first attempt:\n\n          (defun pat-match (pattern input)\n            \"Does pattern match input? WARNING: buggy v e r s i o n . \"\n            ( i f ( v a r i a b l e - p pattern)\n                  ( l i s t (cons pattern i n p u t ) )\n                  ( i f (or (atom pattern) (atom i n p u t ) )\n                           (eql pattern input)\n                           (append (pat-match ( f i r s t pattern) ( f i r s t i n p u t ) )\n                                        (pat-match ( r e s t pattern) ( r e s t i n p u t ) ) ) ) ) )\n\n\n      This implementation looks reasonable: it returns an a-list of one element if the pattern\n      is a variable, and it appends alists if the pattern and input are both lists. However,\n\f5.2  MATCHING                                                                                 157\n\n\n\n      there are several problems. First, the test (eql pattern input) may return T, which\n      is not a list, so append will complain. Second, the same test might return nil, which\n      should indicate failure, but it will just be treated as a list, and will be appended to\n      the rest of the answer. Third, we haven't distinguished between the case where the\n      match fails--and returns nil--versus the case where everything matches, but there\n      are no variables, so it returns the null a-list. (This is the semipredicate problem\n      discussed on page 127.) Fourth, we want the bindings of variables to agree--if ?X is\n      used twice in the pattern, we don't want it to match two different values in the input.\n      Finally, it is inefficient for pat-match to check both the f i r s t and r e s t of Hsts, even\n      when the corresponding f i r s t parts fail to match. (Isn't it amazing that there could\n      be five bugs in a seven-line function?)\n          We can resolve these problems by agreeing on two major conventions. First, it is\n      very convenient to make pat-match a true predicate, so we will agree that it returns\n       i 1 only to indicate failure. That means that we will need a non-nil value to represent\n      the empty binding list. Second, if we are going to be consistent about the values of\n      variables, then the f i rstwillhavetoknow what the restisdoing. We can accomplish\n      this by passing the binding list as a third argument to pat-match. We make it an\n      optional argument, because we want to be able to say simply (pat-match ab).\n          To abstract away from these implementation decisions, we define the constants\n      fai 1 and no-bi ndi ngs to represent the two problematic return values. The special\n      form defconstant is used to indicate that these values will not change. (It is cus\n      tomary to give special variables names beginning and ending with asterisks, but this\n      convention usually is not followed for constants. The reasoning is that asterisks\n      shout out, \"Careful! I may be changed by something outside of this lexical scope.\"\n      Constants, of course, will not be changed.)\n\n          (defconstant f a i l n i l       \" I n d i c a t e s pat-match f a i l u r e \" )\n\n          (defconstant no-bindings ' ( ( t . t ) )\n            \" I n d i c a t e s pat-match s u c c e s s , with no v a r i a b l e s . \" )\n\n\n      Next, we abstract away from assoc by introducing the following four functions:\n\n          (defun g e t - b i n d i n g (var b i n d i n g s )\n            \"Find a ( v a r i a b l e . value) p a i r in a binding l i s t . \"\n            (assoc var b i n d i n g s ) )\n\n          (defun binding-val (binding)\n            \"Get the value part of a s i n g l e b i n d i n g . \"\n            (cdr b i n d i n g ) )\n\n          (defun lookup (var b i n d i n g s )\n            \"Get the value part (for var) from a binding l i s t . \"\n            (binding-val ( g e t - b i n d i n g var b i n d i n g s ) ) )\n\f158                                                                  ELIZA; DIALOG       WITH A       MACHINE\n\n\n\n          (defun extend-bindings (var val bindings)\n            \"Add a (var . value) p a i r to a binding l i s t . \"\n            (cons (cons var v a l ) b i n d i n g s ) )\n\n\n      Now that variables and bindings are defined, pat-match is easy. It consists of five\n      cases. First, if the binding list is f ai 1 , then the match fails (because some previous\n      match must have failed). If the pattern is a single variable, then the match returns\n      whatever match - va r i abl e returns; either the existing binding Ust, an extended one,\n      or f ai 1 . Next, if both pattern and input are lists, we first call pat-match recursively\n      on the first element of each list. This returns a binding list (or f ai 1), which we use\n      to match the rest of the lists. This is the only case that invokes a nontrivial function,\n      so it is a good idea to informally prove that the function will terminate: each of the\n      two recursive calls reduces the size of both pattern and input, and pat -match checks\n      the case of atomic patterns and inputs, so the function as a whole must eventually\n      return an answer (unless both pattern and input are of infinite size). If none of these\n      four cases succeeds, then the match fails.\n\n          (defun pat-match (pattern input &optional (bindings n o - b i n d i n g s ) )\n            \"Match pattern against input i n the context of the b i n d i n g s \"\n            (cond ((eq bindings f a i l ) f a i l )\n                  ( ( v a r i a b l e - p pattern)\n                    (match-variable pattern input b i n d i n g s ) )\n                  ((eql pattern input) b i n d i n g s )\n                  ((and (consp pattern) (consp i n p u t ) )\n                    (pat-match ( r e s t pattern) ( r e s t input)\n                                         (pat-match ( f i r s t pattern) ( f i r s t input)\n                                                    bindings)))\n                  (t f a i l ) ) )\n          (defun match-variable (var input b i n d i n g s )\n            \"Does VAR match input? Uses (or updates) and returns b i n d i n g s . \"\n            ( l e t ( ( b i n d i n g ( g e t - b i n d i n g var b i n d i n g s ) ) )\n                 (cond ((not binding) (extend-bindings var input b i n d i n g s ) )\n                          ((equal input ( b i n d i n g - v a l b i n d i n g ) ) b i n d i n g s )\n                          (t f a i l ) ) ) )\n\n\n      We can now test pat-match and see how it works:\n\n         > (pat-match ' ( i need a ? X ) ' ( i       need a v a c a t i o n ) )\n         ((?X . VACATION) (T . T))\n\n\n      The answer is a list of variable bindings in dotted pair notation; each element of\n      the list is a (vanable , value) pair. The (T . T) is a remnant from n o - b i n d i n g s . It\n      does no real harm, but we can eliminate it by making extend - bi ndi ngs a little more\n      complicated:\n\f5.3 SEGMENT PAnERN MATCHING                                                                     159\n\n\n            (defun extend-bindings (var val b i n d i n g s )\n              \"Add a (var . value) p a i r to a binding l i s t . \"\n              (cons (cons var v a l )\n                         Once we add a \" r e a l \" b i n d i n g ,\n                         we can get r i d of the dummy no-bindings\n                    ( i f (eq bindings n o - b i n d i n g s )\n                          nil\n                          bindings)\n\n\n\n\n           > ( s u b l i s (pat-match ' ( i need a ? X ) ' ( i need a v a c a t i o n ) )\n                           '(what would i t mean to you i f you got a ?X ? ) )\n           (WHAT WOULD IT MEAN TO YOU I F YOU GOT A VACATION ? )\n\n           > (pat-match ' ( i     need a ? X ) ' ( i   r e a l l y need a v a c a t i o n ) )\n           NIL\n\n           > (pat-match ' ( t h i s i s easy) ' ( t h i s i s e a s y ) )\n           ((T . T))\n\n           > (pat-match ' ( ? X i s ? X ) ' ( ( 2 + 2) i s 4 ) )\n           NIL\n\n           > (pat-match ' ( ? X i s ? X ) ' ( ( 2 + 2) i s (2 + 2 ) ) )\n           ((?X 2 + 2 ) )\n\n           > (pat-match ' ( ? P need . ? X ) ' ( i      need a long v a c a t i o n ) )\n           ( ( ? X A LONG VACATION) ( ? P . I ) )\n\n\n        Notice the distinction between NIL and (( .  ) ) . The latter means that the match\n        succeeded, but there were no bindings to return. Also, remember that ( ? X 2 + 2)\n        means the same as ( ? X . (2 + 2 ) ) .\n            A more powerful implementation of pat -match is given in chapter 6. Yet another\n        implementation is given in section 10.4. It is more efficient but more cumbersome\n        to use.\n\n\n\n        5.3       Segment Pattern Matching\n        In the pattern (?P need .     ? X ) , the variable ?X matches the rest of the input Ust,\n        regardless of its length. This is in contrast to ?P, which can only match a single\n        element, namely, the first element of the input. For many applications of pattern\n        matching, this is fine; we only want to match corresponding elements. However,\n        ELIZA is somewhat different in that we need to account for variables in any position\n        that match a sequence of items in the input. We will call such variables segment\n        vanables. We will need a notation to differentiate segment variables from normal\n\f160                                                               ELIZA; DIALOG WITH A MACHINE\n\n\n      variables. The possibilities fall into two classes: either we use atoms to represent\n      segment variables and distinguish them by some spelling convention (as we did to\n      distinguish variables from constants) or we use a nonatomic construct. We will\n      choose the latter, using a list of the form ( ? * variable) to denote segment variables.\n      The symbol ?* is chosen because it combines the notion of variable with the Kleene-\n      star notation. So, the behavior we want from pat-match is now:\n\n         > (pat-match ' ( ( ? * ?p) need ( ? * ? x ) )\n                         '(Mr Hulot and I need a v a c a t i o n ) )\n         ( ( ? P MR HULOT AND I ) (?X A VACATION))\n\n\n      In other words, when both pattern and input are lists and the first element of the\n      pattern is a segment variable, then the variable will match some initial part of the\n      input, and the rest of the pattern will attempt to match the rest. We can update\n      pat-match to account for this by adding a single cond-clause. Defining the predicate\n      to test for segment variables is also easy:\n\n         (defun pat-match (pattern input &optional (bindings n o - b i n d i n g s ) )\n           \"Match pattern against input i n the context of the b i n d i n g s \"\n           (cond ((eq bindings f a i l ) f a i l )\n                 ( ( v a r i a b l e - p pattern)\n                   (match-variable pattern input b i n d i n g s ) )\n                 ((eql pattern input) b i n d i n g s )\n                 ((segment-pattern-p pattern)                                     ; ***\n                   (segment-match pattern input b i n d i n g s ) )               ; ***\n                 ((and (consp pattern) (consp i n p u t ) )\n                   (pat-match ( r e s t pattern) ( r e s t input)\n                                        (pat-match ( f i r s t pattern) ( f i r s t input)\n                                                   bindings)))\n                 (t f a i l ) ) )\n         (defun segment-pattern-p (pattern)\n           \" I s t h i s a segment matching p a t t e r n : ( ( ? * var) . p a t ) \"\n           (and (consp pattern)\n                   ( s t a r t s - w i t h ( f i r s t pattern) ' ? * ) ) )\n\n\n      In writing segment-match, the important question is how much of the input the\n      segment variable should match. One answer is to look at the next element of the\n      pattern (the one after the segment variable) and see at what position it occurs in the\n      input. If it doesn't occur, the total pattern can never match, and we should f ai 1. If\n      it does occur, call its position pos. We will want to match the variable against the\n      initial part of the input, up to pos. But first we have to see if the rest of the pattern\n      matches the rest of the input. This is done by a recursive call to pat-match. Let the\n      result of this recursive call be named b2. If b2 succeeds, then we go ahead and match\n      the segment variable against the initial subsequence.\n\f5.3 SEGMENT   PATTERN MATCHING                                                                                161\n\n\n\n              The tricky part is when bZ fails. We don't want to give up completely, because\n          it may be that if the segment variable matched a longer subsequence of the input,\n          then the rest of the pattern would match the rest of the input. So what we want is to\n          try segment -match again, but forcing it to consider a longer match for the variable.\n          This is done by introducing an optional parameter, s t a r t , which is initially 0 and is\n          increased with each failure. Notice that this policy rules out the possibility of any\n          kind of variable following a segment variable. (Later we will remove this constraint.)\n\n              (defun segment-match (pattern input bindings &optional ( s t a r t 0 ) )\n                \"Match the segment pattern ( ( ? * v a r ) . pat) against i n p u t . \"\n                ( l e t ( ( v a r (second ( f i r s t p a t t e r n ) ) )\n                          (pat ( r e s t p a t t e r n ) ) )\n                    ( i f (null pat)\n                          (match-variable var input bindings)\n                                We assume that pat s t a r t s with a constant\n                                In other words, a pattern c a n ' t have 2 consecutive vars\n                          ( l e t ((pos ( p o s i t i o n ( f i r s t pat) input\n                                                             :start start :test #'equal)))\n                              ( i f (null pos)\n                                    fail\n                                    ( l e t ((b2 (pat-match pat (subseq input pos) b i n d i n g s ) ) )\n                                             I f t h i s match f a i l e d , t r y another longer one\n                                             I f i t worked, check that the v a r i a b l e s match\n                                        ( i f (eq b2 f a i l )\n                                               (segment-match pattern input bindings (+ pos 1))\n                                               (match-variable var (subseq input 0 pos) b 2 ) ) ) ) ) ) ) )\n\n\n          Some examples of segment matching follow:\n\n              > (pat-match ' ( ( ? * ? p ) need ( ? * ? x ) )\n                              '(Mr Hulot and I need a vacation))\n              ( ( ? P MR HULOT AND I ) (?X A VACATION))\n\n              > (pat-match ' ( ( ? * ? x ) i s a ( ? * ? y ) ) '(what he i s i s a f o o l ) )\n              ((?X WHAT HE I S ) (?Y FOOD)\n\n\n          The first of these examples shows a fairly simple case: ?p matches everything up\n          to need, and ?x matches the rest. The next example involves the more complicated\n          backup case. First ?x matches everything up to the first i s (this is position 2, since\n          counting starts at 0 in Common Lisp). But then the pattern a fails to match the input\n          i s, so segment - match tries again with starting position 3. This time everything works;\n          i s matches i s, a matches a, and ( ? * ? y ) matches fool.\n\f162                                                                            ELIZA: DIALOG                WITH A   MACHINE\n\n\n\n          Unfortunately, this version of s egmen t - ma t ch does not match as much as it should.\n      Consider the following example:\n\n\n         > (pat-match * ( ( ? * ? x ) a b ( ? * ? x ) ) ' ( 1 2 a b a b 1 2 a b ) )                            NIL\n\n\n      This fails because ?x is matched against the subsequence ( 1 2 ) , and                                            then\n      the remaining pattern succesfuUy matches the remaining input, but the final\n      call to m a t c h - v a r i a b l e fails, because ?x has two different values. The fix is to call\n      m a t c h - v a r i a b l e before testing whether the b2 fails, so that we will be sure to try\n      segment -match again with a longer match no matter what the cause of the failure.\n\n\n          (defun segment-match (pattern input bindings �optional ( s t a r t 0 ) )\n            \"Match the segment pattern ( ( ? * v a r ) . pat) against i n p u t . \"\n            ( l e t ( ( v a r (second ( f i r s t p a t t e r n ) ) )\n                     (pat ( r e s t p a t t e r n ) ) )\n               (if   (null pat)\n                     (match-variable var input bindings)\n                          We assume that pat s t a r t s with a constant\n                          In other words, a pattern c a n ' t have 2 consecutive vars\n                     ( l e t ((pos ( p o s i t i o n ( f i r s t pat) input\n                                                          i s t a r t s t a r t rtest # ' e q u a l ) ) )\n                        (if    (null pos)\n                               fail\n                               ( l e t ((b2 (pat-match\n                                                  pat (subseq input pos)\n                                                  (match-variable var (subseq input 0 pos)\n                                                                               bindings))))\n                                        I f t h i s match f a i l e d , t r y another longer one\n                                  (if    (eq b2 f a i l )\n                                         (segment-match pattern input bindings ( + pos 1 ) )\n                                         b2)))))))\n\n\n      Now we see that the match goes through:\n\n\n          > (pat-match ' ( ( ? * ? x ) a b ( ? * ? x ) ) ' ( 1 2 a b a b 1 2 a b ) )\n          ((?X 1 2 A B))\n\n\n      Note that this version of segment -match tries the shortest possible match first. It\n      would also be possible to try the longest match first.\n\f5.4   THE ELIZA PROGRAM:             A RULE-BASED            TRANSLATOR                                 163\n\n\n\n\n            5.4         The ELIZA Program:                                   A Rule-Based\n                        Translator\n\n            Now that we have a working pattern matcher, we need some patterns to match.\n            What's more, we want the patterns to be associated with responses. We can do this\n            by inventing a data structure called a r u l e, which consists of a pattern and one or\n            more associated responses. These are rules in the sense that they assert, \"If you\n            see A, then respond with  or C, chosen at random.\" We will choose the simplest\n            possible implementation for rules: as lists, where the first element is the pattern and\n            the rest is a list of responses:\n\n                (defun r u l e - p a t t e r n ( r u l e ) ( f i r s t   rule))\n                (defun rule-responses ( r u l e ) ( r e s t r u l e ) )\n\n\n            Here's an example of a rule:\n\n                (((?*    ? x ) I want ( ? * ? y ) )\n                  (What would i t mean i f you got ? y )\n                  (Why do you want ? y )\n                  (Suppose you got ? y soon))\n\n\n            When applied to the input ( I want t o t e s t t h i s program), this rule (when in\n            terpreted by the ELIZA program) would pick a response at random, substitute in the\n            v a l u e o f ? y , and respond with, say, (why do y o u want t o t e s t t h i s   program).\n               Now that we know what an individual rule will do, we need to decide how to\n            handle a set of rules. If ELIZA is to be of any interest, it will have to have a variety of\n            responses. So several rules may all be applicable to the same input. One possibility\n            would be to choose a rule at random from among the rules having patterns that match\n            the input.\n                Another possibility is just to accept the first rule that matches. This implies that\n            the rules form an ordered list, rather than an unordered set. The clever ELIZA rule\n            writer can take advantage of this ordering and arrange for the most specific rules to\n            come first, while more vague rules are near the end of the list.\n                The original ELIZA had a system where each rule had a priority number associated\n            with it. The matching rule with the highest priority was chosen. Note that putting the\n            rules in order achieves the same effect as having a priority number on each rule: the\n            first rule implicitly has the highest priority, the second rule is next highest, and so on.\n                Here is a short list of rules, selected from Weizenbaum's original article, but with\n            the form of the rules updated to the form we are using. The answer to exercise 5.19\n            contains a longer list of rules.\n\f164                                                                          ELIZA; DIALOG             WITH         AMACHINE\n\n\n\n         (defparameter * e l i z a - r u l e s *\n          ' ( ( ( ( ? * ?x) hello ( ? * ? y ) )\n               (How do you do. Please state your problem.))\n             ( ( ( ? * ? x ) I want ( ? * ? y ) )\n               (What would i t mean i f you got ? y )\n               (Why do you want ? y ) (Suppose you got ? y soon))\n             ( ( ( ? * ?x) i f ( ? * ? y ) )\n               (Do you r e a l l y think i t s l i k e l y that ? y ) (Do you wish that ? y )\n               (What do you t h i n k about ? y ) ( R e a l l y - - i f ? y ) )\n             ( ( ( ? * ? x ) no ( ? * ? y ) )\n               (Why not?) (You are being a b i t negative)\n               (Are you saying \"NO\" j u s t to be n e g a t i v e ? ) )\n             ( ( ( ? * ? x ) I was ( ? * ? y ) )\n               (Were you r e a l l y ? ) (Perhaps I already knew you were ? y )\n               (Why do you t e l l me you were ? y now?))\n             ( ( ( ? * ? x ) I feel ( ? * ? y ) )\n               (Do you often feel ? y ? ) )\n             ( ( ( ? * ?x) I felt ( ? * ?y))\n               (What other f e e l i n g s do you h a v e ? ) ) ) )\n\n\n      Finally we are ready to define ELIZA proper. As we said earlier, the main program\n      should be a loop that reads input, transforms it, and prints the result. Transformation\n      is done primarily by finding some rule such that its pattern matches the input, and\n      then substituting the variables into the rule's response. The program is summarized\n      in figure 5.1.\n          There are a few minor complications. We print a prompt to tell the user to\n      input something. We use the function f 1 atten to insure that the output won't have\n      imbedded lists after variable substitution. An important trick is to alter the input\n      by swapping \"you\" for \"me\" and so on, since these terms are relative to the speaker.\n      Here is the complete program:\n\n         (defun el iza ( )\n           \"Respond to user input using pattern matching r u l e s . \"\n           (loop\n              (print 'eliza>)\n              (write ( f l a t t e n ( u s e - e l i z a - r u l e s ( r e a d ) ) ) ipretty t ) ) )\n\n         (defun u s e - e l i z a - r u l e s ( i n p u t )\n           \"Find some rule with which to transform the i n p u t . \"\n           (some #*(lambda ( r u l e )\n                         ( l e t ( ( r e s u l t (pat-match ( r u l e - p a t t e r n r u l e ) i n p u t ) ) )\n                              ( i f (not (eq r e s u l t f a i l ) )\n                                      ( s u b l i s (switch-viewpoint r e s u l t )\n                                                    (random-elt ( r u l e - r e s p o n s e s r u l e ) ) ) ) ) )\n                 *eliza-rules*))\n\f5.4   THE ELIZA PROGRAM:         A RULE-BASED            TRANSLATOR                                     165\n\n\n\n                                                Top-Level Function\n                  el i z a                      Respond to user input using pattern matching rules.\n                                                Special Variables\n                  *eliza-rules*                 A list of transformation rules.\n                                                Data Types\n                   rule                         An association of a pattern with a list of responses.\n                                                Fimctions\n                  el i z a                      Respond to user input using pattern matching rules.\n                  use-eliza-rules               Find some rule with which to transform the input.\n                  switch-viewpoint              Change I to you and vice versa, and so on.\n                  flatten                       Append together elements of a list.\n                                                Selected Common Lisp Functions\n                  sublis                        Substitute elements into a tree.\n                                                Previously Defined Functions\n                   random-elt                   Pick a random element from a list. (p. 36)\n                  pat-match                     Match a pattern against an input, (p. 160)\n                  mappend                       Append together the results of a mapcar.\n\n                                           Figure 5.1: Glossary for the ELIZA Program\n\n\n\n                 (defun switch-viewpoint (words)\n                   \"Change I to you and vice v e r s a , and so o n . \"\n                   ( s u b l i s ' ( ( I . you) (you . I ) (me . you) (am    are))\n                                 words))\n\n\n             Note the use of wri te with the : p r e t t y keyword true. This will give better formatted\n             output in some cases. The program makes use of the previously defined random- el t ,\n             and f 1 atten, which is defined here using mappend and mkl i s t , a function that is\n             defined in the InterLisp dialect but not in Common Lisp.\n\n                 (defun f l a t t e n ( t h e - l i s t )\n                   \"Append together elements (or l i s t s ) i n the l i s t . \"\n                   (mappend # ' m k l i s t t h e - l i s t ) )\n\n                 (defun m k l i s t ()\n                   \"Return  i f i t i s a l i s t , otherwise ( x ) . \"\n                   (if d i s t p X )\n                           X\n                           (list X ) ) )\n\n                 (defun mappend (fn t h e - l i s t )\n                   \"Apply fn to each element of l i s t and append the r e s u l t s . '\n                   (apply #*append (mapcar fn t h e - l i s t ) ) )\n\f166                                                                ELIZA- DIALOG   WITH A   MACHINE\n\n\n\n         (defun random-elt (choices)\n           \"Choose an element from a l i s t at random.\"\n           ( e l t choices (random (length c h o i c e s ) ) ) )\n\n\n      The actual ELIZA program had a few complications that don't show up in this version.\n      First, there was an alias method for associating several words with the same pattern;\n      both \"mother\" and \"father\" could be associated with the \"family\" pattern. There was\n      also a synonym mechanism that would treat \"don't\" and \"do not\" or \"everybody\" and\n      \"everyone\" the same. In the case of input with several comma-separated phrases,\n      each phrase was processed separately, and the response with the highest priority\n      was selected. In addition, the original ELIZA had a \"memory\" mechanism. When\n      no pattern matched the input, it said something like \"Tell me more about X,\" where\n      X is some input given earlier. Finally, our version has fewer rules. Despite the\n      shortcomings of our version, it can occasionally hold up its end of a conversation, as\n      shown below:\n\n         > (eliza)\n         ELIZA> ( h e l l o there)\n         (HOW DO YOU DO. PLEASE STATE YOUR PROBLEM.)\n         ELIZA> (i want to t e s t t h i s program)\n         (WHAT WOULD IT MEAN I F YOU GOT TO TEST THIS PROGRAM)\n         ELIZA> ( i could see i f           it   works)\n         (DO YOU REALLY THINK ITS LIKELY THAT IT WORKS)\n         ELIZA> (no not r e a l l y )\n         (ARE YOU SAYING \"NO\" JUST TO BE NEGATIVE?)\n         ELIZA> (no)\n         (ARE YOU SAYING \"NO\" JUST TO BE NEGATIVE?)\n         ELIZA> (forget i t - -       i was wondering how general the program i s )\n         (WHY DO YOU TELL ME YOU WERE WONDERING HOW GENERAL THE PROGRAM I S NOW?)\n         ELIZA> ( i f e l t l i k e   it)\n         (WHAT OTHER FEELINGS DO YOU HAVE?)\n         ELIZA> ( i feel t h i s i s enough)\n         (DO YOU OFTEN FEEL THIS I S ENOUGH ? )\n         ELIZA> [Abort]\n\n\n\n      In the end, it is the technique that is important--not the program. ELIZA has been\n      \"explained away\" and should rightfully be moved to the curio shelf. Pattern matching\n      in general remains important technique, and we will see it again in subsequent\n      chapters. The notion of a rule-based translator is also important. The problem\n      of understanding English (and other languages) remains an important part of AI.\n      Clearly, the problem of understanding English is not solved by ELIZA. In part V, we\n      will address the problem again, using more sophisticated techniques.\n\f5.5   HISTORY   AND REFERENCES                                                                              167\n\n\n\n\n             5.5       History and References\n             As mentioned above, the original article describing ELIZA is Weizenbaum 1 9 6 6 . An-\n             other dialog system using similar pattern-matching techniques is Kenneth Colby's\n             ( 1 9 7 5 ) PARRY. This program simulated the conversation of a paranoid person well\n             enough to fool several professional psychologists. Although the pattern matching\n             techniques were simple, the model of belief maintained by the system was much\n             more sophisticated than ELIZA. Colby has suggested that dialog programs like ELIZA,\n             augmented with some sort of belief model like PARRY, could be useful tools in treat-\n             ing mentally disturbed people. According to Colby, it would be inexpensive and\n             effective to have patients converse with a specially designed program, one that could\n             handle simple cases and alert doctors to patients that needed more help. Weizen-\n             baum's book Computer Power and Human Reason ( 1 9 7 6 ) discusses ELIZA and PARRY\n             and takes a very critical view toward Colby's suggestion. Other interesting early\n             work on dialog systems that model belief is reported by Allan Collins ( 1 9 7 8 ) and\n             Jamie Carbonell ( 1 9 8 1 ) .\n\n\n\n\n             5.6       Exercises\n       t�3 Exercise 5.2 [m] Experiment with this version of ELIZA. Show some exchanges\n           where it performs well, and some where it fails. Try to characterize the differ-\n           ence. Which failures could be fixed by changing the rule set, which by changing the\n           pa t - ma tch function (and the pattern language it defines), and which require a change\n           to the el i za program itself?\n\n\n       @     Exercise 5.3 [h] Define a new set of rules that make ELIZA give stereotypical re-\n             sponses to some situation other than the doctor-patient relationship. Or, write a set\n             of rules in a language other than English. Test and debug your new rule set.\n\n\n        @    Exercise 5.4 [s] We mentioned that our version of ELIZA cannot handle commas\n             or double quote marks in the input. However, it seems to handle the apostrophe in\n             both input and patterns. Explain.\n\n\n       [�3   Exercise 5.5 [h] Alter the input mechanism to handle commas and other punctu-\n             ation characters. Also arrange so that the user doesn't have to type parentheses\n             around the whole input expression. (Hint: this can only be done using some Lisp\n             functions we have not seen yet. Look at r e a d - l i n e a n d r e a d - f r o m - s t r i n g . )\n\f168                                                                            ELIZA: DIALOG   WITH A   MACHINE\n\n\n\n      @    Exercise 5.6 [m] Modify ELIZA to have an explicit exit. Also arrange so that the\n           output is not printed in parentheses either.\n\n\n      @    Exercise 5.7 [m] Add the \"memory mechanism\" discussed previously to ELIZA.\n           Also add some way of definining synonyms like \"everyone\" and \"everybody.\"\n\n\n      51   Exercise 5.8 [h] It turns out that none of the rules in the given script uses a variable\n           more than once-there is no rule of the form ( ?x... ?x ). Write a pattern matcher that\n           only adds bindings, never checks variables against previous bindings. Use the time\n           special form to compare your function against the current version.\n\n\n      @    Exercise 5.9 [h] Winston and Horn's book Lisp presents a good pattern-matching\n           program. Compare their implementation with this one. One difference is that they\n           handle the case where the first element of the pattern is a segment variable with the\n           following code (translated into our notation):\n\n              (or         (pat-match ( r e s t pattern) ( r e s t input) b i n d i n g s )\n                          (pat-match pattern ( r e s t input) b i n d i n g s ) )\n\n\n           This says that a segment variable matches either by matching the first element of\n           the input, or by matching more than the first element. It is much simpler than our\n           approach using posi t i on, partly because they don't update the binding list. Can\n           you change their code to handle bindings, and incorporate it into our version of\n           pat-match? Is it still simpler? Is it more or less efficient?\n\n\n      @    Exercise 5.10 What is wrong with the following definition of s i mpl e - equa 1 ?\n\n              (defun simple-equal (x y )\n                    \"Test i f two l i s t s or atoms are e q u a l . \"\n                          Warning - incorrect\n                    (or     (eql  y )\n                            (and   ( l i s t p x) ( l i s t p y )\n                                   (simple-equal ( f i r s t x) ( f i r s t y ) )\n                                   (simple-equal ( r e s t x) ( r e s t y ) ) ) ) )\n\n\n\n\n      @    Exercise 5.11 [m] Weigh the advantages of changing no-bi ndi ngs to ni 1 , and f ai 1\n           to something else.\n\f5.6 EXERCISES                                                                                  169\n\n\n\n      @    Exercise 5.12 [m] Weigh the advantages of making pat-match return multiple val\n           ues: the first would be true for a match and false for failure, and the second would\n           be the binding list.\n\n\n      @   Exercise 5.13 [m] Suppose that there is a call to segment -match where the variable\n          already has a binding. The current definition will keep making recursive calls to\n          segment -match, one for each possible matching position. But this is silly--if the\n          variable is already bound, there is only one sequence that it can possibly match\n          against. Change the definition so that it looks only for this one sequence.\n\n\n      S    Exercise 5.14 [m]    Define a version of ma ppend that, like ma pea r, accepts any number\n           of argument lists.\n\n\n      @    Exercise 5.15 [m]    Give an informal proof that segment -match always terminates.\n\n\n      S    Exercise 5.16 [s] Trick question: There is an object in Lisp which, when passed to\n           v a r i abl e- p, results in an error. What is that object?\n\n\n      0   Exercise 5.17 [m] The current version of ELIZA takes an input, transforms it ac\n          cording to the first applicable rule, and outputs the result. One can also imagine a\n          system where the input might be transformed several times before the final output\n          is printed. Would such a system be more powerful? If so, in what way?\n\n\n      S   Exercise 5.18 [h] Read Weizenbaum's original article on ELIZA and transpose his\n          list of rules into the notation used in this chapter.\n\f170                                                                           ELIZA; DIALOG              WITH A          MACHINE\n\n\n\n\n      5.7      Answers\n\n      Answer 5.1 No. If either the pattern or the input were shorter, but matched every\n      existing element, the every expression would incorrectly return true.\n\n          (every #'pat-match *(a b c) ' ( a ) )                     \n\n\n      Furthermore, if either the pattern or the input were a dotted list, then the result of the\n      every would be undefined--some implementations might signal an error, and others\n      might just ignore the expression after the dot.\n\n         (every #'pat-match ' ( a b . c) ' ( a b . d ) ) => T, N I L . o r e r r o r .\n\n\n\n      Answer 5.4 The expression don't may look like a single word, but to the Lisp reader\n      it is composed of the two elements don and ' t, or (quote t ) . If these elements are\n      used consistently, they will match correctly, but they won't print quite right--there\n      will be a space before the quote mark. In fact the :pretty t argument to write is\n      specified primarily to make (quote t ) print as ' t (See page 559 of Steele's Common\n      Lisp the Language, 2d edition.)\n\n      Answer 5.5 One way to do this is to read a whole line of text with read - l i n e rather\n      than read. Then, substitute spaces for any punctuation character in that string.\n      Finally, wrap the string in parentheses, and read it back in as a list:\n\n         (defun read-line-no-punct ()\n            \"Read an input l i n e , i g n o r i n g punctuation.\"\n            (read-from-string\n              (concatenate ' s t r i n g \" ( \" ( s u b s t i t u t e - i f # \\ s p a c e # ' p u n c t u a t i o n - p\n                                                                                (read-line))\n                                   \")\")))\n\n\n         (defun punctuation-p (char) ( f i n d char                      \".,;:*l?#-()\\\\\\\"\"))\n\n\n      This could also be done by altering the readtable, as in section 23.5, page 821.\n\f5.7 ANSWERS                                                                                                   171\n\n\n\n          Answer 5.6\n\n              (defun e l i z a ( )\n                   \"Respond to user input using pattern matching r u l e s . \"\n                   (loop\n                     (print      *eliza>)\n                     (let* ((input (read-line-no-punct))\n                                (response ( f l a t t e n ( u s e - e l i z a - r u l e s i n p u t ) ) ) )\n                        ( p r i n t - w i t h - s p a c e s response)\n                        (if    (equal response '(good bye)) (RETURN)))))\n\n              (defun p r i n t - w i t h - s p a c e s   (list)\n                   (mapc #'(lambda ( x ) ( p r i n l x ) ( p r i n c \" \" ) ) l i s t ) )\n              or\n              (defun p r i n t - w i t h - s p a c e s   (list)\n                   (format t \"~{~a ~}\" l i s t ) )\n\n\n\n          Answer 5.10 Hint: consider ( s i mpl e-equal ' ( ) ' ( n i l . n i l ) ) .\n\n          Answer 5.14\n\n              (defun mappend ( f n &rest l i s t )\n                   \"Apply fn to each element of l i s t s and append the r e s u l t s . \"\n                   (apply #'append (apply #'mapcar fn l i s t s ) ) )\n\n\n\n          Answer 5.16 It must be a symbol, because for nonsymbols, v a r i a b l e - p just returns\n          nil. Getting the symbol - name of a symbol is just accessing a slot, so that can't cause\n          an error. The only thing left is el t; if the symbol name is the empty string, then\n          accessing element zero of the empty string is an error. Indeed, there is a symbol\n          whose name is the empty string: the symbol.\n\n          Answer 5.17 Among other things, a recursive transformation system could be used\n          to handle abbreviations. That is, a form like \"don't\" could be transformed into \"do\n          not\" and then processed again. That way, the other rules need only work on inputs\n          matching \"do not.\"\n\f172                                                              ELIZA; DIALOG        WITH A   MACHINE\n\n\n\n      Answer 5.19       The following includes most of Weizenbaum's rules:\n\n         (defparameter         *eliza-rules*\n          ' ( ( ( ( ? * ?x) hello ( ? * ?y))\n             (How do you do.          Please state your       problem.))\n            ( ( ( ? * ? x ) computer ( ? * ? y ) )\n             (Do computers worry you?) (What do you think about machines?)\n             (Why do you mention computers?)\n             (What do you think machines have to do with your problem?))\n            ( ( ( ? * ? x ) name ( ? * ? y ) )\n             ( I am not interested i n names))\n            ( ( ( ? * ? x ) sorry ( ? * ? y ) )\n             (Please d o n ' t apologize) (Apologies are not necessary)\n             (What f e e l i n g s do you have when you a p o l o g i z e ) )\n            ( ( ( ? * ? x ) I remember ( ? * ? y ) )\n             (Do you often think of ? y )\n             (Does t h i n k i n g of ?y bring anything e l s e to mind?)\n              (What e l s e do you remember) (Why do you r e c a l l ? y r i g h t now?)\n              (What in the present s i t u a t i o n reminds you of ? y )\n              (What i s the connection between me and ? y ) )\n            ( ( ( ? * ? x ) do you remember ( ? * ? y ) )\n              (Did you think I would forget ? y ? )\n              (Why do you think I should r e c a l l ? y now)\n              (What about ? y ) (You mentioned ? y ) )\n            ( ( ( ? * ?x) if    ( ? * ?y))\n              (Do you r e a l l y think i t s l i k e l y that ? y ) (Do you wish that ? y )\n              (What do you think about ? y ) ( R e a l l y - - i f    ?y))\n\n            ( ( ( ? * ? x ) I dreamt ( ? * ? y ) )\n              ( R e a l l y - - ? y ) (Have you ever fantasized ? y while you were awake?)\n              (Have you dreamt ?y b e f o r e ? ) )\n            ( ( ( ? * ? x ) dream about ( ? * ? y ) )\n              (How do you feel about ?y i n             reality?))\n            ( ( ( ? * ? x ) dream ( ? * ? y ) )\n              (What does t h i s dream suggest to you?) (Do you dream o f t e n ? )\n              (What persons appear in your dreams?)\n              (Don't you believe that dream has to do with your problem?))\n             ( ( ( ? * ? x ) my mother ( ? * ? y ) )\n              (Who e l s e in your family ? y ) (Tell me more about your f a m i l y ) )\n             ( ( ( ? * ? x ) my father ( ? * ? y ) )\n              (Your father) (Does he influence you s t r o n g l y ? )\n              (What e l s e comes to mind when you think of your                father?))\n\f5.7 ANSWERS                                                                            173\n\n\n\n              (((?*   ? x ) I want ( ? * ? y ) )\n               (What would i t mean i f you got ? y )\n               (Why do you want ? y ) (Suppose you got ? y soon))\n              (((?*   ? x ) I am glad ( ? * ? y ) )\n               (How have I helped you to be ? y ) (What makes you happy j u s t now)\n               (Can you explain why you are suddenly ? y ) )\n              (((?*   ? x ) I am sad ( ? * ? y ) )\n               ( I am s o r r y to hear you are depressed)\n               ( I ' m sure i t ' s not pleasant to be sad))\n              (((?*   ? x ) are l i k e ( ? * ? y ) )\n               (What resemblance do you see between ? x and ? y ) )\n              (((?*   ?x) i s like ( ? * ?y))\n               ( I n what way i s i t that ? x i s l i k e ? y )\n               (What resemblance do you see?)\n               (Could there r e a l l y be some connection?) (How?))\n              (((?*   ?x) alike ( ? * ?y))\n               ( I n what way?) (What s i m i l a r i t i e s are t h e r e ? ) )\n              (((?*   ? x ) same ( ? * ? y ) )\n               (What other connections do you s e e ? ) )\n\n\n              (((?*   ? x ) I was ( ? * ? y ) )\n               (Were you r e a l l y ? ) (Perhaps I already knew you were ? y )\n               (Why do you t e l l me you were ? y now?))\n              (((?*   ? x ) was I ( ? * ? y ) )\n               (What i f you were ? y ? ) (Do you think you were ? y )\n               (What would i t mean i f you were ? y ) )\n              (((?*   ? x ) I am ( ? * ? y ) )\n               ( I n what way are you ? y ) (Do you want to be ? y ? ) )\n              (((?*   ? x ) am I ( ? * ? y ) )\n               (Do you believe you are ? y ) (Would you want to be ? y )\n               (You wish I would t e l l you you are ? y )\n               (What would i t mean i f you were ? y ) )\n              (((?*   ? x ) am ( ? * ? y ) )\n               (Why do you say \"AM?\") ( I d o n ' t understand t h a t ) )\n              (((?*   ? x ) are you ( ? * ? y ) )\n               (Why are you interested i n whether I am ? y or n o t ? )\n               (Would you prefer i f I weren't ? y )\n               (Perhaps I am ? y i n your           fantasies))\n              (((?*   ? x ) you are ( ? * ? y ) )\n               (What makes you think I am ? y ? ) )\n\f174                                                       ELIZA; DIALOG        WITH A       MACHINE\n\n\n\n      ( ( ( ? * ? x ) because ( ? * ? y ) )\n        ( I s that the real reason?) (What other reasons might there be?)\n        (Does that reason seem to explain anything e l s e ? ) )\n      ( ( ( ? * ? x ) were you ( ? * ? y ) )\n        (Perhaps I was ? y ) (What do you t h i n k ? ) (What i f I had been ? y ) )\n      ( ( ( ? * ?x) I can't ( ? * ? y ) )\n        (Maybe you could ? y now) (What i f you could ? y ? ) )\n      ( ( ( ? * ? x ) I feel ( ? * ? y ) )\n        (Do you often feel ? y ? ) )\n      (((?* ?x) I felt ( ? * ?y))\n        (What other f e e l i n g s do you have?))\n      ( ( ( ? * ? x ) I ( ? * ? y ) you ( ? * ? z ) )\n        (Perhaps i n your fantasy we ?y each other))\n      ( ( ( ? * ? x ) why d o n ' t you ( ? * ? y ) )\n        (Should you ?y y o u r s e l f ? )\n        (Do you believe I d o n ' t ? y ) (Perhaps I w i l l ? y i n good time))\n      ( ( ( ? * ?x) yes ( ? * ? y ) )\n        (You seem quite p o s i t i v e ) (You are sure) ( I understand))\n      ( ( ( ? * ? x ) no ( ? * ? y ) )\n        (Why not?) (You are being a b i t negative)\n        (Are you saying \"NO\" j u s t to be n e g a t i v e ? ) )\n\n      ( ( ( ? * ? x ) someone ( ? * ? y ) )\n        (Can you be more s p e c i f i c ? ) )\n      ( ( ( ? * ? x ) everyone ( ? * ? y ) )\n        ( s u r e l y not everyone) (Can you think of anyone i n p a r t i c u l a r ? )\n        (Who f o r example?) (You are t h i n k i n g of a special person))\n      ( ( ( ? * ? x ) always ( ? * ? y ) )\n        (Can you think of a s p e c i f i c example) (When?)\n        (What incident are you t h i n k i n g o f ? ) ( R e a l l y - - always))\n      ( ( ( ? * ? x ) what ( ? * ? y ) )\n        (Why do you a s k ? ) (Does that question i n t e r e s t you?)\n        (What i s i t you r e a l l y want to know?) (What do you t h i n k ? )\n        (What comes to your mind when you ask t h a t ? ) )\n      ( ( ( ? * ? x ) perhaps ( ? * ? y ) )\n        (You do not seem quite c e r t a i n ) )\n      ( ( ( ? * ? x ) are ( ? * ? y ) )\n        (Did you think they might not be ? y )\n        ( P o s s i b l y they are ? y ) )\n      ( ( ( ? * ?x))\n        (Very i n t e r e s t i n g ) ( I am not sure I understand you f u l l y )\n        (What does that suggest to you?) (Please continue) (Go on)\n        (Do you feel s t r o n g l y about d i s c u s s i n g such t h i n g s ? ) ) ) )\n\fCHAPTER                    6\n\nBuilding Software Tools\n\n                                                                      Man is a tool-using animal\n                                                                        Without tools he is nothing\n                                                                                  with tools he is all\n                                                                     -Thomas Carlyle (1795- 881)\n\n\n\n\nI\n    n chapters 4 and 5 we were concerned with building two particular programs, GPS and ELIZA.\n    In this chapter, we will reexamine those two programs to discover some common patterns.\n    Those patterns will be abstracted out to form reusable software tools that will prove helpful\nin subsequent chapters.\n\n\n\n6.1      An Interactive Interpreter Tool\nThe structure of the function el i za is a common one. It is repeated below:\n\n    (defun e l i z a ()\n      \"Respond to user input using pattern matching r u l e s . \"\n      (loop\n         (print 'eliza>)\n         (print (flatten (use-eliza-rules (read))))))\n\f176                                                           BUILDING    SOFTWARE      TOOLS\n\n\n\n      Many other appHcations use this pattern, including Lisp itself. The top level of Lisp\n      could be defined as:\n\n         (defun l i s p ()\n           (loop\n              (print '>)\n               ( p r i n t (eval ( r e a d ) ) ) ) )\n\n\n      The top level of a Lisp system has historically been called the \"read-eval-print loop.\"\n      Most modern Lisps print a prompt before reading input, so it should really be called\n      the \"prompt-read-eval-print loop,\" but there was no prompt in some early systems\n      like MacLisp, so the shorter name stuck. If we left out the prompt, we could write a\n      complete Lisp interpreter using just four symbols:\n\n         (loop ( p r i n t (eval ( r e a d ) ) ) )\n\n\n      It may seem facetious to say those four symbols and eight parentheses constitute a\n      Lisp interpreter. When we write that line, have we really accomplished anything?\n      One answer to that question is to consider what we would have to do to write a Lisp\n      (or Pascal) interpreter in Pascal. We would need a lexical analyzer and a symbol table\n      manager. This is a considerable amount of work, but it is all handled by read. We\n      would need a syntactic parser to assemble the lexical tokens into statements, read\n      also handles this, but only because Lisp statements have trivial syntax: the syntax\n      of lists and atoms. Thus read serves fine as a syntactic parser for Lisp, but would\n      fail for Pascal. Next, we need the evaluation or interpretation part of the interpreter;\n      eval does this nicely, and could handle Pascal just as well if we parsed Pascal syntax\n      into Lisp expressions, p r i n t does much less work than read or e v a l , but is still\n      quite handy.\n           The important point is not whether one line of code can be considered an imple\n      mentation of Lisp; it is to recognize common patterns of computation. Both el i z a\n      and l i s p can be seen as interactive interpreters that read some input, transform or\n      evaluate the input in some way, print the result, and then go back for more input. We\n      can extract the following common pattern:\n\n         (defun program ()\n            (loop\n               (print prompt)\n               ( p r i n t (transform ( r e a d ) ) ) ) )\n\n\n      There are two ways to make use of recurring patterns like this: formally and infor\n      mally. The informal alternative is to treat the pattern as a cliche or idiom that will\n      occur frequently in our writing of programs but will vary from use to use. When we\n\f6.1 AN INTERACTIVE      INTERPRETER          TOOL                                                  177\n\n\n\n          want to write a new program, we remember writing or reading a similar one, go back\n          and look at the first program, copy the relevant sections, and then modify them for\n          the new program. If the borrowing is extensive, it would be good practice to insert\n          a comment in the new program citing the original, but there would be no \"official\"\n          connection between the original and the derived program.\n              The formal alternative is to create an abstraction, in the form of functions and per\n          haps data structures, and refer explicitly to that abstraction in each new application--\n          in other words, to capture the abstraction in the form of a useable software tool. The\n          interpreter pattern could be abstracted into a function as follows:\n\n              (defun i n t e r a c t i v e - i n t e r p r e t e r (prompt transformer)\n                \"Read an e x p r e s s i o n , transform i t , and p r i n t the r e s u l t . \"\n                (loop\n                   ( p r i n t prompt)\n\n\n                     ( p r i n t (funcall transformer ( r e a d ) ) ) ) )\n\n\n          This function could then be used in writing each new interpreter:\n              (defun l i s p ()\n                (interactive-interpreter                  *> #'eval))\n\n              (defun e l i z a ()\n                (interactive-interpreter 'eliza>\n                   #'(lambda (x) ( f l a t t e n ( u s e - e l i z a - r u l e s x ) ) ) ) )\n\n\n          Or, with the help of the higher-order function compose:\n\n              (defun compose (f g)\n                \"Return the function that computes ( f (g x ) ) . \"\n                #'(lambda (x) (funcall f (funcall g x ) ) ) )\n\n              (defun e l i z a ()\n                (i nteracti v e - i nterpreter 'el i z a >\n                    (compose # ' f l a t t e n # ' u s e - e l i z a - r u l e s ) ) )\n\n\n          There are two differences between the formal and informal approaches. First, they\n          look different. If the abstraction is a simple one, as this one is, then it is probably\n          easier to read an expression that has the loop explicitly written out than to read one\n          that calls i n t e r a c t ! ve-i nterpreter, since that requires finding the definition of\n          i n t e r a c t i ve - i nterpreter and understanding it as well.\n               The other difference shows up in what's called maintenance. Suppose we find a\n          missing feature in the definition of the interactive interpreter. One such omission is\n          that the 1 oop has no exit. I have been assuming that the user can terminate the loop by\n          hitting some interrupt (or break, or abort) key. A cleaner implementation would allow\n\f178                                                                      BUILDING      SOFTWARE   TOOLS\n\n\n\n      the user to give the interpreter an explicit termination command. Another useful\n      feature would be to handle errors within the interpreter. If we use the irrformal\n      approach, then adding such a feature to one program would have no effect on the\n      others. Butif we use the formal approach, then improving i nteracti ve- i nterpreter\n      would automatically bring the new features to all the programs that use it.\n          The following version of i nteracti ve- i nterpreter adds two new features. First,\n      it uses the macro handler-case^ to handle errors. This macro evaluates its first\n      argument, and normally just returns that value. However, if an error occurs, the\n      subsequent arguments are checked for an error condition that matches the error that\n      occurred. In this use, the case error matches all errors, and the action taken is to\n      print the error condition and continue.\n          This version also allows the prompt to be either a string or a function of no\n      arguments that will be called to print the prompt. The function prompt-generator,\n      for example, returns a function that will print prompts of the form [ 1 ] , C2], and\n      so forth.\n\n         (defun i n t e r a c t i v e - i n t e r p r e t e r (prompt transformer)\n           \"Read an e x p r e s s i o n , transform i t , and p r i n t the r e s u l t . \"\n           (loop\n              (handler-case\n                (progn\n                  ( i f ( s t r i n g p prompt)\n                          ( p r i n t prompt)\n                          (funcall prompt))\n                  ( p r i n t ( f u n c a l l transformer ( r e a d ) ) ) )\n                    In case of e r r o r , do t h i s :\n                (error ( c o n d i t i o n )\n                  (format t \"'^&;; Error ~a ignored, back to top l e v e l . \"\n                                  condition)))))\n\n         (defun prompt-generator (&optional (num 0) ( c t l - s t r i n g \"C^d] \" ) )\n           \"Return a function that p r i n t s prompts l i k e [ 1 ] . C 2 ] . e t c . \"\n           #*(lambda () (format t c t l - s t r i n g ( i n c f num))))\n\n\n\n\n      6.2      A Pattern-Matching Tool\n      The pat-match function was a pattern matcher defined specifically for the ELIZA\n      program. Subsequent programs will need pattern matchers too, and rather than\n      write specialized matchers for each new program, it is easier to define one general\n\n         ^The macro hand! er-case is only in ANSI Common Lisp.\n\f6.2 A PAnERN-MATCHING TOOL                                                                       179\n\n\n        pattern matcher that can serve most needs, and is extensible in case novel needs\n        come up.\n            The problem in designing a \"general\" tool is deciding what features to provide.\n        We can try to define features that might be useful, but it is also a good idea to make\n        the list of features open-ended, so that new ones can be easily added when needed.\n            Features can be added by generalizing or specializing existing ones. For example,\n        we provide segment variables that match zero or more input elements. We can\n        specialize this by providing for a kind of segment variable that matches one or more\n        elements, or for an optional variable that matches zero or one element. Another\n        possibility is to generalize segment variables to specify a match of m to  elements, for\n        any specified m and n. These ideas come from experience with notations for writing\n        regular expressions, as well as from very general heuristics for generalization, such\n        as \"consider important special cases\" and \"zero and one are likely to be important\n        special cases.\"\n            Another useful feature is to allow the user to specify an arbitrary predicate that\n        a match must satisfy. The notation ( ? i s ?n numberp) could be used to match any\n        expression that is a number and bind it to the variable ?n. This would look like:\n\n           > (pat-match ' ( x = ( ? i s ?n numberp)) ' ( x = 3 4 ) ) => ( ( ? n . 3 4 ) )\n\n           > (pat-match ' ( x = ( ? i s ?n numberp)) ' ( x = x ) ) => NIL\n\n\n        Since patterns are like boolean expressions, it makes sense to allow boolean operators\n        on them. Following the question-mark convention, we will use ?and, ?or and ?not\n        for the operators.^ Here is a pattern to match a relational expression with one of three\n        relations. It succeeds because the < matches one of the three possibiUties specified\n        by(?or < = >).\n\n           > (pat-match ' ( ? x ( ? o r < = >) ? y ) *(3 < 4 ) ) =^ ( ( ? Y . 4) (?X . 3 ) )\n\n\n        Here is an example of an ? and pattern that checks if an expression is both a number\n        and odd:\n\n           > (pat-match *(x = (?and ( ? i s ?n numberp) ( ? i s ?n oddp)))\n                        �(x = 3 ) )\n           ((?N . 3 ) )\n\n\n\n\n            ^An alternative would be to reserve the question mark for variables only and use another\n        notation for these match operators. Keywords would be a good choice, such as : and,: or, : i s,\n        etc.\n\f180                                                                    BUILDING      SOFTWARE   TOOLS\n\n\n\n      The next pattern uses ?not to insure that two parts are not equal:\n\n         > (pat-match ' ( ? x / = (?not ? x ) ) ' ( 3 / = 4 ) ) =^ ( ( ? X . 3 ) )\n\n\n      The segment matching notation we have seen before. It is augmented to allow for\n      three possibilities: zero or more expressions; one or more expressions; and zero or\n      one expressions. Finally, the notation ( ? i f exp) can be used to test a relationship\n      between several variables. It has to be Usted as a segment pattern rather than a single\n      pattern because it does not consume any of the input at all:\n\n         > (pat-match ' ( ? x > ?y ( ? i f ( > ? x ? y ) ) ) ' ( 4 > 3 ) ) =>\n         ((?Y . 3) (?X . 4 ) )\n\n\n          When the description of a problem gets this complicated, it is a good idea to\n      attempt a more formal specification. The following table describes a grammar of\n      patterns, using the same grammar rule format described in chapter 2.\n\n\n                 pat =^     var                       match any one expression\n                            constant                  match just this atom\n                            segment-pat               match something against a sequence\n                            single-pat                match something against one expression\n                            (pat. pat)                match the first and the rest\n\n          single-pat =4^    (lis var predicate)       test predicate on one expression\n                            (lor pat...)              match any pattern on one expression\n                            (?andpai...)              match every pattern on one expression\n                            ( ? n o t pat...)         succeed if pattern(s) do not match\n\n        segment-pat -       ((l*var)    ...)          match zero or more expressions\n                            (d+var)     ...)          match one or more expressions\n                            ((V.var)     ...)         match zero or one expression\n                            ((?if    exp)...)         test if exp (which may contain\n                                                      variables) is true\n\n\n                 var-        chars                    a symbol starting with ?\n            constant -      atom                      any nonvariable atom\n\n         Despite the added complexity, all patterns can still be classified into five cases.\n      The pattern must be either a variable, constant, a (generalized) segment pattern,\n      a (generalized) single-element pattern, or a cons of two patterns. The following\n      definition of pat -match reflects the five cases (along with two checks for failure):\n\f6.2 A PAnERN'MATCHING           TOOL                                                                         181\n\n\n\n             (defun pat-match (pattern input �optional (bindings n o - b i n d i n g s ) )\n               \"Match pattern a g a i n s t input in the context of the b i n d i n g s \"\n               (cond ((eq bindings f a i l )               fail)\n                        ((variable-p           pattern)\n                          (match-variable pattern input b i n d i n g s ) )\n                        ((eql pattern input) b i n d i n g s )\n                        ((segment-pattern-p                pattern)\n                          (segment-matcher pattern input b i n d i n g s ) )\n                        ( ( s i n g l e - p a t t e r n - p pattern)                              ; ***\n                          (single-matcher pattern input b i n d i n g s ) )                       ; ***\n                        ((and     (consp pattern)             (consp       input))\n                          (pat-match ( r e s t pattern)                  (rest    input)\n                                             (pat-match ( f i r s t pattern)               (first   input)\n                                                                  bindings)))\n                        (t   fail)))\n\n\n         For completeness, we repeat here the necessary constants and low-level functions\n         from ELIZA:\n\n\n             (defconstant f a i l nil           \" I n d i c a t e s pat-match f a i l u r e \" )\n\n             (defconstant no-bindings ' ( ( t                 .    t))\n               \" I n d i c a t e s pat-match s u c c e s s , with no v a r i a b l e s . \" )\n\n            (defun v a r i a b l e - p (x)\n               \" I s  a v a r i a b l e (a symbol beginning with                        '?*)?\"\n               (and    (symbolp x) (equal (char (symbol-name x) 0) # \\ ? ) ) )\n\n            (defun g e t - b i n d i n g (var b i n d i n g s )\n               \"Find a ( v a r i a b l e . value) pair in a binding l i s t . \"\n               (assoc var b i n d i n g s ) )\n\n            (defun b i n d i n g - v a r (binding)\n               \"Get   the v a r i a b l e part of a s i n g l e b i n d i n g . \"\n               (car b i n d i n g ) )\n\n            (defun binding-val             (binding)\n               \"Get   the value part of a s i n g l e b i n d i n g . \"\n               (cdr b i n d i n g ) )\n\n            (defun make-binding (var v a l ) (cons var v a l ) )\n\n            (defun lookup (var b i n d i n g s )\n               \"Get   the value part (for var) from a binding l i s t . \"\n               (binding-val         ( g e t - b i n d i n g var b i n d i n g s ) ) )\n\f182                                                                                       BUILDING    SOFTWARE   TOOLS\n\n\n\n          (defun extend-bindings (var val b i n d i n g s )\n            \"Add a (var . value) pair to a binding l i s t . \"\n            (cons (make-binding var v a l )\n                            Once we add a \" r e a l \" b i n d i n g ,\n                            we can get r i d of the dummy no-bindings\n                      (if      (eq bindings n o - b i n d i n g s )\n                               nil\n                               bindings)\n\n          (defun match-variable (var input b i n d i n g s )\n            \"Does VAR match input?                   Uses (or updates) and returns b i n d i n g s . \"\n            ( l e t ( ( b i n d i n g ( g e t - b i n d i n g var b i n d i n g s ) ) )\n               (cond ((not binding) (extend-bindings var input b i n d i n g s ) )\n                          ((equal input ( b i n d i n g - v a l b i n d i n g ) ) b i n d i n g s )\n                          (t    fail))))\n\n\n      The next step is to define the predicates that recognize generalized segment and\n      single-element patterns, and the matching functions that operate on them. We could\n      implementsegment-matcherandsingle-matcherwithcasestatementsthatconsider\n      all possible cases. However, that would make it difficult to extend the matcher. A\n      programmer who wanted to add a new kind of segment pattern would have to edit\n      the definitions of both segment-pattern-p and segment-matcher to install the new\n      feature. This by itself may not be too bad, but consider what happens when two\n      programmers each add independent features. If you want to use both, then neither\n      version of segment-matcher (or segment-pattern-p) will do. You'll have to edit the\n      functions again, just to merge the two extensions.\n          The solution to this dilemma is to write one version of segment-pattern-p and\n      segment-matcher, once and for all, but to have these functions refer to a table of\n      pattern/action pairs. The table would say \"if you see ?* in the pattern, then use\n      the function segment-match,\" and so on. Then programmers who want to extend\n      the matcher just add entries to the table, and it is trivial to merge different exten\n      sions (unless of course two programmers have chosen the same symbol to mark\n      different actions).\n          This style of programming, where pattern/action pairs are stored in a table, is\n      called data-driven programming. It is a very flexible style that is appropriate for writing\n      extensible systems.\n          There are many ways to implement tables in Conunon Lisp, as discussed in\n      section 3.6, page 73. In this case, the keys to the table will be symbols (like ?*),\n      and it is fine if the representation of the table is distributed across memory. Thus,\n      property lists are an appropriate choice. We will have two tables, represented by\n      the segment-match property and the si ngl e-match property of symbols like ?*. The\n      value of each property will be the name of a function that implements the match.\n      Here are the table entries to implement the granunar listed previously:\n\f6.2 A PAnERN-MATCHING       TOOL                                                               183\n\n\n\n            (setf   (get   '?is     'single-match)     'match-is)\n            (setf   (get   '?or     'single-match)     'match-or)\n            (setf   (get   '?and    'single-match)     'match-and)\n            (setf   (get   '?not    'single-match)      'match-not)\n\n            (setf   (get   ' ? *   'segment-match) 'segment-match)\n            (setf   (get   '?+     'segment-match) 'segment-match+)\n            (setf   (get   '??     'segment-match) 'segment-match?)\n            (setf   (get   '?if    'segment-match) ' m a t c h - i f )\n\n\n         With the table defined, we need to do two things. First, define the \"glue\" that holds\n         the table together: the predicates and action-taking functions. A function that looks\n         upadata-driven function and calls it (such as segment-matcher and single-matcher)\n         is called a dispatch function.\n\n            (defun segment-pattern-p (pattern)\n              \" I s t h i s a segment-matching pattern l i k e ( ( ? * var) . p a t ) ? \"\n              (and (consp pattern) (consp ( f i r s t pattern))\n                      (symbolp ( f i r s t ( f i r s t p a t t e r n ) ) )\n                      (segment-match-fn ( f i r s t ( f i r s t p a t t e r n ) ) ) ) )\n\n            (defun s i n g l e - p a t t e r n - p (pattern)\n              \" I s t h i s a single-matching pattern?\n              E . g . ( ? i s X predicate) (?and . patterns) ( ? o r .         patterns).\"\n              (and (consp pattern)\n                      (single-match-fn ( f i r s t p a t t e r n ) ) ) )\n\n            (defun segment-matcher (pattern input b i n d i n g s )\n              \"Call the r i g h t function for t h i s kind of segment p a t t e r n . \"\n              (funcall (segment-match-fn ( f i r s t ( f i r s t p a t t e r n ) ) )\n                       pattern input b i n d i n g s ) )\n\n            (defun single-matcher (pattern input b i n d i n g s )\n              \"Call the r i g h t function for t h i s kind of s i n g l e p a t t e r n . \"\n              (funcall (single-match-fn ( f i r s t pattern))\n                        ( r e s t pattern) input b i n d i n g s ) )\n\n            (defun segment-match-fn (x)\n              \"Get the segment-match function for x .\n              i f i t i s a symbol that has o n e . \"\n              (when (symbolp x) (get  'segment-match)))\n\n            (defun single-match-fn (x)\n              \"Get the single-match function for x ,\n              i f i t i s a symbol that has one.\"\n              (when (symbolp x) (get  ' s i n g l e - m a t c h ) ) )\n\f184                                                                       BUILDING     SOFTWARE   TOOLS\n\n\n\n      The last thing to do is define the individual matching functions. First, the single-\n      pattern matching functions:\n\n\n          (defun match-is (var-and-pred input b i n d i n g s )\n            \"Succeed and bind var i f the input s a t i s f i e s pred,\n            where var-and-pred i s the l i s t (var p r e d ) . \"\n            ( l e t * ( ( v a r ( f i r s t var-and-pred))\n                        (pred (second var-and-pred))\n                        (new-bindings (pat-match var input b i n d i n g s ) ) )\n                ( i f (or (eq new-bindings f a i l )\n                             (not (funcall pred i n p u t ) ) )\n                      fail\n                      new-bindings)))\n\n         (defun match-and (patterns input b i n d i n g s )\n           \"Succeed i f a l l the patterns match the i n p u t . \"\n           (cond ((eq bindings f a i l ) f a i l )\n                 ( ( n u l l patterns) b i n d i n g s )\n                 (t (match-and ( r e s t patterns) input\n                                    (pat-match ( f i r s t patterns)          input\n                                                      bindings)))))\n\n         (defun match-or (patterns input b i n d i n g s )\n           \"Succeed i f any one of the patterns match the i n p u t . \"\n           ( i f (null patterns)\n                 fail\n                 ( l e t ((new-bindings (pat-match ( f i r s t patterns)\n                                                         input b i n d i n g s ) ) )\n                      ( i f (eq new-bindings f a i l )\n                            (match-or ( r e s t patterns) input b i n d i n g s )\n                            new-bindings))))\n\n         (defun match-not (patterns input b i n d i n g s )\n           \"Succeed i f none of the patterns match the input.\n           This w i l l never bind any v a r i a b l e s . \"\n           ( i f (match-or patterns input b i n d i n g s )\n                 fail\n                 bindings))\n\n\n      Now the segment-pattern matching functions, segment-match is similar to the ver\n      sion presented as part of ELIZA. The difference is in how we determine pos, the\n      position of the first element of the input that could match the next element of the\n      pattern after the segment variable. In ELIZA, we assumed that the segment variable\n      was either the last element of the pattern or was followed by a constant.                   In the\n      following version, we allow nonconstant patterns to follow segment variables. The\n      function f i r s t -match - pos is added to handle this. If the following element is in fact\n      a constant, the same calculation is done using posi t i on. If it is not a constant, then\n\f6.2 A PAnERN-MATCHING TOOL                                                                                    185\n\n\n        we just return the first possible starting position--unless that would put us past the\n        end of the input, in which case we return nil to indicate failure:\n\n           (defun segment-match (pattern input bindings �optional ( s t a r t 0 ) )\n              \"Match the segment pattern ( ( ? * var) . pat) against i n p u t . \"\n              (let    ( ( v a r (second ( f i r s t p a t t e r n ) ) )\n                       (pat       (rest pattern)))\n                (if    (null pat)\n                       (match-variable var input b i n d i n g s )\n                       ( l e t ((pos ( f i r s t - m a t c h - p o s ( f i r s t pat) input s t a r t ) ) )\n                            (if    (null pos)\n                                  fail\n                                   (let    ((b2 (pat-match\n                                                      pat     (subseq input pos)\n                                                       (match-variable var (subseq input 0 pos)\n                                                                            bindings))))\n                                           I f t h i s match f a i l e d , t r y another longer one\n                                     (if    (eq b2 f a i l )\n                                            (segment-match pattern input bindings (+ pos 1))\n                                            b2)))))))\n\n           (defun f i r s t - m a t c h - p o s (patl input s t a r t )\n             \"Find the f i r s t p o s i t i o n that patl could p o s s i b l y match i n p u t ,\n             s t a r t i n g at p o s i t i o n s t a r t .   I f patl i s non-constant, then j u s t\n             return s t a r t . \"\n             (cond ((and (atom p a t l ) (not ( v a r i a b l e - p p a t l ) ) )\n                         ( p o s i t i o n patl input : s t a r t s t a r t : t e s t #*equal))\n                       ( ( < s t a r t (length i n p u t ) ) s t a r t )\n                       (t     nil)))\n\n\n        In the first example below, the segment variable ?x matches the sequence (b c ) . In\n        the second example, there are two segment variables in a row. The first successful\n        match is achieved with the first variable, ?x, matching the empty sequence, and the\n        second one, ?y, matching ( b e ) .\n\n           > (pat-match ' ( a ( ? * ? x ) d) ' ( a b c d ) ) =^ ( ( ? X   )\n\n           > (pat-match ' ( a ( ? * ? x ) ( ? * ? y ) d) ' ( a b c d ) ) =^ ( ( ? Y  C) ( ? X ) )\n\n\n        In the next example, ?x is first matched against nil and ?y against ( b e d), but that\n        fails, so we try matching ?x against a segment of length one. That fails too, but\n        finally the match succeeds with ?x matching the two-element segment ( b e ) , and ?y\n        matching (d).\n\f186                                                                            BUILDING   SOFTWARE   TOOLS\n\n\n\n         > (pat-match ' ( a ( ? * ? x ) ( ? * ? y ) ? x ? y )\n                      ' ( a b c d (b c) ( d ) ) )           ( ( ? Y D) (?X   )\n\n\n      Given segment - match, it is easy to define the function to match one-or-more elements\n      and the function to match zero-or-one element:\n\n         (defun segment-match+ (pattern input b i n d i n g s )\n           \"Match one or more elements of i n p u t . \"\n           (segment-match pattern input bindings D )\n\n         (defun segment-match? (pattern input b i n d i n g s )\n           \"Match zero or one element of i n p u t . \"\n           ( l e t ( ( v a r (second ( f i r s t p a t t e r n ) ) )\n                     (pat ( r e s t p a t t e r n ) ) )\n                (or (pat-match (cons var pat) input b i n d i n g s )\n                     (pat-match pat input b i n d i n g s ) ) ) )\n\n\n      Finally, we supply the function to test an arbitrary piece of Lisp code. It does this\n      by evaluating the code with the bindings implied by the binding list. This is one of\n      the few cases where it is appropriate to call eval: when we want to give the user\n      unrestricted access to the Lisp interpreter.\n\n         (defun match-if (pattern input b i n d i n g s )\n           \"Test an a r b i t r a r y expression i n v o l v i n g v a r i a b l e s .\n           The pattern looks l i k e ( ( ? i f code) . r e s t ) . \"\n           (and (progv (mapcar #*car b i n d i n g s )\n                         (mapcar # ' c d r b i n d i n g s )\n                   (eval (second ( f i r s t p a t t e r n ) ) ) )\n                (pat-match ( r e s t pattern) input b i n d i n g s ) ) )\n\n\n      Here are two examples using ?i f. The first succeeds because (+ 3 4 ) is indeed 7,\n      and the second fails because (> 3 4 ) is false.\n\n         > (pat-match ' ( ? x ?op ?y i s ? z ( ? i f (eql (?op ? x ? y ) ? z ) ) )\n                         �(3 + 4 i s 7 ) )\n         ( ( ? Z . 7) (?Y . 4) ( ? 0 P . +) (?X . 3 ) )\n\n         > (pat-match � ( ? x ?op ? y ( ? i f (?op ? x ? y ) ) )\n                      '(3 > 4))\n         NIL\n\n\n      The syntax we have defined for patterns has two virtues: first, the syntax is very\n      general, so it is easy to extend. Second, the syntax can be easily manipulated by\n      pat-match. However, there is one drawback: the syntax is a little verbose, and some\n      may find it ugly. Compare the following two patterns:\n\f6.2 A PAnERN-MATCHING        TOOL                                                          187\n\n\n\n            (a ( ? * ? x ) ( ? * ? y ) d)\n            (a ? x * ? y * d)\n\n\n         Many readers find the second pattern easier to understand at a glance. We could\n         change pat-match to allow for patterns of the form ?x*, but that would mean\n         pat-match would have a lot more work to do on every match. An alternative is\n         to leave pat-match as is, but define another level of syntax for use by human readers\n         only. That is, a programmer could type the second expression above, and have it\n         translated into the first, which would then be processed by pat-match.\n             In other words, we will define a facility to define a kind of pattern-matching\n         macro that will be expanded the first time the pattern is seen. It is better to do this\n         expansion once than to complicate pat-match and in effect do the expansion every\n         time a pattern is used. (Of course, if a pattern is only used once, then there is no\n         advantage. But in most programs, each pattern will be used again and again.)\n             We need to define two functions: one to define pattern-matching macros, and\n         another to expand patterns that may contain these macros. We will only allow\n         symbols to be macros, so it is reasonable to store the expansions on each symbol's\n         property list:\n\n            (defun pat-match-abbrev (symbol expansion)\n              \"Define symbol as a macro standing for a pat-match p a t t e r n . \"\n              ( s e t f (get symbol *expand-pat-match-abbrev)\n                      (expand-pat-match-abbrev expansion))\n\n            (defun expand-pat-match-abbrev (pat)\n              \"Expand out a l l pattern matching a b b r e v i a t i o n s i n p a t . \"\n              (cond ((and (symbolp pat) (get pat 'expand-pat-match-abbrev)))\n                    ((atom pat) pat)\n                    (t (cons (expand-pat-match-abbrev ( f i r s t p a t ) )\n                               (expand-pat-match-abbrev ( r e s t p a t ) ) ) ) ) )\n\n\n         We would use this facility as follows:\n\n            > (pat-match-abbrev ' ? x * ' ( ? * ? x ) ) => ( ? * ? X )\n\n            > (pat-match-abbrev ' ? y * ' ( ? * ? y ) )     ( ? * ?Y)\n\n            > ( s e t f axyd (expand-pat-match-abbrev ' ( a ? x * ? y * d ) ) )\n            (A ( ? * ? X ) ( ? * ? Y ) D)\n\n            > (pat-match axyd ' ( a b c d ) )        ( ( ? Y  C) ( ? X ) )\n\n\n\n\n     @   Exercise 6.1 [m] Go back and change the ELIZA rules to use the abbreviation facility.\n         Does this make the rules easier to read?\n\f188                                                                                     BUILDING SOFTWARE TOOLS\n\n\n\n      @   Exercise 6.2 [h] In the few prior examples, every time there was a binding of\n          pattern variables that satisfied the input, that binding was found. Informally, show\n          that pat-match will always find such a binding, or show a counterexample where it\n          fails to find one.\n\n\n\n\n          6.3        A Rule-Based Translator Tool\n          As we have defined it, the pattern matcher matches one input against one pattern. In\n          el i  a, we need to match each input against a number of patterns, and then return a\n          result based on the rule that contains the first pattern that matches. To refresh your\n          memory, here is the function use-el i za - rul es:\n\n              (defun u s e - e l i z a - r u l e s (input)\n                \"Find some rule with which to transform the i n p u t . \"\n                (some #*(lambda ( r u l e )\n                              ( l e t ( ( r e s u l t (pat-match ( r u l e - p a t t e r n r u l e ) i n p u t ) ) )\n                                   ( i f (not (eq r e s u l t f a i l ) )\n                                           ( s u b l i s (switch-viewpoint r e s u l t )\n                                                         (random-elt (rule-responses r u l e ) ) ) ) ) )\n                      *eliza-rules*))\n\n\n          It turns out that this will be a quite common thing to do: search through a list of rules\n          for one that matches, and take action according to that rule. To turn the structure of\n          use-el i z a - r u l e s into a software tool, we will allow the user to specify each of the\n          following:\n\n             � What kind of rule to use. Every rule will be characterized by an if-part and a\n               then-part, but the ways of getting at those two parts may vary.\n\n             � What list of rules to use. In general, each appHcation will have its own list of\n               rules.\n\n             � How to see if a rule matches. By default, we will use pat-match, but it should\n               be possible to use other matchers.\n\n             � What to do when a rule matches. Once we have determined which rule to use,\n               we have to determine what it means to use it. The default is just to substitute\n               the bindings of the match into the then-part of the rule.\n\f6.4 A SET OF SEARCHING         TOOLS                                                                           189\n\n\n\n          The rule-based translator tool now looks like this:\n\n              (defun r u l e - b a s e d - t r a n s l a t o r\n                      (input r u l e s &key (matcher #'pat-match)\n                        ( r u l e - i f # * f i r s t ) (rule-then # * r e s t ) (action # * s u b l i s ) )\n                \"Find the f i r s t rule in r u l e s that matches i n p u t ,\n                and apply the action to that r u l e . \"\n                (some\n                  #'(lambda ( r u l e )\n                        ( l e t ( ( r e s u l t (funcall matcher (funcall r u l e - i f r u l e )\n                                                               input)))\n                             ( i f (not (eq r e s u l t f a i l ) )\n                                    (funcall action r e s u l t (funcall rule-then r u l e ) ) ) ) )\n                   rules))\n\n\n\n              (defun u s e - e l i z a - r u l e s (input)\n                \"Find some rule with which to transform the i n p u t . '\n                ( r u l e - b a s e d - t r a n s l a t o r input * e l i z a - r u l e s *\n                    laction #�(lambda (bindings responses)\n                                            ( s u b l i s (switch-viewpoint b i n d i n g s )\n                                                           (random-elt r e s p o n s e s ) ) ) ) )\n\n\n\n\n           6.4        A Set of Searching Tools\n          The GPS program can be seen as a problem in search. In general, a search problem\n          involves exploring from some starting state and investigating neighboring states\n          until a solution is reached. As in GPS, state means a description of any situation or\n          state of affairs. Each state may have several neighbors, so there will be a choice of\n          how to search. We can travel down one path until we see it is a dead end, or we can\n          consider lots of different paths at the same time, expanding each path step by step.\n          Search problems are called nondeterministic because there is no way to determine\n          what is the best step to take next. AI problems, by their very nature, tend to be\n          nondeterministic. This can be a source of confusion for programmers who are used\n          to deterministic problems. In this section we will try to clear up that confusion.\n          This section also serves as an example of how higher-order functions can be used to\n          implement general tools that can be specified by passing in specific functions.\n              Abstractly, a search problem can be characterized by four features:\n\n              � The siarf state.\n\n              � The ^Oiz/ state (or states).\n\f190                                                               BUILDING    SOFTWARE       TOOLS\n\n\n\n         � The successors, or states that can be reached from any other state.\n\n         � The strategy that determines the order in which we search.\n\n          The first three features are part of the problem, while the fourth is part of the\n      solution. In GPS, the starting state was given, along with a description of the goal\n      states. The successors of a state were determined by consulting the operators. The\n      search strategy was means-ends analysis. This was never spelled out explicitly but\n      was impUcit in the structure of the whole program. In this section we will formulate\n      a general searching tool, show how it can be used to implement several different\n      search strategies, and then show how GPS could be implemented with this tool.\n          The first notion we have to define is the state space, or set of all possible states.\n      We can view the states as nodes and the successor relation as links in a graph. Some\n      state space graphs will have a small number of states, while others have an infinite\n      number, but they can still be solved if we search cleverly. Some graphs will have\n      a regular structure, while others will appear random. We will start by considering\n      only trees--that is, graphs where a state can be reached by only one unique sequence\n      of successor links. Here is a tree:\n\n\n\n\n      Searching Trees\n\n      We will call our first searching tool t r e e - s e a r c h , because it is designed to search\n      state spaces that are in the form of trees. It takes four arguments: (1) a list of valid\n      starting states, (2) a predicate to decide if we have reached a goal state, (3) a function\n      to generate the successors of a state, and (4) a function that decides in what order\n\f6 .4 A SET OF SEARCHING TOOLS                                                                            191\n\n\n         to search. The first argument is a hst rather than a single state so that t r e e - s e a r c h\n         can recursively call itself after it has explored several paths through the state space.\n         Think of the first argument not as a starting state but as a list of possible states from\n         which the goal may be reached. This lists represents the fringe of the tree that has\n         been explored so far. t r e e - s e a r c h has three cases: If there are no more states to\n         consider, then give up and return f a i 1. If the first possible state is a goal state,\n         then return the succesful state. Otherwise, generate the successors of the first state\n         and combine them with the other states. Order this combined list according to the\n         particular search strategy and continue searching. Note that t r e e - search itself does\n         not specify any particular searching strategy.\n\n             (defun tree-search ( s t a t e s goal-p successors combiner)\n               \"Find a state that s a t i s f i e s g o a l - p . S t a r t with s t a t e s ,\n               and search according to successors and combiner.\"\n               (dbg :search \" \" & ; ; Search: ~a\" s t a t e s )\n               (cond ( ( n u l l s t a t e s ) f a i l )\n                      ( ( f u n c a l l goal-p ( f i r s t s t a t e s ) ) ( f i r s t s t a t e s ) )\n                      (t (tree-search\n                                (funcall combiner\n                                              (funcall successors ( f i r s t s t a t e s ) )\n                                              (rest states))\n                                goal-p successors combiner))))\n\n\n         The first strategy we will consider is called depth-first search. In depth-first search,\n         the longest paths are considered first. In other words, we generate the successors\n         of a state, and then work on the first successor first. We only return to one of the\n         subsequent successors if we arrive at a state that has no successors at all. This\n         strategy can be implemented by simply appending the previous states to the end\n         of the Ust of new successors on each iteration. The function d e p t h - f i r s t - s e a r c h\n         takes a single starting state, a goal predicate, and a successor function. It packages\n         the starting state into a Hst as expected by t r e e - s e a r c h , and specifies append as the\n         combining function:\n\n             (defun d e p t h - f i r s t - s e a r c h ( s t a r t goal-p successors)\n               \"Search new states f i r s t u n t i l goal i s reached.\"\n               (tree-search ( l i s t s t a r t ) goal-p successors #'append))\n\n\n         Let's see how we can search through the binary tree defined previously. First, we\n         define the successor function binary-tree. It returns a list of two states, the two\n         numbers that are twice the input state and one more than twice the input state. So the\n         successors of 1 will be 2 and 3, and the successors of 2 will be 4 and 5. The bi na ry - t r e e\n         function generates an infinite tree of which the first 15 nodes are diagrammed in our\n         example.\n\f192                                                                                   BUILDING SOFTWARE TOOLS\n\n\n         (defun b i n a r y - t r e e (  ) ( l i s t ( * 2  ) ( + 1 ( * 2  ) ) ) )\n\n\n       make it easier to specify a goal, we define the function i s as a function that returns\n      a predicate that tests for a particular value. Note that 1 s does not do the test itself.\n      Rather, it returns a function that can be called to perform tests:\n\n         (defun i s (value) #*(lambda ( x ) (eql  v a l u e ) ) )\n\n\n      Now we can turn on the debugging output and search through the binary tree, starting\n      at 1, and looking for, say, 1 2 , as the goal state. Each line of debugging output shows\n      the list of states that have been generated as successors but not yet examined:\n\n         > (debug :search) => (SEARCH)\n\n         >   ( d e p t h - f i r s t - s e a r c h 1 ( i s 12) # * b i n a r y - t r e e )\n         ;;    Search; (1)\n         ;:    Search: (2 3)\n         ;;    Search: (4 5 3)\n          ;;   Search: (8 9 5 3)\n               Search: (16 17 9 5 3)\n          : ; Search: (32 33 17 9 5 3)\n          ; ; Search: (64 65 33 17 9 5 3)\n               Search: (128 129 65 33 17 9 5 3)\n               Search: (256 257 129 65 33 17 9 5 3)\n          ; : Search: (512 513 257 129 65 33 17 9 5 3)\n          ; ; Search: (1024 1025 513 257 129 65 33 17 9 5 3)\n               Search: (2048 2049 1025 513 257 129 65 33 17 9 5 3)\n          [Abort]\n\n\n      The problem is that we are searching an infinite tree, and the depth-first search\n      strategy just dives down the left-hand branch at every step. The or�y way to stop the\n      doomed search is to type an interrupt character.\n          An alternative strategy is breadth-first search, where the shortest path is extended\n      first at each step. It can be implemented simply by appending the new successor\n      states to the end of the existing states:\n\n          (defun prepend (x y ) \"Prepend y to s t a r t of x\" (append y  ) )\n\n          (defun b r e a d t h - f i r s t - s e a r c h ( s t a r t g o a l - p s u c c e s s o r s )\n            \"Search o l d s t a t e s f i r s t u n t i l goal i s reached.\"\n            (tree-search ( l i s t s t a r t ) g o a l - p successors #'prepend))\n\n\n      The or�y difference between depth-first and breadth-first search is the difference\n      between append and prepend. Here we see b r e a d t h - f i r s t - s e a r c h inaction:\n\f6,4 A SET OF SEARCHING          TOOLS                                                                         193\n\n\n\n             > ( b r e a d t h - f i r s t - s e a r c h 1 ( i s 12) * b i n a r y - t r e e )\n                 Search: (1)\n                 Search: (2 3)\n                 Search: (3 4 5)\n                 Search: (4 5 6 7)\n                 Search: ( 5 6 7 8 9 )\n                 Search: (6 7 8 9 10 11)\n                 Search: (7 8 9 10 11 12 13)\n                 Search: (8 9 10 11 12 13 14 15)\n                 Search: (9 10 11 12 13 14 15 16 17)\n                 Search: (10 11 12 13 14 15 16 17 18 19)\n                 Search: (11 12 13 14 15 16 17 18 19 20 21)\n                 Search: (12 13 14 15 16 17 18 19 20 21 22 23)\n             12\n\n\n          Breadth-first search ends up searching each node in numerical order, and so it will\n          eventually find any goal. It is methodical, but therefore plodding. Depth-first search\n          will be much faster--if it happens to find the goal at all. For example, if we were\n          looking for 2048, depth-first search would find it in 12 steps, while breadth-first\n          would take 2048 steps. Breadth-first search also requires more storage, because it\n          saves more intermediate states.\n               If the search tree is finite, then either breadth-first or depth-first will eventually\n          find the goal. Both methods search the entire state space, but in a different order. We\n          will now show a depth-first search of the 15-node binary tree diagrammed previously.\n          It takes about the same amount of time to find the goal (12) as it did with breadth-first\n          search. It would have taken more time to find 15; less to find 8. The big difference is\n          in the number of states considered at one time. At most, depth-first search considers\n          four at a time; in general it will need to store only log2  states to search a n-node tree,\n          while breadth-first search needs to store n / 2 states.\n\n              (defun f i n i t e - b i n a r y - t r e e (n)\n                \"Return a successor function that generates a binary tree\n                with  nodes.\"\n                #'(lambda (x)\n                     (remove-if #*(lambda ( c h i l d ) ( > c h i l d n ) )\n                                          (binary-tree x ) ) ) )\n\n             > ( d e p t h - f i r s t - s e a r c h 1 ( i s 12) ( f i n i t e - b i n a r y - t r e e 15))\n             ; ; Search: (1)\n                 Search: (2 3)\n                 Search: (4 5 3)\n                 Search: (8 9 5 3)\n                 Search: (9 5 3)\n             : : Search: (5 3)\n             : : Search: (10 11 3)\n             ; : Search: (11 3)\n\f194                                                                            BUILDING       SOFTWARE    TOOLS\n\n\n\n              Search: (3)\n              Search: (6 7)\n              Search: (12 13 7)\n         12\n\n\n\n\n      Guiding the Search\n\n      While breadth-first search is more methodical, neither strategy is able to take advan\n      tage of any knowledge about the state space. They both search blindly. In most real\n      applications we will have some estimate of how far a state is from the solution. In\n      such cases, we can implement a best-first search. The name is not quite accurate; if\n      we could really search best first, that would not be a search at all. The name refers to\n      the fact that the state that appears to be best is searched first.\n          To implement best-first search we need to add one more piece of information: a\n      cost function that gives an estimate of how far a given state is from the goal.\n          For the binary tree example, we will use as a cost estimate the numeric difference\n      from the goal. So if we are looking for 12, then 12 has cost 0, 8 has cost 4 and 2048\n      has cost 2036. The higher-order function d i f f , shown in the following, returns a cost\n      function that computes the difference from a goal. The higher-order function s o r t e r\n      takes a cost function as an argument and returns a combiner function that takes the\n      lists of old and new states, appends them together, and sorts the result based on the\n      cost function, lowest cost first. (The built-in function s o r t sorts a list according to\n      a comparison function. In this case the smaller numbers come first, s o r t takes an\n      optional : key argument that says how to compute the score for each element. Be\n      careful--sort is a destructive function.)\n\n          (defun d i f f (num)\n            \"Return the function that f i n d s the difference from num.\"\n            #'(lambda (x) (abs (-  num))))\n\n          (defun s o r t e r ( c o s t - f n )\n            \"Return a combiner function that s o r t s according to c o s t - f n . \"\n            #'(lambda (new old)\n                 ( s o r t (append new old) # ' < :key c o s t - f n ) ) )\n\n\n          (defun b e s t - f i r s t - s e a r c h ( s t a r t g o a l - p successors c o s t - f n )\n            \"Search lowest cost s t a t e s f i r s t u n t i l goal i s reached.\"\n            (tree-search ( l i s t s t a r t ) g o a l - p successors ( s o r t e r c o s t - f n ) ) )\n\n\n      Now, using the difference from the goal as the cost function, we can search using\n      best-first search:\n\f6.4   A SET OF SEARCHING           TOOLS                                                                                          195\n\n\n\n\n                 > ( b e s t - f i r s t - s e a r c h 1 ( i s 12) # ' b i n a r y - t r e e ( d i f f 12))\n                     Search: (1)\n                 ; ; Search: (3 2)\n                     Search: (7 6 2)\n                     Search: (14 15 6 2)\n                     Search: (15 6 2 28 29)\n                 ; ; Search: (6 2 28 29 30 31)\n                     Search: (12 13 2 28 29 30 31)\n                 12\n\n\n             The more we know about the state space, the better we can search. For example, if we\n             know that all successors are greater than the states they come from, then we can use\n             a cost function that gives a very high cost for numbers above the goal. The function\n             p r i c e - i s - r i g h t is like d i f f , except that it gives a high penalty for going over the\n             goal.\"^ Using this cost function leads to a near-optimal search on this example. It\n             makes the \"mistake\" of searching 7 before 6 (because 7 is closer to 12), but does not\n             waste time searching 14 and 15:\n\n                 (defun p r i c e - i s - r i g h t ( p r i c e )\n                   \"Return a function that measures the difference from p r i c e ,\n                   but gives a big penalty for going over p r i c e . \"\n                   #'(lambda (x) ( i f ( >  p r i c e )\n                                                  most-positive-fixnum\n                                                  (- price x ) ) ) )\n\n                 > ( b e s t - f i r s t - s e a r c h 1 ( i s 12) # ' b i n a r y - t r e e ( p r i c e - i s - r i g h t 12))\n                     Search: (1)\n                     Search: (3 2)\n                     Search: (7 6 2)\n                     Search: (6 2 14 15)\n                     Search: (12 2 13 14 15)\n                 12\n\n\n             All the searching methods we have seen so far consider ever-increasing lists of states\n             as they search. For problems where there is only one solution, or a small number of\n             solutions, this is unavoidable. To find a needle in a haystack, you need to look at a\n             lot of hay. But for problems with many solutions, it may be worthwhile to discard\n             unpromising paths. This runs the risk of failing to find a solution at all, but it can\n             save enough space and time to offset the risk. A best-first search that keeps only a\n             fixed number of alternative states at any one time is known as a beam search. Think\n             of searching as shining a light through the dark of the state space. In other search\n\n                ^The built-in constant most-positi ve-fixnum is a large integer, the largest that can be\n             expressed without using bignums. Its value depends on the implementation, but in most\n             Lisps it is over 16 million.\n\f196                                                                               BUILDING        SOFTWARE           TOOLS\n\n\n\n      strategies the light spreads out as we search deeper, but in beam search the light\n      remains tightly focused. Beam search is a variant of best-first search, but it is also\n      similar to depth-first search. The difference is that beam search looks down several\n      paths at once, instead of just one, and chooses the best one to look at next. But\n      it gives up the ability to backtrack indefinitely. The function beam-search is just\n      like b e s t - f i r s t - s e a r c h , except that after we sort the states, we then take only the\n      first beam -wi dth states. This is done with subseq; (subseq list start end) returns the\n      sublist that starts at position start and ends just before position end.\n\n          (defun beam-search ( s t a r t goal-p successors c o s t - f n beam-width)\n            \"Search highest s c o r i n g states f i r s t u n t i l goal i s reached,\n            but never consider more than beam-width s t a t e s at a time.\"\n            (tree-search ( l i s t s t a r t ) goal-p successors\n                         #'(lambda (old new)\n                                  ( l e t ( ( s o r t e d (funcall ( s o r t e r c o s t - f n ) o l d n e w ) ) )\n                                       ( i f ( > beam-width (length s o r t e d ) )\n                                             sorted\n\n                                                (subseq s o r t e d 0 beam-width))))))\n\n\n      We can successfully search for 12 in the binary tree using a beam width of only 2:\n          > (beam-search 1 ( i s 12) # * b i n a r y - t r e e ( p r i c e - i s - r i g h t 12) 2)\n              Search; (1)\n              Search; (3 2)\n          ; ; Search; (7 6)\n              Search; (6 14)\n              Search; (12 13)\n          12\n\n\n      However, if we go back to the scoring function that just takes the difference from 12,\n      then beam search fails. When it generates 14 and 15, it throws away 6, and thus loses\n      its only chance to find the goal:\n\n          > (beam-search 1 ( i s 12) # ' b i n a r y - t r e e ( d i f f 12) 2)\n             Search; (1)\n             Search; (3 2)\n             Search; (7 6)\n             Search; (14 15)\n             Search; (15 28)\n             Search; (28 30)\n             Search; (30 56)\n             Search; (56 60)\n             Search; (60 112)\n             Search; (112 120)\n             Search; (120 224)\n\f6,4 A SET OF SEARCHING TOOLS                                                                          1 97\n\n\n             [Abort]\n\n\n         This search would succeed if we gave a beam width of 3. This illustrates a general\n         principle: we can find a goal either by looking at more states, or by being smarter\n         about the states we look at. That means having a better ordering function.\n             Notice that with a beam width of infinity we get best-first search. With a beam\n         width of 1, we get depth-first search with no backup. This could be called \"depth-only\n         search,\" but it is more commonly known as hill-climbing. Think of a mountaineer\n         trying to reach a peak in a heavy fog. One strategy would be for the moimtaineer to\n         look at adjacent locations, climb to the highest one, and look again. This strategy\n         may eventually hit the peak, but it may also get stuck at the top of a foothill, or local\n         manmum. Another strategy would be for the mountaineer to turn back and try again\n         when the fog lifts, but in AI, unfortunately, the fog rarely lifts.^\n             As a concrete example of a problem that can be solved by search, consider the\n         task of planning a flight across the North American continent in a small airplane, one\n         whose range is limited to 1000 kilometers. Suppose we have a list of selected cities\n         with airports, along with their position in longitude and latitude:\n\n             ( d e f s t r u c t ( c i t y (:type l i s t ) ) name long l a t )\n\n             (defparameter * c i t i e s *\n               '((Atlanta                   84.23   33.45)   (Los-Angeles         118.15   34.03)\n                  (Boston                   71.05   42.21)   (Memphis              90.03   35.09)\n                  (Chicago                  87.37   41.50)   (New-York             73.58   40.47)\n                  (Denver                  105.00   39.45)   (Oklahoma-City        97.28   35.26)\n                  (Eugene                  123.05   44.03)   (Pittsburgh           79.57   40.27)\n                  (Flagstaff               111.41   35.13)   (Quebec               71.11   46.49)\n                  (Grand-Jet               108.37   39.05)   (Reno                119.49   39.30)\n                  (Houston                 105.00   34.00)   (San-Francisco       122.26   37.47)\n                  ( I n d i a n a p o l i s 86.10   39.46)   (Tampa                82.27   27.57)\n                  ( J a c k s o n v i l l e 81.40   30.22)   (Victoria            123.21   48.25)\n                  (Kansas-City 94.35                39.06)   (Wilmington           77.57   34.14)))\n\n\n         This example introduces a new option to defstruct. Instead of just giving the name\n         of the structure, it is also possible to use:\n\n             (defstruct {structure-name {option value),,,) 'Optionaldoc'' slot,,,)\n\n         For city, the option : type is specified as 1 i s t . This means that cities will be imple\n         mented as lists of three elements, as they are in the initial value for *ci t i es*.\n\n            ^In chapter 8 we will see an example where the fog did lift: symbolic integration was once\n         handled as a problem in search, but new mathematical results now make it possible to solve\n         the same class of integration problems without search.\n\f198                                                                            BUILDING     SOFTWARE   TOOLS\n\n\n\n\n                                      Figure 6.1: A Map of Some Cities\n\n\n          The cities are shown on the map in figure 6.1, which has cormections between\n      all cities within the 1000 kilometer range of each other.^ This map was drawn with\n      the help of ai r-di stance, a function that retiutis the distance in kilometers between\n      two cities \"as the crow flies.\" It will be defined later. Two other useful fimctions are\n      nei ghbors, which finds all the cities within 1000 kilometers, and c i ty, which maps\n      from a name to a city. The former uses f i nd - a 11 - i f, which was defined on page 101\n      as a synonym for remove- i f-not.\n\n          (defun neighbors ( c i t y )\n            \"Find a l l c i t i e s w i t h i n 1000 k i l o m e t e r s . \"\n            ( f i n d - a l l - i f #'(lambda (c)\n                                         (and (not (eq c c i t y ) )\n                                              � (air-distance c city)           1000.0)))\n                                    *cities*))\n\n          (defun c i t y (name)\n            \"Find the c i t y with t h i s name.\"\n            (assoc name * c i t i e s * ) )\n\n\n      We are now ready to plan a trip. The fimction t r i p takes the name of a starting and\n      destination city and does a beam search of width one, considering all neighbors as\n\n         ^The astute reader will recognize that this graph is not a tree. The difference between trees\n      and graphs and the implications for searching will be covered later.\n\f6.4 A SET OF SEARCHING       TOOLS                                                              199\n\n\n\n          successors to a state. The cost for a state is the air distance to the destination city:\n\n              (defun t r i p ( s t a r t dest)\n                \"Search for a way from the s t a r t to d e s t . \"\n                (beam-search s t a r t ( i s dest) # ' n e i g h b o r s\n                                  #'(1ambda (c) ( a i r - d i s t a n c e c d e s t ) )\n                                  D)\n\n\n          Here we plan a trip from San Francisco to Boston. The result seems to be the best\n          possible path:\n\n             > (trip (city 'san-francisco)              (city     'boston))\n                 Search: ((SAN-FRANCISCO 122.26 3 7 . 4 7 ) )\n                 Search: ((RENO 119.49 3 9 . 3 ) )\n                 Search: ((GRAND-JCT 108.37 3 9 . 0 5 ) )\n                 Search: ((DENVER 105.0 3 9 . 4 5 ) )\n                 Search: ((KANSAS-CITY 94.35 3 9 . 0 6 ) )\n                 Search: ((INDIANAPOLIS 8 6 . 1 3 9 . 4 6 ) )\n                 Search: ((PITTSBURGH 79.57 4 0 . 2 7 ) )\n              : ; Search: ((BOSTON 7 1 . 0 5 4 2 . 2 1 ) )\n              (BOSTON 71.05 42.21)\n\n\n          But look what happens when we plan the return trip. There are two detours, to\n          Chicago and Flagstaff:\n\n             > ( t r i p ( c i t y 'boston) ( c i t y   'san-francisco))\n                 Search: ((BOSTON 7 1 . 0 5 4 2 . 2 1 ) )\n                 Search: ((PITTSBURGH 79.57 4 0 . 2 7 ) )\n                 Search: ((CHICAGO 87.37 4 1 . 5 ) )\n                  Search: ((KANSAS-CITY 94.35 3 9 . 0 6 ) )\n                  Search: ((DENVER 105.0 3 9 . 4 5 ) )\n                  Search: ((FLAGSTAFF 111.41 3 5 . 1 3 ) )\n                  Search: ((RENO 119.49 3 9 . 3 ) )\n                  Search: ((SAN-FRANCISCO 122.26 3 7 . 4 7 ) )\n              (SAN-FRANCISCO 122.26 37.47)\n\n\n          Why did t r i  go from Denver to San Francisco via Flagstaff? Because Flagstaff is\n          closer to the destination than Grand Junction. The problem is that we are minimizing\n          the distance to the destination at each step, when we should be minimizing the sum\n          of the distance to the destination plus the distance already traveled.\n\f200                                                                                 BUILDING        SOFTWARE            TOOLS\n\n\n\n      Search Paths\n\n      To minimize the total distance, we need some way to talk about the path that leads\n      to the goal. But the functions we have defined so far only deal with individual states\n      along the way. Representing paths would lead to another advantage: we could\n      return the path as the solution, rather than just return the goal state. As it is, t r i \n      only returns the goal state, not the path to it. So there is no way to determine what\n      t r i p has done, except by reading the debugging output.\n            The data structure path is designed to solve both these problems. A path has\n      four fields: the current state, the previous partial path that this path is extending,\n      the cost of the path so far, and an estimate of the total cost to reach the goal. Here is\n      the structure definition for path. It uses the : pri nt- f uncti on option to say that all\n      paths are to be printed with the function pr i nt - pa th, which will be defined below.\n\n           (defstruct (path ( : p r i n t - f u n c t i o n p r i n t - p a t h ) )\n             state (previous n i l ) ( c o s t - s o - f a r 0) ( t o t a l - c o s t 0))\n\n\n      The next question is how to integrate paths into the searching routines with the\n      least amount of disruption. Clearly, it would be better to make one change to\n      t r e e - s e a r c h rather than to change d e p t h - f i r s t - s e a r c h , b r e a d t h - f i r s t - s e a r c h ,\n      and beam-search. However, looking back at the definition of t r e e - s e a r c h , we see\n      that it makes no assumptions about the structure of states, other than the fact that\n      they can be manipulated by the goal predicate, successor, and combiner fimctions.\n      This suggests that we can use t r e e - s e a r c h unchanged if we pass it paths instead of\n      states, and give it functions that can process paths.\n            In the following redefinition of t r i , the beam- sea rch function is called with five\n      arguments. Instead of passing it a city as the start state, we pass a path that has\n      the city as its state field. The goal predicate should test whether its argument is a\n      path whose state is the destination; we assume (and later define) a version of i s that\n      accommodates this. The successor function is the most difficult. Instead of just\n      generating a Ust of neighbors, we want to first generate the neighbors, then make\n      each one into a path that extends the current path, but with an updated cost so far\n      and total estimated cost. The function path - saver returns a function that will do just\n      that. Finally, the cost function we are trying to minimize is path-total - cost, and\n      we provide a beam width, which is now an optional argument to t r i  that defaults\n      to one:\n\n           (defun t r i p ( s t a r t dest �optional (beam-width 1))\n             \"Search f o r the best path from the s t a r t to d e s t . \"\n             (beam-search\n               (make-path : s t a t e s t a r t )\n               ( i s dest :key # * p a t h - s t a t e )\n               (path-saver # ' n e i g h b o r s # ' a i r - d i s t a n c e\n\f6.4  SET or SEARCHING        TOOLS                                                                          201\n\n\n\n                               #'(lambda (c) ( a i r - d i s t a n c e c d e s t ) ) )\n                  #*path-total-cost\n                  beam-width))\n\n\n          The calculation of ai r-di stance involves some complicated conversion of longitude\n          and latitude to x-y-z coordinates. Since this is a problem in solid geometry, not AI,\n          the code is presented without further comment:\n\n             (defconstant earth-diameter 12765.0\n               \"Diameter of planet earth in k i l o m e t e r s . \" )\n\n             (defun a i r - d i s t a n c e ( c i t y l c i t y 2 )\n               \"The great c i r c l e distance between two c i t i e s . \"\n               ( l e t ((d (distance (xyz-coords c i t y l ) (xyz-coords c i t y 2 ) ) ) )\n                        d i s the s t r a i g h t - 1 i n e chord between the two c i t i e s .\n                    ; ; The length of the subtending arc i s given by:\n                    (* earth-diameter ( a s i n ( / d 2 ) ) ) ) )\n\n             (defun xyz-coords ( c i t y )\n               \"Returns the x . y . z coordinates of a point on a sphere.\n               The center i s (0 0 0) and the north pole i s (0 0 D . \"\n               ( l e t ( ( p s i (deg->radians ( c i t y - l a t c i t y ) ) )\n                            (phi (deg->radians ( c i t y - l o n g c i t y ) ) ) )\n                    ( l i s t (* (cos p s i ) (cos p h i ) )\n                              (* (cos p s i ) ( s i n p h i ) )\n                              (sin p s i ) ) ) )\n\n             (defun distance ( p o i n t l point2)\n               \"The Euclidean distance between two p o i n t s .\n               The points are coordinates i n n-dimensional s p a c e . \"\n               ( s q r t (reduce # * + (mapcar #'(lambda (a b) (expt (- a b) 2 ) )\n                                               pointl point2))))\n\n             (defun deg->radians (deg)\n               \"Convert degrees and minutes to r a d i a n s . \"\n               (* (+ (truncate deg) (* (rem deg 1) 100/60)) pi 1/180))\n\n\n          Before showing the auxiliary functions that implement this, here are some examples\n          that show what it can do. With a beam width of 1, the detour to Flagstaff is elin�nated,\n          but the one to Chicago remains. With a beam width of 3, the correct optimal path is\n          found. In the following examples, each call to the new version of t r i  returns a path,\n          which is printed by s how- ci ty - pa th:\n\n             > (show-city-path ( t r i p ( c i t y ' s a n - f r a n c i s c o ) ( c i t y 'boston) 1 ) )\n             #<Path 4514.8 km: San-Francisco - Reno - Grand-Jet - Denver -\n               Kansas-City - I n d i a n a p o l i s - P i t t s b u r g h - Boston>\n\f202                                                                          BUILDING       SOFTWARE    TOOLS\n\n\n\n         > (show-city-path ( t r i p ( c i t y 'boston) ( c i t y ' s a n - f r a n c i s c o ) 1 ) )\n         #<Path 4577.3 km: Boston - P i t t s b u r g h - Chicago - Kansas-City -\n            Denver - Grand-Jet - Reno - San-Francisco>\n\n         > (show-city-path ( t r i p ( c i t y 'boston) ( c i t y ' s a n - f r a n c i s c o ) 3 ) )\n         #<Path 4514.8 km: Boston - P i t t s b u r g h - I n d i a n a p o l i s -\n            Kansas-City - Denver - Grand-Jet - Reno - San-Francisco>\n\n\n      This example shows how search is susceptible to irregularities in the search space. It\n      was easy to find the correct path from west to east, but the return trip required more\n      search, because Flagstaff is a falsely promising step. In general, there may be even\n      worse dead ends lurking in the search space. Look what happens when we limit the\n      airplane's range to 700 kilometers. The map is shown in figure 6.2.\n\n\n\n\n                                 Figure 6.2: A Map of Cities within 700km\n\n          If we try to plan a trip from Tampa to Quebec, we can run into problems with\n      the dead end at Wilmington, North Carolina. With a beam width of 1, the path to\n      Jacksonville and then Wilmington will be tried first. From there, each step of the path\n      alternates between Atlanta and Wilmington. The search never gets any closer to the\n      goal. But with a beam width of 2, the path from Tampa to Atlanta is not discarded,\n      and it is eventually continued on to Indianapolis and eventually to Quebec. So the\n      capability to back up is essential in avoiding dead ends.\n          Now for the implementation details. The function i s still returns a predicate that\n      tests for a value, but now it accepts : key and : t e s t keywords:\n\f6.4  SET OF SEARCHING         TOOLS                                                                                     203\n\n\n\n             (defun i s (value &key (key # ' i d e n t i t y ) ( t e s t # ' e q l ) )\n               \"Returns a predicate that t e s t s f o r a given v a l u e . \"\n               #'(lambda (path) (funcall t e s t value (funcall key p a t h ) ) ) )\n\n\n          The path - saver function returns a function that will take a path as an argument and\n          generate successors paths, path -saver takes as an argument a successor function\n          that operates on bare states. It calls this function and, for each state returned, builds\n          up a path that extends the existing path and stores the cost of the path so far as well\n          as the estimated total cost:\n\n             (defun path-saver (successors c o s t - f n c o s t - l e f t - f n )\n               #*(lambda (old-path)\n                    ( l e t ( ( o l d - s t a t e (path-state o l d - p a t h ) ) )\n                         (mapcar\n                           #*(lambda (new-state)\n                                  (let ((old-cost\n                                                    (+ ( p a t h - c o s t - s o - f a r old-path)\n                                                          (funcall c o s t - f n o l d - s t a t e new-state))))\n                                       (make-path\n                                           : s t a t e new-state\n                                           rprevious old-path\n                                           :cost-so-far old-cost\n                                           : t o t a l - c o s t ( + o l d - c o s t (funcall c o s t - l e f t - f n\n                                                                                                  new-state)))))\n                            (funcall successors o l d - s t a t e ) ) ) ) )\n\n\n          By default a path structure would be printed as #S (PATH . . . ) . But because each path\n          has a previ ous field that is filled by another path, this output would get quite verbose.\n          That is why we installed pr i nt - pa t h as the print function for paths when we defined\n          the structure. It uses the notation # < . . . > , which is a Common Lisp convention for\n          printing output that can not be reconstructed by read. The function show- ci t y - pa t h\n          prints a more complete representation of a path. We also define map-path to iterate\n          over a path, collecting values:\n\n              (defun p r i n t - p a t h (path �optional (stream t ) depth)\n                (declare (ignore depth))\n                (format stream \"#<Path to '\"a cost ~ . l f > \"\n                           (path-state path) ( p a t h - t o t a l - c o s t path)))\n\n              (defun show-city-path (path �optional (stream t ) )\n                \"Show the length of a path, and the c i t i e s along i t . \"\n                (format stream \"#<Path ~ , l f km: \"{^^^         - ~}>\"\n                        ( p a t h - t o t a l - c o s t path)\n                        (reverse (map-path #'city-name path)))\n                (values))\n\f204                                                                              BUILDING        SOFTWARE   TOOLS\n\n\n\n         (defun map-path (fn path)\n           \" C a n fn on each s t a t e i n the path, c o l l e c t i n g r e s u l t s . \"\n           ( i f (null path)\n                  nil\n                  (cons (funcall fn ( p a t h - s t a t e path))\n                        (map-path fn (path-previous p a t h ) ) ) ) )\n\n\n\n\n      Guessing versus Guaranteeing a Good Solution\n\n      Elementary AI textbooks place a great emphasis on search algorithms that are gusir-\n      anteed to find the best solution. However, in practice these algorithms are hardly\n      ever used. The problem is that guaranteeing the best solution requires looking at a lot\n      of other solutions in order to rule them out. For problems with large search spaces,\n      this usually takes too much time. The alternative is to use an algorithm that will\n      probably return a solution that is close to the best solution, but gives no guarantee.\n      Such algorithms, traditionally known as non-admissible heuristic search algorithms,\n      can be much faster.\n          Of the algorithms we have seen so far, best-first search almost, but not quite,\n      guarantees the best solution. The problem is that it terminates a little too early.\n      Suppose it has calculated three paths, of cost 90, 95 and 110. It will expand the 90\n      path next. Suppose this leads to a solution of total cost 100. Best-first search will\n      then retimi that solution. But it is possible that the 95 path could lead to a solution\n      with a total cost less than 100. Perhaps the 95 path is only one unit away from the\n      goal, so it could result in a complete path of length 96. This means that an optimal\n      search should examine the 95 path (but not the 110 path) before exiting.\n          Depth-first seeu-ch and beam search, on the other hand, are defir�tely heuristic\n      algorithms. Depth-first search finds a solution without any regard to its cost. With\n      beam search, picking a good value for the beam width can lead to a good, quick\n      solution, while picking the wrong value can lead to failure, or to a poor solution.\n      One way out of this dilemma is to start with a narrow beam width, and if that does\n      not lead to an acceptable solution, widen the beam and try again. We will call this\n      iterative widening, although that is not a standard term. There are many variations on\n      this theme, but here is a simple one:\n\n         (defun i t e r - w i d e - s e a r c h ( s t a r t g o a l - p successors c o s t - f n\n                                                     &key (width 1) (max 100))\n           \"Search, i n c r e a s i n g beam width from width to max.\n           Return the f i r s t s o l u t i o n found at any w i d t h . \"\n           (dbg .-search \" ; Width: ~d\" width)\n           (unless ( > width max)\n             (or (beam-search s t a r t g o a l - p successors c o s t - f n width)\n                   ( i t e r - w i d e - s e a r c h s t a r t g o a l - p successors c o s t - f n\n\f6.4 A SET OF SEARCHING           TOOLS                                                                                  205\n\n\n                                                         :width (+ width 1) :max max))))\n\n\n          Here i ter-wide-search is used to search through a binary tree, failing with beam\n          width 1 and 2, and eventually succeeding with beam width 3:\n\n             > ( i t e r - w i d e - s e a r c h 1 ( i s 12) ( f i n i t e - b i n a r y - t r e e 15) ( d i f f 12))\n                   Width: 1\n               ; Search: (1)\n               ; Search: (3)\n               ; Search: (7)\n               : Search: (14)\n               ; Search: NIL\n                   Width: 2\n               ; Search: (1)\n               ; Search: (3 2)\n               : Search: (7 6)\n               : Search: (14 15)\n               ; Search: (15)\n               : Search: NIL\n                   Width: 3\n               ; Search: (1)\n               ; Search: (3 2)\n               ; Search: (7 6 2)\n               ; Search: (14 15 6)\n               ; Search: (15 6)\n               ; Search: (6)\n               ; Search: (12 13)\n              12\n\n\n          The name iterative widening is derived from the established term iterative deepening.\n          Iterative deepening is used to control depth-first search when we don't know the\n          depth of the desired solution. The idea is first to limit the search to a depth of 1,\n          then 2, and so on. That way we are guaranteed to find a solution at the minimum\n          depth, just as in breadth-first search, but without wasting as much storage space. Of\n          course, iterative deepening does waste some time because at each increasing depth\n          it repeats all the work it did at the previous depth. But suppose that the average\n          state has ten successors. That means that increasing the depth by one results in ten\n          times more search, so only 10% of the time is wasted on repeated work. So iterative\n          deepening uses only slightly more time and much less space. We will see it again in\n          chapters 11 and 18.\n\f206                                                                           BUILDING         SOFTWARE       TOOLS\n\n\n\n      Searching Graphs\n\n      So far, t r e e - s e a r c h has been the workhorse behind all the searching routines. This\n      is curious, when we consider that the city problem involves a graph that is not a tree\n      at all. The reason t r e e - sea rch works is that any graph can be treated as a tree, if we\n      ignore the fact that certain nodes are identical. For example, the graph in figure 6.3\n      can be rendered as a tree. Figure 6.4 shows only the top four levels of the tree; each\n      of the bottom nodes (except the 6s) needs to be expanded further.\n\n\n\n\n                                                          J      L\n\n\n\n\n                                      Figure 6.3: A Graph with Six Nodes\n\n          In searching for paths through the graph of cities, we were implicitly turning the\n      graph into a tree. That is, if t r e e - sea rch found two paths from Pittsburgh to Kansas\n      City (via Chicago or Indianapolis), then it would treat them as two independent\n      paths, just as if there were two distinct Kansas Cities. This made the algorithms\n      simpler, but it also doubles the number of paths left to examine. If the destination is\n      San Francisco, we will have to search for a path from Kansas City to San Francisco\n      twice instead of once. In fact, even though the graph has only 22 cities, the tree is\n      infinite, because we can go back and forth between adjacent cities any number of\n      times. So, while it is possible to treat the graph as a tree, there are potential savings\n      in treating it as a true graph.\n         The function g raph - sea rch does just that. It is similar to t r e e - sea rch, but accepts\n      two additional cirguments: a comparison function that tests if two states are equal,\n      and a list of states that are no longer being considered, but were examined in the past.\n      The difference between g r a p h - s e a r c h and t r e e - s e a r c h is in the call to n e w - s t a t e s ,\n      which generates successors but eliminates states that �ire in either the list of states\n      currently being considered or the list of old states considered in the past.\n\n           (defun graph-search ( s t a t e s g o a l - p successors combiner\n                                 �optional ( s t a t e = # ' e q l ) o l d - s t a t e s )\n             \"Find a state that s a t i s f i e s g o a l - p . S t a r t with s t a t e s .\n\f6.4 A SET OF SEARCHING        TOOLS                                                                 207\n\n\n\n\n                                       Figure 6.4: The Corresponding Tree\n\n\n                and search according to successors and combiner.\n                Don't t r y the same state t w i c e . \"\n                (dbg :search \" \" & ; ; Search: '\"a\" s t a t e s )\n                (cond ( ( n u l l s t a t e s ) f a i l )\n                      ((funcall goal-p ( f i r s t states)) ( f i r s t states))\n                      (t (graph-search\n                                (funcall\n                                  combiner\n                                  (new-states states successors s t a t e = o l d - s t a t e s )\n                                  (rest states))\n                                goal-p successors combiner state=\n                                (adjoin ( f i r s t s t a t e s ) o l d - s t a t e s\n                                               :test state=)))))\n\n              (defun new-states ( s t a t e s successors s t a t e = o l d - s t a t e s )\n                \"Generate successor s t a t e s that have not been seen before.\"\n                (remove-if\n                  #'(lambda ( s t a t e )\n                       (or (member state s t a t e s : t e s t state=)\n                           (member state o l d - s t a t e s : t e s t state=^)))\n                   (funcall successors ( f i r s t s t a t e s ) ) ) )\n\n\n          Using the successor function next2, we can search the graph shown here either as a\n          tree or as a graph. If we search it as a graph, it takes fewer iterations and less storage\n          space to find the goal. Of course, there is additional overhead to test for identical\n\f208                                                               BUILDING    SOFTWARE       TOOLS\n\n\n\n      States, but on g r a p h s Uke this one w e get a n exponential speed-up for a c o n s t a n t\n      a m o u n t of overhead.\n\n\n          (defun next2 (x) ( l i s t (+  1) (+  2 ) ) )\n\n         > (tree-search ' ( 1 ) ( i s 6) #'next2 #*prepend)\n            Search: (1)\n            Search: (2 3)\n            Search:       4)\n            Search:       4 5)\n            Search:       5 4 5)\n            Search:       4 5 5 6)\n            Search:       5 5 6 5 6)\n            Search:       5 6 5 6 6 7)\n            Search:       6 5 6 6 7 5 6)\n            Search:       5 6 6 7 5 6 6 7)\n            Search:       6 6 7 5 6 6 7 6 7)\n\n\n         > (graph-search ' ( 1 ) ( i s 6) #'next2 #*prepend)\n            Search: (1)\n            Search: (2 3)\n            Search: (3 4)\n            Search: (4 5)\n            Search: (5 6)\n            Search: (6 7)\n\n\n\n      The next step is to extend the graph-sea rch algorithm to handle paths. The compli\n      cation is in deciding which path to keep when two paths reach the same state. If we\n      have a cost function, then the answer is easy: keep the path with the cheaper cost.\n      Best-first search of a graph removing duplicate states is called A * search.\n           A* search is more complicated than graph-search because of the need both to\n      add and to delete paths to the lists of current and old paths. For each new successor\n      state, there are three possibilities. The new state may be in the list of current paths, in\n      the Ust of old paths, or in neither. Within the first two cases, there are two subcases.\n      If the new path is more expensive than the old one, then ignore the new path--it can\n      not lead to a better solution. If the new path is cheaper than a corresponding path\n      in the list of current paths, then replace it with the new path. If it is cheaper than a\n      corresponding path in the list of the old paths, then remove that old path, and put\n      the new path in the list of current paths.\n           Also, rather than sort the paths by total cost on each iteration, they are kept sorted,\n      and new paths are inserted into the proper place one at a time using i nsert-path.\n      Two more functions, better-path and find-path, are used to compare paths and\n      see if a state has already appeared.\n\f6.4 A SET OF SEARCHING        TOOLS                                                                                  209\n\n\n\n              (defun a * - s e a r c h (paths g o a l - p successors c o s t - f n c o s t - l e f t - f n\n                                         �optional ( s t a t e = # ' e q l ) o l d - p a t h s )\n                \"Find a path whose state s a t i s f i e s g o a l - p .                S t a r t with p a t h s ,\n                and expand s u c c e s s o r s , exploring l e a s t cost f i r s t .\n                When there are duplicate s t a t e s , keep the one with the\n                lower cost and d i s c a r d the o t h e r . \"\n                (dbg    :search \" ; ; Search: ~a\" paths)\n                (cond\n                   ( ( n u l l paths) f a i l )\n                   ( ( f u n c a l l g o a l - p (path-state       ( f i r s t paths)))\n                     (values ( f i r s t paths) paths))\n                   (t ( l e t * ((path (pop paths))\n                                  (state (path-state               path)))\n                           ; ; Update PATHS and OLD-PATHS to r e f l e c t\n                               the new successors of STATE:\n                           ( s e t f old-paths ( i n s e r t - p a t h path o l d - p a t h s ) )\n                           (dolist     (state2 (funcall successors s t a t e ) )\n                              ( l e t * ( ( c o s t (+ ( p a t h - c o s t - s o - f a r path)\n                                                         (funcall c o s t - f n state            state2)))\n                                         (cost2 (funcall c o s t - l e f t - f n s t a t e 2 ) )\n                                         (path2 (make-path\n                                                         : s t a t e state2 :previous path\n                                                         : c o s t - s o - f a r cost\n                                                         :total-cost         (+ cost c o s t 2 ) ) )\n                                         (old     nil)\n                                      Place the new path, path2, in the r i g h t                      list:\n                                 (cond\n                                    ( ( s e t f old (find-path state2 paths s t a t e = ) )\n                                      (when (better-path path2 old)\n                                         ( s e t f paths      (insert-path\n                                                                 path2 (delete old p a t h s ) ) ) ) )\n                                    ( ( s e t f old (find-path state2 old-paths s t a t e = ) )\n                                      (when (better-path path2 old)\n                                         ( s e t f paths ( i n s e r t - p a t h path2 paths))\n                                         ( s e t f old-paths (delete old o l d - p a t h s ) ) ) )\n                                    (t ( s e t f paths ( i n s e r t - p a t h path2 p a t h s ) ) ) ) ) )\n                               F i n a l l y , c a l l A* again with the updated path l i s t s :\n                           ( a * - s e a r c h paths g o a l - p successors c o s t - f n c o s t - l e f t - f n\n                                            state= o l d - p a t h s ) ) ) ) )\n\f210                                                                               BUILDING     SOFTWARE   TOOLS\n\n\n\n      Here are the three auxiliary functions:\n\n         (defun f i n d - p a t h ( s t a t e paths state=)\n           \"Find the path with t h i s s t a t e among a l i s t of p a t h s . \"\n           ( f i n d state paths :key # ' p a t h - s t a t e : t e s t s t a t e = ) )\n\n         (defun better-path (pathl path2)\n           \" I s pathl cheaper than path2?\"\n           � ( p a t h - t o t a l - c o s t pathl) ( p a t h - t o t a l - c o s t path2)))\n\n         (defun i n s e r t - p a t h (path paths)\n           \"Put path i n t o the r i g h t p o s i t i o n , sorted by total c o s t . \"\n              MERGE i s a b u i l t - i n function\n           (merge ' l i s t ( l i s t path) paths # ' < :key # ' p a t h - t o t a l - c o s t ) )\n\n         (defun path-states (path)\n           \" C o l l e c t the s t a t e s along t h i s p a t h . \"\n           ( i f (null path)\n                  nil\n                  (cons (path-state path)\n                            ( p a t h - s t a t e s (path-previous p a t h ) ) ) ) )\n\n\n      Below we use a*-search to search for 6 in the graph previously shown in figure 6.3.\n      The cost function is a constant 1 for each step. In other words, the total cost is the\n      length of the path. The heuristic evaluation function is just the difference from the\n      goal. The A* algorithm needs just three search steps to come up with the optimal\n      solution. Contrast that to the graph search algorithm, which needed five steps, and\n      the tree search algorithm, which needed ten steps--and neither of them found the\n      optimal solution.\n\n         > (path-states\n             ( a * - s e a r c h ( l i s t (make-path : s t a t e D ) ( i s 6)\n                                 #'next2 #'(lambda (x y ) 1) ( d i f f 6 ) ) )\n            Search: (#<Path to 1 cost 0 . 0 > )\n            Search: (#<Path to 3 cost 4 . 0 > #<Path to 2 cost 5.0>)\n            Search: (#<Path to 5 cost 3 . 0 > #<Path to 4 cost 4 . 0 >\n                             #<Path to 2 cost 5.0>)\n            Search: (#<Path to 6 cost 3 . 0 > #<Path to 7 cost 4 . 0 >\n                             #<Path to 4 cost 4 . 0 > #<Path to 2 cost 5 . 0 > )\n          (6 5 3 1)\n\n\n      It may seem limiting that these search functions all return a single answer. In some\n      applications, we may want to look at several solutions, or at all possible solutions.\n      Other applications are more naturally seen as optimization problems, where we\n      don't know ahead of time what counts as achieving the goal but are just trying to find\n      some action with a low cost.\n\f6.5 GPS AS SEARCH                                                                                       211\n\n\n\n              It turns out that the functions we have defined are not Umiting at all in this respect.\n          They can be used to serve both these new purposes--provided we carefully specify\n          the goal predicate. To find all solutions to a problem, all we have to do is pass in a\n          goal predicate that always fails, but saves all the solutions in a list. The goal predicate\n          will see all possible solutions and save away just the ones that are real solutions.\n          Of course, if the search space is infinite this will never terminate, so the user has\n          to be careful in applying this technique. It would also be possible to write a goal\n          predicate that stopped the search after finding a certain number of solutions, or after\n          looking at a certain number of states. Here is a function that finds all solutions, using\n          beam search:\n\n\n              (defun s e a r c h - a l l ( s t a r t g o a l - p successors c o s t - f n beam-width)\n                \"Find a l l s o l u t i o n s to a search problem, using beam s e a r c h . \"\n                     Be c a r e f u l : t h i s can lead to an i n f i n i t e   loop,\n                (let ((solutions           nil))\n                    (beam-search\n                      s t a r t #'(lambda (x)\n                                     (when (funcall g o a l - p x) (push  s o l u t i o n s ) )\n                                    nil)\n                      successors c o s t - f n beam-width)\n                    solutions))\n\n\n\n\n          6.5        GPS as Search\n\n          The GPS program can be seen as a problem in search. For example, in the three-block\n          blocks world, there are only 13 different states. They could be arranged in a graph and\n          searched just as we searched for a route between cities. Figure 6.5 shows this graph.\n              The function search-gps does just that. Like the gps function on page 135, it\n          computes a final state and then picks out the actions that lead to that state. But\n          it computes the state with a beam search. The goal predicate tests if the current\n          state satisfies every condition in the goal, the successor function finds all applicable\n          operators and applies them, and the cost function simply sums the number of actions\n          taken so far, plus the number of conditions that are not yet satisfied:\n\f212                                                                          BUILDING       SOFTWARE   TOOLS\n\n\n\n\n                                                           \n\n\n\n                                                                   \n\n                                                           I        \n                                                                   \n\n\n\n\n                                                                                                 \n\n                                                                                                 C\n\n                                                                                                 \n\n\n\n                                         Figure 6.5: The Blocks World as a Graph\n\n\n           (defun search-gps ( s t a r t goal �optional (beam-width 10))\n             \"Search for a sequence of operators leading to g o a l . \"\n             (find-all-if\n               #*action-p\n               (beam-search\n                 (cons ' ( s t a r t ) s t a r t )\n                     #'(lambda ( s t a t e ) (subsetp goal state : t e s t #*equal))\n                     #'gps-successors\n                     #'(lambda ( s t a t e )\n                          (+ ( c o u n t - i f # ' a c t i o n - p s t a t e )\n                             ( c o u n t - i f #'(lambda (con)\n                                                       (not (member-equal con s t a t e ) ) )\n                                               goal)))\n\n                     beam-width)))\n\n\n      H e r e is the s u c c e s s o r f u n c t i o n :\n           (defun g p s - s u c c e s s o r s ( s t a t e )\n             \"Return a l i s t of s t a t e s reachable from t h i s one using o p s . \"\n             (mapcar\n               #�(lambda (op)\n\f6.6 HISTORY   AND REFERENCES                                                                        213\n\n\n\n                       (append\n                          (remove-if #'(lambda (x)\n                                            (member-equal  ( o p - d e l - l i s t o p ) ) )\n                                     state)\n                          (op-add-list op)))\n                   (applicable-ops s t a t e ) ) )\n\n               (defun applicable-ops ( s t a t e )\n                 \"Return a l i s t of a l l ops that are applicable now.\"\n                 (find-all-if\n                   #'(lambda (op)\n                        (subsetp (op-preconds op) state : t e s t # ' e q u a l ) )\n                   *ops*))\n\n\n          The search technique finds good solutions quickly for a variety of problems. Here\n          we see the solution to the Sussman anomaly in the three-block blocks world:\n\n               ( s e t f s t a r t ' ( ( c on a) (a on table) (b on table) (space on c)\n                                        (space on b) (space on t a b l e ) ) )\n\n              > (search-gps s t a r t   ' ( ( a on b) (b on c ) ) )\n              ((START)\n                (EXECUTING (MOVE C      FROM A TO TABLE))\n                (EXECUTING (MOVE        FROM TABLE TO O )\n                (EXECUTING (MOVE A      FROM TABLE TO B ) ) )\n\n              > (search-gps s t a r t   ' ( ( b on c) (a on b ) ) )\n              ((START)\n                (EXECUTING (MOVE C      FROM A TO TABLE))\n                (EXECUTING (MOVE        FROM TABLE TO O )\n                (EXECUTING (MOVE A      FROM TABLE TO B ) ) )\n\n\n          In these solutions we search forward from the start to the goal; this is quite different\n          from the means-ends approach of searching backward from the goal for an appropri\n          ate operator. But we could formulate means-ends analysis as forward search simply\n          by reversing start and goal: GPS's goal state is the search's start state, and the search's\n          goal predicate tests to see if a state matches GPS's start state. This is left as an exercise.\n\n\n\n          6.6        History and References\n          Pattern matching is one of the most important tools for AI. As such, it is cov\n          ered in most textbooks on Lisp. Good treatments include Abelson and Sussman\n          (1984), Wilensky (1986), Winston and Horn (1988), and Kreutzer and McKenzie\n          (1990). An overview is presented in the \"pattern-matching\" entry in Encyclopedia of\n           (Shapiro 1990).\n\f214                                                                     BUILDING     SOFTWARE        TOOLS\n\n\n\n               Nilsson's Problem-Solving Methods in Artificial Intelligence (1971) was an early text\n           book that emphasized search as the most important defining characteristic of AI.\n           More recent texts give less importance to search; Winston's Artificial Intelligence\n           (1984) gives a balanced overview, and his Lisp (1988) provides implementations of\n           some of the algorithms. They are at a lower level of abstraction than the ones in\n           this chapter. Iterative deepening was first presented by Korf (1985), and iterative\n           broadening by Ginsberg and Harvey (1990).\n\n\n\n\n           6.7 Exercises\n      @    Exercise 6.3 [m] Write a version of i  te ra et i ve - i n t e r p r e t e r that is more general\n           than the one defined in this chapter. Decide what features can be specified, and\n           provide defaults for them.\n\n\n      @    Exercise 6.4 [m] Define a version of compose that allows any number of arguments,\n           not just two. Hint: You may want to use the function reduce.\n\n\n      @    Exercise 6.5 [m] Define a version of compose that allows any number of arguments\n           but is more efficient than the answer to the previous exercise. Hint: try to make\n           decisions when compose is called to build the resulting function, rather than making\n           the same decisions over and over each time the resulting function is called.\n\n\n      @    Exercise 6.6 [m] One problem with pat-match is that it gives special significance\n           to symbols starting with ?, which means that they can not be used to match a literal\n           pattern. Define a pattern that matches the input literally, so that such symbols can\n           be matched.\n\n\n      @    Exercise 6.7 [m] Discuss the pros and cons of data-driven programming compared\n           to the conventional approach.\n\n\n      [�3 Exercise 6.8 [m] Write a version of t r e e - s e a r c h using an explicit loop rather than\n          recursion.\n\n\n           Exercise 6.9 [m] The s o r t e r function is inefficient for two reasons: it calls append,\n           which has to make a copy of the first argument, and it sorts the entire result, rather\n           than just inserting the new states into the already sorted o�d states. Write a more\n           efficient s o r t e r .\n\f6.8 ANSWERS                                                                                    215\n\n\n\n      0   Exercise 6.10 [m] Write versions of graph-search and a*-search that use hash\n          tables rather than lists to test whether a state has been seen before.\n\n\n     S    Exercise 6.11 [m] Writeafunctionthatcallsbeam-searchtofindthefirstnsolutions\n          to a problem and returns them in a list.\n\n\n     0    Exercise 6.12 [m] On personal computers without floating-point hardware, the\n          ai r-di stance calculation will be rather slow. If this is a problem for you, arrange\n          to compute the xyz-coords of each city only once and then store them, or store\n          a complete table of air distances between cities. Also precompute and store the\n          neighbors of each city.\n\n\n     @    Exercise 6.13 [d] Write a version of G P S that uses A* search instead of beam search.\n          Compare the two versions in a variety of domains.\n\n\n     S    Exercise 6.14 [d] Write a version of G P S that allows costs for each operator. For\n          example, driving the child to school might have a cost of 2, but calling a limousine\n          to transport the child n�ght have a cost of 100. Use these costs instead of a constant\n          cost of 1 for each operation.\n\n\n     @    Exercise 6.15 [d] Write a version of G P S that uses the searching tools but does\n          means-ends analysis.\n\n\n\n\n          6.8 Answers\n          Answer 6.2 Unfortunately, pat -match does not always find the answer. The prob\n          lem is that it will only rebind a segment variable based on a failure to match the\n          rest of the pattern after the segment variable. In all the examples above, the \"rest of\n          the pattern after the segment variable\" was the whole pattern, so pat-match always\n          worked properly. But if a segment variable appears nested inside a list, then the rest\n          of the segment variable's sublist is only a part of the rest of the whole pattern, as the\n          following example shows:\n\n              > (pat-match ' ( ( ( ? * ?x) (?* ?y))   ?x    ?y)\n                           '((a         b c d )       (a b) (c d))) ^ NIL\n\n          The correct answer with ?x bound to (a b) and ?y bound to ( c d) is not found\n          because the inner segment match succeeds with ?x bound to ( ) and ?y bound to (a\n\f216                                                                            BUILDING          SOFTWARE   TOOLS\n\n\n\n      b e d ) , and once we leave the inner match and return to the top level, there is no\n      going back for alternative bindings.\n\n      Answer 6.3 The following version lets the user specify all four components of the\n      prompt-read-eval-print loop, as well as the streams to use for input and output.\n      Defaults are set up as for a Lisp interpreter.\n\n         (defun i n t e r a c t i v e - i n t e r p r e t e r\n                     (&key (read # ' r e a d ) (eval # ' e v a l ) ( p r i n t # * p r i n t )\n                      (prompt \" > \") (input t ) (output t ) )\n           \"Read an e x p r e s s i o n , evaluate i t , and p r i n t the r e s u l t . \"\n           (loop\n              ( f r e s h - l i n e output)\n              (princ prompt output)\n                (funcall p r i n t (funcall eval (funcall read i n p u t ) )\n                                  output)))\n\n\n      Here is another version that does all of the above and also handles multiple values\n      and binds the various \"history variables\" that the Lisp top-level binds.\n\n         (defun i n t e r a c t i v e - i n t e r p r e t e r\n                (&key (read # ' r e a d ) (eval # ' e v a l ) ( p r i n t # ' p r i n t )\n                  (prompt \" > \") (input t ) (output t ) )\n           \"Read an e x p r e s s i o n , evaluate i t , and p r i n t the r e s u l t ( s ) .\n           Does multiple values and b i n d s : * * * � � � - + + + + + + / / / / / / \"\n           (let ( � * * � * � - + + + + + + / / / / / / vals)\n                   The above v a r i a b l e s are a l l s p e c i a l , except VALS\n                   The v a r i a b l e - holds the current input\n                   �                 ape the 3 most recent values\n                   + ++ +++ are the 3 most recent inputs\n                   / / / / / / are the 3 most recent l i s t s of m u l t i p l e - v a l u e s\n              (loop\n                 ( f r e s h - l i n e output)\n                 (princ prompt output)\n                        F i r s t read and evaluate an expression\n                 (setf -                (funcall read input)\n                              v a l s ( m u l t i p l e - v a l u e - l i s t (funcall eval - ) ) )\n                       Now update the h i s t o r y v a r i a b l e s\n                 ( s e t f +++ ++                     /// //                   *** (first / / / )\n                              ++ +                    // /                          (first //)\n                              +       -               /      vals              *    (first /))\n                        F i n a l l y p r i n t the computed v a l u e ( s )\n                 ( d o l i s t (value v a l s )\n                      (funcall p r i n t value o u t p u t ) ) ) ) )\n\f6.8 ANSWERS                                                                                                  217\n\n\n\n          Answer 6.4\n\n              (defun compose (�rest f u n c t i o n s )\n                \"Return the function that i s the composition of all the a r g s .\n                i . e . (compose f g h) = (lambda (x) (f (g (h x ) ) ) ) . \"\n                #*(lambda (x)\n                       (reduce # ' f u n c a n functions :from-end t . - i n i t i a l - v a l u e x ) ) )\n\n\n          Answer 6.5\n\n              (defun compose (&rest f u n c t i o n s )\n                \"Return the function that i s the composition of all the a r g s .\n                i . e . (compose f g h) = (lambda (x) (f (g (h x ) ) ) ) . \"\n                (case (length f u n c t i o n s )\n                     (0 # ' i d e n t i t y )\n                     (1 ( f i r s t f u n c t i o n s ) )\n                     (2 ( l e t ( ( f ( f i r s t f u n c t i o n s ) )\n                                   (g (second f u n c t i o n s ) ) )\n                            #'(lambda (x) (funcall f (funcall g x ) ) ) ) )\n                     (t #*(lambda (x)\n                                  (reduce # ' f u n c a l l functions :from-end t\n                                                :initial-value x)))))\n\n\n          Answer 6.8\n\n              (defun tree-search ( s t a t e s g o a l - p successors combiner)\n                \"Find a state that s a t i s f i e s g o a l - p . S t a r t with s t a t e s ,\n                and search according to successors and combiner.\"\n                (loop\n                   (cond ( ( n u l l s t a t e s ) (RETURN f a i l ) )\n                         ((funcall goal-p ( f i r s t states))\n                           (RETURN ( f i r s t s t a t e s ) )\n                         (t ( s e t f s t a t e s\n                                         (funcall combiner\n                                                      (funcall successors ( f i r s t s t a t e s ) )\n                                                      (rest s t a t e s ) ) ) ) ) ) ) )\n\n\n          Answer 6.9\n\n              (defun s o r t e r ( c o s t - f n )\n                \"Return a combiner function that s o r t s according to c o s t - f n . \"\n                #'(lambda (new old)\n                     (merge ' l i s t ( s o r t new # ' > :key c o s t - f n )\n                                old # ' > :key c o s t - f n ) ) )\n\f218                                                                 BUILDING     SOFTWARE   TOOLS\n\n\n\n      Answer 6.11\n\n         (defun search-n ( s t a r t  g o a l - p successors c o s t - f n beam-width)\n           \"Find  s o l u t i o n s to a search problem, using beam s e a r c h . \"\n           (let ((solutions n i l ) )\n              (beam-search\n                s t a r t #*(lambda (x)\n                               (cond ((not (funcall g o a l - p x ) ) n i l )\n                                      ( ( =  0) X )\n                                      (t (decf n)\n                                           (push X s o l u t i o n s )\n                                           nil)))\n                successors c o s t - f n beam-width)\n             solutions))\n\fCHAPTER                    7\n\nSTUDENT: Solving Algebra\nWord Problems\n\n                                                       [This] is an example par excellence of the power of\n                                                           using meaning to solve linguistic problems.\n                                                                                -Marvin Minsky (1968)\n                                                                                 MIT computer scientist\n\n\n\n\nS\n       TUDENT was another early language understanding program, written by Daniel Bobrow\n       as his Ph.D. research project in 1964. It was designed to read and solve the kind of word\n       problems found in high school algebra books. An example is:\n     If the number of customers Tom gets is twice the square of 20% of the number of advertise\n     ments he runs, and the number of advertisements is 45, then what is the number of customers\n     Tom gets?\nSTUDENT could correctly reply that the number of customers is 162. To do this, STUDENT must be\nfar more sophisticated than ELIZA; it must process and \"understand\" a great deal of the input,\nrather than just concentrate on a few key words. And it must compute a response, rather than\njust fill in blanks. However, we shall see that the STUDENT program uses little more than the\npattern-matching techniques of ELIZA to translate the input into a set of algebraic equations.\nFrom there, it must know enough algebra to solve the equations, but that is not very difficult.\n\f220                                     STUDENT; SOLVING      ALGEBRA    WORD       PROBLEMS\n\n\n\n          The version of STUDENT we develop here is nearly a full implementation of the\n      original. However, remember that while the original was state-of-the-art as of 1964,\n      AI has made some progress in a quarter century, as subsequent chapters will attempt\n      to show.\n\n\n\n      7.1      Translating English into Equations\n      The description of STUDENT is:\n\n        1. Break the input into phrases that will represent equations.\n\n        2. Break each phrase into a pair of phrases on either side of the = sign.\n\n        3. Break these phrases down further into sums and products, and so on, until\n           finally we bottom out with numbers and variables. (By \"variable\" here, I mean\n           \"mathematical variable,\" which is distinct from the idea of a \"pattern-matching\n           variable\" as used in pat-match in chapter 6).\n\n        4. Translate each English phrase into a mathematical expression. We use the idea\n           of a rule-based translator as developed for ELIZA.\n\n        5. Solve the resulting mathematical equations, coming up with a value for each\n           unknown variable.\n\n        6. Print the values of all the variables.\n\n          For example, we might have a pattern of the form ( I f ?x then ?y), with an asso\n      ciated response that says that ?x and ?y will each be equations or lists of equations.\n      Applying the pattern to the input above, ?y would have the value (what i s the\n      number of customers Tom g e t s ) . Another pattern of the form (?x i s ?y) could have\n      a response corresponding to an equation where ?x and ?y are the two sides of the\n      equation. We could then make up a mathematical variable for (what) and another\n      for (the number o f customers Tom g e t s ) . We would recognize this later phrase as\n      a variable because there are no patterns to break it down further. In contrast, the\n      phrase (twice the square o f 20 per cent o f the number o f advertisements\n      he r uns) could match a pattern of the form (twi ce ?x) and transform to (* 2 ( t h e\n      square o f 20 per cent o f the number o f advertisements he runs)), and by\n      furtherapplyingpatternsof the form (the square o f ?x) and (?x per cent o f\n      ?y) we could arrive at a final response of (* 2 (expt ( * ( / 20 100) n) 2 ) ) , where\n       is the variable generated by (the number o f advertisements he runs).\n          Thus, we need to represent variables, expressions, equations, and sets of equa\n      tions. The easiest thing to do is to use something we know: represent them just as\n      Lisp itself does. Variables will be symbols, expressions and equations will be nested\n\f7.1 TRANSLATING      ENGLISH      INTO EQUATIONS                                                                       221\n\n\n\n          lists with prefix operators, and sets of equations will be lists of equations. With that\n          in mind, we can define a list of pattern-response rules corresponding to the type of\n          statements found in algebra word problems. The structure definition for a rule is\n          repeated here, and the structure exp, an expression, is added. 1 hs and rhs stand for\n          left- and right-hand side, respectively. Note that the constructor mkexp is defined as a\n          constructor that builds expressions without taking keyword arguments. In general,\n          the notation ( : constructor fn args) creates a constructor function with the given\n          name and argument Ust.^\n\n              (defstruct       ( r u l e (:type l i s t ) ) pattern response)\n\n              (defstruct       (exp (:type l i s t )\n                                    ( � c o n s t r u c t o r mkexp ( I h s op r h s ) ) )\n                  op I h s r h s )\n\n              (defun exp-p (x) (consp x ) )\n              (defun exp-args (x) ( r e s t x ) )\n\n\n          We ignored commas and periods in ELIZA, but they are crucial for STUDENT, SO we\n          must make allowances for them. The problem is that a \" , \" in Lisp normally can be\n          used only within a backquote construction, and a \" . \" normally can be used only as a\n          decimal point or in a dotted pair. The special meaning of these characters to the Lisp\n          reader can be escaped either by preceding the character with a backslash ( \\ , ) or by\n          surrounding the character by vertical bars (I J ) .\n\n              (pat-match-abbrev ' ? x * ' ( ? * ? x ) )\n              (pat-match-abbrev ' ? y * * ( ? * ? y ) )\n\n              (defparameter * s t u d e n t - r u l e s * (mapcar #'expand-pat-match-abbrev\n                ' ( ( ( ? x * I.I)                            ?x)\n                     ( ( ? x * I.I ? y * )              (?x ?y))\n                     ( ( i f ? x * I J then ? y * ) ( ? x ? y ) )\n                     ( ( i f ? x * then ? y * )         (?x ? y ) )\n                     ((if ?x* I J ?y*)                  (?x ?y))\n                     ( ( ? x *  and ? y * )             (?x ? y ) )\n                     ( ( f i n d ? x * and ? y * )      ( ( = t o - f i n d - 1 ? x ) (= t o - f i n d - 2 ? y ) ) )\n                     ((find ?x*)                        (= t o - f i n d ? x ) )\n                     ( ( ? x * equals ? y * )           (= ? x ? y ) )\n                     ( ( ? x * same as ? y * )          (= ? x ? y ) )\n                     ((?x* = ? y * )                    (= ? x ? y ) )\n                     ( ( ? x * i s equal to ? y * ) (= ? x ? y ) )\n                     ((?x* is ? y * )                   (= ? x ? y ) )\n                     ((?x* - ? y * )                    (- ? x ? y ) )\n                     ( ( ? x * minus ? y * )            (- ? x ? y ) )\n\n             ^Page 316 of Common Lisp the Language says, \"Because a constructor of this type operates\n          By Order of Arguments, it is sometimes known as a BOA constructor.\"\n\f222                                             STUDENT; SOLVING            ALGEBRA    WORD   PROBLEMS\n\n\n\n               ( ( d i f f e r e n c e between ? x * and ? y * ) (- ? y ? x ) )\n               ( ( d i f f e r e n c e ? x * and ? y * )            (- ? y ? x ) )\n               ((?x* + ?y*)                           (+ ?x ? y ) )\n               ( ( ? x * plus ? y * )                 (+ ?x ? y ) )\n               ((sum ? x * and ? y * )                (+ ?x ? y ) )\n               ((product ? x * and ? y * ) ( * ? x ? y ) )\n               ((?x* * ?y*)                           (* ?x ? y ) )\n               ( ( ? x * times ? y * )                (* ?x ? y ) )\n               ((?x* / ?y*)                           (/ ?x ? y ) )\n               ( ( ? x * per ? y * )                  (/ ?x ?y))\n               ( ( ? x * divided by ? y * )           (/ ?x ? y ) )\n               ((half ? x * )                         (/ ?x 2))\n               ((one h a l f ? x * )                  (/ ?x 2))\n               ((twice ? x * )                        (* 2 ? x ) )\n               ((square ? x * )                       (* ?x ? x ) )\n               ( ( ? x * % l e s s than ? y * ) ( * ? y ( / (- 100 ? x ) 100)))\n               ( ( ? x * % more than ? y * ) ( * ? y ( / (+ 100 ? x ) 100)))\n               ((?x* % ?y*)                           ( * ( / ? x 100) ? y ) ) ) ) )\n\n\n      The main section of STUDENT will search through the list of rules for a response, just\n      as ELIZA did. The first point of deviation is that before we substitute the values of the\n      pat-match variables into the response, we must first recursively translate the value\n      of each variable, using the same list of pattern-response rules. The other difference\n      is that once we're done, we don't just print the response; instead we have to solve the\n      set of equations and print the answers. The program is summarized in figure 7.1.\n           Before looking carefully at the program, let's try a sample problem: \"If  is 3, what\n      is twice z?\" Applying the rules to the input gives the following trace:\n\n         Input: ( I f  i s 3 . what i s twice z )\n         Rule: ( ( i f ?x I J ? y )           (?x ?y))\n         Binding: ( ( ? x . (z i s 3 ) )    ( ? y . (what i s twice z ) ) )\n          Input: (z i s 3)\n          Rule: ( ( ? x i s ? y )             (= ? x ? y ) )\n          Result: (=  3)\n          Input: (what i s twice  ? )\n          Rule: ( ( ? x i s ? y )             (= ? x ? y ) )\n          Binding: ( ( ? x . what) ( ? y . (twice z ) ) )\n           Input: (twice z )\n           Rule: ((twice ? x )            (* 2 ? x ) )\n           Result: (* 2 z )\n          Result: (= what ( * 2 z ) )\n         Result: ( ( =  3) (= what ( * 2 z ) ) )\n\n\n      There are two minor complications. First, we agreed to implement sets of equations\n      as lists of equations. For this example, everything worked out, and the response\n\f7.1 TRANSLATING      ENGLISH    INTO      EQUATIONS                                                       223\n\n\n                                       Top-Level Function\n     Student                           Solve certain algebra word problems.\n                                       Special Variables\n     *student-rules*                   A list of pattern/response pairs.\n                                       Data Types\n     exp                               An operator and its arguments.\n     rule                              A pattern and response.\n                                       Major Functions\n     trans�ate-to-expression           Translate an English phrase into an equation or expression.\n     translate-pair                    Translate the value part of the pair into an equation or expression.\n     create-list-of-equations          Separate out equations embedded in nested parens.\n     solve-equations                   Print the equations and their solution.\n     solve                             Solve a system of equations by constraint propagation.\n                                       Auxiliary Fimctions\n     isolate                           Isolate the lone variable on the left-hand side of an expression.\n     noise-word-p                      Is this a low-content word that can be safely ignored?\n     make-variable                     Create a variable name based on the given list of words.\n     print-equations                   Print a list of equations.\n     inverse -op                       I.e., the inverse of + is - .\n     unknown-p                         Is the argument an unknown (variable)?\n     in-exp                            True if X appears anywhere in exp.\n     no-unknown                        Returns true if there are no unknowns in exp.\n     one-unknown                       Returns the single unknown in exp, if there is exactly one.\n     commutative-p                     Is the operator commutative?\n     solve-arithmetic                  Perform arithmetic on rhs of an equation.\n     binary-exp-p                      Is this a binary expression?\n     prefix->infix                     Translate prefix to infix expressions.\n     mkexp                             Make an expression.\n                                       Previously Defined Functions\n     pat-match                         Match pattern against an input, (p. 180)\n     rule-based-translator             Apply a set of rules, (p. 189)\n\n                                  Figure 7.1: Glossary for the STUDENT Program\n\n\n\n            was a list of two equations. But if nested patterns are used, the response could be\n            something like ( ( = a 5) ( ( = b (+ a 1 ) ) (= c (-�- a b ) ) ) ) , which is not a list of\n            equations. The function c r e a t e -1 i s t - o f - e q u a t i ons transforms a response like this\n            into a proper list of equations. The other complication is choosing variable names.\n            Givenalistof words like (the number of customers Tom g e t s ) , we want to choose\n            a symbol to represent it. We will see below that the symbol customers is chosen, but\n            that there are other possibilities.\n                Here is the main function for STUDENT. It first removes words that have no con\n            tent, then translates the input to one big expression with trans� a t e - t o - e x p r e s s i on,\n            and breaks that into separate equations with create-1 i s t - o f - e q u a t i o n s . Finally,\n            the function sol ve-equati ons does the mathematics and prints the solution.\n\f224                                                     STUDENT; SOLVING                  ALGEBRA          WORD       PROBLEMS\n\n\n\n          (defun Student (words)\n            \"Solve certain Algebra Word Problems.\"\n            (solve-equations\n               (create-list-of-equations\n                 ( t r a n s l a t e - t o - e x p r e s s i o n (remove-if #*noise-word-p w o r d s ) ) ) ) )\n\n\n      The function t r a n s � a t e - t o - e x p r e s s i o n is a rule-based translator. It either finds\n      some rule in *s tudent - r u l e s * to transform the input, or it assumes that the entire in\n      put represents a single variable. The function t r a n s � a t e - p a i r takes a variable/value\n      binding pair and translates the value by a recursive call to t r a n s l a t e - t o - e x p r e s s i o n .\n\n\n          (defun t r a n s l a t e - t o - e x p r e s s i o n (words)\n            \"Translate an E n g l i s h phrase into an equation or e x p r e s s i o n . \"\n            (or ( r u l e - b a s e d - t r a n s l a t o r\n                   words * s t u d e n t - r u l e s *\n                    : r u l e - i f # ' r u l e - p a t t e r n :rule-then # * r u l e - r e s p o n s e\n                    :action #'(lambda (bindings response)\n                                            ( s u b l i s (mapcar # ' t r a n s l a t e - p a i r b i n d i n g s )\n                                                               response)))\n                (make-variable words)))\n\n          (defun t r a n s l a t e - p a i r ( p a i r )\n            \"Translate the value part of the pair into an equation or e x p r e s s i o n . \"\n            (cons (binding-var p a i r )\n                    ( t r a n s l a t e - t o - e x p r e s s i o n (binding-val p a i r ) ) ) )\n\n\n      The function c r e a t e - 1 i s t - o f - e q u a t i o n s takes a single expression containing em\n      bedded equations and separates them into a list of equations:\n\n          (defun c r e a t e - 1 i s t - o f - e q u a t i o n s (exp)\n            \"Separate out equations embedded i n nested p a r e n s . \"\n            (cond ( ( n u l l exp) n i l )\n                   ((atom ( f i r s t exp)) ( l i s t exp))\n                   (t (append ( c r e a t e - 1 i s t - o f - e q u a t i o n s ( f i r s t exp))\n                                          (create-1ist-of-equations (rest exp))))))\n\n\n      Finally, the function make-vari abl e creates a variable to represent a Ust of v^ords.\n      We do that by first removing all \"noise words\" from the input, and then taking the\n      first symbol that remains. So, for example, \"the distance John traveled\" and \"the\n      distance traveled by John\" will both be represented by the same variable, di s t a n c e ,\n      which is certainly the right thing to do. However, \"the distance Mary traveled\" will\n      also be represented by the same variable, which is certainly a mistake. For ( t h e\n      number o f customers Tom g e t s ) , the variable will be customers, since the, o f and\n      number are all noise words. This will match (the customers mentioned above) and\n\f7.2 SOLVING   ALGEBRAIC       EQUATIONS                                                                          225\n\n\n\n          (the number of customers), but not (Tom's customers). For now, we will accept\n          the first-non-noise-word solution, but note that exercise 7.3 asks for a correction.\n\n              (defun make-variable (words)\n                \"Create a v a r i a b l e name based on the given l i s t of words\"\n                      The l i s t of words w i l l already have noise words removed\n                ( f i r s t words))\n\n              (defun noise-word-p (word)\n                \" I s t h i s a low-content word that can be s a f e l y ignored?\"\n                (member word ' ( a an the t h i s number of $ ) ) )\n\n\n\n\n          7.2        Solving Algebraic Equations\n          The next step is to write the equation-solving section of STUDENT. This is more an\n          exercise in elementary algebra than in AI, but it is a good example of a symbol-\n          manipulation task, and thus an interesting programming problem.\n              The STUDENT program mentioned the function sol ve-equati ons, passing it one\n          argument, a Hst of equations to be solved, sol ve-equati ons prints the Hst of equa\n          tions, attempts to solve them using sol ve, and prints the result.\n\n              (defun solve-equations (equations)\n                \" P r i n t the equations and t h e i r s o l u t i o n \"\n                ( p r i n t - e q u a t i o n s \"The equations to be solved a r e : \" equations)\n                ( p r i n t - e q u a t i o n s \"The s o l u t i o n i s : \" ( s o l v e equations n i l ) ) )\n\n\n          The real work is done by sol ve, which has the following specification: (1) Find\n          an equation with exactly one occurrence of an unknown in it. (2) Transform that\n          equation so that the unknown is isolated on the left-hand side. This can be done if\n          we limit the operators to +, -, *, and / . (3) Evaluate the arithmetic on the right-hand\n          side, yielding a numeric value for the unknown. (4) Substitute the numeric value\n          for the unknown in all the other equations, and remember the known value. Then\n          try to solve the resulting set of equations. (5) If step (1) fails--if there is no equation\n          with exactly one unknown--then just return the known values and don't try to solve\n          anything else.\n              The function sol ve is passed a system of equations, along with a list of known\n          variable/value pairs. Initially no variables are known, so this list will be empty,\n          sol ve goes through the list of equations searching for an equation with exactly one\n          unknown. If it can find such an equation, it caHs i s o l a t e to solve the equation\n          in terms of that one unknown, solve then substitutes the value for the variable\n          throughout the list of equations and calls itself recursively on the resulting list. Each\n\f226                                              STUDENT; SOLVING                  ALGEBRA        WORD   PROBLEMS\n\n\n\n      time solve calls itself, it removes one equation from the Ust of equations to be solved,\n      and adds one to the Ust of known variable/value pairs. Since the list of equations is\n      always growing shorter, sol ve must eventually terminate.\n\n         (defun solve (equations known)\n            \"Solve a system of equations by c o n s t r a i n t propagation.\"\n                  Try to solve for one equation, and s u b s t i t u t e i t s value into\n                  the o t h e r s . I f that d o e s n ' t work, return what i s known,\n            (or    (some #*(lambda (equation)\n                                ( l e t ( ( x (one-unknown e q u a t i o n ) ) )\n                                  (when X\n                                     ( l e t ((answer ( s o l v e - a r i t h m e t i c\n                                                             ( i s o l a t e equation x ) ) ) )\n                                        ( s o l v e (subst (exp-rhs answer) (exp-lhs answer)\n                                                               (remove equation equations))\n                                                   (cons answer known))))))\n                          equations)\n                   known))\n\n\n      i s o l a t e is passed an equation guaranteed to have one unknown. It returns an\n      equivalent equation with the unknown isolated on the left-hand side. There are\n      five cases to consider: when the unknown is alone on the left, we're done. The\n      second case is when the unknown is anywhere on the right-hand side. Because\n      is commutative, we can reduce the problem to solving the equivalent equation with\n      left- and right-hand sides reversed.\n           Next we have to deal with the case where the unknown is in a complex expression\n      on the left-hand side. Because we are allowing four operators and the unknown can\n      be either on the right or the left, there are eight possibilities. Letting X stand for\n      an expression containing the unknown and A and  stand for expressions with no\n      unknowns, the possibilities and their solutions are as follows:\n\n         (1)X*A=B         X=B/A                (5)A*X=B           X=B/A\n         (2)X+A=B ^       X=B-A                (6)A+X=B ^         X=B-A\n         (3)X/A=B => X=B*A                     (7)A/X=B           X=A/B\n         (4)X-A=B         X=B+A                (8)A-X=B => X=A-B\n\n\n      Possibilities (1) through (4) are handled by case III, (5) and (6) by case IV, and (7)\n      and (8) by case V. In each case, the transformation does not give us the final answer,\n      since X need not be the unknown; it might be a complex expression involving the\n      unknown. So we have to caU i sol ate again on the resulting equation. The reader\n      should try to verify that transformations (1) to (8) are valid, and that cases III to V\n      implement them properly.\n\f7.2 SOLVING   ALGEBRAIC      EQUATIONS                                                                        227\n\n\n\n              (defun i s o l a t e (e x)\n                \" I s o l a t e the lone  i n e on the left-hand side of e . \"\n                      This assumes there i s exactly one  in e,\n                      and that e i s an equation,\n                (cond ((eq (exp-lhs e) x)\n                                     Case I : X = A - > X = \n                              e)\n                            ( ( i n - e x p X (exp-rhs e))\n                               ; ; Case I I : A = f ( X ) - > f ( X ) = A\n                              ( i s o l a t e (mkexp (exp-rhs e) ' = (exp-lhs e ) ) x ) )\n                            ( ( i n - e x p X (exp-lhs (exp-lhs e ) ) )\n                                     Case I I I : f ( X ) * A =  - > f ( X ) = B/A\n                              ( i s o l a t e (mkexp (exp-lhs (exp-lhs e ) ) *=\n                                                         (mkexp (exp-rhs e)\n                                                                (inverse-op (exp-op (exp-lhs e ) ) )\n                                                                (exp-rhs (exp-lhs e ) ) ) ) x ) )\n                            ((commutative-p (exp-op ( e x p - l h s e ) ) )\n                              : ; Case I V : A * f ( X ) =  - > f ( X ) = B/A\n                              ( i s o l a t e (mkexp (exp-rhs (exp-lhs e)) ' =\n                                                        (mkexp (exp-rhs e)\n                                                                (inverse-op (exp-op ( e x p - l h s e ) ) )\n                                                                (exp-lhs ( e x p - l h s e ) ) ) ) x ) )\n                            (t : ; Case V: A / f ( X ) =  - > f ( X ) = A / B\n                              ( i s o l a t e (mkexp (exp-rhs ( e x p - l h s e ) ) ' =\n                                                        (mkexp ( e x p - l h s ( e x p - l h s e))\n                                                                (exp-op ( e x p - l h s e ) )\n                                                                (exp-rhs e ) ) ) x ) ) ) )\n\n\n          Recall that to prove a function is correct, we have to prove both that it gives the correct\n          answer when it terminates and that it will eventually terminate. For a recursive\n          function with several alternative cases, we must show that each alternative is valid,\n          and also that each alternative gets closer to the end in some way (that any recursive\n          calls involve 'simpler' arguments). For i sol ate, elementary algebra will show that\n          each step is valid--or at least nearly valid. Dividing both sides of an equation by\n          0 does not yield an equivalent equation, and we never checked for that. It's also\n          possible that similar errors could sneak in during the call to eval. However, if we\n          assume the equation does have a single valid solution, then i sol ate performs only\n          legal transformations.\n              The hard part is to prove that 1 sol a t e terminates. Case I clearly terminates, and\n          the others all contribute towards isolating the unknown on the left-hand side. For\n          any equation, the sequence will be first a possible use of case II, followed by a number\n          of recursive calls using cases III to V. The number of calls is bounded by the number\n          of subexpressions in the equation, since each successive call effectively removes an\n          expression from the left and places it on the right. Therefore, assuming the input is\n\f228                                                      STUDENT: SOLVING                  ALGEBRA   WORD   PROBLEMS\n\n\n\n      of finite size, we must eventually reach a recursive call to i sol ate that will use case I\n      and terminate.\n         When i sol ate returns, the right-hand side must consist only of numbers and\n      operators. We could easily write a function to evaluate such an expression. However,\n      we don't have to go to that effort, since the function already exists. The data structure\n      exp was carefully selected to be the same structure (lists with prefix functions) used\n      by Lisp itself for its own expressions. So Lisp will find the right-hand side to be an\n      acceptable expression, one that could be evaluated if typed in to the top level. Lisp\n      evaluates expressions by calling the function e v a l , so we can call eval directly and\n      have it return a number. The function sol ve - a ri t hmet i c returns an equation of the\n      form ( = v a r number).\n          Auxiliary functions for s o l ve are shown below. Most are straightforward, but\n      I will remark on a few of them. The function pref i x - > i n f ix takes an expression\n      in prefix notation and converts it to a fully parenthesized infix expression. Unlike\n      i sol ate, it assumes the expressions will be implemented as lists, p r e f i x->i nf i  is\n      used by p r i n t - e q u a t i ons to produce more readable output.\n\n         (defun p r i n t - e q u a t i o n s (header equations)\n            \" P r i n t a l i s t of e q u a t i o n s . \"\n            (format t \"~%~a\"'{~%                ~{ ~a~}~}~%\" header\n                           (mapcar # * p r e f i x - > i n f i x e q u a t i o n s ) ) )\n\n         (defconstant operators-and-inverses\n            '((+    - ) (- +) (* / ) ( / * ) (= = ) ) )\n\n         (defun inverse-op (op)\n            (second (assoc op o p e r a t o r s - a n d - i n v e r s e s ) ) )\n\n         (defun unknown-p (exp)\n            (symbolp exp))\n\n         (defun in-exp (x exp)\n            \"True i f X appears anywhere i n exp\"\n            (or    (eq  exp)\n                   (and (exp-p exp)\n                            (or    (in-exp  (exp-lhs exp)) (in-exp  (exp-rhs e x p ) ) ) ) ) )\n\n          (defun no-unknown (exp)\n            \"Returns true i f there are no unknowns i n e x p . \"\n            (cond ((unknown-p exp) n i l )\n                      ((atom exp) t )\n                      ((no-unknown (exp-lhs exp)) (no-unknown (exp-rhs e x p ) ) )\n                      (t     nil)))\n\f7.2 SOLVING   ALGEBRAIC      EQUATIONS                                                           229\n\n\n\n              (defun one-unknown (exp)\n                \"Returns the s i n g l e unknown in exp, i f there i s exactly one.\"\n                (cond ((unknown-p exp) exp)\n                      ((atom exp) n i l )\n                      ((no-unknown (exp-lhs exp)) (one-unknown (exp-rhs exp)))\n                      ((no-unknown (exp-rhs exp)) (one-unknown (exp-lhs exp)))\n                      (t n i l ) ) )\n\n              (defun commutative-p (op)\n                \" I s operator commutative?\"\n                (member op ' ( + * = ) ) )\n\n              (defun solve-arithmetic  (equation)\n                \"Do the arithmetic for the right-hand s i d e . \"\n                   This assumes that the right-hand s i d e i s in the r i g h t form,\n                (mkexp (exp-lhs equation) *= (eval (exp-rhs equation))))\n\n              (defun binary-exp-p (x)\n                (and (exp-p x) (= (length (exp-args x ) )         2)))\n\n              (defun p r e f i x - > i n f i x (exp)\n                \"Translate p r e f i x to i n f i x e x p r e s s i o n s . \"\n                ( i f (atom exp) exp\n                      (mapcar # ' p r e f i x - > i n f i x\n                                   ( i f (binary-exp-p exp)\n                                           ( l i s t (exp-lhs exp) (exp-op exp) (exp-rhs exp))\n                                           exp))))\n\n\n          Here's an example of sol ve-equati ons in action, with a system of two equations.\n          The reader should go through the trace, discovering which case was used at each call\n          to i sol ate, and verifying that each step is accurate.\n\n              > (trace i s o l a t e   solve)\n              ( i s o l a t e solve)\n\n              > (solve-equations ' ( ( = (+ 3 4) (* (- 5 (+ 2 x ) ) 7))\n                                      (= (+ (* 3 X ) y) 1 2 ) ) )\n              The equations to be solved are:\n                  (3 + 4) = ((5 - (2 + X)) * 7)\n                  ((3 * X) + Y) = 12\n              (1 ENTER SOLVE: ( ( = (+ 3 4) (* (- 5 (+ 2 X)) 7 ) )\n                                 (= (+ (* 3 X) Y) 12)) NIL)\n                 (1 ENTER ISOLATE: (= (+ 3 4) (* (- 5 (+ 2 X)) 7 ) ) X)\n                    (2 ENTER ISOLATE: (= (* (- 5 (+ 2 X)) 7) (+ 3 4 ) ) X)\n                      (3 ENTER ISOLATE: (= (- 5 (+ 2 X)) (/ (+ 3 4) 7 ) ) X)\n                        (4 ENTER ISOLATE: (= (+ 2 X) (- 5 (/ (+ 3 4) 7 ) ) ) X)\n                          (5 ENTER ISOLATE: (= X (- (- 5 ( / (+ 3 4) 7 ) ) 2 ) ) X)\n                          (5 EXIT ISOLATE: (= X (- (- 5 (/ (+ 3 4) 7 ) ) 2 ) ) )\n                        (4 EXIT ISOLATE: (= X (- (- 5 (/ (+ 3 4) 7 ) ) 2 ) ) )\n\f230                                                STUDENT; SOLVING         ALGEBRA      WORD        PROBLEMS\n\n\n\n                (3 EXIT ISOLATE: (=  (- (- 5 ( / (+ 3 4) 7 ) ) 2 ) ) )\n              (2 EXIT ISOLATE: (= X (- (- 5 ( / (+ 3 4) 7 ) ) 2 ) ) )\n            (1 EXIT ISOLATE: (= X (- (- 5 ( / (+ 3 4) 7 ) ) 2 ) ) )\n            (2 ENTER SOLVE: ( ( = (+ ( * 3 2) Y) 12)) ( ( = X 2 ) ) )\n              (1 ENTER ISOLATE: (= (+ ( * 3 2) Y) 12) Y)\n                (2 ENTER ISOLATE: (= Y (- 12 ( * 3 2 ) ) ) Y)\n                (2 EXIT ISOLATE: (= Y (- 12 ( * 3 2 ) ) ) )\n              (1 EXIT ISOLATE: (= Y (- 12 ( * 3 2 ) ) ) )\n              (3 ENTER SOLVE: NIL ( ( = Y 6) (= X 2 ) ) )\n              (3 EXIT SOLVE: ( ( = Y 6) (= X 2 ) ) )\n            (2 EXIT SOLVE: ( ( = Y 6) (= X 2 ) ) )\n         (1 EXIT SOLVE: ( ( = Y 6) (= X 2 ) ) )\n         The s o l u t i o n i s :\n             Y =6\n             X =2\n         NIL\n\n\n      Now let's tackle the format string             \"'^%~a~{~% \" { ~a''}~}~%\" in p r i n t - e q u a t i o n s .\n      This may look like random gibberish, but there is actually sense behind it. format\n      processes the string by printing each character, except that\"\"\" indicates some special\n      formatting action, depending on the following character. The combination \"~%\"\n      prints a newline, and \"~a\" prints the next argument to format that has not been\n      used yet. Thus the first four characters of the format string, \"            \", print a newline\n      followed by the argument header. The combination \" ~ { \" treats the corresponding\n      argument as a list, and processes each element according to the specification between\n      the \" ~ { \" and the next\" ~ } \" . In this case, equati ons is a list of equations, so each one\n      gets printed with a newline ( \" \" ) followed by two spaces, followed by the processing\n      of the equation itself as a list, where each element is printed in the \"~a \" format and\n      preceded by a blank. The t given as the first argument to format means to print to\n      the standard output; another output stream may be specified there.\n          One of the annoying minor holes in Lisp is that there is no standard convention on\n      where to print newlines! In C, for example, the very first line of code in the reference\n      manual is\n\n          p r i n t f C ' h e l l o , worldXn\");\n\n\n      This makes it clear that newlines are printed after each line. This convention is so\n      ingrained in the UNIX world that some UNIX programs will go into an infinite loop\n      if the last line in a file is not terminated by a newline. In Lisp, however, the function\n      p r i nt puts in a newline before the object to be printed, and a space after. Some Lisp\n      programs carry the newline-before policy over to format, and others use the newline-\n      af ter policy. This only becomes a problem when you want to combine two programs\n      written under different policies. How did the two competing policies arise? In UNIX\n      there was only one reasonable policy, because all input to the UNIX interpreter (the\n\f7.3 EXAMPLES                                                                                      231\n\n\n\n           shell) is terminated by newlines, so there is no need for a newline-before. In some\n           Lisp interpreters, however, input can be terminated by a matching right parenthesis.\n           In that case, a newline-before is needed, lest the output appear on the same line as\n           the input.\n\n\n     [�3   Exercise 7 .1 [m] Implement p r i n t - e q u a t i ons using only primitive printing func-\n           tions such as t e r p r i and p r i nc, along with explicit loops.\n\n\n\n\n           7.3         Examples\n\n           Now we move on to examples, taken from Bobrow's thesis. In the first example, it is\n           necessary to insert a \"then\" before the word \"what\" to get the right answer:\n\n\n               > (student ' ( I f the number of customers Tom gets i s twice the square of\n                                   20 % of the number of advertisements he runs I.I\n                                   and the number of advertisements i s 45 I J\n                                   then what i s the number of customers Tom gets ? ) )\n               The equations to be solved a r e :\n                     CUSTOMERS = (2 * ( ( ( 2 0 / 100) * ADVERTISEMENTS)   *\n                                           ((20 / 100) * ADVERTISEMENTS)))\n                     ADVERTISEMENTS = 45\n                     WHAT = CUSTOMERS\n\n\n               The s o l u t i o n i s :\n                     WHAT = 162\n                     CUSTOMERS = 162\n                     ADVERTISEMENTS = 45\n               NIL\n\n\n           Notice that our program prints the values for all variables it can solve for, while\n           Bobrow's program only printed the values that were explicitly asked for in the text.\n           This is an example of \"more is less\"--it may look impressive to print all the answers,\n           but it is actually easier to do so than to decide just what answers should be printed.\n           The following example is not solved correctly:\n\f232                                           STUDENT; SOLVING           ALGEBRA      WORD        PROBLEMS\n\n\n\n         > (student  '(The d a i l y cost of l i v i n g for a group i s the overhead cost plus\n                       the running cost for each person times the number of people i n\n                       the group I.I This cost for one group equals $ 100 I,I\n                       and the number of people i n the group i s 40 I.I\n                       I f the overhead cost i s 10 times the running cost I,I\n                       f i n d the overhead and running cost for each person I . I ) )\n         The equations to be solved a r e :\n            DAILY = (OVERHEAD + (RUNNING * PEOPLE))\n            COST = 100\n            PEOPLE = 40\n            OVERHEAD = (10 * RUNNING)\n            TO-FIND-1 = OVERHEAD\n            TO-FIND-2 = RUNNING\n\n         The s o l u t i o n i s :\n             PEOPLE = 40\n             COST = 100\n         NIL\n\n\n      This example points out two important limitations of our version of student as\n      compared to Bobrow 's. The first problem is in naming of variables. The phrases \"the\n      daily cost of living for a group\" and \"this cost\" are meant to refer to the same quantity,\n      but our program gives them the names d a i l y and c o s t respectively. Bobrow 's\n      program handled naming by first considering phrases to be the same only if they\n      matched perfectly. If the resulting set of equations could not be solved, he would try\n      again, this time considering phrases with words in common to be identical. (See the\n      following exercises.)\n          The other problem is in our s o l ve function. Assuming we got the variables\n      equated properly, sol ve would be able to boil the set of equations down to two:\n\n             100 = (OVERHEAD + (RUNNING * 4 0 ) )\n             OVERHEAD = (10 * RUNNING)\n\n\n      This is a set of two linear equations in two unknowns and has a unique solution at\n      RUNNING = 2, OVERHEAD = 20. But our version of sol ve couldn't find this solution,\n      since it looks for equations with one unknown. Here is another example that student\n      handles well:\n\n         > (student  ' ( F r a n ' s age divided by R o b i n ' s height i s one h a l f K e l l y ' s 10 I.I\n                         K e l l y ' s IQ minus 80 i s R o b i n ' s height I.I\n                         I f Robin i s 4 feet t a l l 1,1 how old i s Fran ? ) )\n         The equations to be solved a r e :\n            (FRAN / ROBIN) = (KELLY / 2)\n            (KELLY - 80) = ROBIN\n            ROBIN = 4\n\f7.3 EXAMPLES                                                                                                       233\n\n\n\n                     HOW = FRAN\n\n               The s o l u t i o n i s :\n                     HOW = 168\n                     FRAN = 168\n                     KELLY = 84\n                     ROBIN = 4\n               NIL\n\n\n          But a slight variation leads to a problem:\n\n               > (student ' ( F r a n ' s age d i v i d e d by R o b i n ' s height i s one h a l f K e l l y ' s IQ I.I\n                                 K e l l y ' s IQ minus 80 i s R o b i n ' s height I.I\n                                 I f Robin i s 0 feet t a l l      how o l d i s Fran ? ) )\n               The equations to be solved a r e :\n                     (FRAN / ROBIN) = (KELLY / 2)\n                     (KELLY - 80) = ROBIN\n                     ROBIN = 0\n                     HOW = FRAN\n\n               The s o l u t i o n i s :\n                     HOW = 0\n                     FRAN = 0\n                     KELLY = 80\n                     ROBIN = 0\n               NIL\n\n\n          There is no valid solution to this problem, because it involves dividing by zero (Robin's\n          height). But s t u d e n t is willing to transform the first equation into:\n\n               FRAN = ROBIN * (KELLY / 2)\n\n\n          and then substitutes to get 0 for FRAN. Worse, dividing by zero could also come up\n          inside e v a l :\n\n\n               > (student ' ( F r a n ' s age times R o b i n ' s height i s one h a l f K e l l y ' s IQ I.I\n                                   K e l l y ' s IQ minus 80 i s R o b i n ' s height I.I\n                                   I f Robin i s 0 feet t a l l    I J how o l d i s Fran ? ) )\n               The equations to be solved a r e :\n                     (FRAN * ROBIN) = (KELLY / 2)\n                     (KELLY - 80) = ROBIN\n                     ROBIN = 0\n                     HOW = FRAN\n\f234                                           STUDENT; SOLVING        ALGEBRA     WORD   PROBLEMS\n\n\n\n             � E r r o r : There was an attempt to d i v i d e a number by zero\n\n\n          However, one could claim that nasty examples with division by zero don't show up\n          in algebra texts.\n              In summary, STUDENT behaves reasonably well, doing far more than the toy\n          program ELIZA. STUDENT is also quite efficient; on my machine it takes less than\n          one second for each of the prior examples. However, it could still be extended to\n          have more powerful equation-solving capabilities. Its linguistic coverage is another\n          matter. While one could add new patterns, such patterns are really just tricks, and\n          don't capture the underlying structure of English sentences. That is why the STUDENT\n          approach was abandoned as a research topic.\n\n\n\n          7.4      History and References\n          Bobrow's Ph.D. thesis contains a complete description of STUDENT. It is reprinted\n          in Minsky 1968. Since then, there have been several systems that address the same\n          task, with increased sophistication in both their mathematical and linguistic ability.\n          Wong (1981) describes a system that uses its understanding of the problem to get\n          a better linguistic analysis. Sterling et al. (1982) present a much more powerful\n          equation solver, but it does not accept natural language input. Certainly Bobrow's\n          language analysis techniques were not very sophisticated by today's measures. But\n          that was largely the point: if you know that the language is describing an algebraic\n          problem of a certain type, then you don't need to know very much linguistics to get\n          the right answer most of the time.\n\n\n\n          7.5      Exercises\n      @   Exercise 7.2 [h] We said earlier that our program was unable to solve pairs of linear\n          equations, such as:\n\n                100 = (OVERHEAD + (RUNNING * 4 0 ) )\n                OVERHEAD = (10 * RUNNING)\n\n\n          The original STUDENT could solve these equations. Write a routine to do so. You may\n          assume there will be only two equations in two unknowns if you wish, or if you are\n          more ambitious, you could solve a system of  linear equations with  unknowns.\n\n\n      @   Exercise 7.3 [h] Implement a version of Bobrow's variable-naming algorithm. In\n          stead of taking the first word of each equation, create a unique symbol, and associate\n\f7.5 EXERCISES                                                                                  235\n\n\n\n           with it the entire list of words. In the first pass, each nonequal list of words will be\n           considered a distinct variable. If no solution is reached, word lists that share words\n           in common are considered to be the same variable, and the solution is attempted\n           again. For example, an input that contains the phrases \"the rectangle's width\" and\n           \"the width of the rectangle\" might assign these two phrases the variables  1 and 2. If\n           an attempt to solve the problem yields no solutions, the program should realize that\n           vl and  2 have the words \"rectangle\" and \"width\" in common, and add the equation\n           (= vl v2) and try again. Since the variables are arbitrary symbols, the printing\n           routine should probably print the phrases associated with each variable rather than\n           the variable itself.\n\n\n      @    Exercise 7.4 [h] The original STUDENT also had a set of \"common knowledge\" equa\n           tions that it could use when necessary. These were mostly facts about conversion\n           factors, such as (1 inch = 2.54 cm). Also included wereequations like (distance\n           equals rate times time), which could be used to solve problems like \"If the dis\n           tance from Anabru to Champaign is 10 miles and the time it takes Sandy to travel\n           this distance is 2 hours, what is Sandy's rate of speed?\" Make changes to incorporate\n           this facility. It probably only helps in conjunction with a solution to the previous\n           exercise.\n\n\n      [�3 Exercise 7.5 [h] Change student so that it prints values only for those variables\n          that are being asked for in the problem. That is, given the problem \"X is 3. Y is 4.\n          How much is X + Y?\" it should not print values for X and Y.\n\n\n      C�3 Exercise 7.6 [m] Try STUDENT on the following examples. Make sure you handle\n          special characters properly:\n              (a) The price of a radio is 69.70 dollars. If this price is 15% less than the marked\n          price, find the marked price.\n              (b) The number of soldiers the Russians have is one half of the number of guns\n          they have. The number of guns they have is 7000. What is the number of soldiers\n          they have?\n              (c) If the number of customers Tom gets is twice the square of 20 % of the number\n          of advertisements he runs, and the number of advertisements is 45, and the profit\n          Tom receives is 10 times the number of customers he gets, then what is the profit?\n              (d) The average score is 73, The maximum score is 97. What is the square of the\n          difference between the average and the maximum?\n              (e) Tom is twice Mary's age, and Jane's age is half the difference between Mary\n          and Tom. If Mary is 18 years old, how old is Jane?\n              (f)Whatis4 + 5 * 1 4 / 7 ?\n              {g)xxb     = c-\\-d.bxc   = x.x = b-\\-b.b = 5.\n\f236                                                    S T U D E N T ; SOLVING   ALGEBRA   WORD   PROBLEMS\n\n\n\n      @   Exercise 7.7 [h] Student's infix-to-prefix rules account for the priority of operators\n          properly, but they don't handle associativity in the standard fashion. For example,\n          (12 - 6 - 3) translates to ( - 12 ( - 6 3 ) ) or 9, when the usual convention is to\n          interpret this as ( - ( - 12 6) 3) or 3. Fix student to handle this convention.\n\n\n      @   Exercise 7.8 [d] Find a mathematically oriented domain that is sufficiently limited\n          so that STUDENT can solve problems in it. The chemistry of solutions (calculating pH\n          concentrations) might be an example. Write the necessary *student-rules*, and\n          test the resulting program.\n\n\n      @   Exercise 7.9 [m] Analyze the complexity of one-unknown and implement a more\n          efficient version.\n\n\n      @   Exercise 7.10 [h] Bobrow's paper on STUDENT (1968) includes an appendix that\n          abstractly characterizes all the problems that his system can solve. Generate a\n          similar characterization for this version of the program.\n\n\n\n\n          7.6       Answers\n\n          Answer 7.1\n\n              (defun p r i n t - e q u a t i o n s (header equations)\n                (terpri)\n                (princ header)\n                ( d o l i s t (equation equations)\n                   (terpri)\n                   (princ \"       \")\n                   ( d o l i s t (x ( p r e f i x - > i n f i x equation))\n                      ( p r i n c \" \")\n                      (princ x ) ) ) )\n\f7.6 ANSWERS                                                                                      237\n\n\n\n          Answer 7 .9 one-unknown is very inefficient because it searches each subcompo\n          nent of an expression twice. For example, consider the equation:\n\n              (= (+ (+  2) (+ 3 4 ) ) (+ (+ 5 6) (+ 7 8 ) ) )\n\n\n          To decide if this has one unknown, one - unknown will call no - unknown on the left-hand\n          side, and since it fails, call it again on the right-hand side. Although there are only\n          eight atoms to consider, it ends up calling no-unknown 17 times and one-unknown 4\n          times. In general, for a tree of depth n, approximately 2^ calls to no-unknown are\n          made. This is clearly wasteful; there should be no need to look at each component\n          more than once.\n               The following version uses an auxiliary function, f i nd - one - un known, that has an\n          accumulator parameter, unknown. This parameter can take on three possible values:\n          nil, indicating that no unknown has been found; or the single unknown that has\n          been found so far; or the number 2 indicating that two unknowns have been found\n          and therefore the final result should be nil. The function f i nd - one - unknown has four\n          cases: (1) If we have already found two unknowns, then return 2 to indicate this. (2) If\n          the input expression is a nonatomic expression, then first look at its left-hand side\n          for unknowns, and pass the result found in that side as the accumulator to a search\n          of the right-hand side. (3) If the expression is an unknown, and if it is the second one\n          found, return 2; otherwise return the unknown itself. (4) If the expression is an atom\n          that is not an unknown, then just return the accumulated result.\n\n              (defun one-unknown (exp)\n                \"Returns the s i n g l e unknown i n exp, i f there i s exactly o n e . \"\n                ( l e t ((answer (find-one-unknown exp n i l ) ) )\n                     ; ; I f there were two unknowns, return n i l ;\n                          otherwise return the unknown ( i f there was one)\n                     ( i f (eql answer 2)\n                           nil\n                           answer)))\n\n              (defun find-one-unknown (exp unknown)\n                \"Assuming UNKNOWN i s the unknown(s) found so f a r , decide\n                i f there i s exactly one unknown in the e n t i r e e x p r e s s i o n . \"\n                (cond ((eql unknown 2) 2)\n                       ((exp-p exp)\n                        (find-one-unknown\n                              (exp-rhs exp)\n                              (find-one-unknown (exp-lhs exp) unknown)))\n                       ((unknown-p exp)\n                         ( i f unknown\n                                 2\n                             exp))\n                        (t unknown)))\n\f  CHAPTER                 8\n  Symbolic Mathematics:\n  A Simplification Program\n\n                                                                 Our life is frittered away by detail--\n                                                                                        Simplify, simplify.\n                                                               -Henry David Thoreau, Waiden (1854)\n\n\n\n\n�i^^     ymbolic mathematics\" is to numerical mathematics as algebra is to arithmetic: it deals\n         with variables and expressions rather than just numbers. Computers were first developed\n   L..^ primarily to solve arithmetic problems: to add up large columns of numbers, to multiply\n  many-digit numbers, to solve systems of linear equations, and to calculate the trajectories of\n  ballistics. Encouraged by success in these areas, people hoped that computers could also be used\n  on more complex problems; to differentiate or integrate a mathematical expression and come\n  up with another expression as the answer, rather than just a number. Several programs were\n  developed along these lines in the 1960s and 1970s. They were used primarily by professional\n  mathematicians and physicists with access to large mainframe computers. Recently, programs\n  like MATHLAB, DERIVE, and  have given these capabilities to the average personal\n  computer user.\n\fINTRODUCTION                                                                                 239\n\n\n\n            It is interesting to look at some of the history of symbolic algebra, beginning\n        in 1963 with SAINT, James Slagle's program to do symbolic integration. Originally,\n        SAINT was heralded as a triumph of AI. It used general problem-solving techniques,\n        similar in kind to GPS, to search for solutions to difficult problems. The program\n        worked its way through an integration problem by choosing among the techniques\n        known to it and backing up when an approach failed to pan out. SAINT'S behavior\n        on such problems was originally similar to (and eventually much better than) the\n        performance of undergraduate calculus students.\n            Over time, the AI component of symbolic integration began to disappear. Joel\n        Moses implemented a successor to SAINT called SiN. It used many of the same tech\n        niques, but instead of relying on search to find the right combination of techniques,\n        it had additional mathematical knowledge that led it to pick the right technique at\n        each step, without any provision for backing up and trying an alternative. SiN solved\n        more problems and was much faster than SAINT, although it was not perfect: it still\n        occasionally made the wrong choice and failed to solve a problem it could have.\n            By 1970, the mathematician R. Risch and others developed algorithms for indef\n        inite integration of any expression involving algebraic, logarithmic, or exponential\n        extensions of rational functions. In other words, given a \"normal\" function, the Risch\n        algorithm will return either the indefinite integral of the function or an indication\n        that no closed-form integral is possible in terms of elementary functions. Such work\n        effectively ended the era of considering integration as a problem in search.\n            SIN was further refined, merged with parts of the Risch algorithm, and put into the\n        evolving MACSYMA^ program. For the most part, refinement of MACSYMA consisted\n        of the incorporation of new algorithms. Few heuristics of any sort survive. Today\n        MACSYMA is no longer considered an AI program. It is used daily by scientists and\n        mathematicians, while ELIZA and STUDENT are now but historical footnotes.\n            With ELIZA and STUDENT we were able to develop miniature programs that dupli\n        cated most of the features of the original. We won't even try to develop a program\n        worthy of the name MACSYMA; instead we will settle for a modest program to do sym\n        bolic simplification, which we will call (simply) simpl i f i er. Then, we will extend\n        simpl i f i er to do differentiation, and some integration problems. The idea is that\n        given an expression like (2 - 1 ) a : + 0, we want the program to compute the simplified\n        form X.\n            According to the Mathematics Dictionary Qames and James 1949), the word \"sim\n        plified\" is \"probably the most indefinite term used seriously in mathematics.\" The\n        problem is that \"simplified\" is relative to what you want to use the expression for\n        next. Which is simpler, x^ 3x + 2 or (x -\\- l){x -\\- 2)? The first makes it easier to\n\n           ^MACSYMA is the Project MAC SYMbolic MAthematics program. Project MAC is the MIT\n        research organization that was the precursor of MIT's Laboratory for Computer Science.\n        MAC stood either for Machine-Aided Cognition or Multiple-Access Computer, according to\n        one of their annual reports. The cynical have claimed that MAC really stood for Man Against\n        Computer.\n\f240                                     SYMBOLIC       MATHEMATICS:          A SIMPLIFICATION           PROGRAM\n\n\n\n      integrate or differentiate, the second easier to find roots. We will be content to limit\n      ourselves to \"obvious\" simplifications. For example,  is almost always preferable\n      to Ix + 0.\n\n\n\n      8.1        Converting Infix to Prefix Notation\n      We will represent simplifications as a list of rules, much like the rules for STUDENT\n      and ELIZA. But since each simplification rule is an algebraic equation, we will store\n      each one as an exp rather than as a rul e. To make things more legible, we will write\n      each expression in infix form, but store them in the prefix form expected by exp. This\n      requires an i nf i x->pref i  function to convert infix expressions into prefix notation.\n      We have a choice as to how general we want our infix notation to be. Consider:\n\n          (((a * ( X ^ 2 ) ) + (b * X ) ) + c)\n          ( a * x ^ 2 + b * x + c)\n          (a  ^ 2 + b  + c)\n          a x^2 + b*x+c\n\n\n      The first is fully parenthesized infix, the second makes use of operator precedence\n      (multiplication binds tighter than addition and is thus performed first), and the third\n      makes use of implicit multiplication as well as operator precedence. The fourth\n      requires a lexical analyzer to break Lisp symbols into pieces.\n            Suppose we only wanted to handle the fully parenthesized case. To write\n      i nf i x->pref i , one might first look at pref i x->i nf i  (on page 228) trying to adapt\n      it to our new purposes. In doing so, the careful reader might discover a surprise:\n      i n f i x - > p r e f i x and pref i x - > i n f ix are in fact the exact same function! Both leave\n      atoms unchanged, and both transform three-element lists by swapping the exp-op\n      and exp -1 hs. Both apply themselves recursively to the (possibly rearranged) input\n      list. Once we discover this fact, it would be tempting to avoid writing i  f i  - >p r e f i x,\n      and just call pref i x->i nf i  instead. Avoid this temptation at all costs. Instead, de\n      fine i nf i x->pref i  as shown below. The intent of your code will be clearer:\n\n          (defun i n f i x - > p r e f i x ( i n f i x - e x p )\n            \"Convert f u l l y parenthesized i n f i x - e x p to a p r e f i x e x p r e s s i o n \"\n            ; ; Don't use t h i s v e r s i o n for n o n - f u l l y parenthesized exps!\n            (prefix->infix infix-exp))\n\n\n      As we saw above, fully parenthesized infix can be quite ugly, with all those extra\n      parentheses, so instead we will use operator precedence. There are a number of\n      ways of doing this, but the easiest way for us to proceed is to use our previously\n      defined tool rul e-based-trans� ator and its subtool, pat-match. Note that the third\n\f8.1 CONVERTING        INFIX TO PREFIX NOTATION                                                                            241\n\n\n\n          clause of i n f i x - > p r e f i x , the one that calls r u l e - b a s e d - t r a n s l a t o r is unusual in\n          that it consists of a single expression. Most cond-clauses have two expressions: a test\n          and a result, but ones like this mean, \"Evaluate the test, and if it is non-nil, return it.\n          Otherwise go on to the next clause.\"\n\n\n                 (defun i n f i x - > p r e f i x (exp)\n                   \"Translate an i n f i x expression into p r e f i x n o t a t i o n . \"\n                        Note we cannot do i m p l i c i t m u l t i p l i c a t i o n in t h i s system\n                   (cond ((atom exp) exp)\n                            ((=    (length exp) 1) ( i n f i x - > p r e f i x ( f i r s t exp)))\n                            ( ( r u l e - b a s e d - t r a n s l a t o r exp * i n f i x - > p r e f i x - r u l e s *\n                                  :rule-if        # ' r u l e - p a t t e r n : r u l e - t h e n #*rule-response\n                                  :action\n                                  #*(lambda (bindings response)\n                                         ( s u b l i s (mapcar\n                                                           #*(lambda ( p a i r )\n                                                                   (cons ( f i r s t p a i r )\n                                                                              (infix->prefix (rest p a i r ) ) ) )\n                                                           bindings)\n                                                       response))))\n                            ((symbolp ( f i r s t exp))\n                              ( l i s t ( f i r s t exp) ( i n f i x - > p r e f i x ( r e s t e x p ) ) ) )\n                            (t (error \" I l l e g a l e x p \" ) ) ) )\n\n\n          Because we are doing mathematics in this chapter, we adopt the mathematical con\n          vention of using certain one-letter variables, and redefine vari abl e-p so that vari\n          ables are only the symbols m through z.\n\n\n                 (defun v a r i a b l e - p (exp)\n                    \"Variables are the symbols  through Z . \"\n                        put x . y . z f i r s t to f i n d them a l i t t l e f a s t e r\n                    (member exp ' ( x y z m n o p q r s t u v w ) ) )\n\n\n                 (pat-match-abbrev ' x + * ( ? + x ) )\n                 (pat-match-abbrev ' y + ' ( ? + y ) )\n\n\n                 (defun rule-pattern ( r u l e ) ( f i r s t                 rule))\n                 (defun rule-response ( r u l e ) (second r u l e ) )\n\f242                                        SYMBOLIC      MATHEMATICS:      A SIMPLIFICATION          PROGRAM\n\n\n\n          (defpa rameter *i nfi x - > p r e f i x - r u l e s *\n            (mapcar #'expand-pat-match-abbrev\n               ' ( ( ( x + = y+) (= X y ) )\n                    ( ( - x+)    (- X ) )\n                  ((+X+)             (+x))\n                 ((x+ + y+) (+ X           y))\n                 ((x+ - y+) (- X           y))\n                 ((x+ * y+) (* X           y))\n                 ((x+ / y+) ( / X          y))\n                 ((x+ ^ y+)        r   X   y))))\n               \"A l i s t of r u l e s ,   ordered by precedence.\")\n\n\n\n\n      8.2        Simplification Rules\n      Now we are ready to define the simplification rules. We use the definition of the data\n      types rule and exp (page 221) and p r e f i x - > i n f ix (page 228) from STUDENT. They\n      are repeated here:\n\n          ( d e f s t r u c t ( r u l e (:type l i s t ) ) pattern response)\n\n          (defstruct (exp (:type l i s t )\n                             (.�constructor mkexp ( I h s op r h s ) ) )\n            op I h s r h s )\n\n          (defun exp-p (x) (consp x ) )\n          (defun exp-args (x) ( r e s t x ) )\n\n          (defun p r e f i x - > i n f i x (exp)\n            \"Translate p r e f i x to i n f i x e x p r e s s i o n s . \"\n            ( i f (atom exp) exp\n                  (mapcar # ' p r e f i x - > i n f i x\n                               ( i f ( b i n a r y - e x p - p exp)\n                                        ( l i s t ( e x p - l h s exp) (exp-op exp) (exp-rhs exp))\n                                       exp))))\n\n          (defun binary-exp-p (x)\n            (and (exp-p x) (= (length (exp-args x ) ) 2 ) ) )\n\n\n      We also use r u l e - b a s e d - t r a n s l a t o r (page 188) once again, this time on a list of\n      simplification rules. A reasonable list of simplification rules is shown below. This\n      list covers the four arithmetic operators, addition, subtraction, multipHcation, and\n      division, as well as exponentiation (raising to a power), denoted by the symbol\n           Again, it is important to note that the rules are ordered, and that later rules will\n      be applied only when earlier rules do not match. So, for example, 0 / 0 simplifies to\n\f8.2 SIMPLIFICATION          RULES                                                                                   243\n\n\n\n           undef i ned, and not to 1 or 0, because the rule for 0 / 0 comes before the other rules.\n           See exercise 8.8 for a more complete treatment of this.\n\n               (defparameter * s i m p l i f i c a t i o n - r u l e s * (mapcar # ' i n f i x - > p r e f i x *(\n                  (x + 0              = X)\n\n                  (0    + X           = X)\n\n                  (x    + X           = 2         * X)\n\n                  (X    - 0           = X)\n\n                  (0    - X           =       - X)\n\n                  (X    - X           = 0)\n                  (-    - X           = X)\n\n                  (X    * 1           = X)\n\n                  (1    * X           = X)\n\n                  (X    * 0           = 0)\n                  (0    * X           = 0)\n                  (X    * X           =    X ^         2)\n                  (X    / 0           = undefined)\n                  (0    /       X     = 0)\n                  (X    / 1           = X)\n\n                  (X    /       X     = 1)\n                  (0 ^ 0              = undefined)\n                  (X    ^ 0           = 1)\n                  (0            X     = 0)\n                  (1            X     = 1)\n                  (X    ^ 1           = X)\n\n                  (X    ^ -1 = 1                  /    X)\n\n                  (X    * (y /             X)         = y)\n                  ((y       /       X) * X            = y)\n                  ((y *             X) /      X       = y)\n                  ((X       * y) /            X       = y)\n                  (x +          - X =         0)\n                  ((-       X) + X =                  0)\n                  (x + y -                X   = y)\n                  )))\n\n               (defun \" (x y ) \"Exponentiation\" (expt  y ) )\n\n\n           We are now ready to go ahead and write the simplifier. The main function, s i mp 11 f i e r\n           will repeatedly print a prompt, read an input, and print it in simplified form. Input\n           and output is in infix and the computation is in prefix, so we need to convert accord\n           ingly; the function simp does this, and the function simpl 1 fy takes care of a single\n           prefix expression. It is summarized in figure 8.1.\n\f244                                           SYMBOLIC        MATHEMATICS:             A SIMPLIFICATION             PROGRAM\n\n\n\n                                               Top-Level Functions\n      simplifier                               A read-simplify-print loop.\n      simp                                     Simplify an infix expression.\n      simplify                                 Simplify a prefix expression.\n                                               Special Variables\n      *infix->prefix-rules*                    Rules to translate from infix to prefix.\n      * s i mpli f i cati o n - r u l e s *    Rules to simplify an expression.\n                                               Data Types\n      exp                                      A prefix expression.\n                                               Atixiliary Functions\n      simplify-exp                             Simplify a non-atomic prefix expression.\n      infix->prefix                            Convert infix to prefix notation.\n      variable-p                               The symbols m through  are variables.\n                                               An alias for expt, exponentiation.\n      evaluable                                Decide if an expression can be numerically evaluated.\n      simp-rule                                Transform a rule into proper format.\n      length=l                                 Is the argument a list of length 1?\n                                               Previous Functions\n      pat-match                                Match pattern against an input, (p. 180)\n      rule-based-translator                    Apply a set of rules, (p. 189)\n      pat-match-abbrev                         Define an abbreviation for use in pat-match.\n\n                                        Figure 8.1: Glossary for the Simplifier\n\n\n         Here is the program:\n\n         (defun s i m p l i f i e r ( )\n           \"Read a mathematical e x p r e s s i o n , s i m p l i f y i t , and p r i n t the r e s u l t . \"\n           (loop\n              (print 'simplifier>)\n              ( p r i n t (simp ( r e a d ) ) ) ) )\n\n         (defun simp ( i n f ) ( p r e f i x - > i n f i x     (simplify (infix->prefix                  inf))))\n\n         (defun s i m p l i f y (exp)\n           \" S i m p l i f y an expression by f i r s t s i m p l i f y i n g i t s components.\"\n           ( i f (atom exp) exp\n                  ( s i m p l i f y - e x p (mapcar # ' s i m p l i f y e x p ) ) ) )\n\n         (defun s i m p l i f y - e x p (exp)\n           \"Simplify using a r u l e , or by doing a r i t h m e t i c . \"\n           (cond ( ( r u l e - b a s e d - t r a n s l a t o r exp * s i m p l i f i c a t i o n - r u l e s *\n                        : r u l e - i f #'exp-lhs :rule-then #'exp-rhs\n                        .�action #'(lambda (bindings response)\n                                               ( s i m p l i f y ( s u b l i s bindings r e s p o n s e ) ) ) ) )\n                  ((evaluable exp) (eval exp))\n                  (t exp)))\n\f82   SIMPLIFICATION      RULES                                                                           245\n\n\n\n                (defun evaluable (exp)\n                  \" I s t h i s an arithmetic expression that can be evaluated?\"\n                  (and (every #'numberp (exp-args exp))\n                          (or (member (exp-op exp) ' ( + - * / ) )\n                                (and (eq (exp-op exp) ' \" )\n                                     (integerp (second (exp-args e x p ) ) ) ) ) ) )\n\n\n            The function si mpl i fy assures that any compound expression will be simplified by\n            first simplifying the arguments and then calling simpl ify-exp. This latter func\n            tion searches through the simplification rules, much like u s e - e l i z a - r u l e s and\n            trans� a t e - t o - e x p r e s s i on. When it finds a match, simpl i fy -exp substitutes in the\n            proper variable values and calls simpl i fy on the result, simpl i fy -exp also has the\n            ability to call eval to simplify an arithmetic expression to a number. As in STUDENT,\n            it is for the sake of this eval that we require expressions to be represented as lists in\n            prefix notation. Numeric evaluation is done after checking the rules so that the rules\n            can intercept expressions like ( / 1 0) and simplify them to undef i ned. If we did the\n            numeric evaluation first, these expressions would yield an error when passed to e va 1.\n            Because Common Lisp supports arbitrary precision rational numbers (fractions), we\n            are guaranteed there will be no round-off error, unless the input explicitly includes\n            inexact (floating-point) numbers. Notice that we allow computations involving the\n            four arithmetic operators, but exponentiation is only allowed if the exponent is an\n            integer. That is because expressions like ( \" 4 1/2) are not guaranteed to return 2\n            (the exact square root of 4); the answer might be 2 . 0 (an inexact number). Another\n            problem is that - 2 is also a square root of 4, and in some contexts it is the correct\n            one to use.\n                 The following trace shows some examples of the simplifier in action. First we\n            show that it can be used as a calculator; then we show more advanced problems.\n                >     (simplifier)\n                SIMPLIFIER> (2 + 2)\n                4\n                SIMPLIFIER> (5 * 20 + 30 + 7)\n                137\n                SIMPLIFIER> (5 *  - (4 + 1) * x)\n                0\n                SIMPLIFIER> (y /  * (5 *  - (4 + 1) *  ) )\n                O\n                SIMPLIFIER> ( ( 4 - 3) *  + (y / y - 1) *  )\n                X\n                SIMPLIFIER> ( 1 * f ( x ) + 0)\n                (F X)\n                SIMPLIFIER> (3 * 2 * X)\n                (3 * (2 * X))\n                SIMPLIFIER> [Abort]\n                >\n\f246                                         SYMBOLIC          MATHEMATICS:   A SIMPLIFICATION   PROGRAM\n\n\n\n      Here we have terminated the loop by hitting the abort key on the terminal. (The details\n      of this mechanism varies from one implementation of Common Lisp to another.) The\n      simplifier seems to workfairlywell, although it errs on the last example: (3 * (2 *\n      X)) should simplify to (6 * X). In the next section, we will correct that problem.\n\n\n\n\n      8.3       Associativity and Commutativity\n\n      We could easily add a rule to rewrite (3 * (2 * X ) ) a s ( ( 3 * 2) * X) and hence\n      (6 * X). The problem is that this rule would also rewrite ( X * ( 2 * 3 ) ) a s ( ( X *\n      2) * 3 ) , unless we had a way to limit the rule to apply only when it would group\n      numbers together. Fortunately, pat-match does provide just this capability, with the\n      ?i s pattern. We could write this rule:\n\n          ( ( ( ? i s  numberp) * ( ( ? i s m numberp) * x ) ) = ((n * m) * x ) )\n\n\n      This transforms (3 * (2 * x ) ) into ( ( 3 * 2) * ), and hence into (6 * x ) .\n      Unfortunately, the problem is not as simple as that. We also want to simplify ( ( 2 *\n      x) * ( y * 3 ) ) to (6 * ( x * y ) ) . We can do a better job of gathering numbers together\n      by adopting three conventions. First, make numbers first in products: change  *\n      3 to 3 * X. Second, combine numbers in an outer expression with a number in an\n      inner expression: change 3 * ( 5 * x ) t o ( 3 * 5 ) * x . Third, move numbers out\n      of inner expressions whenever possible: change (3 * x ) * y t o 3 * ( x * y ) . We\n      adopt similar conventions for addition, except that we prefer numbers last there: \n      + 1 instead of 1 + x.\n\n             Define  and m as numbers; s as a non-number:\n          (pat-match-abbrev *n '(lis                  numberp))\n          (pat-match-abbrev 'm ' ( ? i s m numberp))\n          (pat-match-abbrev * s ' ( ? i s s not-numberp))\n\n\n          (defun not-numberp (x) (not (numberp x ) ) )\n\n\n          (defun simp-rule ( r u l e )\n            \"Transform a rule into proper format.\"\n            ( l e t ((exp ( i n f i x - > p r e f i x r u l e ) ) )\n               (mkexp (expand-pat-match-abbrev (exp-lhs exp))\n                           (exp-op exp) (exp-rhs e x p ) ) ) )\n\f8.3 550AND                  COMMUTATIVITY                                                         247\n\n\n          (setf *simplification-rules*\n              (append * s i m p l i f i c a t i o n - r u l e s * (mapcar # ' s i m p - r u l e\n               '((s    *  =  * s)\n                  ( * (m *        X)   = ( * m) *          )\n\n                  (    * ( * y ) =  *            (    * y))\n                  (( *      )     * y =  *       (    * y))\n                  ( + s = s + )\n                  ((     + m) +  =             +  -�- m)\n                  (    + (y + ) =          (    + y ) + )\n                  ( (  + ) + y = (  + y ) +  ) ) ) ) )\n\n\n       With the new rules in place, we are ready to try again. For some problems we get just\n       the right answers:\n\n          >     (simplifier)\n          SIMPLIFIER> (3 * 2 * x)\n          (6 * X)\n          SIMPLIFIER> (2 *  *  * 3)\n          (6 * (            2))\n          SIMPLIFIER>             ( 2 * x * 3 * y * 4 * z * 5 * 6 )\n          (720 * (X * (Y *  ) ) )\n          SIMPLIFIER> (3 +  + 4 +  )\n          ((2 * ) + 7)\n          $IMPLIFIER>             ( 2 *  * 3 *  * 4 * ( 1 /  ) * 5 * 6 )\n          (720 * )\n\n\n       Unfortunately, there are other problems that aren't simplified properly:\n\n          SIMPLIFIER> (3 +  + 4 - x )\n          ((X + (4 - X)) + 3)\n          SIMPLIFIER> (x + y + y + x)\n          (X + (Y + (Y +  ) ) )\n          SIMPLIFIER> (3 *  + 4 *  )\n          ((3 * ) + (4 *  ) )\n\n\n       We will return to these problems in section 8.5.\n\n\n   @   Exercise 8.1 Verify that the set of rules just prior does indeed implement the desired\n       conventions, and that the conventions have the proper effect, and always terminate.\n       As an example of a potential problem, what would happen if we used the rule ( *\n        =  * ) instead of the rule (s *  =  * s ) ?\n\f248                                   SYMBOLIC       MATHEMATICS:         A SIMPLIFICATION   PROGRAM\n\n\n\n      8.4       Logs, Trig, and Differentiation\n      In the previous section, we restricted ourselves to the simple arithmetic functions,\n      so as not to intimidate those who are a little leery of complex mathematics. In this\n      section, we add a little to the mathematical complexity, without having to alter the\n      program itself one bit. Thus, the mathematically shy can safely skip to the next\n      section without feeling they are missing any of the fun.\n          We start off by representing some elementary properties of the logarithmic and\n      trigonometric functions. The new rules are similar to the \"zero and one\" rules we\n      needed for the arithmetic operators, except here the constants e and  i (e = 2.71828...\n      and  = 3.14159...) are important in addition to 0 and 1. We also throw in some rules\n      relating logs and exponents, and for sums and differences of logs. The rules assume\n      that complex numbers are not allowed. If they were, log (and even x^) would have\n      multiple values, and it would be wrong to arbitrarily choose one of these values.\n\n         (setf *simplification-rules*\n          (append * s i m p l i f i c a t i o n - r u 1 e s * (mapcar #*simp-rule *(\n           (log 1                  = 0)\n           (log 0                  = undefined)\n           (log e                 =1)\n           (sin 0                 =0)\n           ( s i n pi              = 0)\n           (cos 0                  =1)\n           (cos pi                 = -1)\n           ( s i n ( p i / 2)     =1)\n           (cos(pi / 2)            =0)\n           (log (e \" x )           = x)\n           (e ^ (log x)            = x)\n           ((x ^ y ) * (x ^ z) =  M y + z ) )\n           ((x ^ y ) / (x M ) =  M y - z ) )\n           (log  + log y = l o g ( x * y ) )\n           (log X - log y = l o g ( x / y ) )\n           ( ( s i n X ) ^ 2 + (cos X ) ^ 2 = 1)\n           ))))\n\n\n      Now we would like to go a step further and extend the system to handle differenti\n      ation. This is a favorite problem, and one which has historical significance: in the\n      summer of 1958 John McCarthy decided to investigate differentiation as an interest\n      ing symbolic computation problem, which was difficult to express in the primitive\n      programming languages of the day. This investigation led him to see the importance\n      of functional arguments and recursive functions in the field of symbolic computa\n      tion. For example, McCarthy invented what we now call mapcar to express the idea\n      that the derivative of a sum is the sum of the derivative function applied to each\n      argument. Further work led McCarthy to the publication in October 1958 of MIT\n\f8.4 LOGS,   TRIG, AND DIFFERENTIATION                                                            249\n\n\n\n            AI Lab Memo No. 1: \"An Algebraic Language for the Manipulation of Symbolic\n            Expressions/' which defined the precursor of Lisp.\n                In McCarthy's work and in many subsequent texts you can see symbolic differen\n            tiation programs with a simplification routine tacked on the end to make the output\n            more readable. Here, we take the opposite approach: the simplification routine is\n            central, and differentiation is handled as just another operator, with its own set of\n            simplification rules. We will require a new infix-to-prefix translation rule. While\n            we're at it, we'll add a rule for indefinite integration as well, although we won't write\n            simplification rules for integration yet. Here are the new notations:\n\n                                           math            infix         prefix\n                                           dy/dx           d y / d X     (d y x)\n                                           /ydx            Int y d X     ( i n t y )\n\n            And here are the necessary infix-to-prefix rules:\n\n               (defparameter *infix->prefix-rules*\n                 (mapcar #'expand-pat-match-abbrev\n                  ' ( ( ( x + = y+) (=  y))\n                       ( ( - x+)    (- ))\n                     ((++)            (+x))\n                     ((X-H   + y+)   (+ X y))\n\n                     ((x+ - y+)      (-    y))\n                     ((d y+ / d      x)   (d y x))                     New rule\n                     ((Int y+ d      x)   (int y ))                    New rule\n                     ((x+ * y+)      (*    y))\n                     ((x+ / y+)      (/    y))\n                     ((x+ ^ y+)      r     y)))))\n\n            Since the new rule for differentiation occurs before the rule for division, there won't\n            be any confusion with a differential being interpreted as a quotient. On the other\n            hand, there is a potential problem with integrals that contain d as a variable. The\n            user can always avoid the problem by using (d) instead of d inside an integral.\n                Now we augment the simplification rules, by copying a differentiation table out\n            of a reference book:\n\n               (setf *simplification-rules*\n                (append *simplification-rules* (mapcar #*simp-rule ' (\n                 (d  / d          =1)\n                 (d (u + V) / d  = (d u / d X ) + (d V / d X ) )\n                 (d (u - V) / d  = (d u / d X ) - (d V / d x))\n                 (d (- u) / d X = - (d u / d X ) )\n                 (d (u * V) / d X = u * (d V / d X ) + V * (d u / d X ) )\n                 (d (u / V) / d X = (V * (d u / d X ) - u * (d V / d X ) )\n                                            /   V ^   2)\n\f250                                          SYMBOLIC    MATHEMATICS:     A SIMPLIFICATION   PROGRAM\n\n\n\n            (d (u ^ n) / d            X   =  * u M n - 1) * (d u / d X ) )\n            (d (u   V) / d            X = V   * u M v - 1) * (d u / d X )\n                                          + u ^ V * ( l o g u) * (d V / d x ) )\n            (d   ( l o g u)   /   d   X   = (d u / d X ) / u)\n            (d   ( s i n u)   /   d   X   = (cos u) * (d u / d x ) )\n            (d   (cos u)      /   d   X   = - ( s i n u) * (d u / d x ) )\n            (d   (e ^ u)      /   d   X   = (e ^ u) * (d u / d X ) )\n            (d   u / d X                  = 0)))))\n\n\n      We have added a default rule, (d u / d  = 0); this should only apply when the\n      expression u is free of the variable  (that is, when u is not a function of x). We could\n      use ? 1 f to check this, but instead we rely on the fact that differentiation is closed over\n      the list of operators described here--as long as we don't introduce any new operators,\n      the answer will always be correct. Note that there are two rules for exponentiation,\n      one for the case when the exponent is a number, and one when it is not. This was\n      not strictly necessary, as the second rule covers both cases, but that was the way the\n      rules were written in the table of differentials I consulted, so I left both rules in.\n\n         SIMPLIFIER> (d (x + x) / d x)\n         2\n         SIMPLIFIER> (d (a * x ^ 2 + b * x + c) / d x)\n         ((2 * (A * X ) ) + B)\n         SIMPLIFIER> (d ((a * x ^ 2 + b * x + c) / x) / d x)\n         ( ( ( ( A * (X ^ 2 ) ) + ( ( B * X) + O ) - (X * ( ( 2 * (A * X ) ) + B ) ) )\n           / (X ^ 2 ) )\n         SIMPLIFIER> ( l o g ((d (x + ) / d x) / 2 ) )\n         0\n         SIMPLIFIER> ( l o g ( x + x) - log x)\n         (LOG 2)\n         SIMPLIFIER> (x                  cos p i )\n         (1 / X)\n         SIMPLIFIER> (d (3 * x + (cos x) / x) / d x)\n         ((((COS X) - (X * (- ( S I N X ) ) ) ) / (X ^ 2 ) ) + 3)\n         SIMPLIFIER> (d ( ( c o s x) / x) / d x )\n         (((COS X) - (X * (- ( S I N X ) ) ) ) / (X ^ 2 ) )\n         SIMPLIFIER> (d (3 * x ^ 2 + 2 *  + 1) / d x)\n         ((6 * X) + 2)\n         S I M P i I F I E R > ( s i n ( x + x) ^ 2 + cos(d  ^ 2 / d x) ^ 2)\n         1\n         SIMPLIFIER> ( s i n ( x + x) * s i n ( d  \" 2 / d x) +\n                                 cos(2 * X ) * cos(x * d 2 * y / d y ) )\n         1\n\n\n      The program handles differentiation problems well and is seemingly clever in its use\n      of the identity sin^  - f cos^  = 1.\n\f8.5   LIMITS OF RULE-BASED           APPROACHES                                                251\n\n\n\n            8.5          Limits of Rule-Based Approaches\n\n            In this section we return to some examples that pose problems for the simplifier.\n            Here is a simple one:\n\n                SIMPLIFIER> (x + y + y + ) =^ (X + (Y + (Y + X ) ) )\n\n\n            We would prefer 2 * (x + y ) . The problem is that, although we went to great trouble\n            to group numbers together, there was no effort to group non-numbers. We could\n            write rules of the form:\n\n\n                (y + (y +          x) =   (2 * y ) +      x)\n\n                (y + (x + y ) = (2 * y ) +                x)\n\n\n\n            Thesewouldworkfortheexampleathand, but they would not work for ( + y + \n            + y + ). For that we would need more rules:\n\n\n                (y   +   (    +    (y + X ) ) =     (2   * y)   + X + )\n\n                (y   +   ( +       ( + y ) )    =   (2   * y)   +  +   )\n\n                (y   +   ( ( y + )        + )   =   (2   * y)   +  +   )\n\n                (y   +   ((       + y)    + )   =   (2   * y)   +  +   )\n\n\n\n             handle all the cases, we would need an infinite number of rules. The pattern-\n            matching language is not powerful enough to express this succintly. It might help\n            if nested sums (and products) were unnested; that is, if we allowed + to take an\n            arbitrary number of arguments instead of just one. Once the arguments are grouped\n            together, we could sort them, so that, say, all the ys appear before  and after x. Then\n            like terms could be grouped together. We have to be careful, though. Consider these\n            examples:\n\n                SIMPLIFIER> (3 *  + 4 * x )\n                ((3 * X) + (4 * X))\n                SIMPLIFIER> ( 3 * x + y + x + 4 * x )\n                ((3 * X) + (Y + (X + (4 * X ) ) ) )\n\n\n             We would want (3 * ) to sort to the same place as  and (4 * ) so that they could\n             all be combined to (8 * x ) . In chapter 15, we develop a new version of the program\n             that handles this problem.\n\f252                                            SYMBOLIC          MATHEMATICS:               A SIMPLIFICATION              PROGRAM\n\n\n\n      8.6        Integration\n      So far, the algebraic manipulations have been straightforward. There is a direct\n      algorithm for computing the derivative of every expression. When we consider\n      integrals, or antiderivatives,^ the picture is much more complicated. As you may\n      recall from freshman calculus, there is a fine art to computing integrals. In this\n      section, we try to see how far we can get by encoding just a few of the many tricks\n      available to the calculus student.\n          The first step is to recognize that entries in the simplification table will not be\n      enough. Instead, we will need an algorithm to evaluate or \"simplify\" integrals.\n      We will add a new case to simpl i f y - e x p to check each operator to see if it has a\n      simplification function associated with it. These simplification functions will be\n      associated with operators through the functions s e t - s i m p - f n and s i m p - f n . If an\n      operator does have a simplification function, then that function will be called instead\n      of consulting the simplification rules. The simplification function can elect not to\n      handle the expression after all by returning nil, in which case we continue with the\n      other simplification methods.\n\n          (defun simp-fn (op) (get op ' s i m p - f n ) )\n          (defun s e t - s i m p - f n (op fn) ( s e t f (get op ' s i m p - f n ) f n ) )\n\n          (defun s i m p l i f y - e x p (exp)\n            \" S i m p l i f y using a r u l e , or by doing a r i t h m e t i c ,\n            or by using the simp function supplied for t h i s o p e r a t o r . \"\n            (cond ( ( s i m p l i f y - b y - f n exp))\n                       ( ( r u l e - b a s e d - t r a n s l a t o r exp * s i m p l i f i c a t i o n - r u l e s *\n                              : r u l e - i f #'exp-lhs :rule-then #'exp-rhs\n                              raction #*(lambda (bindings response)\n                                                     ( s i m p l i f y ( s u b l i s bindings r e s p o n s e ) ) ) ) )\n                       ((evaluable exp) (eval exp))\n                       (t exp)))\n\n          (defun s i m p l i f y - b y - f n (exp)\n            \" I f there i s a s i m p l i f i c a t i o n fn for t h i s exp,\n            and i f applying i t gives a non-null r e s u l t ,\n            then s i m p l i f y the r e s u l t and return t h a t . \"\n            ( l e t * ( ( f n (simp-fn (exp-op e x p ) ) )\n                        ( r e s u l t ( i f fn (funcall fn e x p ) ) ) )\n                ( i f (null r e s u l t )\n                      nil\n                      (simplify r e s u l t ) ) ) )\n\n\n         Freshman calculus classes teach a variety of integration techniques. Fortunately,\n      one technique--the derivative-divides technique--can be adopted to solve most of the\n\n         ^The term antiderivative is more correct, because of branch point problems.\n\f8.6 INTEGRATION                                                                                       253\n\n\n\n         problems that come up at the freshman calculus level, perhaps 90% of the problems\n         given on tests. The basic rule is:\n\n\n\n                                         j   f{x)dx      =   Jm^dx.\n         As an example, consider / xsin{x^)dx.      Using the substitution u = x^, we can\n         differentiate to get du/dx = 2x, Then by applying the basic rule, we get:\n\n\n\n                          j xsin{x^)dx            J s i n ( u ) ^ � � a : -- ^ J sin (i�) (�i�.\n\n\n         Assume we have a table of integrals that includes the rule / sin(x) dx = - cos(x).\n         Then we can get the final answer:\n\n\n                                                      --cos{x^).\n\n\n            Abstracting from this example, the general algorithm for integrating an expres-\n         sion y with respect to  is:\n\n\n           1. Pick a factor of y, calling it f{u).\n\n\n            2. Compute the derivative du/dx.\n\n\n            3. Divide y by f{u)  du/dx, calling the quotient k.\n\n\n            4. If /c is a constant (with respect to x), then the result is A:/              f{u)du.\n\n\n            This algorithm is nondeterrninistic, as there may be many factors of y. In our\n         example, f{u) = sin(x^),w = x^, and du/dx = 2x. So k = \\, and the answer is\n         -^COs (x2).\n             The first step in implementing this technique is to make sure that division is done\n         correctly. We need to be able to pick out the factors of y, divide expressions, and then\n         determine if a quotient is free of x. The function f acton* ze does this. It keeps a list\n         of factors and a running product of constant factors, and augments them with each\n         call to the local function f ac.\n\f254                                          SYMBOLIC          MATHEMATICS:             A SIMPLIFICATION                 PROGRAM\n\n\n\n\n          (defun f a c t o r i z e (exp)\n            \"Return a l i s t of the f a c t o r s of exp^n,\n            where each factor i s of the form  y  ) . \"\n            (let ((factors n i l )\n                      (constant 1 ) )\n              (labels\n                 ( ( f a c ( X n)\n                        (cond\n                          ((numberp x)\n                           ( s e t f constant (* constant (expt   ) ) ) )\n                         ( ( s t a r t s - w i t h  **)\n                           (fac ( e x p - l h s x) n)\n                           (fac (exp-rhs x) n ) )\n                         ((starts-with  V )\n                           (fac ( e x p - l h s x) n)\n                           (fac (exp-rhs x) (- n ) ) )\n                         ((and ( s t a r t s - w i t h  * - ) (length=l (exp-args x ) ) )\n                           ( s e t f constant (- constant))\n                           (fac ( e x p - l h s x) n ) )\n                         ((and ( s t a r t s - w i t h  ' \" ) (numberp (exp-rhs x ) ) )\n                           (fac ( e x p - l h s x ) ( *  (exp-rhs x ) ) ) )\n                         (t ( l e t ( ( f a c t o r ( f i n d  f a c t o r s :key # ' e x p - l h s\n                                                              :test #'equal)))\n                                   ( i f factor\n                                            ( i n c f (exp-rhs f a c t o r ) n)\n                                            (push         ,x ,n) f a c t o r s ) ) ) ) ) ) )\n                   ; ; Body of f a c t o r i z e :\n                   (fac exp 1)\n                   (case constant\n                      (0    *{r    0 1)))\n                      (1 f a c t o r s )\n                       (t   '{      .constant 1)           ..factors))))))\n\n\n      f a c t o r i ze maps from an expression to a list of factors, but we also need unf actor i ze\n      to turn a list back into an expression:\n\n          (defun unfactorize ( f a c t o r s )\n            \"Convert a l i s t of f a c t o r s back into p r e f i x form.\"\n            (cond ( ( n u l l f a c t o r s ) 1)\n                  ((length=l factors) ( f i r s t factors))\n                  (t � ( * . ( f i r s t f a c t o r s ) . ( u n f a c t o r i z e ( r e s t f a c t o r s ) ) ) ) ) )\n\n\n      The derivative-divides method requires a way of dividing two expressions. We do this\n      by factoring each expression and then dividing by cancelling factors. There may be\n      cases where, for example, two factors in the numerator could be multiplied together\n\f8.6 INTEGRATION                                                                                                       255\n\n\n\n          to cancel a factor in the denominator, but this possibility is not considered. It turns\n          out that most problems from freshman calculus do not require such sophistication.\n\n               (defun d i v i d e - f a c t o r s (numer denom)\n                 \"Divide a l i s t of f a c t o r s by another, producing a t h i r d . \"\n                 ( l e t ( ( r e s u l t (mapcar # ' c o p y - l i s t numer)))\n                      ( d o l i s t (d denom)\n                         ( l e t ( ( f a c t o r ( f i n d (exp-lhs d) r e s u l t :key # * e x p - l h s\n                                                           :test #*equal)))\n                              ( i f factor\n                                    (decf (exp-rhs f a c t o r ) (exp-rhs d ) )\n                                    (push *r , ( e x p - l h s d) . ( - (exp-rhs d ) ) ) r e s u l t ) ) ) )\n                      (delete 0 r e s u l t :key # ' e x p - r h s ) ) )\n\n\n          Finally, the predicate f r e e - o f returns true if an expression does not have any occur\n          rences of a particular variable in it.\n\n               (defun f r e e - o f (exp v a r )\n                 \"True i f expression has no occurrence of v a r . \"\n                 (not (find-anywhere var exp)))\n\n               (defun find-anywhere (item tree)\n                 \"Does item occur anywhere i n tree? I f s o . return i t . \"\n                 (cond ((eql item tree) tree)\n                        ((atom tree) n i l )\n                        ((find-anywhere item ( f i r s t t r e e ) ) )\n                        ((find-anywhere item ( r e s t t r e e ) ) ) ) )\n\n\n          In f a c t o r i z e we made use of the auxiliary function l e n g t h = l .                 The function call\n           ( l e n g t h = l x) is faster than ( = ( l e n g t h x) 1) because the latter has to compute\n           the length of the whole list, while the former merely has to see if the list has a r e s t\n           element or not.\n\n               (defun length=l ( x )\n                 \" I s X a l i s t of length 1 ? \"\n                 (and (consp x) (null ( r e s t x ) ) ) )\n\n\n               Given these preliminaries, the function i n t e g r a t e is fairly easy. We start with\n           some simple cases for integrating sums and constant expressions. Then, we factor\n           the expression and split the list of factors into two: a Ust of constant factors, and\n           a list of factors containing x. (This is done with p a r t i t i o n - i f , a combination of\n           r e m o v e - i f and r e m o v e - i f - n o t . ) Finally, we call d e r i  - d i v i d e s , giving it a chance\n           with each of the factors. If none of them work, we return an expression indicating\n           that the integral is unknown.\n\f256                                     SYMBOLIC          MATHEMATICS:            A SIMPLIFICATION                   PROGRAM\n\n\n\n      (defun integrate (exp x)\n             F i r s t t r y some t r i v i a l     cases\n        (cond\n           ( ( f r e e - o f exp x) * ( * ,exp x ) )                           I n t c dx = c*x\n           ( ( s t a r t s - w i t h exp *+)                                   Int f + g         =\n             *(+ . ( i n t e g r a t e (exp-lhs exp) x)                           Int f + Int g\n                      . ( i n t e g r a t e (exp-rhs exp) x ) ) )\n           ( ( s t a r t s - w i t h exp * - )\n             (ecase (length (exp-args exp))\n                 (1 ( i n t e g r a t e (exp-lhs exp) x ) )                    Int - f = - Int f\n                 (2 ' ( - . ( i n t e g r a t e (exp-lhs exp) x)               Int f - g         =\n                             . ( i n t e g r a t e (exp-rhs exp) x ) ) ) ) )        ; Int f - Int g\n                Now move the constant f a c t o r s to the l e f t of the integral\n           ((multiple-value-bind (const-factors x-factors)\n                      ( p a r t i t i o n - i f #'(lambda ( f a c t o r ) ( f r e e - o f factor x ) )\n                                            ( f a c t o r i z e exp))\n                 (simplify\n                      �(* .(unfactorize const-factors)\n                                And t r y to i n t e g r a t e :\n                            .(cond ( ( n u l l x - f a c t o r s ) x)\n                                       ((some #'(lambda ( f a c t o r )\n                                                        ( d e r i v - d i v i d e s factor x - f a c t o r s x ) )\n                                                  x-factors))\n                                       ; ; <other methods here>\n                                       (t   *(int? .(unfactorize x-factors)                      .x)))))))))\n\n\n      (defun p a r t i t i o n - i f (pred l i s t )\n         \"Return 2 v a l u e s : elements of l i s t that s a t i s f y pred.\n        and elements that d o n ' t . \"\n         (let    ((yes-list nil)\n                  (no-list         nil))\n            ( d o l i s t (item     list)\n                (if    (funcall pred item)\n                       (push item y e s - l i s t )\n                       (push item n o - l i s t ) ) )\n            (values (nreverse y e s - l i s t ) (nreverse n o - l i s t ) ) ) )\n\f8.6 INTEGRATION                                                                                                         257\n\n\n\n             Note that the place in i n t e g r a t e where other techniques could be added is\n         marked. We will only implement the derivative-divides method. It turns out that\n         the function is a little more complicated than the simple four-step algorithm outlined\n         before:\n\n             (defun d e r i v - d i v i d e s (factor f a c t o r s x)\n               ( a s s e r t ( s t a r t s - w i t h factor\n               ( l e t * ((u (exp-lhs f a c t o r ) )                  ; factor = u^n\n                            (n (exp-rhs f a c t o r ) )\n                            (k ( d i v i d e - f a c t o r s\n                                    factors (factorize ' ( * .factor ,(deriv u x ) ) ) ) ) )\n                   (cond ( ( f r e e - o f k x)\n                                 I n t k*u\"n*du/dx dx = k*Int u\"n du\n                                                      = k * u ^ ( n + l ) / ( n + l ) for  / = - 1\n                                                      = k * l o g ( u ) for  = - 1\n                           (if     (=  - 1 )\n                                   ' ( * . ( u n f a c t o r i z e k) ( l o g . u ) )\n                                   * ( / (* , ( u n f a c t o r i z e k)  ,u . ( +  1 ) ) )\n                                         ,(+  1))))\n                         ((and (=  1) ( i n - i n t e g r a l - t a b l e ? u ) )\n                                 I n t y ' * f ( y ) dx = I n t f ( y ) dy\n                           ( l e t ((k2 ( d i v i d e - f a c t o r s\n                                                 factors\n                                              ( f a c t o r i z e * ( * ,u , ( d e r i v (exp-lhs u) x ) ) ) ) ) )\n                             (if     ( f r e e - o f k2 x)\n                                     � ( * . ( i n t e g r a t e - f r o m - t a b l e (exp-op u) ( e x p - l h s u))\n                                             .(unfactorize k 2 ) ) ) ) ) ) ) )\n\n\n         There are three cases. In any case, all factors are of the form ( \" u  ) , so we separate\n         the factor into a base, u, and exponent, n. li u or u\"^ evenly divides the original\n         expression (here represented as f a c t o r s ) , then we have an answer. But we need to\n         check the exponent, because / u'^du is u'^~^'^/{n -h 1) forn             - 1 , but it is log(u) for\n          = - 1 , But there is a third case to consider. The factor may be something like (\n         (sin      X 2 ) ) 1 ) , in which case we should c o n s i d e r / (   ) = sin(x^). This case is\n         handled with the help of an integral table. We don't need a derivative table, because\n         we can just use the simplifier for that.\n\n             (defun deriv (y x) ( s i m p l i f y *(d ,y . x ) ) )\n\n             (defun i n t e g r a t i o n - t a b l e ( r u l e s )\n               (dolist (i-rule rules)\n                 (let ((rule (infix->prefix i-rule)))\n                   ( s e t f (get (exp-op (exp-lhs (exp-lhs r u l e ) ) )                   'int)\n                              rule))))\n\f258                                         SYMBOLIC         MATHEMATICS:            A SIMPLIFICATION            PROGRAM\n\n\n\n          (defun i n - i n t e g r a l - t a b l e ? (exp)\n            (and (exp-p exp) (get (exp-op exp) ' i n t ) ) )\n\n          (defun integrate-from-table (op arg)\n            ( l e t ( ( r u l e (get op ' i n t ) ) )\n                 (subst arg (exp-lhs (exp-lhs (exp-lhs r u l e ) ) ) (exp-rhs r u l e ) ) ) )\n\n\n          (integration-table\n             ' ( ( I n t l o g ( x ) d  =  * l o g ( x ) - )\n                  ( I n t exp(x) d  = exp(x))\n                  (Int sin(x) d X = - cos(x))\n                  ( I n t cos(x) d X = s i n ( x ) )\n                  ( I n t tan(x) d  = - l o g ( c o s ( x ) ) )\n                  (Int sinh(x) d  = cosh(x))\n                  ( I n t cosh(x) d X = s i n h ( x ) )\n                  ( I n t tanh(x) d  = l o g ( c o s h ( x ) ) )\n                  ))\n\n\n      The last step is to install i n t e g r a t e as the simplification function for the operator\n      Int. The obvious way to do this is:\n\n          (set-simp-fn ' I n t         'integrate)\n\n\n      Unfortunately, that does not quite work. The problem is that i n t e g r a t e expects\n      two arguments, corresponding to the two arguments y and xin ilnt y x). But the\n      convention for simplification functions is to pass them a single argument, consisting\n      of the whole expression ( I n t y jc). We could go back and edit simpl Ify-exp to\n      change the convention, but instead I choose to make the conversion this way:\n\n          ( s e t - s i m p - f n ' I n t #'(lambda (exp)\n                                               ( i n t e g r a t e ( e x p - l h s exp) (exp-rhs e x p ) ) ) )\n\n\n      Here are some examples, taken from chapters 8 and 9 of Calculus (Loomis 1974):\n\n         SIMPLIFIER> ( I n t  * s i n ( x      2) d x)\n         (1/2 * (- (COS (X ^ 2 ) ) ) )\n         SIMPLIFIER> ( I n t ( ( 3 *  ^ 3) - 1 / (3 *  ^ 3 ) ) d x)\n         ((3 * ((X ^ 4) / 4 ) ) - ( 1 / 3 * ((X ^ - 2 ) / - 2 ) ) )\n         SIMPLIFIER> ( I n t (3 *  + 2) ^ - 2 / 3 d x)\n         ( ( ( 3 * X) + 2)     1/3)\n         SIMPLIFIER> ( I n t s i n ( x ) ^ 2 * c o s ( x ) d x)\n         ( ( ( S I N X) ^ 3) / 3)\n         SIMPLIFIER> ( I n t s i n ( x ) / ( 1 + c o s ( x ) ) d x)\n         ( - 1 * (LOG ((COS X) + 1 ) ) )\n         SIMPLIFIER> ( I n t (2 *  + 1) / (x ^ 2 +  - 1) d x)\n\f87   HISTORY     AND REFERENCES                                                                    259\n\n\n\n                  (LOG ((X ^ 2) + (X - 1 ) ) )\n                  SIMPLIFIER> ( I n t 8 *  ^ 2 / (x ^ 3 + 2) ^ 3 d x)\n                  (8 * ( ( 1 / 3 * ( ( ( X ^ 3) + 2) -2)) / -2))\n\n\n           All the answers are correct, although the last one could be made simpler. One quick\n           way to simplify such an expression is to factor and unfactor it, and then simplify\n           again:\n\n                  (set-simp-fn ' I n t\n                    #'(lambda (exp)\n                         (unfactorize\n                          (factorize\n\n\n                            ( i n t e g r a t e ( e x p - l h s exp) (exp-rhs e x p ) ) ) ) ) )\n\n\n               With this change, w e get:\n                  SIMPLIFIER> ( I n t 8 *  ^ 2 / (x                 3 + 2) ^ 3 d x)\n                  ( - 4 / 3 * ( ( ( X ^ 3) + 2) ^ - 2 ) )\n\n\n\n\n               8.7      History and References\n               A brief history is given in the introduction to this chapter. An interesting point is that\n               the history of Lisp and of symbolic algebraic manipulation are deeply intertwined.\n               It is not too gross an exaggeration to say that Lisp was invented by John McCarthy\n               to express the symbolic differentiation algorithm. And the development of the first\n               high-quality Lisp system, MacLisp, was driven largely by the needs of MACSYMA,\n               one of the first large Lisp systems. See McCarthy 1958 for early Lisp history and\n               the differentiation algorithm, and Martin and Fateman 1 9 7 1 and Moses (1975) for\n               more details on MACSYMA. A comprehensive book on computer algebra systems\n               is Davenport 1 9 8 8 . It covers the MACSYMA and REDUCE systems as well as the\n               algorithms behind those systems.\n                   Because symbolic differentiation is historically important, it is presented in a\n               number of text books, from the original Lisp 1.5 Primer (Weissman 1967) and Allen's\n               influential Anatomy of Lisp (1978) to recent texts like Brooks 1985, Hennessey 1989,\n               and Tanimoto 1990. Many of these books use rules or data-driven programming,\n               but each treats differentiation as the main task, with simplification as a separate\n               problem. None of them use the approach taken here, where differentiation is just\n               another kind of simplification.\n                   The symbolic integration programs SAINT and SiN are covered in Slagle 1963 and\n               Moses 1967, respectively. The mathematical solution to the problem of integration\n\f260                                     SYMBOLIC     MATHEMATICS:     A SIMPLIFICATION       PROGRAM\n\n\n\n            in closed term is addressed in Risch 1969, but be warned; this paper is not for the\n            mathematically naive, and it has no hints on programming the algorithm. A better\n            reference is Davenport et al. 1988.\n                In this book, techniques for improving the efficiency of algebraic manipulation\n            are covered in sections 9.6 and 10.4. Chapter 15 presents a reimplementation that\n            does not use pattern-matching, and is closer to the techniques used in MACSYMA.\n\n\n\n\n            8.8      Exercises\n      t�l   Exercise 8.2 [s] Some notations use the operator ** instead of \" to indicate expo-\n            nentiation. Fix i n f i x - > p r e f i  so that either notation is allowed.\n\n\n            Exercise 8.3 [m] Can the system as is deal with imaginary numbers? What are\n            some of the difficulties?\n\n\n      @     Exercise 8.4 [h] There are some simple expressions involving sums that are not\n            handled by the i ntegrate function. The function can integrate               axx^-\\-bxx-\\-c\n            but not 5 X {a X x^ b X X + c ) . Similarly, it can integrate x^ + 2x x^ -\\- x^ but not\n            (2 + x)^^ and it can do    +     +  -h 1 but not (x^ -f 1)  (x + 1). Modify i ntegrate\n            so that it expands out products (or small exponents) of sums. You will probably want\n            to try the usual techniques first, and do the expansion only when that fails.\n\n\n      [�]   Exercise 8.5 [d] Another very general integration technique is called integration\n            by parts. It is based on the rule:\n\n\n                                             J     udv = uv --   J   vdu\n\n            So, for example, given\n\n                                                   /   X cos xdx\n\n            we can take u = x,dv = cos xdx. Then we can determine  = sin  by integration,\n            and come up with the solution:\n\n\n\n                           J   X cos xdx = X sin   ^ ~ J ^ ^ ~ ^ ^ ^\" ^\n                It is easy to program an integration by parts routine. The hard part is to program\n            the control component. Integration by parts involves a recursive call to i ntegrate,\n            and of all the possible ways of breaking up the original expression into a u and a dv,\n\f.   EXERCISES                                                                                      261\n\n\n\n           few, if any, will lead to a successful integration. One simple control rule is to allow\n           integration by parts only at the top level, not at the recursive level. Implement this\n           approach.\n\n\n      @    Exercise 8.6 [d] A more complicated approach is to try to decide which ways of\n           breaking up the original expression are promising and which are not. Derive some\n           heuristics for making this division, and reimplement i ntegrate to include a search\n           component, using the search tools of chapter 6.\n              Look in a calculus textbook to see how / sin^ xdx is evaluated by two integrations\n           by parts and a division. Implement this technique as well.\n\n\n      @    Exercise 8.7 [m]          Write simplification rules for predicate calculus expressions. For\n           example,\n\n                (true and  = x)\n                ( f a l s e and  = f a l s e )\n                (true or X = true)\n                ( f a l s e or X = f a l s e )\n\n\n\n\n      t�3 Exercise 8.8 [m] The simplification rule ( / 0 = undef i ned) is necessary to avoid\n          problems with division by zero, but the treatment of undef i ned is inadequate. For\n          example, the expression ( ( 0 / 0 ) - ( 0 / 0 ) ) will simplify to zero, when it should\n          simplify to undef i ned. Add rules to propagate undef i ned values and prevent them\n          from being simplified away.\n\n\n      @    Exercise 8.9 [d] Extend the method used to handle undef i ned to handle + i n f i ni ty\n           and - i nf i ni ty as well.\n\fCHAPTER                   9\n\nEfficiency issues\n\n                                                      A Lisp programmer knows the value of every thing,\n                                                                               but the cost of nothing.\n                                                                                           - A l a n J. Perils\n\n                                                           Lisp is not inherently less efficient than other\n                                                                                     high-level languages.\n                                                                                   --Richard J. Fateman\n\n\n\n\nO\n          ne of the reasons Lisp has enjoyed a long history is because it is an ideal language for\n          what is now called rapid-prototyping--developing a program quickly, with little regards\n          for details. That is what we have done so far in this book: concentrated on getting a\nworking algorithm. Unfortunately, when a prototype is to be turned into a production-quality\nprogram, details can no longer be ignored. Most \"real\" AI programs deal with large amounts of\ndata, and with large search spaces. Thus, efficiency considerations become very important.\n   However, this does not mean that writing an efficient program is fundamentaly different\nfrom writing a working program. Ideally, developing an efficient program should be a three-step\nprocess. First, develop a working program, using proper abstractions so that the program will be\neasy to change if necessary. Second, instrument the program to determine where it is spending\nmost of the time. Third, replace the slow parts with faster versions, while maintaining the\nprogram's correctness.\n\f266                                                                          EFFICIENCY     ISSUES\n\n\n\n          The term efficiency will be used primarily to talk about the speed or run time of a\n      program. To a lesser extent, efficiency is also used to refer to the space or amount of\n      storage consumed by a program. We will also talk about the cost of a program. This\n      is partly a use of the metaphor \"time is money,\" and partly rooted in actual monetary\n      costs--if a critical program runs unacceptably slowly, you may need to buy a more\n      expensive computer.\n          Lisp has been saddled with a reputation as an \"inefficient language.\" Strictly\n      speaking, it makes no sense to call a language efficient or inefficient. Rather, it is only\n      a particular implementation of the language executing a particular program that can be\n      measured for efficiency. So saying Lisp is inefficient is partly a historical claim: some\n      past implementations have been inefficient. It is also partly a prediction: there are\n      some reasons why future implementations are expected to suffer from inefficiencies.\n      These reasons mainly stem from Lisp's flexibility. Lisp allows many decisions to be\n      delayed until run time, and that can make the run time take longer. In the past decade,\n      the \"efficiency gap\" between Lisp and \"conventional languages\" Uke FORTRAN or\n      C has narrowed. Here are the reasons--some deserved, some not--behind Lisp's\n      reputation for inefficiency:\n\n          � Early implementations were interpreted rather than compiled, which made\n            them inherently inefficient. Common Lisp implementations have compilers,\n            so this is no longer a problem. While Lisp is (primarily) no longer an interpreted\n            language, it is still an interactive language, so it retains its flexibility.\n\n          � Lisp has often been used to write interpreters for embedded languages, thereby\n            compounding the problem. Consider this quote from Cooper and Wogrin's\n            (1988) book on the rule-based programming language OPS5:\n\n                 The efficiency of implementations that compile rules into executable code\n                 compares favorably to that of programs wntten in most sequential lan\n                 guages such as FORTRAN or Pascal Implementations that compile rules\n                 into data structures to be interpreted, as do many Lisp-based ones, could be\n                 noticeably slower.\n\n            Here Lisp is guilty by association. The fallacious chain of reasoning is: Lisp has\n            been used to write interpreters; interpreters are slow; therefore Lisp is slow.\n            While it is true that Lisp makes it very easy to write interpreters, it also makes\n            it easy to write compilers. This book is the first that concentrates on using Lisp\n            as both the implementation and target language for compilers.\n\n          � Lisp encourages a style with lots of function calls, particularly recursive calls.\n            In some older systems, function calls were expensive. But it is now understood\n            that a function call can be compiled into a simple branch instruction, and that\n\fINTRODUCTION                                                                                       267\n\n\n\n                many recursive calls can be made no more expensive than an equivalent itera\n                tive loop (see chapter 22). It is also possible to instruct a Common Lisp compiler\n                to compile certain functions inline, so there is no calling overhead at all.\n                On the other hand, many Lisp systems require two fetches instead of one to find\n                the code for a function, and thus will be slower. This extra level of indirection\n                is the price paid for the freedom of being able to redefine functions without\n                reloading the whole program.\n\n                Run-time type-checking is slow. Lisp provides a repertoire of generic functions.\n                For example, we can write (+ x y) without bothering to declare if  and y are in\n                tegers, floatingpoint, bignums, complex numbers, rationals, or some combina\n                tion of the above. This is very convenient, but it means that type checks must be\n                made at run time, so the generic+will be slower than, say, a 16-bit integer addi\n                tion with no check for overflow. If efficiency is important. Common Lisp allows\n                the programmer to include declarations that can eUminate run-time checks.\n                In fact, once the proper declarations are added. Lisp can be as fast or faster\n                than conventional languages. Fateman (1973) compared the FORTRAN cube\n                root routine on the PDP-10 to a MacLisp transliteration. The MacLisp version\n                produced almost identical numerical code, but was 18% faster overall, due to\n                a superior function-calling sequence.^ The epigraph at the beginning of this\n                chapter is from this article.\n                Berlin and Weise (1990) show that with a special compilation technique called\n                partial evaluation, speeds 7 to 90 times faster than conventionally compiled code\n                can be achieved. Of course, partial evaluation could be used in any language,\n                but it is very easy to do in Lisp.\n                The fact remains that Lisp objects must somehow represent their type, and\n                even with declarations, not all of this overhead can be eliminated. Most Lisp\n                implementations optimize access to lists and fixnums but pay the price for the\n                other, less commonly used data types.\n\n                Lisp automatically manages storage, and so it must periodically stop and collect\n                the unused storage, or garbage. In early systems, this was done by periodically\n                sweeping through all of memory, resulting in an appreciable pause. Modern\n                systems tend to use incremental garbage-collection techniques, so pauses are\n                shorter and usually unnoticed by the user (although the pauses may still be too\n                long for real-time applications such as controlling a laboratory instrument).\n                The problem with automatic garbage collection these days is not that it is\n                slow-in fact, the automatic systems do about as well as handcrafted storage\n\n              ^One could say that the FORTRAN compiler was \"broken.\" This underscores the problem\n          of defining the efficiency of a language-do we judge by the most popular compiler, by the best\n          compiler available, or by the best compiler imaginable?\n\f268                                                                         EFFICIENCY    ISSUES\n\n\n\n            allocation. The problem is that they make it convenient for the programmer\n            to generate a lot of garbage in the first place. Programmers in conventional\n            languages, who have to clean up their own garbage, tend to be more careful\n            and use static rather than dynamic storage more often. If garbage becomes a\n            problem, the Lisp programmer can just adopt these static techniques.\n\n            Lisp systems are big and leave little room for other programs. Most Lisp sys\n            tems are designed to be complete environments, within which the programmer\n            does all program development and execution. For this kind of operation, it\n            makes sense to have a large language like Common Lisp with a huge set of\n            tools. However, it is becoming more common to use Lisp as just one compo\n            nent in a computing environment that may include UNIX, X Windows, emacs,\n            and other interacting programs. In this kind of heterogeneous environment,\n            it would be useful to be able to define and run small Lisp processes that do\n            not include megabytes of unused tools. Some recent compilers support this\n            option, but it is not widely available yet.\n\n            Lisp is a complicated high-level language, and it can be difficult for the pro\n            grammer to anticipate the costs of various operations. In general, the problem\n            is not that an efficient encoding is impossible but that it is difficult to arrive at\n            that efficient encoding. In a language like C, the experienced programmer has\n            a pretty good idea how each statement will compile into assembly language\n            instructions. But in Lisp, very similar statements can compile into widely dif\n            ferent assembly-level instructions, depending on subtle interactions between\n            the declarations given and the capabilities of the compiler. Page 318 gives an\n            example where adding a declaration speeds up a trivial function by 40 times.\n            Nonexperts do not understand when such declarations are necessary and are\n            frustrated by the seeming inconsistencies. With experience, the expert Lisp\n            programmer eventually develops a good \"efficiency model,\" and the need for\n            such declarations becomes obvious. Recent compilers such as CMU's Python\n            provide feedback that eases this learning process.\n\n          In summary. Lisp makes it possible to write programs in a wide variety of styles,\n      some efficient, some less so. The programmer who writes Lisp programs in the\n      same style as C programs will probably find Lisp to be of comparable speed, perhaps\n      slightly slower. The programmer who uses some of the more dynamic features of\n      Lisp typically finds that it is much easier to develop a working program. Then, if\n      the resulting program is not efficient enough, there will be more time to go back\n      and improve critical sections. Deciding which parts of the program use the most\n      resources is called instrumentation. It is foolhardy to try to improve the efficiency of\n      a program without first checking if the improvement will make a real difference.\n          One route to efficiency is to use the Lisp prototype as a specification and reimple\n      ment that specification in a lower-level language, such as C or C++. Some commercial\n\f9,1 CACHING   RESULTS OF PREVIOUS       COMPUTATIONS:        MEMOIZATION                             269\n\n\n\n          AI vendors are taking this route. An alternative is to use Lisp as the language for both\n          the prototype and the final implementation. By adding declarations and making\n          minor changes to the original program, it is possible to end up with a Lisp program\n          that is similar in efficiency to a C program.\n              There are four very general and language-independent techniques for speeding\n          up an algorithm:\n\n              � Caching the results of computations for later reuse.\n\n              � Compiling so that less work is done at run time.\n\n              � Delaying the computation of partial results that may never be needed.\n\n              � Indexing a data structure for quicker retrieval.\n\n              This chapter covers each of the four techniques in order. It then addresses the\n          important problem of instrumentation. The chapter concludes with a case study of\n          the s i mpl i f y program. The techniques outlined here result in a 130-fold speed-up in\n          this program.\n              Chapter 10 concentrates on lower-level \"tricks\" for improving efficiency further.\n\n\n\n          9.1       Caching Results of Previous Computations:\n                    Memoization\n          We start with a simple mathematical function to demonstrate the advantages of\n          caching techniques. Later we will demonstrate more complex examples.\n              The Fibonacci sequence is defined as the numbers 1 , 1 , 2 , 3 , 5 , 8 , . . . where each\n          number is the sum of the two previous numbers. The most straightforward function\n          to compute the nth number in this sequence is as follows:\n\n              (defun f i b (n)\n                \"Compute the nth number in the Fibonacci sequence.\"\n                ( i f (<=  1) 1\n                      (+ ( f i b (-  D ) ( f i b (-  2 ) ) ) ) )\n\n\n          The problem with this function is that it computes the same thing over and over\n          again. To compute ( f i b 5) means computing ( f i b 4 ) and ( f i b 3 ) , but ( f i b 4)\n          also requires ( f i b 3 ) , they both require ( f i b 2 ) , and so on. There are ways to rewrite\n          the function to do less computation, but wouldn't it be nice to write the function as\n          is, and have it automatically avoid redundant computation? Amazingly, there is\n          a way to do just that. The idea is to use the function f i b to build a new function\n          that remembers previously computed results and uses them, rather than recompute\n\f270                                                                                   EFFICIENCY ISSUES\n\n\n      them. This process is called memoization. The function memo below is a higher-order\n      function that takes a function as input and returns a new function that will compute\n      the same results, but not do the same computation twice.\n\n          (defun memo (fn)\n             \"Return a memo-function of f n . \"\n             ( l e t ( ( t a b l e (make-hash-table)))\n               #'(lambda (x)\n                    ( m u l t i p l e - v a l u e - b i n d (val found-p)\n                          (gethash  t a b l e )\n                       (if   found-p\n                             val\n                             ( s e t f (gethash  table) (funcall fn x ) ) ) ) ) ) )\n\n\n      The expression (memo # ' f i b ) will produce a function that remembers its results\n      between calls, so that, for example, if we apply it to 3 twice, the first call will do the\n      computation of ( f i b 3 ) , but the second will just look up the result in a hash table.\n      With f i b traced, it would look like this:\n\n         > ( s e t f memo-fib (memo # ' f i b ) ) ^         #<CLOSURE -67300731>\n\n         > (funcall memo-fib 3)\n          (1 ENTER F I B : 3)\n             (2 ENTER F I B : 2)\n               (3 ENTER F I B : 1)\n               (3 EXIT F I B : 1)\n               (3 ENTER F I B : 0)\n               (3 EXIT F I B : 1)\n             (2 EXIT F I B : 2)\n             (2 ENTER F I B : 1)\n             (2 EXIT F I B : 1)\n          (1 EXIT F I B : 3)\n         3\n\n         > (funcall memo-fib 3)                 3\n\n\n      The second time we call memo - f i b with 3 as the argument, the answer is just retrieved\n      rather than recomputed. But the problem is that during the computation of ( f i b\n      3 ) , we still compute ( f i b 2 ) multiple times. It would be better if even the internal,\n      recursive calls were memoized, but they are calls to f i b, which is unchanged, not to\n      memo - f i b . We can solve this problem easily enough with the function memoi ze:\n\f9.1 CACHING   RESULTS    OF PREVIOUS       COMPUTATIONS:           MEMOIZATION                                 271\n\n\n\n              (defun memoize (fn-name)\n                \"Replace fn-name's global d e f i n i t i o n with a memoized v e r s i o n . \"\n                ( s e t f (symbol-function fn-name) (memo (symbol-function fn-name))))\n\n\n          When passed a symbol that names a function, memoi ze changes the global definition\n          of the function to a memo-function. Thus, any recursive calls will go first to the\n          memo-function, rather than to the original function. This is just what we want. In\n          the following, we contrast the memoized and unmemoized versions of f i b. First, a\n          call to ( f i b 5 ) with f i b traced:\n\n              > ( f i b 5)\n              (1 ENTER F I B : 5)\n                (2 ENTER F I B : 4)\n                     (3 ENTER F I B : 3)\n                       (4 ENTER F I B : 2)\n                         (5 ENTER F I B : 1)\n                         (5 EXIT F I B : 1)\n                         (5 ENTER F I B : 0)\n                         (5 EXIT F I B : 1)\n                       (4 EXIT F I B : 2)\n                       (4 ENTER F I B : 1)\n                       (4 EXIT F I B : 1)\n                     (3 EXIT F I B : 3)\n                     (3 ENTER F I B : 2)\n                       (4 ENTER F I B : 1)\n                       (4 EXIT F I B : 1)\n                       (4 ENTER F I B : 0)\n                       (4 EXIT F I B : 1)\n                     (3 EXIT F I B : 2)\n                (2 EXIT F I B : 5)\n                (2 ENTER F I B : 3)\n                     (3 ENTER F I B : 2)\n                       (4 ENTER F I B : 1)\n                       (4 EXIT F I B : 1)\n                       (4 ENTER F I B : 0)\n                       (4 EXIT F I B : 1)\n                     (3 EXIT F I B : 2)\n                     (3 ENTER F I B : 1)\n                     (3 EXIT F I B : 1)\n                (2 EXIT F I B : 3)\n              (1 EXIT F I B : 8)\n              8\n\n\n          We see that ( f i b 5 ) and ( f i b 4) are each computed once, but ( f i b 3 ) is computed\n          twice, ( f i b 2 ) t h r e e t i m e s , a n d ( f i b 1) five times. Below we call (memoize ' f i b ) and\n          repeat the calculation. This time, each computation is done only once. Furthermore,\n\f272                                                                          EFFICIENCY ISSUES\n\n\n      when the computation of ( f i b 5 ) is repeated, the answer is returned immediately\n      with no intermediate computation, and a further call to ( f i b 6 ) can make use of the\n      valueofCfib 5 ) .\n\n         > (memoize ' f i b ) => #<CLOSURE 76626607>\n\n         > ( f i b 5)\n         (1 ENTER F I B : 5)\n           (2 ENTER F I B : 4)\n                (3 ENTER F I B : 3)\n                  (4 ENTER F I B : 2)\n                    (5 ENTER F I B : 1)\n                    (5 EXIT F I B : 1)\n                    (5 ENTER F I B : 0)\n                    (5 EXIT F I B : 1)\n                  (4 EXIT F I B : 2)\n                (3 EXIT F I B : 3)\n           (2 EXIT F I B : 5)\n         (1 EXIT F I B : 8)\n         8\n\n         > ( f i b 5) ^   8\n\n         > ( f i b 6) =>\n         (1 ENTER F I B : 6)\n         (1 EXIT F I B : 13)\n         13\n\n\n      Understanding why this works requires a clear understanding of the distinction\n      between functions and function names. The original (defun f i b . . . ) form does two\n      things: builds a function and stores it as the symbol - f u n c t i on value of f i b. Within\n      that function there are two references to f i b; these are compiled (or interpreted) as\n      instructions to fetch the symbol - f u n c t i on of f i b and apply it to the argument.\n          What memo i ze does is fetch the original function and transform it with memo to a\n      function that, when called, will first look in the table to see if the answer is already\n      known. If not, the original function is called, and a new value is placed in the table.\n      The trick is that memoi ze takes this new function and makes it the symbol - f u n c t i on\n      value of the function name. This means that all the references in the original function\n      will now go to the new function, and the table will be properly checked on each\n      recursive call. One further complication to memo: the function g e t h a s h returns both\n      the value found in the table and an indicator of whether the key was present or not.\n      We use mul t i pi e - va 1 ue - bi nd to capture both values, so that we can distinguish the\n      case when n i l is the value of the function stored in the table from the case where\n      there is no stored value.\n          If you make a change to a memoized function, you need to recompile the original\n      definition, and then redo the call to memoize. In developing your program, rather\n\f9.1 CACHING   RESULTS   OF PREVIOUS       COMPUTATIONS:      MEMOIZATION                   273\n\n\n          than saying (memoize * f ) , it might be easier to wrap appropriate definitions in a\n          memoi ze form as follows:\n\n              (memoize\n               (defun f ( X ) . . . )\n               )\n\n\n\n          Or define a macro that combines defun and memoi ze:\n\n              (defmacro defun-memo (fn args &body body)\n                \"Define a memoized f u n c t i o n . \"\n                *(memoize (defun ,fn , a r g s . ,body)))\n\n              (defun-memo f (x) . . . )\n\n\n          Both of these approaches rely on the fact that defun returns the name of the function\n          defined.\n\n\n                            ( f i b n)     unmemoized     memoized    memoized up to\n                      25      121393               1.1        .010                 0\n                      26      196418               1.8         .001              25\n                      27      317811               2.9        .001               26\n                      28      514229               4.7         .001              27\n                      29      832040               8.2         .001               28\n                      30    1346269               12.4         .001              29\n                      31    2178309               20.1         .001              30\n                      32    3524578               32.4         .001              31\n                      33    5702887               52.5         .001              32\n                      34    9227465               81.5         .001              33\n                      50       2.0el0                --        .014              34\n                     100       5.7e20                --        .031              50\n                     200       4.5e41                --        .096             100\n                     500     2.2el04                 --        .270             200\n                    1000     7.0e208                 --        .596             500\n                    1000     7.0e208                 --        .001            1000\n                    1000     7.0e208                  -        .876                0\n\n\n\n              Now we show a table giving the values of ( f i b ) for certain n, and the time in\n          seconds to compute the value, before and after (memoi ze ' f i b ) . For larger values\n          of , approximations are shown in the table, although f i b actually returns an exact\n          integer. With the unmemoized version, I stopped at  = 34, because the times were\n          getting too long. For the memoized version, even  = 1000 took under a second.\n\f274                                                                           EFFICIENCY    ISSUES\n\n\n\n         Note there are three entries for ( f i b 1000 ). The first entry represents the incre\n      mental computation when the table contains the memoized values up to 500, the\n      second entry shows the time for a table lookup when ( f i b 1000) is already com\n      puted, and the third entry is the time for a complete computation starting with an\n      empty table.\n          It should be noted that there are two general approaches to discussing the effi\n      ciency of an algorithm. One is to time the algorithm on representative inputs, as we\n      did in this table. The other is to analyze the asymptotic complexity of the algorithm. For\n      the f i b problem, an asymptotic analysis considers how long it takes to compute ( f i b\n      ) as  approaches infinity. The notation 0 ( / ( n ) ) is used to describe the complexity.\n      For example, the memoized version f i b is an 0 ( n ) algorithm because the computa\n      tion time is bounded by some constant times n, for any value of n. The unmemoized\n      version, it turns out, is O (1. 7^ ), meaning computing f i b of n+1 can take up to 1.7 times\n      as long as f i b of n. In simpler terms, the memoized version has linear complexity,\n      while the unmemoized version has exponential complexity. Exercise 9.4 (page 308)\n      describes where the 1.7 comes from, and gives a tighter bound on the complexity.\n          The version of memo presented above is inflexible in several ways. First, it only\n      works for functions of one argument. Second, it only returns a stored value for\n      arguments that are e q l , because that is how hash tables work by default. For some\n      applications we want to retrieve the stored value for arguments that are equa 1 . Third,\n      there is no way to delete entries from the hash table. In many applications there are\n      times when it would be good to clear the hash table, either because it has grown too\n      large or because we have finished a set of related problems and are moving on to a\n      new problem.\n          The versions of memo and memoi ze below handle these three problems. They are\n      compatible with the previous version but add three new keywords for the extensions.\n      The name keyword stores the hash table on the property list of that name, so it can\n      be accessed by cl ear-memoi ze. The t e s t kejword tells what kind of hash table to\n      create: eq, e q l , or equal. Finally, the key keyword tells which arguments of the\n      function to index under. The default is the first argument (to be compatible with the\n      previous version), but any combination of the arguments can be used. If you want\n      to use all the arguments, specify 1 dent i t y as the key. Note that if the key is a Ust of\n      arguments, then you will have to use equal hash tables.\n\n          (defun memo (fn name key t e s t )\n            \"Return a memo-function of f n . \"\n            ( l e t ( ( t a b l e (make-hash-table : t e s t t e s t ) ) )\n                ( s e t f (get name 'memo) table)\n                #'(lambda (&rest a r g s )\n                        ( l e t ( ( k (funcall key a r g s ) ) )\n                            (multiple-value-bind (val found-p)\n                                   (gethash k table)\n                               ( i f found-p val\n\f9.2 COMPILING     ONE LANGUAGE          INTO ANOTHER                                                     275\n\n\n\n                                    ( s e t f (gethash k t a b l e ) (apply fn a r g s ) ) ) ) ) ) ) )\n\n                (defun memoize (fn-name &key (key # * f i r s t ) ( t e s t # ' e q l ) )\n                  \"Replace fn-name's global d e f i n i t i o n with a memoized v e r s i o n . \"\n                  ( s e t f (symbol-function fn-name)\n                          (memo (symbol-function fn-name) fn-name key t e s t ) ) )\n\n                (defun clear-memoize (fn-name)\n                  \"Clear the hash table from a memo f u n c t i o n . \"\n                  ( l e t ( ( t a b l e (get fn-name 'memo)))\n                      (when table ( c l r h a s h t a b l e ) ) ) )\n\n\n\n\n          9.2         Compiling One Language into Another\n          In chapter 2 we defined a new language--the language of grammar rules--which was\n          processed by an interpreter designed especially for that language. An interpreter is\n          a program that looks at some data structure representing a \"program\" or sequence\n          of rules of some sort and interprets or evaluates those rules. This is in contrast to a\n          compiler, which translates some set of rules in one language into a program in another\n          language.\n              The function generate was an interpreter for the \"language\" defined by the set of\n          grammar rules. Interpreting these rules is straightforward, but the process is some\n          what inefficient, in that generate must continually search through the *gramma r* to\n          find the appropriate rule, then count the length of the right-hand side, and so on.\n              A compiler for this rule-language would take each rule and translate it into a func\n          tion. These functions could then call each other with no need to search through the\n          *grammar*. We implement this approach with the function compi 1 e - rul e. It makes\n          use of the auxiliary functions one-of and r u l e - l h s and r u l e - r h s from page 40,\n          repeated here:\n\n                (defun r u l e - l h s ( r u l e )\n                  \"The left-hand side of a r u l e . \"\n                  ( f i r s t rule))\n\n                (defun r u l e - r h s ( r u l e )\n                  \"The right-hand side of a r u l e . \"\n                  (rest (rest rule)))\n\n                (defun one-of ( s e t )\n                  \"Pick one element of s e t , and make a l i s t of              it.\"\n                  ( l i s t (random-elt s e t ) ) )\n\f276                                                                                               EFFICIENCY   ISSUES\n\n\n\n          (defun random-elt (choices)\n            \"Choose an element from a l i s t at random.\"\n            ( e l t choices (random (length c h o i c e s ) ) ) )\n\n\n      The function c o m p i l e - r u l e turns a rule into a function definition by building up\n      Lisp code that implements all the actions that generate would take in interpreting\n      the rule. There are three cases. If every element of the right-hand side is an atom,\n      then the rule is a lexical rule, which compiles into a call to one-of to pick a word at\n      random. If there is only one element of the right-hand side, then bui 1 d - code is called\n      to generate code for it. Usually, this will be a call to append to build up a list. Finally,\n      if there are several elements in the right-hand side, they are each turned into code\n      by b u i l d - c o d e ; are given a number by b u i l d - c a s e s ; and then a c a s e statement is\n      constructed to choose one of the cases.\n\n          (defun compile-rule ( r u l e )\n            \"Translate a grammar rule into a LISP function d e f i n i t i o n . \"\n            (let ((rhs (rule-rhs rule)))\n               '(defun , ( r u l e - l h s r u l e ) ( )\n                     .(cond ((every #*atom r h s ) *(one-of                   '.rhs))\n                                ( ( l e n g t h = l r h s ) (build-code ( f i r s t    rhs)))\n                                (t ' ( c a s e (random . ( l e n g t h r h s ) )\n                                         .�(build-cases 0 r h s ) ) ) ) ) ) )\n\n          (defun b u i l d - c a s e s (number choices)\n            \"Return a l i s t of c a s e - c l a u s e s \"\n            (when choices\n              (cons ( l i s t number (build-code ( f i r s t c h o i c e s ) ) )\n                        ( b u i l d - c a s e s ( + number 1) ( r e s t c h o i c e s ) ) ) ) )\n\n          (defun build-code (choice)\n            \"Append together multiple c o n s t i t u e n t s \"\n            (cond ( ( n u l l choice) n i l )\n                  ((atom choice) ( l i s t choice))\n                  ( ( l e n g t h = l choice) choice)\n                  (t '(append .�(mapcar # ' b u i l d - c o d e c h o i c e ) ) ) ) )\n\n          (defun length=l ( x )\n            \" I s X a l i s t of length 1 ? \"\n            (and (consp x) (null ( r e s t x ) ) ) )\n\n\n      The Lisp code built by c o m p i l e - r u l e must be compiled or interpreted to make it\n      available to the Lisp system. We can do that with one of the following forms.\n      Normally we would want to call compi 1 e, but during debugging it may be easier\n      not to.\n\f9.2 COMPILING     ONE LANGUAGE          INTO ANOTHER                                               277\n\n\n\n                ( d o l i s t ( r u l e ^grammar*) (eval (compile-rule r u l e ) ) )\n                ( d o l i s t ( r u l e *grammar*) (compile (eval (compile-rule r u l e ) ) ) )\n\n\n          One frequent way to use compilation is to define a macro that expands into the code\n          generated by the compiler. That way, we just type in calls to the macro and don't\n          have to worry about making sure all the latest rules have been compiled. We might\n          implement this as follows:\n\n\n                (defmacro defrule (&rest rule)\n                  \"Define a grammar r u l e \"\n                  (compile-rule r u l e ) )\n\n\n                (defrule Sentence - > (NP VP))\n                (defrule NP - > (Art Noun))\n                (defrule VP - > (Verb NP))\n                (defrule Art - > the a)\n                (defrule Noun - > man ball woman t a b l e )\n                (defrule Verb - > h i t took saw l i k e d )\n\n\n          Actually, the choice of using one big list of rules (like * g r amma r *) versus using individ\n          ual macros to define rules is independent of the choice of compiler versus interpreter.\n          Wecould justas easily definedef r u l e simply to push the ruleonto *grammar*. Macros\n          like def rul e are useful when you want to define rules in different places, perhaps in\n          several separate files. The def parameter method is appropriate when all the rules\n          can be defined in one place.\n              We can see the Lisp code generated by compi 1 e - rul e in two ways: by passing it\n          a rule directly:\n\n\n                > (compile-rule '(Sentence - > (NP V P ) ) )\n                (DEFUN SENTENCE ()\n                  (APPEND (NP) (VP)))\n\n\n                > (compile-rule '(Noun - > man ball woman t a b l e ) )\n                (DEFUN NOUN ()\n                  (ONE-OF '(MAN BALL WOMAN TABLE)))\n\n\n          or by macroexpanding a def rul e expression. The compiler was designed to produce\n          the same code we were writing in our first approach to the generation problem (see\n          page 35).\n\f278                                                                               EFFICIENCY   ISSUES\n\n\n\n         > (macroexpand ' ( d e f r u l e A d j * - > () Adj (AdJ A d j * ) ) )\n         (DEFUN ADJ* ()\n           (CASE (RANDOM 3)\n             (0 NIL)\n             (1 (ADJ))\n             (2 (APPEND (ADJ) ( A D J * ) ) ) ) )\n\n\n      Interpreters are usually easier to write than compilers, although in this case, even\n      the compiler was not too difficult. Interpreters are also inherently more flexible than\n      compilers, because they put off making decisions until the last possible moment.\n      For example, our compiler considers the right-hand side of a rule to be a list of words\n      only if every element is an atom. In all other cases, the elements are treated as\n      nonterminals. This could cause problems if we extended the definition of Noun to\n      include the compound noun \"chow chow\":\n\n         (defrule Noun - > man ball woman table (chow chow))\n\n\n      The rule would expand into the following code:\n\n         (DEFUN NOUN ()\n            (CASE (RANDOM 5)\n              (0 (MAN))\n              (1 ( B A L D )\n              (2 (WOMAN))\n              (3 (TABLE))\n              (4 (APPEND (CHOW) (CHOW)))))\n\n\n      The problem is that ma  and b a l l and all the others are suddenly treated as functions,\n      not as literal words. So we would get a run-time error notifying us of undefined\n      functions. The equivalent rule would cause no trouble for the interpreter, which waits\n      until it actually needs to generate a symbol to decide if it is a word or a nonterminal.\n      Thus, the semantics of rules are different for the interpreter and the compiler, and\n      we as program implementors have to be very careful about how we specify the actual\n      meaning of a rule. In fact, this was probably a bug in the interpreter version, since\n      it effectively prohibits words like \"noun\" and \"sentence\" from occurring as words if\n      they are also the names of categories. One possible resolution of the conflict is to\n      say that an element of a right-hand side represents a word if it is an atom, and a list\n      of categories if it is a list. If we did indeed settle on that convention, then we could\n      modify both the interpreter and the compiler to comply with the convention. Another\n      possibility would be to represent words as strings, and categories as symbols.\n           The flip side of losing run-time flexibility is gaining compile-time diagnostics. For\n      example, it turns out that on the Common Lisp system I am currently using, I get\n      some useful error messages when I try to compile the buggy version of Noun:\n\f9.2 COMPILING      ONE LANGUAGE             INTO ANOTHER                                     279\n\n\n\n                > (defrule Noun - > man ball woman table (chow chow))\n                The following functions were referenced but d o n ' t seem d e f i n e d :\n                 CHOW referenced by NOUN\n                 TABLE referenced by NOUN\n                 WOMAN referenced by NOUN\n                 BALL referenced by NOUN\n                 MAN referenced by NOUN\n                NOUN\n\n\n          Another problem with the compilation scheme outlined here is the possibility of name\n          clashes. Under the interpretation scheme, the only names used were the function\n          g e n e r a t e and the variable ^grammar*. With compilation, every left-hand side of a\n          rule becomes the name of a function. The grammar writer has to make sure he or\n          she is not using the name of an existing Lisp function, and hence redefining it. Even\n          worse, if more than one grammar is being developed at the same time, they cannot\n          have any functions in common. If they do, the user will have to recompile with\n          every switch from one grammar to another. This may make it difficult to compare\n          grammars. The best away around this problem is to use the Common Lisp idea of\n          packages, but for small exercises name clashes can be avoided easily enough, so we\n          will not explore packages until section 24.1.\n               The major advantage of a compiler is speed of execution, when that makes a\n          difference. For identical grammars running in one particular implementation of\n          Common Lisp on one machine, our interpreter generates about 75 sentences per\n          second, while the compiled approach turns out about 200. Thus, it is more than twice\n          as fast, but the difference is negligible unless we need to generate many thousands of\n          sentences. In section 9.6 we will see another compiler with an even greater speed-up.\n               The need to optimize the code produced by your macros and compilers ultimately\n          depends on the quality of the underlying Lisp compiler. For example, consider the\n          following code:\n\n                > (defun f l (n 1)\n                    (let ((11 ( f i r s t D )\n                            (12 (second 1 ) ) )\n                      (expt (* 1 (+  0 ) )\n                               (- 4 (length ( l i s t 11 1 2 ) ) ) ) ) )\n                Fl\n\n                > (defun f2 (n 1) (*  n ) )             F2\n\n                > (disassemble       'fl)\n                   6 PUSH                   ARG 10      ; \n                   7 MOVEM                  PDL-PUSH\n                   8 *                      PDL-POP\n                   9 RETURN                 PDL-POP\n                Fl\n\f280                                                                             EFFICIENCY     ISSUES\n\n\n\n          > (disassemble ' f 2 )\n             6 PUSH                ARGO     ; \n             7 MOVEM               PDL-PUSH\n             8 *                   PDL-POP\n             9 RETURN              PDL-POP\n          F2\n\n\n      This particular Lisp compiler generates the exact same code for f 1 and f 2. Both\n      fimctions square the argument n, and the four machine instructions say, \"Take the\n      0th argument, make a copy of it, multiply those two numbers, and return the result.\"\n      It's clear the compiler has some knowledge of the basic Lisp functions. In the case\n      of f 1, it was smart enough to get rid of the local variables 11 and 12 (and their\n      initialization), as well as the calls to f 1 r s t , second, 1 ength, and 1 i s t and most of the\n      arithmetic. The compiler could do this because it has knowledge about the functions\n      1 ength and 1 i s t and the arithmetic functions. Some of this knowledge might be in\n      the form of simplification rules.\n           As a user of this compiler, there's no need for me to write clever macros or\n      compilers that generate streamlined code as seen in f 2; I can blindly generate code\n      with possible inefficiencies Uke those in f 1, and assume that the Lisp compiler\n      will cover up for my laziness. With another compiler that didn't know about such\n      optimizations, I would have to be more careful about the code I generate.\n\n\n\n      9.3       Delaying Computation\n      Back on page 45, we saw a program to generate all strings derivable from a grammar.\n      One drawback of this program was that some grammars produce an infinite number\n      of strings, so the program would not terminate on those grammars.\n          It turns out that we often want to deal with infinite sets. Of course, we can't\n      enumerate all the elements of an infinite set, but we should be able to represent the\n      set and pick elements out one at a time. In other words, we want to be able to specify\n      how a set (or other object) is constructed, but delay the actual construction, perhaps\n      doing it incrementally over time. This soimds like a job for closures: we can specify\n      the set constructor as a function, and then call the function some time later. We will\n      implement this approach with the sjmtax used in Scheme--the macro del ay builds a\n      closure to be computed later, and the function force calls that function and caches\n      away the value. We use structures of type del ay to implement this. A delay structure\n      has two fields: the value and the function. Initially, the value field is undefined, and\n      the function field holds the closure that will compute the value. The first time the\n      delay is forced, the function is called, and its result is stored in the value field. The\n      function field is then set to nil to indicate that there is no need to call the function\n      again. The function force checks if the fimction needs to be called, and returns the\n\f93   DELAYING    COMPUTATION                                                                   281\n\n\n\n           value. If force is passed an argument that is not a delay, it just returns the argument.\n\n\n\n                (defstruct delay (value n i l ) ( f u n c t i o n n i l ) )\n\n                (defmacro delay (&rest body)\n                  \"A computation that can be executed l a t e r by FORCE.\"\n                  *(make-delay : f u n c t i o n #'(lambda ( ) . .body)))\n\n                (defun force (x)\n                  \"Find the value of x . by computing i f i t i s a d e l a y . \"\n                  ( i f (not (delay-p x ) )\n                        \n                        (progn\n                          (when ( d e l a y - f u n c t i o n x )\n                            ( s e t f (delay-value x)\n                                      (funcall ( d e l a y - f u n c t i o n x ) ) )\n                            ( s e t f ( d e l a y - f u n c t i o n x) n i l ) )\n                          (delay-value x ) ) ) )\n\n\n           Here's an example of the use of del ay. The list  is constructed using a combination\n           of normal evaluation and delayed evaluation. Thus, the 1 is printed when  is created,\n           but the 2 is not:\n\n                > ( s e t f X ( l i s t ( p r i n t 1) (delay ( p r i n t 2 ) ) ) )\n                1\n                (1 #S(DELAY .-FUNCTION (LAMBDA () (PRINT 2 ) ) ) )\n\n\n           The second element is evaluated (and printed) when it is forced. But then forcing it\n           again just retrieves the cached value, rather than calling the function again:\n\n                > (force (second x ) )\n                2\n                2\n\n                > X = > ( 1 #S(DELAY :VALUE 2 ) )\n\n                > (force (second x ) )             2\n\n\n           Now let's see how delays can be used to build infinite sets. An infinite set will be\n           considered a special case of what we will call a pipe: a list with a f i r s t component\n           that has been computed, and a r e s t component that is either a normal list or a\n           delayed value. Pipes have also been called delayed Usts, generated lists, and (most\n           commonly) streams. We will use the term pipe because stream already has a meaning\n           in Common Lisp. The book Artificial Intelligence Programming (Charniak et al. 1987)\n\f282                                                                                 EFFICIENCY   ISSUES\n\n\n\n      also calls these structures pipes, reserving streams for delayed structures that do not\n      cache computed results.\n          To distinguish pipes from lists, we will use the accessors head and t a i 1 instead\n      of f i r s t and r e s t . We will also use empty-pipe instead of ni 1, make-pipe instead\n      of cons, and p i p e - e l t instead of el t. Note that make-pipe is a macro that delays\n      evaluation of the tail.\n\n         (defmacro make-pipe (head t a i l )\n           \"Create a pipe by evaluating head and delaying t a i l . \"\n           '(cons .head (delay . t a i l ) ) )\n\n         (defconstant empty-pipe n i l )\n\n         (defun head (pipe) ( f i r s t p i p e ) )\n         (defun t a i l ( p i p e ) ( f o r c e ( r e s t p i p e ) ) )\n\n         (defun p i p e - e l t (pipe i )\n           \"The i-th element of a pipe. 0-based\"\n           ( i f (= i 0)\n                 (head pipe)\n                 ( p i p e - e l t ( t a i l pipe) (- i 1 ) ) ) )\n\n\n      Here's a function that can be used to make a large or infinite sequence of integers\n      with delayed evaluation:\n\n         (defun integers (&optional ( s t a r t 0) end)\n           \"A pipe of integers from START to END.\n           I f END i s n i l . t h i s i s an i n f i n i t e p i p e . \"\n           ( i f (or (null end) (<= s t a r t end))\n                 (make-pipe s t a r t ( i n t e g e r s (+ s t a r t 1) end))\n                  nil))\n\n\n      And here is an example of its use. The pipe c represents the numbers from 0 to in\n      finity. When it is created, only the zeroth element, 0, is evaluated. The computation\n      of the other elements is delayed.\n\n         > (setf c (integers 0)) ^                   (0 . #S(DELAY :FUNCTION #<CLOSURE -77435477>))\n\n         > ( p i p e - e l t c 0) => 0\n\n\n      Calling pi pe - el t to look at the third element causes the first through third elements\n      to be evaluated. The numbers 0 to 3 are cached in the correct positions, and further\n      elements remain unevaluated. Another call to pi pe-el t with a larger index would\n      force them by evaluating the delayed function.\n\f9.3 DELAYINC    COMPUTATION                                                                                       283\n\n\n\n               > ( p i p e - e l t c 3) ^    3\n\n               > c =^\n               (0 . #S(DELAY\n                            :VALUE\n                            (1 . #S(DELAY\n                                            :VALUE\n                                            (2 . #S(DELAY\n                                                     :VALUE\n                                                     (3 . #S(DELAY\n                                                                 :FUNCTION\n                                                                 #<CLOSURE - 7 7 4 3 2 7 2 4 � ) ) ) ) ) ) )\n\n\n          While this seems to work fine, there is a heavy price to pay. Every delayed value must\n          be stored in a two-element structure, where one of the elements is a closure. Thus,\n          there is some storage wasted. There is also some time wasted, as ta  or pi p e - e l t\n          must traverse the structures.\n              An alternate representation for pipes is as ( value. closure) pairs, where the closure\n          values are stored into the actual cons cells as they are computed. Previously we\n          needed structures of type del ay to distinguish a delayed from a nondelayed object,\n          but in a pipe we know the rest can be only one of three things: nil, a list, or a delayed\n          value. Thus, we can use the closures directly instead of using del ay structures, if we\n          have some way of distinguishing closures from lists. Compiled closures are atoms, so\n          they can always be distinguished from lists. But sometimes closures are implemented\n          as lists beginning with 1 ambda or some other implementation-dependent symbol.^\n          The built-in function f uncti onp is defined to be true of such lists, as well as of all\n          symbols and all objects returned by compi 1 e. But using f uncti onp means that we\n          can not have a pipe that includes the symbol 1 ambda as an element, because it will be\n          confused for a closure:\n\n               > (functionp ( l a s t ' ( t h e t a iota kappa lambda))) ^ \n\n\n          If we consistently use compiled functions, then we could eliminate the problem by\n          testing with the built-in predicate compi 1 e d - f uncti on-p. The following definitions\n          do not make this assumption:\n\n               (defmacro make-pipe (head t a i l )\n                  \"Create a pipe by evaluating head and delaying t a i l . \"\n                  '(cons .head #'(lambda ()           .tail)))\n\n\n               ^In K C L , the symbol 1 ambda -cl osure is used, and in Allegro, it is e x c l : . 1 exi cal - cl osure.\n\f284                                                                                    EFFICIENCY   ISSUES\n\n\n\n         (defun t a i l (pipe)\n           \"Return t a i l of pipe or l i s t , and d e s t r u c t i v e l y update\n           the t a i l i f i t i s a f u n c t i o n . \"\n           ( i f (functionp ( r e s t p i p e ) )\n                 ( s e t f ( r e s t pipe) (funcall ( r e s t p i p e ) ) )\n                 (rest pipe)))\n\n\n      Everything else remains the same. If we recompile i n t e g e r s (because it uses the\n      macro ma ke - pi pe), we see the following behavior. First, creation of the infinite pipe\n      c is similar:\n\n         > ( s e t f c ( i n t e g e r s 0))   (0 , #<CLOSURE 77350123>)\n\n         > ( p i p e - e l t c 0) => 0\n\n\n      Accessing an element of the pipe forces evaluation of all the intervening elements,\n      and as before leaves subsequent elements unevaluated:\n\n         > ( p i p e - e l t c 5) =^ 5\n\n         > c =^ (0 1 2 3 4 5 . #<CLOSURE 77351636�\n\n\n      Pipes can also be used for finite lists. Here we see a pipe of length 1 1 :\n\n         > ( s e t f i (integers 0 10)) =^ (0 . #<CLOSURE 77375357>)\n\n         > ( p i p e - e l t i 10) ^ 10\n\n         > ( p i p e - e l t i 11) => NIL\n\n         > i ^      (0 1 2 3 4 5 6 7 8 9 10)\n\n\n      Clearly, this version wastes less space and is much neater about cleaning up after\n      itself. In fact, a completely evaluated pipe turns itself into a list! This efficiency was\n      gained at the sacrifice of a general principle of program design. Usually we strive\n      to build more complicated abstractions, like pipes, out of simpler ones, like delays.\n      But in this case, part of the functionality that delays were providing was duplicated\n      by the cons cells that make up pipes, so the more efficient implementation of pipes\n      does not use delays at all.\n          Here are some more utility functions on pipes:\n\n          (defun enumerate (pipe &key count key ( r e s u l t p i p e ) )\n            \"Go through a l l (or count) elements of pipe,\n            p o s s i b l y applying the KEY f u n c t i o n . (Try P R I N T . ) \"\n                 Returns RESULT, which d e f a u l t s to the pipe i t s e l f ,\n            ( i f (or (eq pipe empty-pipe) (eql count 0 ) )\n\f9.3 DELAYING   COMPUTATION                                                                    285\n\n\n\n                        result\n                        (progn\n                          (unless (null key) (funcall key (head p i p e ) ) )\n                          (enumerate ( t a i l pipe) :count ( i f count (- count 1 ) )\n                                     :key key : r e s u l t r e s u l t ) ) ) )\n\n               (defun f i l t e r (pred pipe)\n                 \"Keep only items i n pipe s a t i s f y i n g p r e d . \"\n                 ( i f (funcall pred (head pipe))\n                       (make-pipe (head pipe)\n                                        ( f i l t e r pred ( t a i l p i p e ) ) )\n                       ( f i l t e r pred ( t a i l p i p e ) ) ) )\n\n\n          And here's an application of pipes: generating prime numbers using the sieve of\n          Eratosthenes algorithm:\n\n               (defun sieve (pipe)\n                 (make-pipe (head pipe)\n                            ( f i l t e r #'(lambda (x) ( / = (mod  (headpipe)) 0 ) )\n                                          (sieve ( t a i l pipe)))))\n\n               (defvar *primes* ( s i e v e ( i n t e g e r s 2 ) ) )\n\n\n\n\n               > *primes* ^         (2 . #<CLOSURE 3075345>)\n\n               > (enumerate *primes* icount 10) =^\n               (2 3 5 7 11 13 17 19 23 29 31 . #<CLOSURE 5224472�\n\n\n          Finally, let's return to the problem of generating all strings in a grammar. First we're\n          going to need some more utility functions:\n\n               (defun map-pipe (fn pipe)\n                 \"Map fn over pipe, delaying a l l but the f i r s t fn c a l l . \"\n                 ( i f (eq pipe empty-pipe)\n                       empty-pipe\n                       (make-pipe (funcall fn (head pipe))\n                                  (map-pipe fn ( t a i l p i p e ) ) ) ) )\n\n               (defun append-pipes (x y )\n                 \"Return a pipe that appends the elements of  and y . \"\n                 ( i f (eq X empty-pipe)\n                       y\n                       (make-pipe (head x)\n                                  (append-pipes ( t a i l x) y ) ) ) )\n\f286                                                                                            EFFICIENCY   ISSUES\n\n\n\n         (defun mappend-pipe (fn pipe)\n           \" L a z i l y map fn over pipe, appending r e s u l t s . \"\n           (if   (eq pipe empty-pipe)\n                 empty-pipe\n                 (let         ( ( X (funcall fn (head p i p e ) ) ) )\n                       (make-pipe (head x)\n                                              (append-pipes ( t a i l x)\n                                                                  (mappend-pipe\n                                                                     fn ( t a i l    pipe)))))))\n\n\n      Now we can rewrite generate-all and combine-all to use pipes instead of lists.\n      Everything else is the same as on page 45.\n\n         (defun generate-all                 (phrase)\n           \"Generate a random sentence or phrase\"\n           (if   ( l i s t p phrase)\n                 (if         (null phrase)\n                             (list    nil)\n                             (combine-all-pipes\n                              (generate-all        ( f i r s t phrase))\n                              (generate-all        (rest    phrase))))\n                 (let         ((choices ( r u l e - r h s   (assoc phrase *grammar*))))\n                       (if     choices\n                              (mappend-pipe #*generate-all            choices)\n                              (list (list       phrase))))))\n\n\n         (defun combine-all-pipes (xpipe ypipe)\n           \"Return a pipe of pipes formed by appending a y to an x\"\n           ; ; In other words, form the c a r t e s i a n                 product,\n           (mappend-pipe\n              #'(lambda (y)\n                       (map-pipe #'(lambda (x) (append-pipes  y ) )\n                                             xpipe))\n             ypipe))\n\n\n      With these definitions, here's the pipe of all sentences from *grammar2* (from\n      page 43):\n\n         > ( s e t f s s (generate-all             'sentence))\n         ((THE   . #<CLOSURE 27265720>) . #<CLOSURE 27266035�\n\f9.3 DELAYING   COMPUTATION                                                                                  287\n\n\n\n               > (enumerate s s rcount 5) =i\n                                           >\n               ((THE . #<CLOSURE 27265720>)\n                (A . #<CLOSURE 27273143�\n                (THE . #<CLOSURE 27402545>)\n                (A . #<CLOSURE 27404344>)\n                (THE . #<CLOSURE 27404527>)\n                (A . #<CLOSURE 27405473� . #<CLOSURE 27405600>)\n\n               > (enumerate s s .-count 5 :key #'enumerate)\n               ((THE MAN HIT THE MAN)\n                (A MAN HIT THE MAN)\n                (THE BIG MAN HIT THE MAN)\n                (A BIG MAN HIT THE MAN)\n                (THE LITTLE MAN HIT THE MAN)\n                (THE . #<CLOSURE 27423236>) . #<CL0SURE 27423343�\n\n               > (enumerate ( p i p e - e l t s s 200))\n               (THE ADIABATIC GREEN BLUE MAN HIT THE MAN)\n\n\n          While we were able to represent the infinite set of sentences and enumerate instances\n          of it, we still haven't solved all the problems. For one, this enumeration will never\n          get to a sentence that does not have \"hit the man\" as the verb phrase. We will see\n          longer and longer lists of adjectives, but no other change. Another problem is that\n          left-recursive rules will still cause infinite loops. For example, if the expansion for\n          Adj*hadbeen (Adj*           -> (Adj*Adj)        ( ) ) instead of ( A d j *   -> ()   (Adj A d j * ) ) ,\n          then the enumeration would never terminate, because pipes need to generate a first\n          element.\n              We have used delays and pipes for two main purposes: to put off until later\n          computations that may not be needed at all, and to have an expHcit representation of\n          large or infinite sets. It should be mentioned that the language Prolog has a different\n          solution to the first problem (but not the second). As we shall see in chapter 1 1 , Prolog\n          generates solutions one at a time, automatically keeping track of possible backtrack\n          points. Where pipes allow us to represent an infinite number of alternatives in the\n          data, Prolog allows us to represent those alternatives in the program itself.\n\n\n          Exercise 9.1 [h] When given a function f and a pipe p. mappend-pipe returns a\n          new pipe that will eventually enumerate all of ( f ( f i r s t  ) ) , then all of ( f (second\n           ) ) , and so on. This is deemed \"unfair\" if ( f ( f i r s t  ) ) has an infinite number of\n          elements. Define a function that will fairly interleave elements, so that all of them are\n          eventually enumerated. Show that the function works by changing generate - a 11 to\n          work with it.\n\f288                                                                          EFFICIENCY   ISSUES\n\n\n\n      9.4      Indexing Data\n\n      Lisp makes it very easy to use lists as the universal data structure. A list can represent\n      a set or an ordered sequence, and a list with sublists can represent a tree or graph.\n      For rapid prototyping, it is often easiest to represent data in lists, but for efficiency\n      this is not always the best idea. To find an element in a list of length  will take n/2\n      steps on average. This is true for a simple list, an association list, or a property list.\n      If  can be large, it is worth looking at other data structures, such as hash tables,\n      vectors, property lists, and trees.\n          Picking the right data structure and algorithm is as important in Lisp as it is in\n      any other programming language. Even though Lisp offers a wide variety of data\n      structures, it is often worthwhile to spend some effort on building just the right data\n      structure for frequently used data. For example. Lisp's hash tables are very general\n      and thus can be inefficient. You may want to build your own hash tables if, for\n      example, you never need to delete elements, thus making open hashing an attractive\n      possibility. We will see an example of efficient indexing in section 9.6 (page 297).\n\n\n\n\n      9.5      Instrumentation: Deciding What\n               to Optimize\n\n      Because Lisp is such a good rapid-prototyping language, we can expect to get a\n      working implementation quickly. Before we go about trying to improve the efficiency\n      of the implementation, it is a good idea to see what parts are used most often.\n      Improving little-used features is a waste of time.\n          The minimal support we need is to count the number of calls to selected functions,\n      and then print out the totals. This is called profiling the functions.^ For each function\n      to be profiled, we change the definition so that it increments a counter and then calls\n      the original function.\n          Most Lisp systems have some built-in profiling mechanism. If your system has\n      one, by all means use it. The code in this section is provided for those who lack such\n      a feature, and as an example of how functions can be manipulated. The following is\n      a simple profiling facility. For each profiled function, it keeps a count of the number\n      of times it is called under the prof i 1 e - count property of the function's name.\n\n\n         ^The terms metering and monitoring are sometimes used instead of profiling.\n\f9.5 INSTRUMENTATION:         DECIDING         WHAT TO OPTIMIZE                                                289\n\n\n\n              (defun p r o f i l e l   (fn-name)\n                 \"Make the function count how often i t                    i s called\"\n                     F i r s t save away the o l d , u n p r o f i l e d function\n                     Then make the name be a new function that increments\n                     a counter and then c a l l s the o r i g i n a l function\n                 ( l e t ( ( f n (symbol-function fn-name)))\n                    ( s e t f (get fn-name ' u n p r o f i l e d - f n ) fn)\n                    ( s e t f (get fn-name ' p r o f i l e - c o u n t ) 0)\n                    ( s e t f (symbol-function fn-name)\n                             ( p r o f i l e d - f n fn-name f n ) )\n                   fn-name))\n\n              (defun u n p r o f i l e l (fn-name)\n                 \"Make the function stop counting how often i t                        is called.\"\n                 ( s e t f (symbol-function fn-name) (get fn-name ' u n p r o f i l e d - f n ) )\n                fn-name)\n\n              (defun p r o f i l e d - f n (fn-name fn)\n                 \"Return a function that increments the count.\"\n                #'(lambda (&rest a r g s )\n                       ( i n c f (get fn-name ' p r o f i l e - c o u n t ) )\n                       (apply fn a r g s ) ) )\n\n              (defun p r o f i l e - c o u n t (fn-name) (get fn-name ' p r o f i l e - c o u n t ) )\n\n              (defun p r o f i l e - r e p o r t (fn-names �optional (key # ' p r o f i l e - c o u n t ) )\n                \"Report p r o f i l i n g s t a t i s t i c s on given f u n c t i o n s . \"\n                (loop for name i n ( s o r t fn-names # ' > :key key) do\n                          (format t \"~&~7D ~A\" ( p r o f i l e - c o u n t name) name)))\n\n\n          That's all we need for the bare-bones functionality. However, there are a few ways\n          we could improve this. First, it would be nice to have macros that, like t r a c e and\n          untrace, allow the user to profile multiple functions at once and keep track of what\n          has been profiled. Second, it can be helpful to see the length of time spent in each\n          function, as well as the number of calls.\n              Also, it is important to avoid profiling a function twice, since that would double\n          the number of calls reported without alerting the user of any trouble. Suppose we\n          entered the following sequence of commands:\n\n              (defun f ( X ) (g x ) )\n              (profilel       'f)\n              (profilel       'f)\n\n\n          Then the definition of f would be roughly:\n\f290                                                                                                     EFFICIENCY   ISSUES\n\n\n\n          (lambda (&rest a r g s )\n             ( i n c f (get ' f ' p r o f i l e - c o u n t ) )\n             (apply #'(lambda (&rest a r g s )\n                            ( i n c f (get ' f ' p r o f i l e - c o u n t ) )\n                            (apply #'(lambda (x) (g x ) )\n                                             args))\n                        args))\n\n\n      The result is that any call to f will eventually call the original f , but only after\n      incrementing the count twice.\n          Another consideration is what happens when a profiled function is redefined by\n      the user. The only way we could ensure that a redefined function would continue\n      profiling would be to change the definition of the macro defun to look for functions\n      that should be profiled. Changing system functions like defun is a risky prospect,\n      and in Common Lisp the Language, 2d edition, it is explicitly disallowed. Instead,\n      we'll do the next best thing: ensure that the next call to p r o f i 1 e will reprofile any\n      functions that have been redefined. We do this by keeping track of both the original\n      unprofiled function and the profiled function. We also keep a list of all functions\n      that are currently profiled.\n          In addition, we will count the amount of time spent in each function. However,\n      the user is cautioned not to trust the timing figures too much. First, they include the\n      overhead cost of the profiling facility. This can be significant, particularly because\n      the facility conses, and thus can force garbage collections that would not otherwise\n      have been done. Second, the resolution of the system clock may not be fine enough\n      to make accurate timings. For functions that take about 1/10 of a second or more, the\n      figures will be reliable, but for quick functions they may not be.\n          Here is the basic code for prof i 1 e and unprof i 1 e:\n\n          (defvar * p r o f i l e d - f u n c t i o n s * n i l\n            \"Function names that are c u r r e n t l y p r o f i l e d \" )\n\n          (defmacro p r o f i l e (&rest fn-names)\n            \" P r o f i l e fn-names. With no a r g s , l i s t p r o f i l e d f u n c t i o n s . \"\n            '(mapcar # ' p r o f i l e l\n                            (setf *profiled-functions*\n                                   (union * p r o f i l e d - f u n c t i o n s * ' , f n - n a m e s ) ) ) )\n\n          (defmacro u n p r o f i l e (&rest fn-names)\n            \"Stop p r o f i l i n g fn-names. With no a r g s , stop a l l p r o f i l i n g . \"\n            '(progn\n               (mapcar # ' u n p r o f i l e l\n                           , ( i f fn-names \" , f n - n a m e s ' * p r o f i l e d - f u n c t i o n s * ) )\n               (setf *profiled-functions*\n                      . ( i f (null fn-names)\n                                  nil\n\f9.5 INSTRUMENTATION:       DECIDING      WHAT     TO OPTIMIZE                                         291\n\n\n\n                                  '(set-difference *profiled-functions*\n                                                   *,fn-names)))))\n\n\n          The idiom * ' , f n - n a m e s deserves comment, since it is common but can be con\n          fusing at first. It may be easier to understand when written in the equivalent form\n           ' (quote , f n - n a m e s ) . As always, the backquote builds a structure with both constant\n          and evaluated components. In this case, the quote is constant and the variable\n          fn-names is evaluated. In MacLisp, the function kwote was defined to serve this\n          purpose:\n\n              (defun kwote (x) ( l i s t 'quote x ) )\n\n\n          Now we need to change p r o f i 1 e l and unprof i 1 e l to do the additional bookkeeping:\n          For p r o f i 1 e l , there are two cases. If the user does a p r o f i 1 e l on the same function\n          name twice in a row, then on the second time we will notice that the current function\n          is the same as the functioned stored under the p r o f i l e d - f n property, so nothing\n          more needs to be done. Otherwise, we create the profiled function, store it as the\n          current definition of the name under the p r o f i 1 e d - f  property, save the unprofiled\n          function, and initialize the counts.\n\n              (defun p r o f i l e l (fn-name)\n                \"Make the function count how often i t i s c a l l e d \"\n                      F i r s t save away the o l d , u n p r o f i l e d function\n                      Then make the name be a new function that increments\n                      a counter and then c a l l s the o r i g i n a l function\n                ( l e t ( ( f n (symbol-function fn-name)))\n                    (unless (eq fn (get fn-name ' p r o f i l e d - f n ) )\n                       ( l e t ((new-fn ( p r o f i l e d - f n fn-name f n ) ) )\n                            ( s e t f (symbol-function fn-name) new-fn\n                                      (get fn-name ' p r o f i l e d - f n ) new-fn\n                                      (get fn-name ' u n p r o f i l e d - f n ) fn\n                                      (get fn-name ' p r o f i l e - t i m e ) 0\n                                      (get fn-name ' p r o f i l e - c o u n t ) 0 ) ) ) )\n                fn-name)\n\n              (defun u n p r o f i l e l (fn-name)\n                \"Make the function stop counting how often i t i s c a l l e d . \"\n                ( s e t f (get fn-name ' p r o f i l e - t i m e ) 0)\n                ( s e t f (get fn-name ' p r o f i l e - c o u n t ) 0)\n                (when (eq (symbol-function fn-name) (get fn-name ' p r o f i l e d - f n ) )\n                    ; ; normal case: restore u n p r o f i l e d version\n                    ( s e t f (symbol-function fn-name)\n                              (get fn-name ' u n p r o f i l e d - f n ) ) )\n                fn-name)\n\f292                                                                                                 EFFICIENCY   ISSUES\n\n\n\n      Now we look into the question of timing. There is a built-in Common Lisp func\n      tion, g e t - i n t e r n a l - r e a l -time, that returns the elapsed time since the Lisp ses\n      sion started. Because this can quickly become a bignum, some implementations\n      provide another timing function that wraps around rather than increasing forever,\n      but which may have a higher resolution than g e t - i n t e r n a l - real - time. For ex\n      ample, on TI Explorer Lisp Machines, g e t - i n t e r n a l - r e a l - t i m e measures 1/60-\n      second intervals, while time:microsecond-time measures l/l,000,000-second in\n      tervals, but the value returned wraps around to zero every hour or so. The func\n      tion t i m e : m i c r o s e c o n d - t i m e - d i f f e r e n c e is used to compare two of these num\n      bers with compensation for wraparound, as long as no more than one wraparound\n      has occurred.\n          In the code below, I use the conditional read macro characters #+ and # - to define\n      the right behavior on both Explorer and non-Explorer machines. We have seeen\n      that # is a special character to the reader that takes different action depending on\n      the following character. For example, # ' f  is read as ( f uncti on f  ). The character\n      sequence #+ is defined so that ^+feature expression reads as expression if the feature is\n      defined in the current implementation, and as nothing at all if it is not. The sequence\n      #- acts in just the opposite way. For example, on a TI Explorer, we would get the\n      following:\n\n          > ' ( h i #+TI t #+Symbolics s #-Explorer e #-Mac m) ^                                  (HI  )\n\n\n      The conditional read macro characters are used in the following definitions:\n\n          (defun g e t - f a s t - t i m e ( )\n            \"Return the elapsed time. This may wrap around;\n            use FAST-TIME-DIFFERENCE to compare.\"\n            #+Explorer (time:microsecond-time)                           ; do t h i s on an Explorer\n            #-Explorer ( g e t - i n t e r n a l - r e a l - t i m e ) ) ; do t h i s on a non-Explorer\n\n          (defun f a s t - t i m e - d i f f e r e n c e (end s t a r t )\n            \"Subtract two time p o i n t s . \"\n            #+Explorer (time:microsecond-time-difference end s t a r t )\n            #-Explorer (- end s t a r t ) )\n\n          (defun fast-time->seconds (time)\n            \"Convert a f a s t - t i m e interval into seconds.\"\n            #+Explorer ( / time 1000000.0)\n            #-Explorer ( / time i n t e r n a l - t i m e - u n i t s - p e r - s e c o n d ) )\n\n\n      The next step is to update prof i 1 ed - f  to keep track of the timing data. The simplest\n      way to do this would be to set a variable, say s t a r t , to the time when a function is\n      entered, run the function, and then increment the function's time by the difference be\n      tween the current time and s t a r t . The problem with this approach is that every func-\n\f9.5 INSTRUMENTATION:           DECIDING          WHAT TO OPTIMIZE                                                   293\n\n\n\n          tion in the call stack gets credit for the time of each called function. Suppose the func\n          tion f calls itself recursively five times, with each call and return taking place a second\n          apart, so that the whole computation takes nine seconds. Then f will be charged nine\n          seconds for the outer call, seven seconds for the next call, and so on, for a total of\n          25 seconds, even though in reality it only took nine seconds for all of them together.\n                A better algorithm would be to charge each function only for the time since the\n          last call or return. Then f would only be charged the nine seconds. The variable\n          * p r o f i l e - c a l l -stack* is used to holdastack of functionname/entry time pairs. This\n          stack is manipulated by p r o f i 1 e-enter and p r o f i 1 e-exi t to get the right timings.\n                The functions that are used on each call to a profiled function are declared i n l i n e .\n          In most cases, a call to a function compiles into machine instructions that set up the\n          argument list and branch to the location of the function's definition. With an i nl i ne\n          function, the body of the function is compiled in line at the place of the function\n          call. Thus, there is no overhead for setting up the argument list and branching to the\n          definition. An i nl i ne declaration can appear anywhere any other declaration can\n          appear. In this case, the function proel aim is used to register a global declaration.\n          Inline declarations are discussed in more depth on page 317.\n\n              (proclaim ' ( i n l i n e p r o f i l e - e n t e r p r o f i l e - e x i t    inc-profile-time))\n              (defun p r o f i l e d - f n (fn-name fn)\n                \"Return a function that increments the count, and t i m e s . \"\n                #'(lambda (&rest a r g s )\n                     ( p r o f i l e - e n t e r fn-name)\n                     (multiple-value-progl\n                            (apply fn a r g s )\n                            ( p r o f i l e - e x i t fn-name))))\n              (defvar * p r o f i l e - c a l l - s t a c k * n i l )\n              (defun p r o f i l e - e n t e r (fn-name)\n                ( i n c f (get fn-name ' p r o f i l e - c o u n t ) )\n                (unless (null * p r o f i l e - c a l l - s t a c k * )\n                         Time charged against the c a l l i n g f u n c t i o n :\n                     (inc-profile-time ( f i r s t *profile-call-stack*)\n                                                 (car ( f i r s t * p r o f i l e - c a l l - s t a c k * ) ) ) )\n                ; ; Put a new entry on the stack\n                (push (cons fn-name ( g e t - f a s t - t i m e ) )\n                          *profi l e - c a l l - s t a c k * ) )\n\n              (defun p r o f i l e - e x i t (fn-name)\n                      Time charged against the current f u n c t i o n :\n                ( i n c - p r o f i l e - t i m e (pop * p r o f i l e - c a l l - s t a c k * )\n                                                  fn-name)\n                      Change the top entry to r e f l e c t current time\n                (unless (null * p r o f i l e - c a l l - s t a c k * )\n                      ( s e t f (cdr ( f i r s t * p r o f i l e - c a l l - s t a c k * ) )\n                                  (get-fast-time))))\n\f294                                                                                                              EFFICIENCY   ISSUES\n\n\n\n          (defun i n c - p r o f i l e - t i m e (entry fn-name)\n            ( i n c f (get fn-name ' p r o f i l e - t i m e )\n                      ( f a s t - t i m e - d i f f e r e n c e ( g e t - f a s t - t i m e ) (cdr e n t r y ) ) ) )\n\n\n       Finally, we need to update prof i 1 e- report to print the timing data as well as the\n      counts. Note that the default f  - names is a copy of the global list. That is because we\n      pass f  - names to sort, which is a destructive function. We don't want the global list\n      to be modified as a result of this sort.\n\n         (defun p r o f i l e - r e p o r t (�optional\n                                                (fn-names ( c o p y - l i s t * p r o f i l e d - f u n c t i o n s * ) )\n                                                (key # ' p r o f i l e - c o u n t ) )\n           \"Report p r o f i l i n g s t a t i s t i c s on given f u n c t i o n s . \"\n           (let ((total-time                (reduce # ' + (mapcar # ' p r o f i l e - t i m e fn-names))))\n             (unless (null key)\n                ( s e t f fn-names ( s o r t fn-names # ' > :key k e y ) ) )\n             (format t \"~&Total elapsed time: ~d s e c o n d s . \"\n                           (fast-time->seconds t o t a l - t i m e ) )\n             (format t \"~& Count                         Sees Time% Name\")\n             (loop for name i n fn-names do\n                        (format t \"\"ryo                  \"�.ZF '*'3d% ~A\"\n                                      ( p r o f i l e - c o u n t name)\n                                      (fast-time->seconds ( p r o f i l e - t i m e name))\n                                      (round ( / ( p r o f i l e - t i m e name) t o t a l - t i m e ) .01)\n                                      name))))\n\n         (defun p r o f i l e - t i m e (fn-name) (get fn-name ' p r o f i l e - t i m e ) )\n\n\n      These functions can be used by calling p r o f i l e , then doing some representative com\n      putation, then calling prof i 1 e - report, and finally unprof i 1 e. It can be convenient\n      to provide a single macro for doing all of these at once:\n\n          (defmacro w i t h - p r o f i l i n g (fn-names &rest body)\n            '(progn\n                ( u n p r o f i l e . ,fn-names)\n                ( p r o f i l e . .fn-names)\n                (setf *profile-call-stack* n i l )\n                (unwind-protect\n                        (progn . .body)\n                    (profile-report',fn-names)\n                    ( u n p r o f i l e . .fn-names))))\n\n\n      Note the use of unwi nd - protect to produce the report and call unprof i 1 e even if the\n      computation is aborted, unwind-protect is a special form that takes any number\n      of arguments. It evaluates the first argument, and if all goes well it then evaluates\n\f9.6 A CASE STUDY    IN EFFICIENCY:         THE SIMPLIFY          PROGRAM                                             295\n\n\n\n          the other arguments and returns the first one, just like progl. But if an error occurs\n          during the evaluation of the first argument and computation is aborted, then the\n          subsequent arguments (called cleanup forms) are evaluated anyway.\n\n\n\n          9.6        A Case Study in Efficiency: The\n                     SIMPLIFY Program\n          Suppose we wanted to speed up the s i m p l i f y program of chapter 8. This sec\n          tion shows how a combination of general techniques--memoizing, indexing, and\n          compiling--can be used to speed up the program by a factor of 130. Chapter 15 will\n          show another approach: replace the algorithm with an entirely different one.\n              The first step to a faster program is defining a benchmark, a test suite representing\n          a typical work load. The following is a short list of test problems (and their answers)\n          that are typical of the s i mpl i f y task.\n\n              (defvar n e s t - d a t a * (mapcar # ' i n f i x - > p r e f i x\n                �((d ( a * x ^ 2 + b * x + c ) / d x )\n                   (d ((a *           2 + b *  + c) / x) / d x)\n                   (d ((a *  ^ 3 + b *  ^ 2 + c *  + d) /  ^ 5) / d x)\n                   ( ( s i n ( X + X ) ) * ( s i n (2 * x ) ) + (cos (d (x ^ 2) / d x ) ) ^ 1)\n                   (d (3 * X + (cos X ) / X ) / d X ) ) ) )\n              (defvar ^^answers* (mapcar # ' s i m p l i f y * t e s t - d a t a * ) )\n\n\n          The function t e s t - i t runs through the test data, making sure that each answer is\n          correct and optionally printing profiling data.\n\n             (defun t e s t - i t (�optional ( w i t h - p r o f i l i n g t ) )\n               \"Time a t e s t r u n , and make sure the answers are c o r r e c t . \"\n               ( l e t ((answers\n                         (if with-profiling\n                                 ( w i t h - p r o f i l i n g ( s i m p l i f y s i m p l i f y - e x p pat-match\n                                                                 match-variable v a r i a b l e - p )\n                                    (mapcar # * s i m p l i f y n e s t - d a t a * ) )\n                                 (time (mapcar # ' s i m p l i f y * t e s t - d a t a * ) ) ) ) )\n                    (mapc #*assert-equal answers *answers*)\n                   t))\n              (defun assert-equal (x y )\n                \" I f X i s not equal to y , complain.\"\n                ( a s s e r t (equal  y ) ( y )\n                              \"Expected \"a to be equal to ~a\"  y ) )\n\n\n          Here are the results of ( t e s t - i t ) with and without profiling:\n\f296                                                                                 EFFICIENCY   ISSUES\n\n\n\n         > (test-it nil)\n         Evaluation of (MAPCAR #'SIMPLIFY *TEST-DATA*) took 6.612 seconds.\n\n         > ( t e s t - i t t)\n         Total elapsed time: 22.819614 seconds.\n           Count          Sees Time% Name\n           51690 11.57 51% PAT-MATCH\n           37908          8.75    38% VARIABLE-P\n             1393         0.32     1% MATCH-VARIABLE\n               906        0.20     1% SIMPLIFY\n               274        1.98     9% SIMPLIFY-EXP\n\n\n      Running the test takes 6.6 seconds normally, although the time triples when the\n      profiling overhead is added in. It should be clear that to speed things up, we have\n      to either speed up or cut down on the number of calls to pat-match or v a r i abl e -p,\n      since together they account for 89% of the calls (and 89% of the time as well). We\n      will look at three methods for achieving both those goals.\n\n\n      Memoization\n\n      Consider the rule that transforms (x + x) into (2 * ). Once this is done, we have\n      to simplify the result, which involves resimplifying the components. If x were some\n      complex expression, this could be time-consuming, and it will certainly be wasteful,\n      because  is already simplified and cannot change. We have seen this type of problem\n      before, and the solution is memoization: make simpl i fy remember the work it has\n      done, rather than repeating the work. We can just say:\n\n         (memoize ' s i m p l i f y : t e s t # ' e q u a l )\n\n\n      Two questions are unclear: what kind of hash table to use, and whether we should\n      clear the hash table between problems. The simplifier was timed for all four combi\n      nations of eq or equal hash tables and resetting or nonresetting between problems.\n      The fastest result was equal hashing and nonresetting. Note that with eq hashing,\n      the resetting version was faster, presumably because it couldn't take advantage of\n      the common subexpressions between examples (since they aren't eq).\n\n                                              hashing           resetting   time\n                                              none                  --        6.6\n                                              equal                yes        3.8\n                                              equal                no         3.0\n                                              eq                   yes        7.0\n                                              eq                   no        10.2\n\f9.6 A CASE STUDY   IN EFFICIENCY    THE SIMPLIFY    PROGRAM                                           297\n\n\n\n              This approach makes the function simpl i fy remember the work it has done, in\n          a hash table. If the overhead of hash table maintenance becomes too large, there is\n          an alternative: make the data remember what simplify has done. This approach was\n          taken in MACSYMA: it represented operators as lists rather than as atoms. Thus, in\n          stead of (* 2 X ) , MACSYMA would use ( ( * ) 2 ). The simplification function would\n          destructively insert a marker into the operator list. Thus, the result of simplifying 2x\n          would be ( ( * s i mp) 2 ). Then, when the simplifier was called recursively on this\n          expression, it would notice the s i mp marker and return the expression as is.\n              The idea of associating memoization information with the data instead of with the\n          function will be more efficient unless there are many functions that all want to place\n          their marks on the same data. The data-oriented approach has two drawbacks: it\n          doesn't identify structures that are equal but not eq, and, because it requires explicitly\n          altering the data, it requires every other operation that manipulates the data to know\n          about the markers. The beauty of the hash table approach is that it is transparent; no\n          code needs to know that memoization is taking place.\n\n\n\n          Indexing\n\n\n          We currently go through the entire list of rules one at a time, checking each rule. This\n          is inefficient because most of the rules could be trivially ruled out--if only they were\n          indexed properly. The simplest indexing scheme would be to have a separate list\n          of rules indexed under each operator. Instead of having simpl ify-exp check each\n          member of *s i mpl i f i cat i on - rul es*, it could look only at the smaller list of rules for\n          the appropriate operator. Here's how:\n\n\n              (defun simplify-exp (exp)\n                \"Simplify using a rule, or by doing arithmetic,\n                or by using the simp function supplied for this operator.\n                This version indexes simplification rules under the operator.\"\n                (cond ((simplify-by-fn exp))\n                      ((rule-based-translator exp (rules-for (exp-op exp))\n                          :rule-if #'exp-lhs :rule-then #'exp-rhs\n                          :action #'(lambda (bindings response)\n                                       (simplify (sublis bindings response)))))\n                      ((evaluable exp) (eval exp))\n                      (t exp)))\n\n              (defvar *rules-for* (make-hash-table :test #*eq))\n\n              (defun main-op (rule) (exp-op (exp-lhs rule)))\n\f298                                                                                        EFFICIENCY   ISSUES\n\n\n\n              (defun i n d e x - r u l e s ( r u l e s )\n                 \"Index a l l the rules under the main o p . \"\n                 (clrhash * r u l e s - f o r * )\n                 (dolist (rule rules)\n                    : ; nconc instead of push to preserve the order of rules\n                    ( s e t f (gethash (main-op r u l e ) * r u l e s - f o r * )\n                              (nconc (gethash (main-op r u l e ) * r u l e s - f o r * )\n                                         (list      rule)))))\n\n             (defun r u l e s - f o r (op) (gethash op * r u l e s - f o r * ) )\n\n             (i ndex-rules * s i mpli f i cati on-rul e s * )\n\n\n          Timing the memoized, indexed version gets us to .98 seconds, down from 6.6 seconds\n          for the original code and 3 seconds for the memoized code. If this hadn't helped, we\n          could have considered more sophisticated indexing schemes. Instead, we move on\n          to consider other means of gaining efficiency.\n\n\n      @   Exercise 9.2 [m] The list of rules for each operator is stored in a hash table with\n          the operator as key. An alternative would be to store the rules on the property list\n          of each operator, assuming operators must be symbols. Implement this alternative,\n          and time it against the hash table approach. Remember that you need some way of\n          clearing the old rules--trivial with a hash table, but not automatic with property lists.\n\n\n\n          Compilation\n\n          You can look at simpl i fy-exp as an interpreter for the simplification rule language.\n          One proven technique for improving efficiency is to replace the interpreter with a\n          compiler. Forexample, the rule (x +  = 2 * ) could be compiled into something\n          like:\n\n             (lambda (exp)\n                 (if   (and (eq (exp-op exp) ' + ) (equal (exp-lhs exp) (exp-rhs exp)))\n                       (make-exp :op ' * : l h s 2 : r h s (exp-rhs e x p ) ) ) )\n\n\n          This eliminates the need for consing up and passing around variable bindings, and\n          should be faster than the general matching procedure. When used in conjunction\n          with indexing, the individual rules can be simpler, because we already know we have\n          the right operator. For example, with the above rule indexed under \"-�-\", it could now\n          be compiled as:\n\f9.6 A CASE STUDY        IN EFFICIENCY     THE SIMPLIFY              PROGRAM                   299\n\n\n              (lambda (exp)\n                  (if     (equal (exp-lhs exp) (exp-rhs exp))\n                          (make-exp :op ' * : l h s 2 : r h s (exp-lhs e x p ) ) ) )\n\n\n          It is important to note that when these functions return nil, it means that they\n          have failed to simplify the expression, and we have to consider another means of\n          simplification.\n              Another possibility is to compile a set of rules all at the same time, so that the\n          indexing is in effect part of the compiled code. As an example, I show here a small set\n          of rules and a possible compilation of the rule set. The generated function assumes\n          that  is not an atom. This is appropriate because we are replacing simpl 1 fy-exp,\n          not simpl ify. Also, we will return nil to indicate that  is already simplified. I\n          have chosen a slightly different format for the code; the main difference is the 1 et\n          to introduce variable names for subexpressions. This is useful especially for deeply\n          nested patterns. The other difference is that I explicitly build up the answer with a\n          call to 1 i St, rather than make-exp. This is normally considered bad style, but since\n          this is code generated by a compiler, I wanted it to be as efficient as possible. If the\n          representation of the exp data type changed, we could simply change the compiler; a\n          much easier task than hunting down all the references spread throughout a human-\n          written program. The comments following were not generated by the compiler.\n\n             (x * 1 = x)\n             (1 *  = x)\n             (x * 0 = 0)\n             (0 *  = 0)\n             (X    * X    =  ^ 2)\n\n             (lambda (x)\n                  ( l e t ((xT (exp-lhs x ) )\n                            (xr   (exp-rhs x ) ) )\n                    (or     (if   (eql xr *1)                   ; (x         1   = X)\n                                  xl)\n                            ( i f (eql xl *1)                   ; (1     �   X = X)\n                                  xr)\n                            (if   (eql xr *0)                   ;   (X   �   0 = 0)\n                                  )\n                            (if   (eql xl  )                    ; (0     �   X   = 0)\n                                  )\n                            (if   (equal xr x l )               :   (X   *   X =   X ^   2)\n                                  (list      Xl ' 2 ) ) ) ) )\n\n\n         I chose this format for the code because I imagined (and later show) that it would be\n         fairly easy to write the compiler for it.\n\f300                                                                         EFFICIENCY ISSUES\n\n\n      The Single-Rule Compiler\n\n      Here I show the complete single-rule compiler, to be followed by the indexed-rule-set\n      compiler. The single-rule compiler works like this:\n\n         > (compile-rule ' ( = (+  x) (* 2 x ) ) )\n         (LAMBDA (X)\n            ( I F (OP? X ' + )\n                 (LET ((XL (EXP-LHS X ) )\n                          (XR (EXP-RHS X ) ) )\n                    ( I F (EQUAL XR XL)\n                          (SIMPLIFY-EXP (LIST ' * ' 2 X L ) ) ) ) ) )\n\n\n      Given a rule, it generates code that first tests the pattern and then builds the right-\n      hand side of the rule if the pattern matches. As the code is generated, correspon\n      dences are built between variables in the pattern, like x, and variables in the generated\n      code, like x l . These are kept in the association Ust * b i ndi ngs*. The matching can be\n      broken down into four cases: variables that haven't been seen before, variables that\n      have been seen before, atoms, and lists. For example, the first time we run across\n       in the rule above, no test is generated, since anything can match x. But the entry\n      (x . x l ) is added to the * b i ndi ngs* Hst to mark the equivalence. When the second \n      is encountered, the test (equal xr x l ) is generated.\n          Organizing the compiler is a little tricky, because we have to do three things at\n      once: return the generated code, keep track of the * b i ndi ngs*, andkeep track of what\n      to do \"next\"--that is, when a test succeeds, we need to generate more code, either\n      to test further, or to build the result. This code needs to know about the bindings,\n      so it can't be done before the first part of the test, but it also needs to know where it\n      should be placed in the overall code, so it would be messy to do it after the first part\n      of the test. The answer is to pass in a function that will tell us what code to generate\n      later. This way, it gets done at the right time, and ends up in the right place as well.\n      Such a function is often called a continuation, because it tells us where to continue\n      computing. In our compiler, the variable consequent is a continuation function.\n          The compiler is called compi 1 e - rul e. It takes a rule as an argument and returns\n      a lambda expression that implements the rule.\n\n          (defvar * b i n d i n g s * n i l\n            \"A l i s t of bindings used by the rule c o m p i l e r . \" )\n\n          (defun compile-rule ( r u l e )\n            \"Compile a s i n g l e r u l e . \"\n            (let ((*bindings* n i l ) )\n               '(lambda (x)\n                   ,(compile-exp ' x (exp-lhs r u l e ) ;  i s the lambda parameter\n                                     (delay ( b u i l d - e x p (exp-rhs r u l e )\n\f9.6 A CASE STUDY   IN EFFICIENCY     THE SIMPLIFY     PROGRAM                                      301\n\n\n\n                                                               ^bindings*))))))\n\n\n          All the work is done by compi 1 e -exp, which takes three arguments: a variable that\n          will represent the input in the generated code, a pattern that the input should be\n          matched against, and a continuation for generating the code if the test passes. There\n          are five cases: (1) If the pattern is a variable in the list of bindings, then we generate\n          an equality test. (2) If the pattern is a variable that we have not seen before, then\n          we add it to the binding list, generate no test (because anything matches a variable)\n          and then generate the consequent code. (3) If the pattern is an atom, then the match\n          succeeds only if the input is eql to that atom. (4) If the pattern is a conditional like\n          ( ? i s  numberp ), then we generate the test (numberp  ) . Other such patterns could\n          be included here but have not been, since they have not been used. Finally, (5) if the\n          pattern is a list, we check that it has the right operator and arguments.\n\n             (defun compile-exp (var pattern consequent)\n               \"Compile code that t e s t s the e x p r e s s i o n , and does consequent\n               i f i t matches. Assumes bindings i n * b i n d i n g s * . \"\n               (cond ( ( g e t - b i n d i n g pattern * b i n d i n g s * )\n                                 Test a p r e v i o u s l y bound v a r i a b l e\n                          * ( i f (equal , v a r ,(lookup pattern * b i n d i n g s * ) )\n                                    , ( f o r c e consequent)))\n                       ( ( v a r i a b l e - p pattern)\n                          ; ; Add a new b i n d i n g s ; do type checking i f needed,\n                          (push (cons pattern v a r ) * b i n d i n g s * )\n                          (force consequent))\n                       ((atom pattern)\n                                 Match a l i t e r a l atom\n                          * ( i f (eql , v a r pattern)\n                                    , ( f o r c e consequent)))\n                       ( ( s t a r t s - w i t h pattern ' ? i s )\n                          (push (cons (second pattern) v a r ) * b i n d i n g s * )\n                          � ( i f ( , ( t h i r d pattern) , v a r )\n                                    , ( f o r c e consequent)))\n                       ; ; S o , f a r , only the ? i s pattern i s covered, because\n                       ; ; i t i s the only one used i n s i m p l i f i c a t i o n r u l e s .\n                       ; ; Other patterns could be compiled by adding code here.\n                              Or we could switch to a data-driven approach,\n                       (t          Check the operator and arguments\n                          ' ( i f (op? , v a r *,(exp-op pattern))\n                                    ,(compile-args var pattern consequent)))))\n\n\n          The function compi 1 e - a rgs is used to check the arguments to a pattern. It generates\n          a 1 et form binding one or two new variables (for a unary or binary expression), and\n          then calls compi 1 e-exp to generate code that actually makes the tests. It just passes\n          along the continuation, consequent, to compi 1 e-exp.\n\f302                                                                                     EFFICIENCY   ISSUES\n\n\n\n         (defun compile-args (var pattern consequent)\n           \"Compile code that checks the arg or a r g s , and does consequent\n           i f the a r g ( s ) match.\"\n                  F i r s t make up v a r i a b l e names f o r the a r g ( s ) .\n           ( l e t ( ( L (symbol var ' D )\n                        (R (symbol var ' R ) ) )\n                ( i f (exp-rhs pattern)\n                        ; ; two arg case\n                        � ( l e t ( ( , L (exp-lhs , v a r ) )\n                                    (,R (exp-rhs , v a r ) ) )\n                              ,(compile-exp L (exp-lhs pattern)\n                                                 (delay\n                                                   (compile-exp R (exp-rhs pattern)\n                                                                  consequent))))\n                              one arg case\n                        � ( l e t ( ( , L (exp-lhs , v a r ) ) )\n                              ,(compile-exp L (exp-lhs pattern) consequent)))))\n\n\n      The remaining functions are simpler, bui 1 d-exp generates code to build the right-\n      hand side of a rule, op? tests if its first argument is an expression with a given\n      operator, and symbol constructs a new symbol. Also given is new-symbol, although\n      it is not used in this program.\n\n         (defun build-exp (exp b i n d i n g s )\n           \"Compile code that w i l l b u i l d the exp, given the b i n d i n g s . \"\n           (cond ((assoc exp b i n d i n g s ) ( r e s t (assoc exp b i n d i n g s ) ) )\n                 ( ( v a r i a b l e - p exp)\n                   (error \"Variable ~a occurred on right-hand s i d e , ~\n                                  but not l e f t . \" exp))\n                 ((atom exp) \" , e x p )\n                 (t ( l e t ((new-exp (mapcar #*(lambda ( x )\n                                                             (build-exp  b i n d i n g s ) )\n                                                         exp)))\n                             �(simplify-exp ( l i s t .,new-exp))))))\n\n         (defun op? (exp op)\n           \"Does the exp have the given op as i t s operator?\"\n           (and (exp-p exp) (eq (exp-op exp) o p ) ) )\n\n         (defun symbol (&rest a r g s )\n           \"Concatenate symbols or s t r i n g s to form an interned symbol\"\n           ( i n t e r n (format n i l \" - { - a ^ } \" a r g s ) ) )\n\n         (defun new-symbol (&rest a r g s )\n           \"Concatenate symbols or s t r i n g s to form an uninterned symbol\"\n           (make-symbol (format n i l \" ' \" { ^ a \" } \" a r g s ) ) )\n\f9.6  CASE STUDY   IN EFFICIENCY       THE SIMPLIFY     PROGRAM                                        303\n\n\n\n             Here are some examples of the compiler:\n\n             > (compile-rule ' ( = ( l o g (^ e x ) ) x ) )\n             (LAMBDA (X)\n                ( I F (OP? X 'LOG)\n                     (LET ((XL (EXP-LHS X ) ) )\n                        ( I F (OP? XL\n                              (LET ((XLL (EXP-LHS XL))\n                                       (XLR (EXP-RHS X L ) ) )\n                                 ( I F (EQL XLL  )\n                                       XLR))))))\n\n             > (compile-rule (simp-rule ' ( n * (m * x) = (n * m) * x ) ) )\n             (LAMBDA (X)\n                (IF (OP? X �*)\n                   (LET ((XL (EXP-LHS X))\n                            (XR (EXP-RHS X ) ) )\n                      ( I F (NUMBERP XL)\n                            ( I F (OP? XR ' * )\n                                 (LET ((XRL (EXP-LHS XR))\n                                         (XRR (EXP-RHS X R ) ) )\n                                    (IF (NUMBERP XRL)\n                                       (SIMPLIFY-EXP\n                                         (LIST �*\n                                                (SIMPLIFY-EXP (LIST ' * XL XRL))\n                                               XRR)))))))))\n\n\n\n\n         The Rule-Set Compiler\n\n         The next step is to combine the code generated by this single-rule compiler to generate\n         more compact code for sets of rules. We'll divide up the complete set of rules into\n         subsets based on the main operator (as we did with the r u l e s - f o r function), and\n         generate one big function for each operator. We need to preserve the order of the\n         rules, so only certain optimizations are possible, but if we make the assumption\n         that no function has side effects (a safe assumption in this application), we can\n         still do pretty well. We'll use the s i m p - f n facility to install the one big function for\n         each operator.\n              The function compi 1 e - r u l e - s e t takes an operator, finds all the rules for that oper\n         ator, and compiles each rule individually. (It uses compi 1 e - i ndexed - r u l e rather than\n         compi 1 e - rul e, because it assumes we have already done the indexing for the main op\n         erator.) After each rule has been compiled, they are combined with combi ne- r u l e s ,\n         which merges similar parts of rules and concatenates the different parts. The result\n         is wrapped in a 1 ambda expression and compiled as the final simplification function\n         for the operator.\n\f304                                                                                                EFFICIENCY         ISSUES\n\n\n\n            (defun compile-rule-set (op)\n              \"Compile a l l r u l e s indexed under a given main op.\n              and make them into the simp-fn for that o p . \"\n              (set-simp-fn op\n                (compile nil\n                   '(lambda (x)\n                       .(reduce #'combine-rules\n                                  (mapcar #*compile-indexed-rule\n                                            (rules-for op)))))))\n\n            (defun compile-indexed-rule ( r u l e ) .\n              \"Compile one rule into lambda-less code,\n              assuming indexing of main o p . \"\n              (let ((*bindings* n i l ) )\n                 (compile-args\n                   ' x (exp-lhs r u l e )\n\n\n                    (delay (build-exp          (exp-rhs r u l e )      ^bindings*)))))\n\n\n      H e r e are t w o e x a m p l e s of w h a t compi 1 e - i ndexed - r u l e generates:\n           > (compile-indexed-rule ' ( = (log 1) 0 ) )\n           (LET ((XL (EXP-LHS X ) ) )\n              ( I F (EQL XL  )\n                    ))\n\n           > (compile-indexed-rule * ( = (log (\" e x ) )                   x))\n           (LET ((XL (EXP-LHS X ) ) )\n              ( I F (OP? XL      *n\n                    (LET ((XLL (EXP-LHS XL))\n                             (XLR (EXP-RHS X L ) ) )\n                       ( I F (EQL XLL  )\n                             XLR))))\n\n\n      T h e n e x t s t e p i s to c o m b i n e several of these rules into one. T h e f u n c t i o n comb i n e - r u l e s\n      takes two rules a n d m e r g e s t h e m together a s m u c h a s p o s s i b l e .\n\n\n           (defun combine-rules (a b)\n             \"Combine the code for two rules i n t o one, maintaining o r d e r . \"\n                In the default case, we generate the code (or a b ) ,\n                but we try to be cleverer and share common code,\n                on the assumption that there are no s i d e - e f f e c t s ,\n             (cond ((and d i s t p a) d i s t p b)\n                           (= (length a) (length b) 3)\n                           (equal ( f i r s t a) ( f i r s t b))\n                           (equal (second a) (second b ) ) )\n                     ; ; a=(f  y ) , b=(f   ) = > ( f  (combine-rules y  ) )\n                         This can apply when f = I F or f=LET\n\f9.6  CASE STUDY   IN EFFICIENCY        THE SIMPLIFY        PROGRAM                                 305\n\n\n\n                         ( l i s t ( f i r s t a) (second a)\n                                    (combine-rules ( t h i r d a) ( t h i r d b ) ) ) )\n                       ( ( m a t c h i n g - i f s a b)\n                         ' ( i f .(second a)\n                                   .(combine-rules ( t h i r d a) ( t h i r d b ) )\n                                   .(combine-rules (fourth a) (fourth b ) ) ) )\n                       ((starts-with a O r )\n                                  a=(or . . . ( i f  y ) ) . b = ( i f   ) = >\n                                          (or . . . ( i f  (combine-rules y  ) ) )\n                                else\n                                  a=(or . . . ) b = > (or . . . b)\n                         ( i f (matching-ifs ( l a s t l a) b)\n                                 (append ( b u t l a s t a)\n                                                 ( l i s t (combine-rules ( l a s t l a) b ) ) )\n                                 (append a ( l i s t b ) ) ) )\n                       (t         a . b = > (or a b)\n                         ' ( o r .a . b ) ) ) )\n\n            (defun matching-ifs (a b)\n              \"Are a and b i f statements with the same predicate?\"\n              (and ( s t a r t s - w i t h a ' i f ) ( s t a r t s - w i t h b ' i f )\n                   (equal (second a) (second b ) ) ) )\n\n            (defun l a s t l ( l i s t )\n              \"Return the l a s t element (not l a s t cons c e l l ) of l i s t \"\n              (first (last l i s t ) ) )\n\n\n\n            Here is what combi ne- rul es does with the two rules generated above:\n\n            > (combine-rules\n                 ' ( l e t ( ( x l (exp-lhs x ) ) ) ( i f (eql xl  )  ) )\n                 ' ( l e t ( ( x l (exp-lhs x ) ) )\n                         ( i f (op? xl ' ^ )\n                               (let ( ( x l l (exp-lhs x D )\n                                          ( x l r (exp-rhs x l ) ) )\n                                    ( i f (eql x l l ' e ) x l r ) ) ) ) )\n            (LET ( ( X L (EXP-LHS X ) ) )\n               (OR ( I F (EQL XL  )  )\n                      ( I F (OP? XL \"^)\n                              (LET ((XLL (EXP-LHS XL))\n                                         (XLR (EXP-RHS X L ) ) )\n                                 ( I F (EQL XLL  ) X L R ) ) ) ) )\n\n\n\n         Now we run the compiler by calling compi 1 e - a l l - rul e s - i n d e x e d and show the\n         combined compiled simplification function for 1 og. The comments were entered by\n         hand to show what simplification rules are compiled where.\n\f306                                                                                                 EFFICIENCY   ISSUES\n\n\n\n         (defun c o m p i l e - a l l - r u l e s - i n d e x e d ( r u l e s )\n           \"Compile a separate fn for each operator, and store i t\n           as the simp-fn of the operator.\"\n           (index-rules rules)\n           ( l e t ( ( a l l - o p s ( d e l e t e - d u p l i c a t e s (mapcar #*main-op r u l e s ) ) ) )\n                (mapc # ' c o m p i l e - r u l e - s e t a l l - o p s ) ) )\n\n\n\n\n         > (compile-all-rules-indexed                  *simplification-rules*)\n         (SIN COS LOG ^ * / - + D)\n\n         > (simp-fn ' l o g )\n         (LAMBDA (X)\n            (LET ((XL (EXP-LHS X ) ) )\n              (OR ( I F (EQL XL  )\n                        )                                                     logl = 0\n                  ( I F (EQL XL  )\n                        'UNDEFINED)                                           log 0 - undefined\n                  ( I F (EQL XL '  )\n                           )                                                  loge = l\n                     ( I F (OP? XL ' ^ )\n                           (LET ((XLL (EXP-LHS XL))\n                                   (XLR (EXP-RHS X L ) ) )\n                             ( I F (EQL XLL  )\n                                   XLR))))))                                lloge\"\" = X\n\n\n      If we want to bypass the rule-based simplifier altogether, we can change s i mp 1 i f y - exp\n      once again to eliminate the check for rules:\n\n          (defun s i m p l i f y - e x p (exp)\n            \" S i m p l i f y by doing arithmetic, or by using the simp function\n            supplied for t h i s operator.              Do not use r u l e s of any k i n d . \"\n            (cond ( ( s i m p l i f y - b y - f n exp))\n                       ((evaluable exp) (eval exp))\n                       (t e x p ) ) )\n\n\n      At last, we are in a position to run the benchmark test on the new compiled code; the\n      function t e s t - i t runs in about .15 seconds with memoization and .05 without. Why\n      would memoization, which helped before, now hurt us? Probably because there is a\n      lot of overhead in accessing the hash table, and that overhead is only worth it when\n      there is a lot of other computation to do.\n          We've seen a great improvement since the original code, as the following table\n      summarizes. Overall, the various efficiency improvements have resulted in a 130-\n      fold speed-up--we can do now in a minute what used to take two hours. Of course,\n      one must keep in mind that the statistics are only good for this one particular set of\n\f9.7 HISTORY   AND   REFERENCES                                                             307\n\n\n          test data on this one machine. It is an open question what performance you will get\n          on other problems and on other machines.\n              The following table summarizes the execution time and number of function calls\n          on the test data:\n\n                                 original   memo     memo+index       memo+comp       comp\n              run time (sees)         6.6     3.0            .98             .15         .05\n              speed-up                 --       2              7              44        130\n              calls\n              pat-match            51690    20003             5159                0       0\n              variable-p           37908    14694             4798                0       0\n              match-vari able       1393      551              551                0       0\n              simplify               906      408              408              545     906\n              simplify-exp           274      118              118              118     274\n\n\n\n\n          9.7       History and References\n\n          The idea of memoization was introduced by Donald Michie 1968. He proposed\n          using a list of values rather than a hash table, so the savings was not as great. In\n          mathematics, the field of dynamic programming is really just the study of how to\n          compute values in the proper order so that partial results will already be cached away\n          when needed.\n              A large part of academic computer science covers compilation; Aho and Ullman\n          1972 is just one example. The technique of compiling embedded languages (such as\n          the language of pattern-matching rules) is one that has achieved much more attention\n          in the Lisp community than in the rest of computer science. See Emanuelson and\n          Haraldsson 1980, for an example.\n              Choosing the right data structure, indexing it properly, and defining algorithms\n          to operate on it is another important branch of computer science; Sedgewick 1988 is\n          one example, but there are many worthy texts.\n              Delaying computation by packaging it up in a 1 ambda expression is an idea that\n          goes back to Algol's use of thunks--a mechanism to implement call-by-name parame\n          ters, essentially by passing functions of no arguments. The name thunk comes from\n          the fact that these functions can be compiled: the system does not have to think\n          about them at run time, because the compiler has already thunk about them. Peter\n          Ingerman 1961 describes thunks in detail. Abelson and Sussman 1985 cover delays\n          nicely. The idea of eliminating unneeded computation is so attractive that entire lan\n          guages have built around the concept of lazy evaluation--don't evaluate an expression\n          until its value is needed. See Hughes 1985 or Field and Harrison 1988.\n\f308                                                                                EFFICIENCY ISSUES\n\n\n\n            9.8       Exercises\n      [�3 Exercise 9.3 [d] In this chapter we presented a compiler for s i mp1 i f y . It is not too\n          much harder to extend this compiler to handle the full power of pat-match. Instead\n          of looking at expressions only, allow trees with variables in any position. Extend and\n          generalize the definitions of compi 1 e - rul e and compi 1 e - rul e -set so that they can\n          be used as a general tool for any application program that uses pat-match and/or\n          rul e -based -trans1 ator. Make sure that the compiler is data-driven, so that the\n          programmer who adds a new kind of pattern to pat-match can also instruct the\n          compiler how to deal with it. One hard part will be accounting for segment variables.\n          It is worth spending a considerable amount of effort at compile time to make this\n          efficient at run time.\n\n\n      @     Exercise 9.4 [m] Define the time to compute (fib n) without memoization as Tn.\n            Write a formula to express T^. Given that T25 � 1.1 seconds, predict Tioo-\n\n\n      t�J   Exercise 9.5 [m] Consider a version of the game of Nim played as follows: there is\n            a pile of  tokens. Two players alternate removing tokens from the pile; on each turn\n            a player must take either one, two, or three tokens. Whoever takes the last token\n            wins. Write a program that, given n, returns the number of tokens to take to insure\n            a win, if possible. Analyze the execution times for your program, with and without\n            memoization.\n\n\n      @     Exercise 9.6 [m] A more complicated Nim-like game is known as Grundy's game.\n            The game starts with a single pile of  tokens. Each player must choose one pile and\n            split it into two uneven piles. The first player to be unable to move loses. Write a\n            program to play Grundy's game, and see how memoization helps.\n\n\n      [�3 Exercise 9.7 [h] This exercise describes a more challenging one-person game. In\n          this game the player rolls a six-sided die eight times. The player forms four two-digit\n          decimal numbers such that the total of the four numbers is as high as possible, but\n          not higher than 170. A total of 171 or more gets scored as zero.\n                The game would be deterministic and completely boring if not for the requirement\n            that after each roll the player must immediately place the digit in either the ones or\n            tens column of one of the four numbers.\n                Here is a sample game. The player first rolls a 3 and places it in the ones column\n            of the first number, then rolls a 4 and places it in the tens column, and so on. On the\n            last roll the player rolls a 6 and ends up with a total of 180. Since this is over the limit\n            of 170, the player's final score is 0.\n\f9.8   EXERCISES                                                                               309\n\n\n                                   roll         3    4    6     6    3    5      3    6\n                                   1st num.    -3   43   43   43    43   43    43    43\n                                   2nd num.\n                                                -    -   -6   -6    36   36    36    36\n                                   3rd num.\n                                   4th num.\n                                                -    -    -    -6   -6   -6    36    36\n                                                                         -5     -5   65\n                                   total       03   43   49   55    85   90   120     0\n\n\n              Write a function that allows you to play a game or a series of games. The function\n           should take as argument a function representing a strategy for playing the game.\n\n\n      S    Exercise 9.8 [h] Define a good strategy for the dice game described above. (Hint:\n           my strategy scores an average of 143.7.)\n\n\n      S    Exercise 9.9 [m] One problem with playing games involving random numbers is\n           the possibility that a player can cheat by figuring out what random is going to do next.\n           Read the definition of the function random and describe how a player could cheat.\n           Then describe a countermeasure.\n\n\n      S    Exercise 9.10 [m] On page 292 we saw the use of the read-time conditionals,       and\n           # -, where #+ is the read-time equivalent of when, and # - is the read-time equivalent\n           of unless. Unfortunately, there is no read-time equivalent of case. Implement one.\n\n\n      @    Exercise 9.11 [h] Write a compiler for ELIZA that compiles all the rules at once into\n           a single function. How much naore efficient is the compiled version?\n\n\n      0    Exercise 9.12 [d] Write some rules to simplify Lisp code. Some of the algebraic\n           simplification rules will still be valid, but new ones will be needed to simplify nonal-\n           gebraic functions and special forms. (Since n i 1 is a valid expression in this domain,\n           you will have to deal with the semipredicate problem.) Here are some example rules\n           (using prefix notation):\n\n                  = (+  0) )\n                  = 'nil    nil)\n                  = (car (cons  y ) ) )\n                  = (cdr (cons  y ) ) y )\n                  = (if    t     y)   )\n                  = (if    nil   X y)     y)\n\n                  = (length n i l ) 0)\n                  = (expt y ( ? i f X numberp)) (expt (expt y ( /  2 ) ) 2 ) )\n\f310                                                                                                  EFFICIENCY   ISSUES\n\n\n\n      S   Exercise 9.13 [m] Consider the following two versions of the sieve of Eratosthenes\n          algorithm. The second explicitly binds a local variable. Is this worth it?\n\n              (defun sieve (pipe)\n                (make-pipe (head pipe)\n                           ( f i l t e r #*(lambda ( x ) ( / = (mod  (headpipe)) 0 ) )\n                                         (sieve (tail p i p e ) ) ) ) )\n\n              (defun sieve (pipe)\n                ( l e t ( ( f i r s t - n u m (head p i p e ) ) )\n                    (make-pipe f i r s t - n u m\n                                          ( f i l t e r #'(lambda (x) ( / = (mod  f i r s t - n u m ) 0 ) )\n                                                        (sieve (tail p i p e ) ) ) ) ) )\n\n\n\n\n          9.9        Answers\n          Answer 9.4 Let Fn denote ( f i b ). Then the time to compute Fn, Tn, is a small\n          constant for  < 1, and is roughly equal to Tn-\\ plus Tn-i for larger n. Thus, Tn is\n          roughly proportional to Fn'.\n\n                                                            T,, =     4\n          We could use some small value of Ti to calculate Tioo if we knew Fioo- Fortunately,\n          we can use the equation:\n\n\n          where   =              ^J{5))|1 � 1.618. This equation was derived by de Moivre in 1718\n          (see Knuth, Donald E. Fundamental Algorithms, pp. 78-83), but the number  has a\n          long interesting history. Euclid called it the \"extreme and mean ratio,\" because the\n          ratio of A to  is the ratio of A -h J5 to A if A/JB is . In the Renaissance it was called\n          the \"divine proportion,\" and in the last century it has been known as the \"golden\n          ratio,\" because a rectangle with sides in this ratio can be divided into two smaller\n          rectangles that both have the same ratio between sides. It is said to be a pleasing\n          proportion when employed in paintings and architecture. Putting history aside,\n          given T25 � l . l s e c we can now calculate:\n\n                                             Tioo�<A'�''^�5xlO^W\n\n          which is roughly 150 million years. We can also see that the timing data in the table\n          fits the equation fairly well. However, we would expect some additional time for\n          larger numbers because it takes longer to add and garbage collect bignums than\n          fixnums.\n\f9.9 ANSWERS                                                                                    311\n\n\n\n          Answer 9.5 First we'll define the notion of a forced win. This occurs either when\n          there are three or fewer tokens left or when you can make a move that gives your\n          opponent a possible loss. A possible loss is any position that is not a forced win. If\n          you play perfectly, then a possible loss for your opponent will in fact be a win for you,\n          since there are no ties. See the functions wi  and 1 oss below. Now your strategy\n          should be to win the game outright if there are three or fewer tokens, or otherwise\n          to choose the largest number resulting in a possible loss for your opponent. If there\n          is no such move available to you, take only one, on the grounds that your opponent\n          is more likely to make a mistake with a larger pile to contend with. This strategy is\n          embodied in the function nim below.\n\n              (defun win (n)\n                \" I s a p i l e of  tokens a win for the player to move?\"\n                (or (<=  3)\n                      ( l o s s (-  D )\n                      ( l o s s (-  2 ) )\n                      ( l o s s (-  3 ) ) ) )\n\n              (defun l o s s (n) (not (win n ) ) )\n\n              (defun nim (n)\n                \"Play Nim: a player must take 1 - 3 ; taking the l a s t one w i n s . \"\n                (cond ( ( < =  3) n)         ; an immediate win\n                      ( d o s s (-  3 ) ) 3) ; an eventual win\n                      ( d o s s (-  2 ) ) 2) ; an eventual win\n                      ( d o s s (-  1)) 1) ; an eventual win\n                      (t 1 ) ) )             ; a l o s s ; the 1 i s a r b i t r a r y\n\n              (memoize d o s s )\n\n\n          From this we are able to produce a table of execution times (in seconds), with and\n          without memoization. Only 1 oss need be memoized. (Why?) Do you have a good\n          explanation of the times for the unmemoized version? What happens if you change\n          the order of the loss clauses in wi  and/or  i m?\n\n          Answer 9.6 We start by defining a function, moves, which generates all possible\n          moves from a given position. This is done by considering each pile of  tokens within\n          a set of piles s. Any pile bigger than two tokens can be split. We take care to eliminate\n          duplicate positions by sorting each set of piles, and then removing the duplicates.\n\n              (defun moves ( s )\n                \"Return a l i s t of a l l p o s s i b l e moves i n Grundy's game\"\n                ; ; S i s a l i s t of integers g i v i n g the s i z e s of the p i l e s\n                (remove-duplicates\n                   (loop for  i n s append (make-moves  s ) )\n                   :test #'equal))\n\f312                                                                        EFFICIENCY   ISSUES\n\n\n\n         (defun make-moves (n s )\n            (when (>=  2)\n              ( l e t ( ( s / n (remove  s icount 1 ) ) )\n                 (loop for i from 1 to (- ( c e i l i n g  2) 1)\n                         collect (sort* ( l i s t * i ( - n i )   s/n)\n                                               #'�))))\n\n         (defun s o r t * (seq pred &key key)\n            \"Sort without a l t e r i n g the sequence\"\n            ( s o r t (copy-seq seq) pred :key key))\n\n\n      This time a loss is defined as a position from which you have no moves, or one from\n      which your opponent can force a win no matter what you do. A winning position\n      is one that is not a loss, and the strategy is to pick a move that is a loss for your\n      opponent, or if you can't, just to play anything (here we arbitrarily pick the first move\n      generated).\n\n         (defun l o s s ( s )\n          ( l e t ((choices (moves s ) ) )\n              (or (null choices)\n                  (every #'win c h o i c e s ) ) ) )\n\n         (defun win ( s ) (not ( l o s s s ) ) )\n\n         (defun grundy ( s )\n           ( l e t ((choices (moves s ) ) )\n             (or ( f i n d - i f # ' l o s s choices)\n                  ( f i r s t choices))))\n\n\n\n      Answer 9.7 The answer assumes that a strategy function takes four arguments:\n      the current die roll, the score so far, the number of remaining positions in the tens\n      column, and the number of remaining positions in the ones column. The strategy\n      function should return 1 or 1 0 .\n\n          (defun play-games (�optional (n-games 10) (player 'make-move))\n            \"A d r i v e r for a simple dice game. In t h i s game the player\n            r o l l s a s i x - s i d e d die eight times. The player forms four\n            t w o - d i g i t decimal numbers such that the total of the four\n            numbers i s as high as p o s s i b l e , but not higher than 170.\n            A total of 171 or more gets scored as zero. After each die\n            i s r o l l e d , the player must decide where to put i t .\n            This function returns the p l a y e r ' s average s c o r e . \"\n            ( / (loop repeat n-games summing (play-game player 0 4 4 ) )\n                   ( f l o a t n-games)))\n\f9.9 ANSWERS                                                                                     313\n\n\n\n              (defun play-game (player &optional (total 0) (tens 4) (ones 4 ) )\n                (cond ( ( o r ( > total 170) � tens 0) ( < ones 0 ) ) 0)\n                      ((and (= tens 0) (= ones 0 ) ) t o t a l )\n                      (t ( l e t ( ( d i e ( r o l l - d i e ) ) )\n                              (case (funcall player die total tens ones)\n                                 (1 (play-game player {+ total d i e )\n                                                           tens (- ones 1 ) ) )\n                                 (10 (play-game player (+ total (* 10 d i e ) )\n                                                           (- tens 1) ones))\n                                   (t   0))))))\n\n              (defun r o l l - d i e () (+ 1 (random 6 ) ) )\n\n          So, the expression (play-games 5 #'make-move) would play five games with a\n          strategy called make-move. This returns only the average score of the games; if you\n          want to see each move as it is played, use this function:\n\n              (defun show ( p l a y e r )\n                \"Return a player that p r i n t s out each move i t makes.\"\n                #'(lambda (die total tens ones)\n                     (when (= total 0) ( f r e s h - l i n e ) )\n                     ( l e t ((move (funcall player die total tens ones)))\n                          ( i n c f total (* die move))\n                          (format t \"~2d->~3d I ~@[*~]\" (* move d i e ) total ( > total 170))\n                         move)))\n\n\n          and call (pi ay-games 5 (show #'make-moves)).\n\n          Answer 9.9 The expression (random 6 (make-random-state)) returns the next\n          number that rol 1 -di e will return. To guard against this, we can make rol 1 -di e use\n          a random state that is not accessible through a global variable:\n\n              ( l e t ( ( s t a t e (make-random-state t ) ) )\n                   (defun r o l l - d i e () (+ 1 (random 6 s t a t e ) ) ) )\n\n\n          Answer 9.10 Because this has to do with read-time evaluation, it must be imple\n          mented as a macro or read macro. Here's one way to do it:\n\n              (defmacro read-time-case ( f i r s t - c a s e &rest other-cases)\n                \"Do the f i r s t case, where normally cases are\n                s p e c i f i e d with #+ or p o s s i b l y #- marks.\"\n                (declare (ignore o t h e r - c a s e s ) )\n                first-case)\n\f314                                                                     EFFICIENCY ISSUES\n\n\n\n      A fanciful example, resurrecting a number of obsolete Lisps, follows:\n\n         (defun g e t - f a s t - t i m e 0\n           (read-time-case\n              #+Explorer                 ( t i me:mi crosecond-ti me)\n              #+Franz                    (sysitime)\n              #+(or PSL UCI) (time)\n              #+YKT                      (currenttime)\n              #+MTS                      ( s t a t u s 39)\n              #+Interlisp                (clock 1)\n              #+Lispl.5                  (tempus-fugit)\n                 otherwise\n                                         (get-internal-real-time)))\n\n\n      Answer 9.13 Yes. Computing (head pipe) may be a trivial computation, but it\n      will be done many times. Binding the local variable makes sure that it is only done\n      once. In general, things that you expect to be done multiple times should be moved\n      out of delayed functions, while things that may not be done at all should be moved\n      inside a delay.\n\fCHAPTER                     10\n\nLow-Level\nEfficiency Issues\n\n                                                     There are only two qualities in the world: efficiency\n                                                      and inefficiency; and only two sorts of people: the\n                                                                             efficient and the inefficient\n                                                                               --George Bernard Shaw\n                                                                         John Bull's Other Island (1904)\n\n\n\n\nr I 1 he efficiency techniques of the previous chapter all involved fairly significant changes\n   I     to an algorithm. But what happens when you already are using the best imaginable\n        algorithms, and performance is still a problem? One answer is to find what parts of the\nprogram are used most frequently and make micro-optimizations to those parts. This chapter\ncovers the following six optimization techniques. If your programs all run quickly enough, then\nfeel free to skip this chapter. But if you would like your programs to run faster, the techniques\ndescribed here can lead to speed-ups of 40 times or more.\n\f316                                                                      LOW-LEVEL EFFICIENCY ISSUES\n\n\n         � Use declarations.\n\n         � Avoid generic functions.\n\n         � Avoid complex argument lists.\n\n         � Provide compiler macros.\n\n         � Avoid unnecessary consing.\n\n         � Use the right data structure.\n\n\n\n      10.1         Use Declarations\n      On general-purpose computers running Lisp, much time is spent on type-checking.\n      You can gain efficiency at the cost of robustness by declaring, or promising, that\n      certain variables will always be of a given type. For example, consider the following\n      function to compute the sum of the squares of a sequence of numbers:\n\n         (defun sum-squares (seq)\n           ( l e t ((sum 0 ) )\n                (dotimes (i (length seq))\n                  ( i n c f sum (square ( e l t seq i ) ) ) )\n               sum))\n\n         (defun square (x) (*  x ) )\n\n\n      If this function will only be used to sum vectors of fixnums, we can make it a lot faster\n      by adding declarations:\n\n          (defun sum-squares (vect)\n            (declare (type (simple-array fixnum * ) vect)\n                            ( i n l i n e square) (optimize speed (safety 0 ) ) )\n            ( l e t ((sum 0 ) )\n                 (declare (fixnum sum))\n                 (dotimes (i (length vect))\n                   (declare (fixnum i ) )\n                   ( i n c f sum (the fixnum (square ( s v r e f vect i ) ) ) ) ) ) )\n                sum))\n\n\n      The fixnum declarations let the compiler use integer arithmetic directly, rather than\n      checking the type of each addend. The ( t h e f i xnum . . . ) special form is a promise\n      that the argument is a fbcnum. The ( o p t i mi ze speed ( s a f e t y 0 ) ) declaration tells\n      the compiler to make the function run as fast as possible, at the possible expense of\n\f10.1 USE DECLARATIONS                                                                                317\n\n\n\n          making the code less safe (by ignoring type checks and so on). Other quantities that\n          can be optimized are c o m p i l a t i o n - s p e e d , space and in ANSI Common Lisp only,\n          debug (ease of debugging). Quantities can be given a number from 0 to 3 indicating\n          how important they are; 3 is most important and is the default if the number is left out.\n              The ( i n l i n e squa re) declaration allows the compiler to generate the multipli\n          cation specified by square right in the loop, without explicitly making a function\n          call to square. The compiler will create a local variable for ( s v r e f vect i ) and will\n          not execute the reference twice--inline functions do not have any of the problems\n          associated with macros as discussed on page 853. However, there is one drawback:\n          when you redefine an inline function, you may need to recompile all the functions\n          that call it.\n              You should declare a function i n l ine when it is short and the function-calling\n          overhead will thus be a significant part of the total execution time. You should not\n          declare a function i nl i ne when the function is recursive, when its definition is likely\n          to change, or when the function's definition is long and it is called from many places.\n              In the example at hand, declaring the function i n l i n e saves the overhead of\n          a function call. In some cases, further optimizations are possible. Consider the\n          predicate s t a r t s - w i t h :\n\n\n               (defun s t a r t s - w i t h ( l i s t x)\n                 \" I s t h i s a l i s t whose f i r s t element i s x ? \"\n                 (and (consp l i s t ) (eql ( f i r s t l i s t ) x ) ) )\n\n\n          Suppose we have a code fragment like the following:\n\n               (if   (consp l i s t ) ( s t a r t s - w i t h l i s t x) . . . )\n\n\n          If s t a r t s - w i t h is declared i nl i ne this will expand to:\n\n               (if   (consp l i s t ) (and (consp l i s t ) (eql ( f i r s t l i s t ) x)) . . . )\n\n\n          which many compilers will simplify to:\n\n               (if   (consp l i s t ) (eql ( f i r s t l i s t ) x) . . . )\n\n\n          Very few compilers do this kind of simplification across functions without the hint\n          provided by i n l i n e .\n              Besides eliminating run-time type checks, declarations also allow the compiler\n          to choose the most efficient representation of data objects. Many compilers support\n          both boxed and unboxed representations of data objects. A boxed representation\n          includes enough information to determine the type of the object. An unboxed\n          representation is just the \"raw bits\" that the computer can deal with directly. Consider\n\f318                                                                  LOW-LEVEL     EFFICIENCY   ISSUES\n\n\n\n      the following function, which is used to clear a 1024x1024 array of floating point\n      numbers, setting each one to zero:\n\n          (defun clear-m-array ( a r r a y )\n            (declare (optimize (speed 3) ( s a f e t y 0 ) ) )\n            (declare (type (simple-array s i n g l e - f l o a t (1024 1024)) a r r a y ) )\n            (dotimes (i 1024)\n              (dotimes (j 1024)\n                 ( s e t f (aref array i j ) 0 . 0 ) ) ) )\n\n\n      In Allegro Common Lisp on a Sun SPARCstation, this compiles into quite good code,\n      comparable to that produced by the C compiler for an equivalent C program. If the\n      declarations are omitted, however, the performance is about 40 times worse.\n          The problem is that without the declarations, it is not safe to store the raw floating\n      point representation of 0 . 0 in each location of the array. Instead, the program\n      has to box the 0 . 0 , allocating storage for a typed pointer to the raw bits. This\n      is done inside the nested loops, so the result is that each call to the version of\n      clear-m-array without declarations calls the floating-point-boxing function 1048567\n      times, allocating a megaword of storage. Needless to say, this is to be avoided.\n\n          Not all compilers heed all declarations; you should check before wasting time\n      with declarations your compiler may ignore. The function di sassembl e can be used\n      to show what a function compiles into. For example, consider the trivial function to\n      add two numbers together. Here it is with and without declarations:\n\n          (defun f (x y )\n            (declare (fixnum  y ) (optimize ( s a f e t y 0) (speed 3 ) ) )\n            (the fixnum (+  y ) ) )\n\n         (defun g (x y ) (+  y ) )\n\n\n      Here is the disassembled code for f from Allegro Common Lisp for a Motorola\n      68000-series processor:\n\n         > (disassemble *f)\n             disassembling #<Function f � #x83ef79>\n             form�is:  y\n         ; ; code vector (^ #x83ef44\n         0:       link     a6.#0\n         4:       move.l a 2 . - ( a 7 )\n         6:       move.l a 5 , - ( a 7 )\n         8:       move.l 7 ( a 2 ) , a 5\n         12:      move.l 8(a6),d4        y\n         16:      add.l    12(a6),d4 ; X\n         20:      move.l # l , d l\n\f10.1 USE     DECLARATIONS                                                                       319\n\n\n              22       move.l    -8(a6),a5\n              26       unlk      a6\n              28       rtd       #8\n\n\n           This may look intimidating at first glance, but you don't have to be an expert at 68000\n           assembler to gain some appreciation of what is going on here. The instructions\n           labeled 0-8 (labels are in the leftmost column) comprise the typical function preamble\n           for the 68000. They do subroutine linkage and store the new function object and\n           constant vector into registers. Since f uses no constants, instructions 6, 8, and 22\n           are really unnecessary and could be omitted. Instructions 0 , 4 , and 26 could also be\n           omitted if you don't care about seeing this function in a stack trace during debugging.\n           More recent versions of the compiler will omit these instructions.\n               The heart of function f is the two-instruction sequence 12-16. Instruction 12\n           retrieves y, and 16 adds y to x, leaving the result in d4, which is the \"result\" register.\n           Instruction 20 sets dl, the \"number of values returned\" register, to 1.\n               Contrast this to the code for g, which has no declarations and is compiled at\n           default speed and safety settings:\n\n                  (disassemble ' g )\n                 ; disassembling #<Function g @ #x83dbdl>\n                 ; form�is:  y\n              ; ; code vector @ #x83db64\n              0:        add.l    #8.31(a2)\n              4:        sub.w    #2,dl\n              6:        beq.s    12\n              8:        jmp      16(a4) ; wnaerr\n              12        link     a6.#0\n              16        move.l a 2 , - ( a 7 )\n              18        move.l a 5 , - ( a 7 )\n              20        move.l 7 ( a 2 ) , a 5\n              24        tst.b    -208(a4)          ; signal-hit\n              28        beq.s    34\n              30        jsr      872(a4) ; p r o c e s s - s i g\n              34        move.l 8 ( a 6 ) , d 4 ; y\n              38        move.l 12(a6),d0 ; X\n              42        or.l     d4,d0\n              44        and.b    #7.d0\n              48        bne.s    62\n              50        add.l    12(a6),d4 ; X\n              54        bvc.s    76\n              56        jsr      696(a4) ; add-overflow\n              60        bra.s    76\n              62        move.l 1 2 ( a 6 ) , - ( a 7 ) ; \n              66        move.l d 4 . - ( a 7 )\n              68        move.l # 2 . d l\n\f320                                                             LOW-LEVEL EFFICIENCY ISSUES\n\n\n\n         70         move.l   -304(a4),a0      ; +-2op\n         74         jsr      (a4)\n         76         move.l   #Ldl\n         78         move.l   -8(a6).a5\n         82         unl k    a6\n         84         rtd      #8\n\n\n      See how much more work is done. The first four instructions ensure that the right\n      number of arguments have been passed to g. If not, there is a jump to wnae rr (wrong-\n      number-of-arguments-error). Instructions 12-20 have the argument loading code\n      that was at 0-8 in f. At 24-30 there is a check for asynchronous signals, such as the\n      user hitting the abort key. After  and y are loaded, there is a type check (42-48). If\n      the arguments are not both fixnums, then the code at instructions 62-74 sets up a\n      call to +_2op, which handles type coercion and non-fixnum addition. If all goes well,\n      we don't have to call this routine, and do the addition at instruction 50 instead. But\n      even then we are not done--just because the two arguments were fixnums does not\n      mean the result will be. Instructions 54-56 check and branch to an overflow routine\n      if needed. Finally, instructions 76-84 return the final value, just as in f.\n         Some low-quality compilers ignore declarations altogether. Other compilers\n      don't need certain declarations, because they can rely on special instructions in the\n      underlying architecture. On a Lisp Machine, both f and g compile into the same\n      code:\n\n\n              6 PUSH                ARG 10\n              7 +                   ARG I I\n              8 RETURN              PDL-POP\n\n\n      The Lisp Machine has a microcoded + instruction that simultaneously does a fixnum\n      add and checks for non-fixnum arguments, branching to a subroutine if either argu\n      ment is not a fixnum. The hardware does the work that the compiler has to do on a\n      conventional processor. This makes the Lisp Machine compiler simpler, so compil\n      ing a function is faster. However, on modern pipelined computers with instruction\n      caches, there is little or no advantage to microcoding. The current trend is away from\n      microcode toward reduced instruction set computers (RISC).\n          On most computers, the following declarations are most likely to be helpful:\n\n         � fixnum and f l o a t . Numbers declared as fixnums or floating-point numbers\n           can be handled directly by the host computer's arithmetic instructions. On\n           some systems, f l o a t by itself is not enough; you have to say s i n g l e - f l o a t\n           or doubl e - f l oat. Other numeric declarations will probably be ignored. For\n           example, declaring a variable as integer does not help the compiler much,\n           because bignums are integers. The code to add bignums is too complex to put\n\f10.1 USE DECLARATIONS                                                                               321\n\n\n\n                inline, so the compiler will branch to a general-purpose routine (like +_2op in\n                Allegro), the same routine it would use if no declarations were given.\n\n              � l i s t and a r ray, Many Lisp systems provide separate functions for the list- and\n                array- versions of commonly used sequence functions. For example, (del e t e\n                X (the l i s t 1 ) ) compiles into (sys: del e t e - l i s t - e q l  1) on a TI Explorer\n                Lisp Machine. Another function, s y s : del e t e - v e c t o r , is used for arrays, and\n                the generic function del e t e is used only when the compiler can't tell what type\n                the sequence is. So if you know that the argument to a generic function is either\n                a 1 i s t or an a rray, then declare it as such.\n\n              � simpl e-vector and simpl e-array. Simple vectors and arrays are those that\n                do not share structure with other arrays, do not have fill pointers, and are\n                not adjustable. In many implementations it is faster to a r e f a simpl e-vector\n                than a vector. It is certainly much faster than taking an el t of a sequence of\n                unknown type. Declare your arrays to be simple (if they in fact are).\n\n             � (a r ray type). It is often important to specialize the type of array elements. For\n               example, an (a r ray short - fl o a t ) may take only half the storage of a general\n               array, and such a declaration will usually allow computations to be done using\n               the CPU's native floating-point instructions, rather than converting into and\n               out of Common Lisp's representation of floating points. This is very important\n               because the conversion normally requires allocating storage, but the direct\n               computation does not. The specifiers (simpl e-array iype) and (vector type)\n               should be used instead of (array type) when appropriate. A very common\n               mistake is to declare (s i mpl e - vector type). This is an error because Common\n               Lisp expects (simple-vector s/ze)--don't ask me why,\n\n             � (array '^dimensions). Thefullformof an array or si mpl e-array type specifier\n               is (array type dimensions).      So, for example, (array b i t ( * * ) ) is a two-\n               dimensional bit array, and (a r ray b i t (1024 1024)) is a 1024  1024 bit array.\n               It is very important to specify the number of dimensions when known, and less\n               important to specify the exact size, although with multidimensional arrays,\n               declaring the size is more important. The format for a vector type specifier is\n                ( v e c t o r type size).\n\n\n             Note that several of these declarations can apply all at once. For example, in\n\n              (position # \\ . (the simple-string file-name))\n\n\n          the variable filename has been declared to be a vector, a simple array, and a se\n          quence of type s t r i n g - c h a r . All three of these declarations are helpful. The type\n          simple-string is an abbreviation for (simple-array s t r i n g - c h a r ) .\n\f322                                                                  LOW-LEVEL     EFFICIENCY   ISSUES\n\n\n\n         This guide applies to most Common Lisp systems, but you should look in the\n      implementation notes for your particular system for more advice on how to fine-tune\n      your code.\n\n\n\n\n      10.2        Avoid Generic Functions\n      Common Lisp provides functions with great generality, but someone must pay the\n      price for this generality. For example, if you write ( e l t  0 ) , different machine\n      instruction will be executed depending on if  is a list, string, or vector. Without\n      declarations, checks will have to be done at runtime. You can either provide decla\n      rations, as in ( e l t (the l i s t x) O),oruseamorespecificfunction,suchas ( f i r s t\n      x) in the case of lists, (char  0) for strings, ( a r e f xO) for vectors, and ( s v r e f \n      0) for simple vectors. Of course, generic functions are useful--I wrote random-el t\n      as shown following to work on lists, when I could have written the more efficient\n      random-mem instead. The choice paid off when I wanted a function to choose a ran\n      dom character from a string--random-el t does the job unchanged, while random-mem\n      does not.\n\n         (defun random-elt ( s ) ( e l t s (random (length s ) ) ) )\n         (defun random-mem (1) (nth (random (length (the l i s t 1))) 1))\n\n\n      This example was simple, but in more complicated cases you can make your sequence\n      functions more efficient by having them explicitly check if their arguments are lists\n      or vectors. See the definition of map- i nto on page 857.\n\n\n\n\n      10.3        Avoid Complex Argument Lists\n      Functions with keyword arguments suffer a large degree of overhead. This may also\n      be true for optional and rest arguments, although usually to a lesser degree. Let's\n      look at some simple examples:\n\n         (defun   reg   ( a b e d ) (list a b e d ) )\n         (defun   rst   (a b c &rest d) ( l i s t * a b e d ) )\n         (defun   opt   (�optional a b (c 1) (d ( s q r t a ) ) ) ( l i s t a b e d ) )\n         (defun   key   (&key a b (c 1) (d ( s q r t a ) ) ) ( l i s t a b e d ) )\n\n\n      We can see what these compile into for the TI Explorer, but remember that your\n      compiler may be quite different.\n\f103   AVOID    COMPLEX    ARGUMENT        LISTS                                                323\n\n\n                 > (disassemble ' r e g )\n                    8 PUSH                ARG 10        A\n                    9 PUSH                ARG I I       \n                   10 PUSH                ARG 12        C\n                   11 PUSH                ARG 13        D\n                   12 TAIL-REC CALL-4 FEFI3             #'LIST\n\n                 > (disassemble ' r s t )\n                    8 PUSH                ARG 10        A\n                    9 PUSH                 ARGIl.       \n                   10 PUSH                ARG 12        C\n                   11 PUSH                LOCAL 10      D\n                   12 RETURN CALL-4 FEE 13              #'LIST*\n\n\n              With the regular argument list, we just push the four variables on the argument stack\n              and branch to the list function. (Chapter 22 explains why a tail-recursive call is just\n              a branch statement.)\n                  With a rest argument, things are almost as easy. It turns out that on this machine,\n              the microcode for the calling sequence automatically handles rest arguments, storing\n              them in local variable 0. Let's compare with optional arguments:\n\n                 (defun opt (�.optional a b (c 1) (d ( s q r t a ) ) ) ( l i s t   abed))\n\n                 > (disassemble O p t )\n                   24 DISPATCH          FEFI5            C0=^25;l=^25\n                   25 PUSH-NUMBER       1\n                   26 POP               ARG 12          C\n                   27 PUSH              ARG 10          A\n                   28 PUSH CALL-1       FEFI3           #'SQRT\n                   29 POP               ARG 13          D\n                   30 PUSH              ARG 10          A\n                   31 PUSH              ARGIl           \n                   32 PUSH              ARG 12          C\n                   33 PUSH              ARG 13          D\n                   34 TAIL-REC CALL-4 FEFI4             #'LIST\n\n\n              Although this assembly language may be harder to read, it turns out that optional\n              arguments are handled very efficiently. The calling sequence stores the number of\n              optional arguments on top of the stack, and the DISPATCH instruction uses this to\n              index into a table stored at location FEFI 5 (an offset five words from the start of\n              the function). The result is that in one instruction the function branches to just the\n              right place to initialize any unspecified arguments. Thus, a function with optional\n              arguments that are all supplied takes only one more instruction (the dispatch) than\n              the \"regular\" case. Unfortunately, keyword arguments don't fare as well:\n\n                 (defun key (&key a b (c 1) (d ( s q r t a ) ) ) ( l i s t   abed))\n\f324                                                            LOW-LEVEL    EFFICIENCY    ISSUES\n\n\n\n         > (disassemble ' k e y )\n           14 PUSH-NUMBER         1\n           15 POP                 LOCALIS\n           16 PUSH                FEE 13    SYS:-.KEYWORD-GARBAGE\n           17 POP                 LOCAL 14\n           18 TEST                LOCAL 10\n           19 BR-NULL     24\n           20 PUSH                FEE 14    ' ( : A :B :C :D)\n           21 SET-NIL             PDL-PUSH\n           22 PUSH-LOC            LOCAL I I\n           23 (AUX) %STORE-KEY-WORD-ARGS\n           24 PUSH                LOCAL I I A\n           25 PUSH                LOCAL 12  \n           26 PUSH                LOCAL 13  C\n            27   PUSH             LOCAL 14\n            28   EQ               FEE 13        SYS::KEYWORD-GARBAGE\n            29   BR-NULL     33\n            30   PUSH             LOCAL I I     A\n            31   PUSH CALL-1      FEFI5         #'SQRT\n            32   RETURN CALL-4    FEE 16        #'LIST\n            33   PUSH             LOCAL 14\n            34   RETURN CALL-4    FEE 16        #'LIST\n\n\n      It is not important to be able to read all this assembly language. The point is that there\n      is considerable overhead, even though this architecture has a specific instruction\n      (%STORE-KEY-WORD-ARGS) to help deal with keyword arguments.\n           Now let's look at the results on another system, the Allegro compiler for the\n      68000. First, here's the assembly code for reg, to give you an idea of the minimal\n      calling sequence:^\n\n            (disassemble ' r e g )\n             disassembling #<Function reg � #x83db59>\n             form�is: a b e d\n             code vector @ #x83dblc\n         0         link     a6,#0\n         4        move.l    a2.-(a7)\n         6        move.l    a5.-(a7)\n         8        move.l    7(a2),a5\n         12       move.l    20(a6),-(a7)    a\n         16       move.l    16(a6).-(a7)    b\n         20       move.l    12(a6),-(a7)    c\n         24       move.l    8(a6).-(a7)     d\n         28       move.l    #4.dl\n         30       jsr       848(a4)         list\n\n         ^ These are all done with safety 0 and speed 3.\n\f103   AVOID     COMPLEX   ARGUMENT       LISTS                                                    325\n\n\n                 34       move.l    -8(a6).a5\n                 38       unlk     a6\n                 40       rtd      #10\n\n\n              Now we see that &rest arguments take a lot more code in this system:\n\n                 > (disassemble ' r s t )\n                 ;; disassembling #<Function r s t    @ #x83de89>\n                 ;; form�is: a D c &rest d\n                 11 code vector � #x83de34\n                 0:      sub.w   #3,dl\n                 2:      bge.s   8\n                 4:      jmp     16(a4)               ; wnaerr\n                 8:      move.l ( a 7 ) + . a l\n                 10      move.l d 3 . - ( a 7 )       ;   nil\n                 12      sub.w   #l,dl\n                 14      blt.s   38\n                 16      move.l a l , - 5 2 ( a 4 )   ; c-protected-retaddr\n                 20      jsr     40(a4)               ; cons\n                 24      move.l d 4 , - ( a 7 )\n                 26      dbra    dl,20\n                 30      move.l - 5 2 ( a 4 ) . a l   ; C -protected-retaddr\n                 34      clr.l    -52(a4)             ; C -protected-retaddr\n                 38      move.l a l . - ( a 7 )\n                 40      link    a6.#0\n                 44      move.l a 2 . - ( a 7 )\n                 46      move.l a 5 , - ( a 7 )\n                 48      move.l 7 ( a 2 ) . a 5\n                 52      move.l -332(a4),a0           ;   list*\n                 56      move.l - 8 ( a 6 ) , a 5\n                 60      unlk    a6\n                 62      move.l # 4 , d l\n                 64      jmp     (a4)\n\n\n              The loop from 20-26 builds up the &rest list one cons at a time. Part of the difficulty\n              is that cons could initiate a garbage collection at any time, so the list has to be built\n              in a place that the garbage collector will know about. The function with optional\n              arguments is even worse, taking 34 instructions (104 bytes), and keywords are worst\n              of all, weighing in at 71 instructions (178 bytes), and including a loop. The overhead\n              for optional arguments is proportional to the number of optional arguments, while\n              for keywords it is proportional to the product of the number of parameters allowed\n              and the number of arguments actually supplied.\n                  A good guideline to follow is to use keyword arguments primarily as an interface\n              to infrequently used functions, and to provide versions of these functions without\n              keywords that can be used in places where efficiency is important. Consider:\n\f326                                                               LOW-LEVEL   EFFICIENCY   ISSUES\n\n\n\n          (proclaim ' ( i n l i n e key))\n          (defun key (&key a b (c 1) (d ( s q r t a ) ) ) (*no-key   abed))\n          (defun *no-key ( a b e d )         (list    abed))\n\n\n      Here the function key is used as an interface to the function no - key, which does the\n      real work. The inline proclamation should allow the compiler to compile a call to key\n      as a call to no - key with the appropriate arguments:\n\n         > (disassemble #'(lambda (x y ) (key :b  :a y ) ) )\n            10 PUSH                ARG I I             Y\n            11 PUSH                ARG 10              X\n            12 PUSH-NUMBER          1\n            13 PUSH                ARG I I             Y\n            14 PUSH CALL-1          FEFI3              #'SQRT\n            15 TAIL-REC CALL-4          FEFI4          #*NO-KEY\n\n\n      The overhead only comes into play when the keywords are not known at compile\n      time. In the following example, the compiler is forced to call key, not no - key, because\n      it doesn't know what the keyword k will be at run time:\n\n         > (disassemble #*(lambda (k  y ) (key k  :a y ) ) )\n            10 PUSH                ARGIO               \n            11 PUSH                ARG 11              \n            12 PUSH                 FEFI3              ':\n            13 PUSH                ARG 12             \n            14 TAIL-REC CALL- 4         FEFI4         #\n\n\n      Of course, in this simple example I could have replaced no-key with 1 i s t , but in\n      general there will be some more complex processing. If I had proclaimed no-key\n      inline as well, then I would get the following:\n\n         > (disassemble #'(lambda (x y ) (key :b  :a y ) ) )\n            10 PUSH                ARG 11            ; Y\n            11 PUSH                ARG 10            ; \n            12 PUSH-NUMBER         1\n            13 PUSH                ARG I I           ; Y\n            14 PUSH CALL-1          FEFI3            ; #'SQRT\n            15 TAIL-REC CALL-4          FEFI4        ; #'LIST\n\n\n      If you like, you can define a macro to automatically define the interface to the keyword-\n      less function:\n\f103   AVOID    COMPLEX       ARGUMENT           LISTS                                                       327\n\n\n\n                 (defmacro defun* (fn-name a r g - l i s t &rest body)\n                   \"Define two f u n c t i o n s , one an interface to a &keyword-less\n                   v e r s i o n . Proclaim the interface function i n l i n e . \"\n                   ( i f (and (member '&key a r g - l i s t )\n                                    (not (member *&rest a r g - l i s t ) ) )\n                           ( l e t ((no-key-fn-name (symbol fn-name ' * n o - k e y ) )\n                                     (args (mapcar # ' f i r s t - o r - s e l f\n                                                          (set-difference\n                                                            arg-list\n                                                             1 ambda-list-keywords))))\n                                '(progn\n                                    (proclaim ' ( i n l i n e ,fn-name))\n                                    (defun ,no-key-fn-name ,args\n                                       ..body)\n                                    (defun ,fn-name , a r g - l i s t\n                                      (,no-key-fn-name . . a r g s ) ) ) )\n                           '(defun ,fn-name , a r g - l i s t\n                                ..body)))\n\n                 > (macroexpand ' ( d e f u n * key (&key a b (c 1) (d ( s q r t a ) ) )\n                                      ( l i s t a b c d)))\n                 (PROGN (PROCLAIM ' ( I N L I N E KEY))\n                        (DEFUN KEY*NO-KEY (A  C D) (LIST A  C D))\n                        (DEFUN KEY (&KEY A  (C 1) (D (SQRT A ) ) )\n                          (KEY*NO-KEY A  C D ) ) )\n\n                 > (macroexpand ' ( d e f u n * reg ( a b e d )             (list     abed)))\n                 (DEFUN REG (A  C D) (LIST A  C D))\n\n\n              There is one disadvantage to this approach: a user who wants to declare key inHne\n              or not inline does not get the expected result. The user has to know that key is\n              implemented with key*no- key, and declare key*no- key inline.\n                  An alternative is just to proclaim the function that uses &key to be inline. Rob\n              MacLachlan provides an example. In CMU Lisp, the function member has the follow\n              ing definition, which is proclaimed inline:\n\n                 (defun member (item l i s t &key (key # ' i d e n t i t y )\n                                             ( t e s t #'eql t e s t p ) ( t e s t - n o t n i l   notp))\n                   (do ( ( l i s t l i s t (cdr l i s t ) ) )\n                          ((null l i s t ) n i l )\n                      ( l e t ( ( c a r (car l i s t ) ) )\n                           ( i f (cond\n                                  (testp\n                                    (funcall t e s t item\n                                               (funcall key c a r ) ) )\n                                  (notp\n                                    (not\n\f328                                                                    LOW-LEVEL   EFFICIENCY   ISSUES\n\n\n\n                              (funcall t e s t - n o t item\n                                       (funcall key c a r ) ) ) )\n                          (t\n                           (funcall t e s t item\n                                      (funcall key c a r ) ) ) )\n                         (return l i s t ) ) ) ) )\n\n\n      A call like (member ch 1 :key # ' f i r s t - l e t t e r r t e s t #'cha r=) expands into the\n      equivalent of the following code. Unfortunately, not all compilers are this clever with\n      inline declarations.\n\n          (do ( ( l i s t l i s t (cdr l i s t ) ) )\n                 ((null l i s t ) n i l )\n             ( l e t ( ( c a r (car l i s t ) ) )\n                 ( i f (char= ch ( f i r s t - l e t t e r c a r ) )\n                       (return l i s t ) ) ) )\n\n\n      This chapter is concerned with efficiency and so has taken a stand against the use\n      of keyword parameters in frequently used functions. But when maintainability\n      is considered, keyword parameters look much better. When a program is being\n      developed, and it is not clear if a function will eventually need additional arguments,\n      keyword parameters may be the best choice.\n\n\n\n\n      10.4          Avoid Unnecessary Consing\n      The cons function may appear to execute quite quickly, but like all functions that\n      allocate new storage, it has a hidden cost. When large amounts of storage are\n      used, eventually the system must spend time garbage collecting. We have not\n      mentioned it earlier, but there are actually two relevant measures of the amount of\n      space consumed by a program: the amount of storage allocated, and the amount of\n      storage retained. The difference is storage that is used temporarily but eventually\n      freed. Lisp guarantees that unused space will eventually be reclaimed by the garbage\n      collector. This happens automatically--the programmer need not and indeed can not\n      explicitly free storage. The problem is that the efficiency of garbage collection can\n      vary widely. Garbage collection is particularly worrisome for real-time systems,\n      because it can happen at any time.\n          The antidote to garbage woes is to avoid unnecessary copying of objects in often-\n      used code. Try using destructive operations, like nreverse, d e l e t e , and nconc,\n      rather than their nondestructive counterparts, (like reverse, remove, and append)\n      whenever it is safe to do so. Or use vectors instead of lists, and reuse values rather\n      than creating copies. As usual, this gain in efficiency may lead to errors that can\n\f10.4 AVOID     UNNECESSARY            CONSINC                                                                      329\n\n\n\n             be difficult to debug. However, the most common kind of unnecessary copying\n             can be eliminated by simple reorganization of your code. Consider the following\n             version of f 1 a t t e n , which returns a list of all the atoms in its input, preserving order.\n             Unlike the version in chapter 5, this version returns a single list of atoms, with no\n             embedded lists.\n\n                 (defun f l a t t e n ( i n p u t )\n                   \"Return a f l a t l i s t of the atoms i n the i n p u t .\n                   Ex: ( f l a t t e n ' ( ( a ) (b (c) d ) ) ) = > (a b c d ) . \"\n                   (cond ( ( n u l l input) n i l )\n                            ((atom input) ( l i s t i n p u t ) )\n                            (t (append ( f l a t t e n ( f i r s t i n p u t ) )\n                                               (flatten (rest input))))))\n\n\n             This definition is quite simple, and it is easy to see that it is correct. However, each\n             call to append requires copying the first argument, so this version can cons O ( n ^ ) cells\n             on an input with  atoms. The problem with this approach is that it computes the\n             list of atoms in the f 1 r s t and r e s t of each subcomponent of the input. But the f i r s t\n             sublist by itself is not part of the final answer--that's why we have to call append. We\n             could avoid generating garbage by replacing append with nconc, but even then we\n             would still be wasting time, because nconc would have to scan through each sublist\n             to find its end.\n                  The version below makes use of an accumulator to keep track of the atoms that\n             have been collected in the r e s t , and to add the atoms in the f 1 r s t one at a time with\n             cons, rather than building up unnecessary sublists and appending them. This way\n             no garbage is generated, and no subcomponent is traversed more than once.\n\n                 (defun f l a t t e n (input &optional accumulator)\n                   \"Return a f l a t l i s t of the atoms i n the i n p u t .\n                   Ex: ( f l a t t e n ' ( ( a ) (b (c) d ) ) ) = > (a b c d ) . \"\n                   (cond ( ( n u l l input) accumulator)\n                            ((atom input) (cons input accumulator))\n                            (t ( f l a t t e n ( f i r s t input)\n                                                ( f l a t t e n ( r e s t input) a c c u m u l a t o r ) ) ) ) )\n\n\n             The version with the accumulator may be a little harder to understand, but it is far\n             more efficient than the original version. Experienced Lisp programmers become\n             quite skilled at replacing calls to append with accumulators.\n\n                 Some of the early Lisp machines had unreliable garbage-collection, so users\n             just turned garbage collection off, used the machine for a few days, and rebooted\n             when they ran out of space. With a large virtual memory system this is a feasible\n             approach, because virtual memory is a cheap resource. The problem is that real\n             memory is still an expensive resource. When each page contains mostly garbage\n\f330                                                                LOW-LEVEL     EFFICIENCY     ISSUES\n\n\n\n      and only a little live data, the system will spend a lot of time paging data in and out.\n      Compacting garbage-collection algorithms can relocate live data, packing it into a\n      minimum number of pages.\n         Some garbage-collection algorithms have been optimized to deal particularly well\n      with just this case. If your system has an ephemeral or generational garbage collector,\n      you need not be so concerned with short-lived objects. Instead, it will be the medium-\n      aged objects that cause problems. The other problem with such systems arises when\n      an object in an old generation is changed to point to an object in a newer generation.\n      This is to be avoided, and it may be that reverse is actually faster than nreverse in\n      such cases. To decide what works best on your particular system, design some test\n      cases and time them.\n\n           As an example of efficient use of storage, here is a version of pat-match that\n      eliminates (almost) all consing. The original version of pat-match, as used in ELIZA\n      (page 180), used an association list of variable/value pairs to represent the binding\n      list. This version uses two sequences: a sequence of variables and a sequence of\n      values. The sequences are implemented as vectors instead of lists. In general, vectors\n      take half as much space as lists to store the same information, since half of every list\n      is just pointing to the next element.\n           In this case, the savings are much more substantial than just half. Instead of\n      building up small binding lists for each partial match and adding to them when the\n      match is extended, we will allocate a sufficiently large vector of variables and values\n      just once, and use them over and over for each partial match, and even for each\n      invocation of pat-match. To do this, we need to know how many variables we are\n      currently using. We could initialize a counter variable to zero and increment it each\n      time we found a new variable in the pattern. The only difficulty would be when the\n      counter variable exceeds the size of the vector. We could just give up and print an\n      error message, but there are more user-friendly alternatives. For example, we could\n      allocate a larger vector for the variables, copy over the existing ones, and then add in\n      the new one.\n           It turns out that Common Lisp has a built-in facility to do just this. When a\n      vector is created, it can be given a fill pointer. This is a counter variable, but one that\n      is conceptually stored inside the vector. Vectors with fill pointers act like a cross\n      between a vector and a stack. You can push new elements onto the stack with the\n      functions vector -push or vector- push -extend. The latter will automatically allocate\n      a larger vector and copy over elements if necessary. You can remove elements with\n      vector - pop, or you can explicitly look at the fill pointer with f  1 - poi  te r, or change\n      it with a s e t f . Here are some examples (with * p r i n t - a r r a y * set to t so we can see\n      the results):\n\n         > (setf a (make-array 5 :fiH-pointer 0)) ^ #()\n\n         > (vector-push 1 a)         0\n\f10.4   AVOID     UNNECESSARY         CONSING                                                             331^\n\n\n\n\n                   > (vector-push 2 a) => 1\n\n                   > a =^ # ( 1 2)\n\n                   > (vector-pop a) =^ 2\n\n                   > a     #(1)\n\n                   > (dotimes (i 10) (vector-push-extend ' x a ) )                NIL\n\n                   >a=:^#(lXXXXXXXXXX)\n\n                  > ( f i l l - p o i n t e r a) => 11\n\n                  > (setf ( f i l l - p o i n t e r a) 1)   1\n\n                  > a =^ #(1)\n\n                  > (find *x a) =^ NIL NIL                  ; FIND can't find past the fill pointer\n\n                  > (aref a 2) =^ X                         ; But AREF can see beyond the fill pointer\n\n\n               Using vectors with fill pointers in pat -match, the total storage for binding lists is\n               just twice the number of variables in the largest pattern. I have arbitrarily picked\n               10 as the maximum number of variables, but even this is not a hard limit, because\n               vector -push -extend can increase it. In any case, the total storage is small, fixed\n               in size, and amortized over all calls to pat -match. These are just the features that\n               indicate a responsible use of storage.\n                   However, there is a grave danger with this approach: the value returned must\n               be managed carefully. The new pat -match returns the value of success when it\n               matches, success is bound to a cons of the variable and value vectors. These can be\n               freely manipulated by the calling routine, but only up until the next call to pa t - ma tch.\n               At that time, the contents of the two vectors can change. Therefore, if any calling\n               function needs to hang on to the returned value after another call to pat -match, it\n               should make a copy of the returned value. So it is not quite right to say that this\n               version of pat -match eliminates all consing. It will cons when vector- push -extend\n               runs out of space, or when the user needs to make a copy of a returned value.\n                   Here is the new definition of pat -match. It is implemented by closing the defi\n               nition of pat -match and its two auxilliary functions inside a 1 e t that establishes the\n               bindings of vars, val s , and s u c c e s s , but that is not crucial. Those three variables\n               could have been implemented as global variables instead. Note that it does not sup\n               port segment variables, or any of the other options implemented in the pat -match\n               of chapter 6.\n\n                   ( l e t * ((vars (make-array 10 : f i l l - p o i n t e r 0 ladjustable t ) )\n                              (vals (make-array 10 : f i l l - p o i n t e r 0 :adjustable t ) )\n                              (success (cons vars v a l s ) ) )\n\f332                                                                       LOW-LEVEL EFFICIENCY ISSUES\n\n\n            (defun efficient-pat-match (pattern input)\n              \"Match pattern against i n p u t . \"\n              ( s e t f ( f i l l - p o i n t e r v a r s ) 0)\n              ( s e t f ( f i l l - p o i n t e r v a l s ) 0)\n              (pat-match-1 pattern i n p u t ) )\n\n\n            (defun pat-match-1 (pattern input)\n              (cond ( ( v a r i a b l e - p pattern) (match-var pattern i n p u t ) )\n                    ((eql pattern input) success)\n                    ((and (consp pattern) (consp i n p u t ) )\n                      (and (pat-match-1 ( f i r s t pattern) ( f i r s t i n p u t ) )\n                                (pat-match-1 ( r e s t pattern) ( r e s t i n p u t ) ) ) )\n                    (t f a i l ) ) )\n\n\n            (defun match-var (var input)\n              \"Match a s i n g l e v a r i a b l e against i n p u t . \"\n              ( l e t ( ( i ( p o s i t i o n var v a r s ) ) )\n                   (cond ( ( n u l l i )\n                            (vector-push-extend var v a r s )\n                            (vector-push-extend input v a l s )\n                            success)\n                           ((equal input (aref v a l s i ) ) success)\n                           (t f a i l ) ) ) ) )\n\n\n      An example of its use:\n\n         > (efficient-pat-match ' ( T x + ? x = ?y . ? z )\n                                ' ( 2 + 2 = (3 + 1) i s t r u e ) )\n         (#(?X ?Y 11) . #(2 (3 + 1) ( I S TRUE)))\n\n\n      Extensible vectors with fill pointers are convenient, and much more efficient than\n      consing up lists. However, there is some overhead involved in using them, and for\n      those sections of code that must be most efficient, it is best to stick with simple\n      vectors. The following version of e f f i cient-pat-match explicitly manages the size\n      of the vectors and explicitly replaces them with new ones when the size is exceeded:\n\n         ( l e t * ( ( c u r r e n t - s i z e 0)\n                     (max-size 1)\n                     (vars (make-array max-size))\n                     ( v a l s (make-array max-size))\n                     (success (cons vars v a l s ) ) )\n             (declare (simple-vector vars v a l s )\n                             (fixnum c u r r e n t - s i z e max-size))\n\fWA   AVOID     UNNECESSARY              CONSING                                                         333\n\n\n\n                    (defun efficient-pat-match (pattern input)\n                         \"Match pattern against i n p u t . \"\n                         ( s e t f c u r r e n t - s i z e 0)\n                         (pat-match-1 pattern i n p u t ) )\n\n\n\n                          pat-match-1 i s unchanged\n\n\n\n                   (defun match-var (var input)\n                         \"Match a s i n g l e v a r i a b l e against i n p u t . \"\n                         (let    ( ( i ( p o s i t i o n var v a r s ) ) )\n                            (cond\n                                ((null      i)\n                                 (when (= c u r r e n t - s i z e max-size)\n                                         Make new vectors when we run out of space\n                                     ( s e t f max-size ( * 2 max-size)\n                                                 vars (replace (make-array max-size) v a r s )\n                                                 v a l s (replace (make-array max-size) v a l s )\n                                                 success (cons vars v a l s ) ) )\n                                 ; ; Store var and i t s value i n vectors\n                                 ( s e t f (aref vars c u r r e n t - s i z e ) v a r )\n                                 ( s e t f (aref v a l s c u r r e n t - s i z e ) input)\n                                 (incf current-size)\n                                 success)\n                                ((equal input (aref v a l s i ) ) success)\n                                (t   fail)))))\n\n\n             In conclusion, replacing lists with vectors can often save garbage. But when you\n             must use lists, it pays to use a version of cons that avoids consing when possible. The\n             following is such a version:\n\n                 (proclaim ' ( i n l i n e reuse-cons))\n\n                 (defun reuse-cons (x y x - y )\n                   \"Return (cons  y ) , or j u s t x - y i f i t i s equal to (cons  y ) . \"\n                   (if      (and (eql  (car x - y ) ) (eql y (cdr x - y ) ) )\n                           x-y\n                           (cons X y ) ) )\n\n\n             The trick is based on the definition of s u b s t in Steele's Common Lisp the          Language.\n             Here is a definition for a version of remove that uses r e u s e - c o n s :\n\f334                                                                                 LOW-LEVEL          EFFICIENCY   ISSUES\n\n\n\n          (defun remq (item l i s t )\n             \"Like REMOVE, but uses EQ, and only works on l i s t s . \"\n             (cond ( ( n u l l l i s t )   nil)\n                      ((eq    item ( f i r s t l i s t ) )    (remq item ( r e s t l i s t ) ) )\n                      (t (reuse-cons ( f i r s t             list)\n                                              (remq item ( r e s t l i s t ) )\n                                              list))))\n\n\n\n\n      Avoid Consing: Unique Lists\n\n      Of course, reuse - cons only works when you have candidate cons cells around. That\n      is, ( r e u s e - c o n s a b c ) only saves space when c is (or might be) equal to (cons a b ) .\n      For some applications, it is useful to have a version of cons that returns a unique cons\n      cell without needing c as a hint. We will call this version ucons for \"unique cons.\"\n      ucons maintains a double hash table: *uni q - cons - tabl e* is a hash table whose keys\n      are the cars of cons cells. The value for each car is another hash table whose keys\n      are the cdrs of cons cells. The value of each cdr in this second table is the original\n      cons cell. So two different cons cells with the same ca r and cdr will retrieve the same\n      value. Here is an implementation of ucons:\n\n          (defvar * u n i q - c o n s - t a b l e * (make-hash-table : t e s t # ' e q ) )\n\n          (defun ucons (x y )\n            \"Return a cons s . t . (eq (ucons  y ) (ucons  y ) ) i s t r u e . \"\n            ( l e t ( ( c a r - t a b l e (or (gethash  * u n i q - c o n s - t a b l e * )\n                                             ( s e t f (gethash  * u n i q - c o n s - t a b l e * )\n                                                       (make-hash-table : t e s t # ' e q ) ) ) ) )\n               (or   (gethash y c a r - t a b l e )\n                     ( s e t f (gethash y c a r - t a b l e ) (cons  y ) ) ) ) )\n\n\n      ucons, unlike cons, is a true function: it will always return the same value, given\n      the same arguments, where \"same\" is measured by eq. However, if ucons is given\n      arguments that are equal but not eq, it will not return a unique result. For that\n      we need the function unique. It has the property that (unique x) is eq to (unique\n      y) whenever  and y are equal. unique uses a hash table for atoms in addition to\n      the double hash table for conses. This is necessary because strings and arrays can\n      be equal without being eq. Besides unique, we also define ul i s t and uappend for\n      convenience.\n\n          (defvar *uniq-atom-table* (make-hash-table .-test # ' e q u a l ) )\n\f10.4 AVOID     UNNECESSARY          CONSING                                                                    335\n\n\n\n                 (defun unique (exp)\n                   \"Return a canonical representation that i s EQUAL to exp.\n                   such that (equal  y ) implies (eq (unique x) (unique y ) ) . \"\n                   (typecase exp\n                      (symbol exp)\n                      (fixnum exp)          Remove i f fixnums are not eq i n your Lisp\n                      (atom    (or (gethash exp *uniq-atom-table*)\n                                   ( s e t f (gethash exp *uniq-atom-table*) exp)))\n                      (cons    (unique-cons (car exp) (cdr e x p ) ) ) ) )\n\n\n                 (defun unique-cons (x y )\n                   \"Return a cons s . t . (eq (ucons  y ) (ucons x2 y 2 ) ) i s true\n                   whenever (equal  x2) and (equal y y 2 ) are t r u e . \"\n                   (ucons (unique x) (unique y ) ) )\n\n                 (defun u l i s t (&rest args)\n                   \"A u n i q u i f i e d l i s t . \"\n                   (unique a r g s ) )\n\n                 (defun uappend (x y )\n                   \"A unique l i s t equal to (append  y ) . \"\n                   ( i f (null X )\n                         (unique y )\n                         (ucons ( f i r s t x) (uappend ( r e s t x) y ) ) ) )\n\n\n             The above code works, but it can be improved. The problem is that when uni que is\n             applied to a tree, it always traverses the tree all the way to the leaves. The function\n             u n i q u e - c o n s is like ucons, except that u n i q u e - c o n s assumes its arguments are not\n             yet unique. We can modify uni que - cons so that it first checks to see if its arguments\n             are unique, by looking in the appropriate hash tables:\n\n                 (defun unique-cons (x y )\n                   \"Return a cons s . t . (eq (ucons  y ) (ucons x2 y 2 ) ) i s true\n                   whenever (equal  x2) and (equal y y 2 ) are t r u e . \"\n                   (let ((ux) (uy))                                          : unique  and y\n                     (let ((car-table\n                               (or (gethash  * u n i q - c o n s - t a b l e * )\n                                     (gethash ( s e t f ux (unique x ) ) * u n i q - c o n s - t a b l e * )\n                                     ( s e t f (gethash ux * u n i q - c o n s - t a b l e * )\n                                               (make-hash-table : t e s t # * e q ) ) ) ) )\n                       (or (gethash y c a r - t a b l e )\n                           (gethash ( s e t f uy (unique y ) ) c a r - t a b l e )\n                           ( s e t f (gethash uy c a r - t a b l e )\n                                     (cons ux u y ) ) ) ) ) )\n\n\n                Another advantage of uni que is that it can help in indexing. If lists are unique,\n             then they can be stored in an eq hash table instead of a equal hash table. This can\n\f336                                                                    LOW-LEVEL EFFICIENCY ISSUES\n\n\n      lead to significant savings v^hen the list structures are large. An eq hash table for\n      lists is almost as good as a property list on symbols.\n\n\n      Avoid Consing: Multiple Values\n\n      Parameters and multiple values can also be used to pass around values, rather than\n      building up lists. For example, instead of:\n\n          (defstruct point \"A point i n 3-D c a r t e s i a n s p a c e . \"  y z)\n\n          (defun s c a l e - p o i n t (k pt)\n            \" M u l t i p l y a point by a constant, K.\"\n            (make-point :x (* k ( p o i n t - x p t ) )\n                                :y ( * k ( p o i n t - y p t ) )\n                                :z ( * k ( p o i n t - z p t ) ) ) )\n\n\n      one could use the following approach, which doesn't generate structures:\n\n          (defun s c a l e - p o i n t (k  y z )\n            \" M u l t i p l y the point ( x , y , z ) by a constant, K.\"\n            (values ( * k x) ( * k y ) (* k z ) ) )\n\n\n      Avoid Consing: Resources\n\n      Sometimes it pays to manage explicitly the storage of instances of some data type. A\n      pool of these instances may be called a resource. Explicit management of a resource\n      is appropriate when: (1) instances are frequently created, and are needed only\n      temporarily; (2) it is easy/possible to be sure when instances are no longer needed;\n      and (3) instances are fairly large structures or take a long time to initialize, so that it\n      is worth reusing them instead of creating new ones. Condition (2) is the crucial one:\n      If you deallocate an instance that is still being used, that instance will mysteriously\n      be altered when it is reallocated. Conversely, if you fail to deallocate unneeded\n      instances, then you are wasting valuable memory space. (The memory management\n      scheme is said to leak in this case.)\n          The beauty of using Lisp's built-in memory management is that it is guaranteed\n      never to leak and never to deallocate structures that are in use. This eliminates two\n      potential bug sources. The penalty you pay for this guarantee is some inefficiency of\n      the general-purpose memory management as compared to a custom user-supplied\n      management scheme. But beware: modern garbage-collection techniques are highly\n      optimized. In particular, the so-called generation scavenging or ephemeral garbage\n      collectors look more often at recently allocated storage, on the grounds that recently\n      made objects are more likely to become garbage. If you hold on to garbage in your\n      own data structures, you may end up with worse performance.\n\fWA   AVOID    UNNECESSARY           CONSING                                                                            337\n\n\n\n                With all these warnings in mind, here is some code to manage resources:\n\n                (defmacro defresource (name &key constructor ( i n i t i a l - c o p i e s 0)\n                                                           ( s i z e (max i n i t i a l - c o p i e s 1 0 ) ) )\n                  ( l e t ((resource (symbol name ' - r e s o u r c e ) )\n                                (deallocate (symbol ' d e a l l o c a t e - name))\n                                ( a l l o c a t e (symbol ' a l l o c a t e - name)))\n                       ' ( l e t ( ( . r e s o u r c e (make-array . s i z e i f i l l - p o i n t e r 0 ) ) )\n                              (defun . a l l o c a t e ()\n                                   \"Get an element from the resource p o o l , or make o n e . \"\n                                   ( i f (= ( f i l l - p o i n t e r .resource) 0)\n                                           .constructor\n                                           (vector-pop . r e s o u r c e ) ) )\n                              (defun .deallocate (.name)\n                                   \"Place a no-longer-needed element back in the p o o l . \"\n                                   (vector-push-extend .name . r e s o u r c e ) )\n                              . ( i f (> i n i t i a l - c o p i e s 0)\n                                         '(mapc # ' . d e a l l o c a t e (loop repeat . i n i t i a l - c o p i e s\n                                                                                     collect (.allocate))))\n                              '.name)))\n\n\n             Let's say we had some structure called a buffer which we were constantly making\n             instances of and then discarding. Furthermore, suppose that buffers are fairly\n             complex objects to build, that we know we'll need at least 10 of them at a time, and\n             that we probably won't ever need more than 100 at a time. We might use the buffer\n             resource as follows:\n\n                (defresource buffer :constructor (make-buffer)\n                             : s i z e 100 : i n i t i a l - c o p i e s 10)\n\n\n             This expands into the following code:\n\n                ( l e t ( ( b u f f e r - r e s o u r c e (make-array 100 : f i l 1-pointer 0 ) ) )\n                     (defun a l l o c a t e - b u f f e r ()\n                       \"Get an element from the resource p o o l , or make o n e . \"\n                       ( i f (= ( f i l 1 - p o i n t e r buffer-resource) 0)\n                            (make-buffer)\n                            (vector-pop b u f f e r - r e s o u r c e ) ) )\n                     (defun deallocate-buffer (buffer)\n                        \"Place a no-longer-needed element back in the p o o l . \"\n                       (vector-push-extend buffer b u f f e r - r e s o u r c e ) )\n                     (mapc # ' d e a n o c a t e - b u f f e r\n                              (loop repeat 10 c o l l e c t          (allocate-buffer)))\n                     'buffer)\n\f338                                                                        LOW-LEVEL   EFFICIENCY   ISSUES\n\n\n\n      We could then use:\n\n          (let ((b (allocate-buffer)))\n\n            (process b)\n\n            (deallocate-buffer b ) ) )\n\n\n      The important thing to remember is that this works only if the buffer b really can\n      be deallocated. If the function process stored away a pointer to b somewhere,\n      then it would be a mistake to deallocate b, because a subsequent allocation could\n      unpredictably alter the stored buffer. Of course, if p r o c e s s stored a copy of b, then\n      everything is alright. This pattern of allocation and deallocation is so common that\n      we can provide a macro for it:\n\n          (defmacro with-resource ( ( v a r resource �optional protect) &rest body)\n            \"Execute body with VAR bound to an instance of RESOURCE.\"\n            ( l e t ( ( a l l o c a t e (symbol ' a l l o c a t e - resource))\n                       (deallocate (symbol ' d e a l l o c a t e - r e s o u r c e ) ) )\n                 ( i f protect\n                       �(let ((.var n i l ) )\n                             (unwind-protect\n                                 (progn ( s e t f , v a r ( . a l l o c a t e ) ) .�body)\n                                 (unless (null . v a r ) ( . d e a l l o c a t e . v a r ) ) ) )\n                       �(let ((.var (.allocate)))\n                             .�body\n                             (.deallocate . v a r ) ) ) ) )\n\n\n      The macro allows for an optional argument that sets up an unwi nd - p r o t e c t environ\n      ment, so that the buffer gets deallocated even when the body is abnormally exited.\n      The following expansions should make this clearer:\n\n         > (macroexpand ' ( w i t h - r e s o u r c e (b buffer)\n                             \"...\"        (process b) \" . . . \" ) )\n         (let ((b (allocate-buffer)))\n                  It\n\n            (process b)\n            11    II\n\n            (deallocate-buffer b ) )\n\n         > (macroexpand ' ( w i t h - r e s o u r c e (b buffer t )\n                                  \"...\"    (process b) \" . . . \" ) )\n         ( l e t ((b n i l ) )\n             (unwind-protect\n                  (progn ( s e t f b ( a l l o c a t e - b u f f e r ) )\n\f10.5 USE THE RIGHT   DATA STRUCTURES                                                             339\n\n\n\n                           (process b)\n                           \"...\")\n                  (unless (null b)\n                    (deallocate-buffer b ) ) ) )\n\n\n          An alternative to full resources is to just save a single data object. Such an approach\n          is simpler because there is no need to index into a vector of objects, but it is sufficient\n          for some applications, such as a tail-recursive function call that only uses one object\n          at a time.\n               Another possibility is to make the system slower but safer by having the\n          deal 1 ocate function check that its argument is indeed an object of the correct type.\n               Keep in mind that using resources may put you at odds with the Lisp system's own\n          storage management scheme. In particular, you should be concerned with paging\n          performance on virtual memory systems. A common problem is to have only a few\n          live objects on each page, thus forcing the system to do a lot of paging to get any work\n          done. Compacting garbage collectors can collect live objects onto the same page, but\n          using resources may interfere with this.\n\n\n\n\n          10.5        Use the Right Data Structures\n          It is important to implement key data types with the most efficient implementation.\n          This can vary from machine to machine, but there are a few techniques that are\n          universal. Here we consider three case studies.\n\n\n          The Right Data Structure: Variables\n\n          As an example, consider the implementation of pattern-matching variables. We saw\n          from the instrumentation of s i mp 1 i f y that variable-p was one of the most frequently\n          used functions. In compiling the matching expressions, I did away with all calls to\n          vari abl e-p, but let's suppose we had an application that required run-time use of\n          variables. The specification of the data type vari abl e will include two operators,\n          the recognizer vari abl e-p, and the constructor make-vari abl e, which gives a new,\n          previously unused variable. (This was not needed in the pattern matchers shown so\n          far, but will be needed for unification with backward chaining.) One implementation\n          of variables is as symbols that begin with the character # \\ ? :\n\n              (defun v a r i a b l e - p (x)\n                \" I s X a v a r i a b l e (a symbol beginning with * ? ' ) ? \"\n                (and (symbolp x) (equal ( e l t (symbol-name x) 0) # \\ ? ) ) )\n\f340                                                                                    LOW-LEVEL         EFFICIENCY   ISSUES\n\n\n\n          (defun make-variable () \"Generate a new v a r i a b l e \" (gentemp \" ? \" ) )\n\n\n      We could try to speed things up by changing the implementation of variables to be\n      keywords and making the functions inline:\n\n          (proclaim ' ( i n l i n e v a r i a b l e - p make-variable))\n          (defun v a r i a b l e - p (x) \" I s  a v a r i a b l e ? \" (keywordp x ) )\n          (defun make-variable () (gentemp \" X \" # . ( f i n d - p a c k a g e \"KEYWORD\")))\n\n\n      (The reader character sequence # . means to evaluate at read time, rather than at\n      execution time.) On my machine, this implementation is pretty fast, and I accepted\n      it as a viable compromise. However, other implementations were also considered.\n      One was to have variables as structures, and provide a read macro and print function:\n\n          (defstruct ( v a r i a b l e ( i p r i n t - f u n c t i o n p r i n t - v a r i a b l e ) ) name)\n\n          (defvar * v a r s * (make-hash-table))\n\n          (set-macro-character # \\ ?\n            #'(lambda (stream char)\n                       Find an old v a r , or make a new one with the given name\n                 (declare (ignore char))\n                 ( l e t ((name (read stream t n i l t ) ) )\n                     (or (gethash name * v a r s * )\n                           ( s e t f (gethash name * v a r s * ) (make-variable mame name))))))\n\n          (defun p r i n t - v a r i a b l e (var stream depth)\n            (declare (ignore depth))\n            (format stream \" ? ~ a \" (var-name v a r ) ) )\n\n\n      It turned out that, on all three Lisps tested, structures were slower than keywords\n      or symbols. Another alternative is to have the ? read macro return a cons whose\n      first is, say, : var. This requires a special output routine to translate back to the ?\n      notation. Yet another alternative, which turned out to be the fastest of all, was to\n      implement variables as negative integers. Of course, this means that the user cannot\n      use negative integers elsewhere in patterns, but that turned out to be acceptable for\n      the application at hand. The moral is to know which features are done well in your\n      particular implementation and to go out of your way to use them in critical situations,\n      but to stick with the most straightforward implementation in noncritical sections.\n          Lisp makes it easy to rely on lists, but one must avoid the temptation to overuse\n      lists; to use them where another data structure is more appropriate. For example, if\n      you need to access elements of a sequence in arbitrary order, then a vector is more\n      appropriate than list. If the sequence can grow, use an adjustable vector. Consider\n      the problem of maintaining information about a set of people, and searching that set.\n      A naive implementation might look like this:\n\f10.5 USE THE RIGHT   DATA STRUCTURES                                                            341\n\n\n\n              (defvar *people* n i l   \"Will hold a l i s t of people\")\n\n              (defstruct person name address id-number)\n\n              (defun person-with-id ( i d )\n                ( f i n d id *people* :key #'person-id-number))\n\n\n          In a traditional language like C, the natural solution is to include in the person\n          structure a pointer to the next person, and to write a loop to follow these pointers.\n          Of course, we can do that in Lisp too:\n\n              (defstruct person name address id-number next)\n\n              (defun person-with-id ( i d )\n                (loop for person = *people* then (person-next person)\n                      u n t i l (null person)\n                      do (when (eql id (person-id-number person))\n                               (RETURN p e r s o n ) ) ) )\n\n\n          This solution takes less space and is probably faster, because it requires less memory\n          accesses: one for each person rather than one for each person plus one for each\n          cons cell. So there is a small price to pay for using lists. But Lisp programmers feel\n          that price is worth it, because of the convenience and ease of coding and debugging\n          afforded by general-purpose functions like f i nd.\n              In any case, if there are going to be a large number of people, the list is definitely\n          the wrong data structure. Fortunately, Lisp makes it easy to switch to more efficient\n          data structures, for example:\n\n             (defun person-with-id ( i d )\n               (gethash id *people*))\n\n\n\n\n          The Right Data Structure: Queues\n\n          A queue is a data structure where one can add elements at the rear and remove them\n          from the front. This is almost like a stack, except that in a stack, elements are both\n          added and removed at the same end.\n               Lists can be used to implement stacks, but there is a problem in using lists to\n          implement queues: adding an element to the rear requires traversing the entire list.\n          So collecting  elements would be O(n^) instead of 0{n).\n               An alternative implementation of queues is as a cons of two pointers: one to the\n          list of elements of the queue (the contents), and one to the last cons cell in the list.\n          Initially, both pointers would be nil. This implementation in fact existed in BBN Lisp\n          and UCI Lisp under the function name tconc:\n\f342                                                                   LOW-LEVEL   EFFICIENCY   ISSUES\n\n\n\n         ;;;     A queue i s a (contents . l a s t ) p a i r\n\n         (defun tconc (item q)\n           \" I n s e r t item at the end of the queue.\"\n           ( s e t f (cdr q)\n                       ( i f (null (cdr q ) )\n                             ( s e t f (car q) (cons item n i l ) )\n                             ( s e t f ( r e s t (cdr q ) )\n                                       (cons item n i l ) ) ) ) )\n\n\n      The tconc implementation has the disadvantage that adding the first element to\n      the contents is different from adding subsequent elements, so an i f statement is\n      required to decide which action to take. The definition of queues given below avoids\n      this disadvantage with a clever trick. First, the order of the two fields is reversed.\n      The car of the cons cell is the last element, and the cdr is the contents. Second, the\n      empty queue is a cons cell where the cdr (the contents field) is nil, and the car (the\n      last field) is the cons itself. In the definitions below, we change the name tconc to\n      the more standard enqueue, and provide the other queue functions as well:\n\n         ;;;     A queue i s a ( l a s t . contents) p a i r\n\n         (proclaim ' ( i n l i n e queue-contents make-queue enqueue dequeue\n                                   front empty-queue-p queue-nconc))\n\n         (defun queue-contents (q) (cdr q ) )\n\n         (defun make-queue ()\n           \" B u i l d a new queue, with no elements.\"\n           ( l e t ((q (cons n i l n i l ) ) )\n               ( s e t f (car q) q ) ) )\n\n         (defun enqueue (item q)\n           \" I n s e r t item at the end of the queue.\"\n           ( s e t f (car q)\n                       ( s e t f ( r e s t (car q ) )\n                                 (cons item n i l ) ) )\n           q)\n\n         (defun dequeue (q)\n           \"Remove an item from the f r o n t of the queue.\"\n           (pop (cdr q ) )\n               (if   (null (cdr q ) ) ( s e t f (car q) q ) )\n           q)\n\n         (defun front (q) ( f i r s t (queue-contents q ) ) )\n\n         (defun empty-queue-p (q) (null (queue-contents q ) ) )\n\f10,5 USE THE RIGHT    DATA STRUCTURES                                                               343\n\n\n\n              (defun queue-nconc (q l i s t )\n                \"Add the elements of LIST to the end of the queue.\"\n                ( s e t f (car q)\n                          ( l a s t ( s e t f ( r e s t (car q ) ) l i s t ) ) ) )\n\n\n\n\n          The Right Data Structure: Tables\n\n          A table is a data structure to which one can insert a key and associate it with a value,\n          and later use the key to look up the value. Tables may have other operations, like\n          counting the number of keys, clearing out all keys, or mapping a function over each\n          key/value pair.\n              Lisp provides a wide variety of choices to implement tables. An association list\n          is perhaps the simplest: it is just a list of key/value pairs. It is appropriate for small\n          tables, up to a few dozen pairs. The hash table is designed to be efficient for large\n          tables, but may have significant overhead for small ones. If the keys are symbols,\n          property lists can be used. If the keys are integers in a narrow range (or can be\n          mapped into them), then a vector may be the most efficient choice.\n              Here we implement an alternative data structure, the trie. A trie implements a\n          table for keys that are composed of a finite sequence of components. For example,\n          if we were implementing a dictionary as a trie, each key would be a word, and\n          each letter of the word would be a component. The value of the key would be the\n          word's definition. At the top of the dictionary trie is a multiway branch, one for each\n          possible first letter. Each second-level node has a branch for every possible second\n          letter, and so on. To find an n-letter word requires  reads. This kind of organization\n          is especially good when the information is stored on secondary storage, because a\n          single read can bring in a node with all its possible branches.\n              If the keys can be arbitrary list structures, rather than a simple sequence of letters,\n          we need to regularize the keys, transforming them into a simple sequence. One way\n          to do that makes use of the fact that any tree can be written as a linear sequence\n          of atoms and cons operations, in prefix form. Thus, we would make the following\n          transformation:\n\n              (a (b c) d) =\n              (cons a (cons (cons b (cons c n i l ) ) (cons d n i l ) ) )       =\n              (cons a cons cons b cons c n i l         cons d n i l )\n\n\n          In the implementation of tries below, this transformation is done on the fly: The four\n          user-level functions are make-trie to create a new trie, p u t - t r i e and g e t - t r i e to\n          add and retrieve key/value pairs, and del e t e - t r i e to remove them.\n               Notice that we use a distinguished value to mark deleted elements, and that\n          g e t - t r i e returns two values: the actual value found, and a flag saying if anything\n\f344                                                                                     LOW-LEVEL     EFFICIENCY   ISSUES\n\n\n\n      was found or not.            This is consistent with the interface to g e t h a s h and f i n d , and\n      allows us to store null values in the trie. It is an inobtrusive choice, because the\n      programmer who decides not to store null values can just ignore the second value,\n      and everything will work properly.\n\n         (defstruct t r i e (value n i l ) (arcs n i l ) )\n         (defconstant t r i e - d e l e t e d \"deleted\")\n\n\n         (defun p u t - t r i e (key t r i e value)\n           \"Set the value of key i n t r i e . \"\n           ( s e t f ( t r i e - v a l u e ( f i n d - t r i e key t t r i e ) ) v a l u e ) )\n\n         (defun g e t - t r i e (key t r i e )\n           \"Return the value for a key in a t r i e , and t / n i l i f                           found.\"\n           ( l e t * ( ( k e y - t r i e ( f i n d - t r i e key n i l t r i e ) )\n                       (val ( i f k e y - t r i e ( t r i e - v a l u e k e y - t r i e ) ) ) )\n               ( i f (or (null k e y - t r i e ) (eq val t r i e - d e l e t e d ) )\n                     (values n i l n i l )\n                     (values val t ) ) ) )\n\n\n         (defun d e l e t e - t r i e (key t r i e )\n           \"Remove a key from a t r i e . \"\n           ( p u t - t r i e key t r i e t r i e - d e l e t e d ) )\n\n         (defun f i n d - t r i e (key extend? t r i e )\n           \"Find the t r i e node for t h i s key.\n           I f EXTEND? i s t r u e , make a new node i f need b e . \"\n           (cond ( ( n u l l t r i e ) n i l )\n                   ((atom key)\n                     ( f o l l o w - a r c key extend? t r i e ) )\n                   (t ( f i n d - t r i e\n                               (cdr key) extend?\n                               (find-trie\n                                  (car key) extend?\n                                  (find-trie\n                                     \" . \" extend? t r i e ) ) ) ) ) )\n\n         (defun f o l l o w - a r c (component extend? t r i e )\n           \"Find the t r i e node for t h i s component of the key.\n           I f EXTEND? i s t r u e , make a new node i f need b e . \"\n           ( l e t ( ( a r c (assoc component ( t r i e - a r c s t r i e ) ) ) )\n                (cond ((not (null a r c ) ) (cdr a r c ) )\n                         ((not extend?) n i l )\n                         (t ( l e t ((new-trie ( m a k e - t r i e ) ) )\n                                 (push (cons component new-trie)\n                                       (trie-arcs trie))\n                                new-trie)))))\n\f10.5 USE THE RIGHT DATA STRUCTURES                                                             345\n\n\n\n         There are a few subtleties in the implementation. First, we test for deleted entries\n         with an eq comparison to a distinguished marker, the string t r i e-de1 eted. No other\n         object will be eq to this string except t r i e-del eted itself, so this is a good test. We\n         also use a distinguished marker, the string \" . \" , to mark cons cells. Components are\n         implicitly compared against this marker with an eql test by the assoc in fol 1 ow - arc.\n         Maintaining the identity of this string is crucial; if, for example, you recompiled\n         the definition of f i nd-tri e (without changing the definition at all), then you could\n         no longer find keys that were indexed in an existing trie, because the \" . \" used by\n         f i nd-tri e would be a different one from the \" . \" in the existing trie.\n            Artificial Intelligence Programming   (Charniak et al. 1987) discusses variations on\n         the trie, particularly in the indexing scheme. If we always use proper lists (no non-null\n         cdrs), then a more efficient encoding is possible. As usual, the best type of indexing\n         depends on the data to be indexed. It should be noted that Charniak et al. call the trie\n         a discrimination net. In general, that term refers to any tree with tests at the nodes.\n             A trie is, of course, a kind of tree, but there are cases where it pays to convert a trie\n         into a dag--di directed acyclic graph. A dag is a tree where some of the subtrees are\n         shared. Imagine you have a spelUng corrector program with a list of some 50,000 or\n         so words. You could put them into a trie, each word with the value t. But there would\n         be many subtrees repeated in this trie. For example, given a word list containing look,\n         looks, looked, and looking as well as show, shows, showed, and showing,      there would\n         be repetition of the subtree containing -s, -ed and -ing. After the trie is built, we\n         could pass the whole trie to un i que, and it would collapse the shared subtrees, saving\n         storage. Of course, you can no longer add or delete keys from the dag without risking\n         unintended side effects.\n              This process was carried out for a 56,000 word list. The trie took up 3.2Mbytes,\n         while the dag was 1.1 Mbytes. This was still deemed unacceptable, so a more compact\n         encoding of the dag was created, using a .2Mbytes vector. Encoding the same word\n         list in a hash table took twice this space, even with a special format for encoding\n         suffixes.\n             Tries work best when neither the indexing key nor the retrieval key contains\n         variables. They work reasonably well when the variables are near the end of the\n         sequence. Consider looking up the pattern \"yel 1 o?\" in the dictionary, where the \" ?\"\n         character indicates a match of any letter. Following the branches for \"yel 1 o\" leads\n         quickly to the only possible match, \"yel 1 ow\". In contrast, fetching with the pattern\n         \" ??11 ow\" is much less efficient. The table lookup function would have to search all\n         26 top-level branches, and for each of those consider all possible second letters, and\n         for each of those consider the path \" 11 ow\". Quite a bit of searching is required before\n         arriving at the complete set of matches: bellow, billow, fallow, fellow, follow, hallow,\n         hollow, mallow, mellow, pillow, sallow, tallow, wallow, willow, and yellow.\n            We will return to the problem of discrimination nets with variables in section 14.8,\n         page 472.\n\f346                                                                               LOW-LEVEL EFFICIENCY ISSUES\n\n\n\n            10.6           Exercises\n      @     Exercise 10.1 [h] Define tlie macro d e f t a b l e , such that (def t a b l e person a s s o c )\n            will act much like a def struct-- it will define a set of functions for manipulating a\n            table of people: g e t - p e r s o n , p u t - p e r s o n , cl e a r - p e r s o n , and map-person. The table\n            should be implemented as an association list. Later on, you can change the represen\n            tation of the table simply by changing the form to ( def tabl e person h a s h ) , without\n            having to change anything else in your code. Other implementation options include\n            property lists and vectors, def t a b l e should also take three keyword arguments:\n            i nl i ne, s i ze and t e s t . Here is a possible macroexpansion:\n\n                > (macroexpand ' ( d e f t a b l e p e r s o n hash .-inline t : s i z e 100)) =\n                (progn\n                  (proclaim ' ( i n l i n e get-person put-person map-person))\n                  (defparameter * p e r s o n - t a b l e *\n                    (make-hash-table : t e s t #'eql : s i z e 100))\n                  (defun get-person (x �optional d e f a u l t )\n                    (gethash  * p e r s o n - t a b l e * d e f a u l t ) )\n                  (defun put-person (x value)\n                    ( s e t f (gethash  * p e r s o n - t a b l e * ) value))\n                  (defun clear-person () ( c l r h a s h * p e r s o n - t a b l e * ) )\n                  (defun map-person ( f n ) (maphash fn * p e r s o n - t a b l e * ) )\n                  (defsetf get-person put-person)\n                  'person)\n\n\n\n\n      @     Exercise 10.2 [m] We can use the : type option to d e f s t r u c t to define structures\n            implemented as lists. However, often we have a two-field structure that we would\n            like to implement as a cons cell rather than a two-element list, thereby cutting storage\n            in half. Since d e f s t r u c t does not allow this, define a new macro that does.\n\n\n      @     Exercise 10.3 [m] Use reuse - cons to write a version of f 1 a t t e n (see page 329) that\n            shares as much of its input with its output as possible.\n\n\n      t�l   Exercise 10.4 [h] Consider the data type set. A set has two main operations: adjoin\n            an element and test for membership. It is convenient to also add a map-over-elements\n            operation. With these primitive operations it is possible to build up more complex\n            operations like union and intersection.\n                As mentioned in section 3.9, Common Lisp provides several implementations\n            of sets. The simplest uses lists as the underlying representation, and provides the\n\f10.7 ANSWERS                                                                                             347\n\n\n\n          functions ad j oi , member, uni on, i n t e r s e c t i on, and s e t - d i f f erence. Another uses\n          bit vectors, and a similar one uses integers viewed as bit sequences. Analyze the\n          time complexity of each implementation for each operation.\n               Next, show how sorted lists can be used to implement sets, and compare the\n          operations on sorted lists to their counterparts on unsorted lists.\n\n\n\n          10.7           Answers\n          Answer 10.2\n\n               (defmacro d e f - c o n s - s t r u c t (cons car cdr &optional i n l i n e ? )\n                 \"Define a l i a s e s f o r cons, car and c d r . \"\n                 '(progn (proclaim ' ( . ( i f i n l i n e ? ' i n l i n e ' n o t i n l i n e )\n                                                .car .cdr . c o n s ) )\n                         (defun . c a r ( x ) (car x ) )\n                         (defun .cdr ( x ) (cdr x ) )\n                         ( d e f s e t f . c a r ( x ) ( v a l ) ' ( s e t f (car . x ) . v a l ) )\n                         (defsetf .cdr (x) ( v a l ) ' ( s e t f (cdr . x ) . v a l ) )\n                         (defun .cons (x y ) (cons  y ) ) ) )\n\n\n          Answer 10.3\n\n               (defun f l a t t e n (exp �optional ( s o - f a r n i l ) l a s t - c o n s )\n                 \"Return a f l a t l i s t of the atoms i n the input.\n                 Ex: ( f l a t t e n ' ( ( a ) (b ( c ) d ) ) ) = > (a b c d ) . \"\n                 (cond ( ( n u l l exp) s o - f a r )\n                          ((atom exp) (reuse-cons exp s o - f a r l a s t - c o n s ) )\n                          (t ( f l a t t e n ( f i r s t exp)\n                                              ( f l a t t e n ( r e s t exp) s o - f a r exp)\n                                             exp))))\n\fCHAPTER\n\nLogic Programming\n\n                                                            A language that doesn't affect the way you think\n                                                                  about programming is not worth knowing.\n                                                                                              --Alan Perlis\n\n\n\n\nL\n        isp is the major language for AI work, but it is by no means the only one. The other\n        strong contender is Prolog, whose name derives from \"programming in logic.\"^ The idea\n        behind logic programming is that the programmer should state the relationships that\ndescribe a problem and its solution. These relationships act as constraints on the algorithms\nthat can solve the problem, but the system itself, rather than the programmer, is responsible for\nthe details of the algorithm. The tension between the \"programming\" and \"logic\" will be covered\nin chapter 14, but for now it is safe to say that Prolog is an approximation to the ideal goal of logic\nprogramming. Prolog has arrived at a comfortable niche between a traditional programming\nlanguage and a logical specification language. It relies on three important ideas:\n\n\n   ^Actually, programmation en logique, since it was invented by a French group (see page 382).\n\fINTRODUCTION                                                                                         349\n\n\n\n               � Prolog encourages the use of a single uniform data base. Good compilers provide\n                 efficient access to this data base, reducing the need for vectors, hash tables,\n                 property lists, and other data structures that the Lisp programmer must deal\n                 with in detail. Because it is based on the idea of a data base, Prolog is relational,\n                 while Lisp (and most languages) are functional. In Prolog we would represent\n                 a fact like \"the population of San Francisco is 750,000\" as a relation. In Lisp,\n                 we would be inclined to write a function, p o p u l a t i o n , which takes a city as\n                 input and returns a number. Relations are more flexible; they can be used not\n                 only to find the population of San Francisco but also, say, to find the cities with\n                 populations over 500,000.\n\n\n\n               � Prolog provides logic variables instead of \"normal\" variables. A logic variable is\n                 bound by unification rather than by assignment. Once bound, a logic variable\n                 can never change. Thus, they are more like the variables of mathematics. The\n                 existence of logic variables and unification allow the logic programmer to state\n                 equations that constrain the problem (as in mathematics), without having to\n                 state an order of evaluation (as with assignment statements).\n\n\n\n               � Prolog provides automatic backtracking. In Lisp each function call returns a single\n                 value (unless the programmer makes special arrangements to have it return\n                 multiple values, or a list of values). In Prolog, each query leads to a search for\n                 relations in the data base that satisfy the query. If there are several, they are\n                 considered one at a time. If a query involves multiple relations, as in \"what city\n                 has a population over 500,000 and is a state capital?,\" Prolog will go through\n                 the popul a t i on relation to find a city with a population over 500,000. For each\n                 one it finds, it then checks the capi t a l relation to see if the city is a capital. If\n                 it is, Prolog prints the city; otherwise it backtracks, trying to find another city\n                 in the p o p u l a t i o n relation. So Prolog frees the programmer from worrying\n                 about both how data is stored and how it is searched. For some problems, the\n                 naive automatic search will be too inefficient, and the programmer will have to\n                 restate the problem. But the ideal is that Prolog programs state constraints on\n                 the solution, without spelling out in detail how the solutions are achieved.\n\n\n\n              This chapter serves two purposes: it alerts the reader to the possibility of writing\n          certain programs in Prolog rather than Lisp, and it presents implementations of the\n          three important Prolog ideas, so that they may be used (independently or together)\n          within Lisp programs. Prolog represents an interesting, different way of looking\n          at the programming process. For that reason it is worth knowing. In subsequent\n          chapters we will see several useful applications of the Prolog approach.\n\f350                                                                        LOGIC        PROGRAMMING\n\n\n\n      11.1         Idea 1: A Uniform Data Base\n      The first important Prolog idea should be familiar to readers of this book: manip\n      ulating a stored data base of assertions. In Prolog the assertions are called clauses,\n      and they can be divided into two types: facts, which state a relationship that holds\n      between some objects, and rules, which are used to state contingent facts. Here\n      are representations of two facts about the population of San Francisco and the cap\n      ital of California. The relations are p o p u l a t i o n and c a p i t a l , and the objects that\n      participate in these relations are SF, 750000, Sacramento, and CA:\n\n          (population SF 750000)\n          (capital Sacramento CA)\n\n\n      We are using Lisp syntax, because we want a Prolog interpreter that can be imbedded\n      in Lisp. The actual Prolog notation would be popul a t i o n ( s f , 7 5 0 0 0 0 ) . Here are\n      some facts pertaining to the 1 i kes relation:\n\n          (likes   Kim Robin)\n          (likes   Sandy Lee)\n          (likes   Sandy Kim)\n          (likes   Robin cats)\n\n\n      These facts could be interpreted as meaning that Kim likes Robin, Sandy likes both\n      Lee and Kim, and Robin likes cats. We need some way of telling Lisp that these are\n      to be interpreted as Prolog facts, not a Lisp function call. We will use the macro < - to\n      mark facts. Think of this as an assignment arrow which adds a fact to the data base:\n\n          �-    (likes   Kim Robin))\n          (<-   (likes   Sandy Lee))\n          (<-   (likes   Sandy Kim))\n          (<-   (likes   Robin c a t s ) )\n\n\n      One of the major differences between Prolog and Lisp hinges on the difference\n      between relations and functions. In Lisp, we would define a function 1 i kes, so\n      that ( l i k e s 'Sandy) would return the list (Lee Kim). If we wanted to access the\n      information the other way, we would define another function, say, 1 i k e r s - o f , so\n      that (1 i ker s - o f ' Lee ) returns ( S a n d y ) . In Prolog, we have a single 1 i kes relation\n      instead of multiple functions. This single relation can be used as if it were multiple\n      functions by posing different queries. For example, the query (1 i kes Sandy ?who)\n      succeeds with ?who bound to Lee or Kim, and the query (1 i kes ?who Lee ) succeeds\n      with ?who bound to Sandy.\n\f/ hl   IDEA   1: A UNIFORM       DATA BASE                                                             351\n\n\n\n                  The second type of clause in a Prolog data base is the rule. Rules state contingent\n              facts. For example, we can represent the rule that Sandy likes anyone who likes cats\n              as follows:\n\n\n                  ( < - ( l i k e s Sandy ?x) ( l i k e s ?x c a t s ) )\n\n\n              This can be read in two ways. Viewed as a logical assertion, it is read, \"For any x,\n              Sandy likes  if  likes cats.\" This is a declarative interpretation. Viewed as a piece\n              of a Prolog program, it is read, \"If you ever want to show that Sandy likes some x,\n              one way to do it is to show that  likes cats.\" This is a procedural interpretation.\n              It is called a backward-chaining interpretation, because one reasons backward from\n              the goal (Sandy likes x) to the premises (x likes cats). The symbol <- is appropriate\n              for both interpretations: it is an arrow indicating logical implication, and it points\n              backwards to indicate backward chaining.\n                  It is possible to give more than one procedural interpretation to a declarative form.\n              (We did that in chapter 1, where grammar rules were used to generate both strings\n              of words and parse trees.) The rule above could have been interpreted procedurally\n              as \"If you ever find out that some  likes cats, then conclude that Sandy likes x.\" This\n              would be forward chaining: reasoning from a premise to a conclusion. It turns out\n              that Prolog does backward chaining exclusively. Many expert systems use forward\n              chaining exclusively, and some systems use a mixture of the two.\n                  The leftmost expression in a clause is called the head, and the remaining ones are\n              called the body. In this view, a fact is just a rule that has no body; that is, a fact is true\n              no matter what. In general, then, the form of a clause is:\n\n\n                  (<- head body...)\n\n\n              A clause asserts that the head is true only if all the goals in the body are true. For\n              example, the following clause says that Kim likes anyone who likes both Lee and\n              Kim:\n\n\n                  ( < - ( l i k e s Kim ?x) ( l i k e s ?x Lee) ( l i k e s ?x Kim))\n\n\n              This can be read as:\n\n\n                 For any X, deduce that Km l i k e s \n                   if it can be proved that X l i k e s lee and  l i k e s Kim.\n\f352                                                                            LOGIC   PROGRAMMING\n\n\n\n      11.2         Idea 2: Unification of Logic Variables\n      Unification is a straightforward extension of the idea of pattern matching. The\n      pattern-matching functions we have seen so far have always matched a pattern\n      (an expression containing variables) against a constant expression (one with no\n      variables). In unification, two patterns, each of which can contain variables, are\n      matched against each other. Here's an example of the difference between pattern\n      matching and unification:\n\n         > (pat-match ' ( T x + ? y ) ' ( 2 + D ) ^         ( ( ? Y . 1) (?X . 2 ) )\n\n         > (unify ' ( ? x + 1) ' ( 2 + ? y ) ) => ( ( ? Y . 1) (?X . 2 ) )\n\n\n      Within the unification framework, variables (such as ?x and ? y above) are called logic\n      variables. Like normal variables, a logic variable can be assigned a value, or it can\n      be unbound. The difference is that a logic variable can never be altered. Once it is\n      assigned a value, it keeps that value. Any attempt to unify it with a different value\n      leads to failure. It is possible to unify a variable with the same value more than once,\n      just as it was possible to do a pattern match of (?x + ?x) with (2 + 2).\n          The difference between simple pattern matching and unification is that unifica\n      tion allows two variables to be matched against each other. The two variables remain\n      unbound, but they become equivalent. If either variable is subsequently bound to\n      a value, then both variables adopt that value. The following example equates the\n      variables ?x and ? y by binding ?x to ? y :\n\n         > (unify ' ( f ? x ) ' ( f ? y ) ) => ( ( ? X . ? Y ) )\n\n\n      Unification can be used to do some sophisticated reasoning. For example, if we have\n      two equations,  -h  = 0 and              y = y, and if we know that these two equations\n      unify, then we can conclude that a, x, and y are all 0. The version of uni f y we will\n      define shows this result by binding ? y to 0, ?x to ? y , and ?a to ?x. We will also\n      define the function u n i f i e r , which shows the structure that results from unifying\n      two structures.\n\n         > (unify ' ( ? a + ?a = 0) ' ( ? x + ? y = ? y ) ) =^\n         ((?Y . 0) (?X . ? Y ) (?A . ? X ) )\n\n         > ( u n i f i e r ' ( ? a + ?a = 0) ' ( ? x + ? y = ? y ) ) =^ (0 + 0 = 0)\n\n\n      To avoid getting carried away by the power of unification, it is a good idea to take stock\n      of exactly what unification provides. It does provide a way of stating that variables\n      are equal to other variables or expressions. It does not provide a way of automatically\n      solving equations or applying constraints other than equality. The following example\n\f/1.2   IDEA 2: UNIFICATION        OF LOGIC        VARIABLES                                                          353\n\n\n\n            makes it clear that unification treats the symbol + only as an uninterpreted atom, not\n            as the addition operator:\n\n                > ( u n i f i e r ' ( ? a + ?a = 2) ' ( ? x + ? y = ? y ) )        ^ ( 2 + 2 = 2 )\n\n\n            Before developing the code for un i f y, we repeat here the code taken from the pattern-\n            matching utility (chapter 6):\n\n                (defconstant f a i l n i l \" I n d i c a t e s pat-match f a i l u r e \" )\n\n                (defconstant no-bindings * ( ( t . t ) )\n                  \" I n d i c a t e s pat-match s u c c e s s , with no v a r i a b l e s . \" )\n\n                (defun v a r i a b l e - p (x)\n                  \" I s X a v a r i a b l e (a symbol beginning with * ? * ) ? \"\n                  (and (symbolp x) (equal (char (symbol-name x) 0) # \\ ? ) ) )\n\n                (defun get-binding (var b i n d i n g s )\n                  \"Find a ( v a r i a b l e . value) pair i n a binding l i s t . \"\n                  (assoc var b i n d i n g s ) )\n\n                (defun binding-val (binding)\n                  \"Get the value part of a s i n g l e b i n d i n g . \"\n                  (cdr b i n d i n g ) )\n\n                (defun lookup (var b i n d i n g s )\n                  \"Get the value part ( f o r v a r ) from a binding l i s t . \"\n                  (binding-val (get-binding var b i n d i n g s ) ) )\n\n                (defun extend-bindings (var val b i n d i n g s )\n                  \"Add a (var . value) pair to a binding l i s t . \"\n                  (cons (cons var v a l )\n                             Once we add a \" r e a l \" b i n d i n g ,\n                             we can get r i d of the dummy no-bindings\n                        ( i f (and (eq bindings n o - b i n d i n g s ) )\n                              nil\n                              bindings)))\n\n                (defun match-variable (var input b i n d i n g s )\n                  \"Does VAR match input? Uses (or updates) and returns b i n d i n g s . \"\n                  ( l e t ((binding (get-binding var b i n d i n g s ) ) )\n                       (cond ( ( n o t binding) (extend-bindings var input b i n d i n g s ) )\n                             ((equal input (binding-val b i n d i n g ) ) b i n d i n g s )\n                             (t f a i l ) ) ) )\n\n\n            The u n i f y function follows; it is identical to p a t - m a t c h (as defined on page 180)\n            except for the addition of the line marked                           The function uni f y - v a r i abl e also\n            follows match - v a r i a b l e closely:\n\f354                                                                                        LOGIC   PROGRAMMING\n\n\n\n          (defun unify ( y �optional (bindings n o - b i n d i n g s ) )\n            \"See i f X and y match with given b i n d i n g s . \"\n            (cond ((eq bindings f a i l ) f a i l )\n                    ((variable-p x) (unify-variable  y bindings))\n                    ((variable-p y) (unify-variable y  bindings))\n                    ((eql X y ) b i n d i n g s )\n                    ((and (consp x) (consp y ) )\n                      ( u n i f y ( r e s t x) ( r e s t y )\n                                  (unify ( f i r s t x) ( f i r s t y ) b i n d i n g s ) ) )\n                    (t f a i l ) ) )\n\n          (defun u n i f y - v a r i a b l e (var  b i n d i n g s )\n            \"Unify var with x . using (and maybe extending) b i n d i n g s . \"\n                 Warning - buggy v e r s i o n\n            ( i f ( g e t - b i n d i n g var b i n d i n g s )\n                  (unify (lookup var b i n d i n g s )  b i n d i n g s )\n                  (extend-bindings var  b i n d i n g s ) ) )\n\n\n      Unfortunately, this definition is not quite right. It handles simple examples:\n\n         > (unify ' ( ? x + 1) ' ( 2 + ? y ) ) => ( ( ? Y . 1) (?X . 2 ) )\n\n         > (unify ' ? x ' ? y )           ((?X . ?Y))\n\n         > (unify ' ( ? x ? x ) ' ( T y ? y ) ) =^ ( ( ? Y . ? Y ) (?X . ? Y ) )\n\n\n      but there are several pathological cases that it can't contend with:\n\n         > (unify ' ( ? x ? x ? x ) ' ( ? y ? y ? y ) )\n         � T r a p #043622 (PDL-OVERFLOW REGULAR)\n         The regular push-down l i s t has overflowed.\n         While i n the function GET-BINDING ^ UNIFY-VARIABLE = UNIFY\n\n\n      The problem here is that once ? y gets bound to itself, the call to u n i f y inside\n      uni f y - v a r i abl e leads to an infinite loop. But matching ? y against itself must al\n      ways succeed, so we can move the equality test in uni f y before the variable test. This\n      assumes that equal variables are e q l , a valid assumption for variables implemented\n      as symbols (but be careful if you ever decide to implement variables some other way).\n\n          (defun unify (x y �optional (bindings n o - b i n d i n g s ) )\n            \"See i f X and y match with given b i n d i n g s . \"\n            (cond ((eq bindings f a i l ) f a i l )\n                    ((eql X y ) b i n d i n g s )       moved t h i s l i n e\n                    ((variable-p x) (unify-variable  y bindings))\n                    ((variable-p y) (unify-variable y  bindings))\n                    ((and (consp x) (consp y ) )\n                      (unify ( r e s t x) ( r e s t y )\n\f; 1.2 IDEA 2: UNIFICATION      OF LOGIC        VARIABLES                                            355\n\n\n\n                                   (unify ( f i r s t x) ( f i r s t y ) b i n d i n g s ) ) )\n                         (t   fail)))\n\n\n           H e r e are some test cases:\n\n              > (unify ' ( ? x ? x ) ' ( ? y ? y ) )        ((?X . ?Y))\n              > (unify ' ( ? x ? x ? x ) ' ( ? y ?y ? y ) )          ((?X . ?Y))\n              > (unify ' ( ? x ? y ) ' ( ? y ? x ) ) ^      ( ( ? Y . ? X ) (?X . ? Y ) )\n              > (unify ' ( ? x ?y a) ' ( ? y ? x ? x ) )\n              � T r a p #043622 (PDL-OVERFLOW REGULAR)\n              The regular push-down l i s t has overflowed.\n              While in the function GET-BINDING ^ UNIFY-VARIABLE <= UNIFY\n\n\n           We have pushed off the problem but not solved it. Allowing both (?Y . ?X) and\n           (?X . ?Y) in the same binding list is as bad as allowing (?Y . ?Y). To avoid the\n           problem, the policy should be never to deal with bound variables, but rather with\n           their values, as specified in the binding list. The function uni f y - v a r i abl e fails to\n           implement this policy. It does have a check that gets the binding for va r when it is a\n           bound variable, but it should also have a check that gets the value of x, when  is a\n           bound variable:\n\n               (defun u n i f y - v a r i a b l e (var  bindings)\n                 \"Unify var with x , using (and maybe extending) b i n d i n g s . \"\n                 (cond ( ( g e t - b i n d i n g var bindings)\n                         (unify (lookup var b i n d i n g s )  b i n d i n g s ) )\n                       ((and ( v a r i a b l e - p x) (get-binding  b i n d i n g s ) )\n                         (unify var (lookup  b i n d i n g s ) b i n d i n g s ) )\n                       (t (extend-bindings var  b i n d i n g s ) ) ) )\n\n\n           Here are some more test cases:\n\n              > (unify ' ( ? x ? y ) * ( ? y ? x ) )       ((?X . ?Y))\n              > (unify ' ( ? x ?y a) ' ( ? y ? x ? x ) ) ^         ( ( ? Y . A) (?X . ? Y ) )\n\n\n          It seems the problem is solved. Now let's try a new problem:\n\n              > (unify ' ? x ' ( f ? x ) ) => ( ( ? X F ? X ) )\n\n\n          H e r e ( ( ? X F ?X)) really means ((?X . ( ( F ? X ) ) ) ) , so ?X is bound to (F ?X).This\n          represents a circular, infinite unification. Some versions of Prolog, notably Prolog II\n          (Giannesini et al. 1986), provide an interpretation for such structures, but it is tricky\n          to define the semantics of infinite structures.\n\f356                                                                                             LOGIC   PROGRAMMING\n\n\n\n          The easiest way to deal with such infinite structures is just to ban them. This\n      ban can be realized by modifying the unifier so that it fails whenever there is an\n      attempt to unify a variable with a structure containing that variable. This is known in\n      unification circles as the occurs check. In practice the problem rarely shows up, and\n      since it can add a lot of computational complexity, most Prolog systems have ignored\n      the occurs check. This means that these systems can potentially produce unsound\n      answers. In the final version of uni f y following, a variable is provided to allow the\n      user to turn occurs checking on or off.\n\n          (defparameter *occurs-check* t \"Should we do the occurs check?\")\n\n          (defun unify (x y �optional (bindings n o - b i n d i n g s ) )\n            \"See i f X and y match with given b i n d i n g s . \"\n            (cond ((eq bindings f a i l ) f a i l )\n                   ((eql X y ) b i n d i n g s )\n                   ( ( v a r i a b l e - p x) ( u n i f y - v a r i a b l e  y b i n d i n g s ) )\n                    ((variable-p y) (unify-variable y  bindings))\n                    ((and (consp x ) (consp y ) )\n                      (unify ( r e s t x) ( r e s t y )\n                                   (unify ( f i r s t x) ( f i r s t y ) b i n d i n g s ) ) )\n                    (t f a i l ) ) )\n\n          (defun u n i f y - v a r i a b l e (var  b i n d i n g s )\n            \"Unify var with x . using (and maybe extending) b i n d i n g s . \"\n            (cond ( ( g e t - b i n d i n g var b i n d i n g s )\n                    ( u n i f y (lookup var b i n d i n g s )  b i n d i n g s ) )\n                  ((and ( v a r i a b l e - p x) ( g e t - b i n d i n g  b i n d i n g s ) )\n                    (unify var (lookup  b i n d i n g s ) b i n d i n g s ) )\n                  ((and *occurs-check* (occurs-check var  b i n d i n g s ) )\n                    fail)\n                  (t (extend-bindings var  b i n d i n g s ) ) ) )\n\n          (defun occurs-check (var  b i n d i n g s )\n            \"Does var occur anywhere i n s i d e x ? \"\n            (cond ((eq var x) t )\n                  ((and ( v a r i a b l e - p x) ( g e t - b i n d i n g  b i n d i n g s ) )\n                    (occurs-check var (lookup  b i n d i n g s ) b i n d i n g s ) )\n                  ((consp x) (or (occurs-check var ( f i r s t x) b i n d i n g s )\n                                          (occurs-check var ( r e s t x) b i n d i n g s ) ) )\n                  (t n i l ) ) )\n\n\n      Now we consider how u n i f y will be used. In particular, one thing we want is a\n      function for substituting a binding list into an expression. We originally chose\n      association lists as the implementation of bindings because of the availability of the\n      function s u b l i s . Ironically, s u b l i s won't work any more, because variables can\n      be bound to other variables, which are in turn bound to expressions. The function\n      s u b s t - b i ndi ngs acts like s u b l i s, except that it substitutes recursive bindings.\n\f/12   IDEA 2: UNIFICATION          OF LOGIC         VARIABLES                                                  357\n\n\n\n               (defun s u b s t - b i n d i n g s (bindings x)\n                 \" S u b s t i t u t e the value of v a r i a b l e s i n bindings into x ,\n                 taking r e c u r s i v e l y bound v a r i a b l e s into account.\"\n                 (cond ((eq bindings f a i l ) f a i l )\n                            ((eq bindings n o - b i n d i n g s ) x)\n                            ((and ( v a r i a b l e - p x) ( g e t - b i n d i n g  b i n d i n g s ) )\n                               ( s u b s t - b i n d i n g s bindings (lookup  b i n d i n g s ) ) )\n                           ((atom x) x)\n                            (t (reuse-cons ( s u b s t - b i n d i n g s bindings (car x ) )\n                                                           ( s u b s t - b i n d i n g s bindings (cdr x ) )\n                                                           x))))\n\n\n           Now let's try uni f y on some examples:\n\n               > (unify ' ( ? x ? y a) ' ( ? y ? x ? x ) ) =^ ( ( ? Y . A) (?X . ? Y ) )\n\n               > (unify � ?  ' ( f ? x ) )            NIL\n\n               > (unify ' ( ? x ? y ) ' ( ( f ? y ) ( f ? x ) ) ) ^ NIL\n\n               > (unify ' ( ? x ? y ? z ) ' ( ( T y ? z ) ( ? x ? z ) ( ? x ? y ) ) ) => NIL\n\n               > (unify ' a ' a )             ((T . T ) )\n\n\n           Finally, the function u n i f i e r calls u n i f y and substitutes the resulting binding Ust\n           into one of the arguments. The choice of  is arbitrary; an equal result would come\n           from substituting the binding list into y.\n\n               (defun u n i f i e r (x y )\n                \"Return something that u n i f i e s with both  and y (or f a i l ) . \"\n                ( s u b s t - b i n d i n g s (unify  y )  ) )\n\n\n           Here are some examples of uni f i er:\n\n               > (unifier        ' ( ?  ? y a) ' ( ? y ? x ? x ) )           (A A A)\n\n               > (unifier ' ( ( ? a * ? x ^ 2) + ( ? b * ? x ) + ? c )\n                          ' ( ? z + (4 * 5) + 3 ) ) =^\n               ((?A * 5 ^ 2) + (4 * 5) + 3)\n\f358                                                                               LOGIC   PROGRAMMING\n\n\n\n      When *occurs - check* is false, we get the following answers:\n\n          > (unify ' ? x *(f ? x ) ) ^        ((?X F ?X))\n\n          > (unify ' ( ? x ? y ) ' ( ( f ? y ) ( f ? x ) ) ) =>\n          ((?Y F ? X ) (?X F ? Y ) )\n\n          > (unify ' ( ? x ?y ? z ) ' ( ( ? y ? z ) ( ? x ? z ) ( ? x ? y ) ) )\n          ( ( ? Z ?X ?Y) (?Y ?X        11)   (?X ?Y ? Z ) )\n\n\n\n\n      Programming with Prolog\n\n      The amazing thing about Prolog clauses is that they can be used to express relations\n      that we would normally think of as \"programs,\" not \"data.\" For example, we can\n      define the member relation, which holds between an item and a list that contains that\n      item. More precisely, an item is a member of a list if it is either the first element of the\n      list or a member of the rest of the list. This definition can be translated into Prolog\n      almost verbatim:\n\n          ( < - (member ?item (?item . ? r e s t ) ) )\n          ( < - (member ?item ( ? x . ? r e s t ) ) (member ?item ? r e s t ) )\n\n\n      Of course, we can write a similar definition in Lisp. The most visible difference is that\n      Prolog allows us to put patterns in the head of a clause, so we don't need recognizers\n      like consp or accessors like f i r s t and r e s t . Otherwise, the Lisp definition is similar:^\n\n          (defun lisp-member (item l i s t )\n             (and   (consp l i s t )\n                    (or   (eql item ( f i r s t    list))\n                          (lisp-member item ( r e s t        list)))))\n\n\n      If we wrote the Prolog code without taking advantage of the pattern feature, it would\n      look more like the Lisp version:\n\n          ( < - (member ?item ? l i s t )\n               (= ? l i s t (?item . ? r e s t ) ) )\n\n\n\n         ^Actually, this is more like the Lisp f i nd than the Lisp member. In this chapter we have\n      adopted the traditional Prolog definition of member.\n\f/1.2   IDEA 2: UNIFICATION          OF LOGIC        VARIABLES                                    359\n\n\n\n                ( < - (member ?item ? l i s t )\n                      (= ? l i s t ( ? x . ? r e s t ) )\n                      (member ?item ? r e s t ) )\n\n\n            If we define or in Prolog, we would write a version that is clearly just a syntactic\n            variant of the Lisp version.\n\n                ( < - (member ?item ? l i s t )\n                      (= ? l i s t ( ? f i r $ t . ? r e s t ) )\n                      (or (= ?item ? f i r s t )\n                          (member ? i tern ? r e s t ) ) )\n\n\n            Let's see how the Prolog version of member works. Imagine that we have a Prolog\n            interpreter that can be given a query using the macro ? - , and that the definition of\n            member has been entered. Then we would see:\n\n                > ( ? - (member 2 ( 1 2 3 ) ) )\n                Yes;\n\n                > ( ? - (member 2 ( 1 2 3 2 1 ) ) )\n                Yes;\n                Yes;\n\n\n            The answer to the first query is \"yes\" because 2 is a member of the rest of the list. In\n            the second query the answer is \"yes\" twice, because 2 appears in the list twice. This\n            is a little surprising to Lisp programmers, but there still seems to be a fairly close\n            correspondence between Prolog's and Lisp's member. However, there are things that\n            the Prolog member can do that Lisp cannot:\n\n                > ( ? - (member ? x (1 2 3 ) ) )\n                ?X = 1 ;\n                ?X = 2\n                ?X = 3\n\n\n            Here member is used not as a predicate but as a generator of elements in a Hst.\n            While Lisp functions always map from a specified input (or inputs) to a specified\n            output, Prolog relations can be used in several ways. For member, we see that the\n            first argument, ?x, can be either an input or an output, depending on the goal that\n            is specified. This power to use a single specification as a function going in several\n            different directions is a very flexible feature of Prolog. (Unfortunately, while it works\n            very well for simple relations like member, in practice it does not work well for large\n            programs. It is very difficult to, say, design a compiler and automatically have it work\n            as a disassembler as well.)\n\f360                                                                              LOGIC         PROGRAMMING\n\n\n\n          Now we turn to the implementation of the Prolog interpreter, as summarized in\n      figure 1 1 . 1 . The first implementation choice is the representation of rules and facts.\n      We will build a single uniform data base of clauses, without distinguishing rules from\n      facts. The simplest representation of clauses is as a cons cell holding the head and\n      the body. For facts, the body will be empty.\n\n          ; ; Clauses are represented as (head . body) cons c e l l s\n          (defun clause-head (clause) ( f i r s t c l a u s e ) )\n          (defun clause-body (clause) ( r e s t c l a u s e ) )\n\n\n      The next question is how to index the clauses. Recall the procedural interpretation\n      of a clause: when we want to prove the head, we can do it by proving the body. This\n      suggests that clauses should be indexed in terms of their heads. Each clause will be\n      stored on the property list of the predicate of the head of the clause. Since the data\n      base is now distributed across the property list of various symbols, we represent the\n      entire data base as a Hst of symbols stored as the value of *db-predi cates*.\n\n             Clauses are stored on the p r e d i c a t e ' s p l i s t\n          (defun g e t - c l a u s e s (pred) (get pred ' c l a u s e s ) )\n          (defun predicate ( r e l a t i o n ) ( f i r s t r e l a t i o n ) )\n\n          (defvar * d b - p r e d i c a t e s * n i l\n            \"A l i s t of a l l predicates stored i n the d a t a b a s e . \" )\n\n\n      Now we need a way of adding a new clause. The work is split up into the macro < - ,\n      which provides the user interface, and a function, add-cl a use, that does the work.\n      It is worth defining a macro to add clauses because in effect we are defining a new\n      language: Prolog-In-Lisp. This language has only two syntactic constructs: the < -\n      macro to add clauses, and the ? - macro to make queries.\n\n          (defmacro < - (&rest clause)\n            \"Add a clause to the data b a s e . \"\n            �(add-clause ' . c l a u s e ) )\n\n          (defun add-clause (clause)\n            \"Add a clause to the data base, indexed by head's p r e d i c a t e . \"\n                  The predicate must be a non-variable symbol,\n            ( l e t ((pred (predicate (clause-head c l a u s e ) ) ) )\n                ( a s s e r t (and (symbolp pred) (not ( v a r i a b l e - p p r e d ) ) ) )\n                (pushnew pred * d b - p r e d i c a t e s * )\n                ( s e t f (get pred ' c l a u s e s )\n                            (nconc ( g e t - c l a u s e s pred) ( l i s t c l a u s e ) ) )\n                pred))\n\n\n      Now all we need is a way to remove clauses, and the data base will be complete.\n\f11.2 IDEA 2: UNIFICATION                OF LOGIC      VARIABLES                                         361\n\n\n\n                                                Top-Level Macros\n     <-                                         Add a clause to the data base.\n     ?-                                         Prove a query and print answer(s).\n                                                Special Variables\n     *db-precli c a t e s *                     A list of all predicates.\n     *occurs -check*                            Should we check for circular unifications?\n                                                Data Types\n     clause                                     Consists of a head and a body.\n     variable                                   A symbol starting with a ?.\n                                                Major Functions\n     add-clause                                 Add a clause to the data base.\n     prove                                      Return a list of possible solutions to goal.\n     prove-all                                  Return a list of solutions to the conjunction of goals.\n     top-level-prove                            Prove the goals, and print variables readably.\n                                                Auxiliary F^mctions\n     get-clauses                                Find all the clauses for a predicate.\n     predicate                                  Pick out the predicate from a relation.\n     clear-db                                   Remove all clauses (for all predicates) from the data base.\n     clear-predicate                            Remove the clauses for a single predicate.\n     rename-variables                           Replace all variables in  with new ones.\n     unique-find-anywhere-if                    Find all unique leaves satisfying predicate.\n     s h o w - p r o l o g - s o l u t i ons    Print the variables in each of the solutions.\n     show-prolog-vars                           Print each variable with its binding.\n     variables-in                               Return a list of all the variables in an expression.\n                                                Previously Defined Constants\n     fail                                       An indication that unification has failed.\n     no-bindings                                A succesful unification with no variables.\n                                                Previously Defined Functions\n     unify                                      Return bindings that unify two expressions (section 11.2).\n     unify-variable                             Unify a variable against an expression.\n     occurs-check                               See if a particular variable occurs inside an expression.\n     subst-bindings                             Substitute bindings into an expression.\n     get-binding                                Get the ( var . val) binding for a variable.\n     lookup                                     Get the value for a variable.\n     extend-bindings                            Add a new variable/value pair to a binding list.\n     variable-p                                 Is the argument a variable?\n     reuse-cons                                 Like cons, except will reuse an old value if possible.\n\n                                          Figure 1 1 . 1 : Glossary for the Prolog Interpreter\n\f362                                                                                              LOGIC              PROGRAMMING\n\n\n\n         (defun clear-db ()\n            \"Remove a l l clauses (for a l l predicates) from the data b a s e . \"\n            (mapc # ' c l e a r - p r e d i c a t e * d b - p r e d i c a t e s * ) )\n\n         (defun c l e a r - p r e d i c a t e (predicate)\n            \"Remove the clauses for a s i n g l e p r e d i c a t e . \"\n            ( s e t f (get predicate ' c l a u s e s )              nil))\n\n\n      A data base is useless without a way of getting data out, as well as putting it in. The\n      function prove will be used to prove that a given goal either matches a fact that is in\n      the data base directly or can be derived from the rules. To prove a goal, first find all\n      the candidate clauses for that goal. For each candidate, check if the goal unifies with\n      the head of the clause. If it does, try to prove all the goals in the body of the clause.\n      For facts, there will be no goals in the body, so success will be immediate. For rules,\n      the goals in the body need to be proved one at a time, making sure that bindings from\n      the previous step are maintained. The implementation is straightforward:\n\n         (defun prove (goal b i n d i n g s )\n            \"Return a l i s t of p o s s i b l e s o l u t i o n s to g o a l . \"\n            (mapcan #'(lambda (clause)\n                                 ( l e t ((new-clause (rename-variables c l a u s e ) ) )\n                                     ( p r o v e - a l l (clause-body new-clause)\n                                                        (unify goal (clause-head new-clause) b i n d i n g s ) ) ) )\n                          ( g e t - c l a u s e s (predicate g o a l ) ) ) )\n\n         (defun prove-all (goals b i n d i n g s )\n            \"Return a l i s t of s o l u t i o n s to the conjunction of g o a l s . ' \"\n            (cond ((eq bindings f a i l )                  fail)\n                      ((null goals) ( l i s t             bindings))\n                      (t (mapcan #*(lambda ( g o a l l - s o l u t i o n )\n                                                 (prove-all ( r e s t g o a l s ) g o a l l - s o l u t i o n ) )\n                                          (prove ( f i r s t g o a l s ) b i n d i n g s ) ) ) ) )\n\n\n      The tricky part is that we need some way of distinguishing a variable ? x in one\n      clause from another variable ? x in another clause. Otherwise, a variable used in two\n      different clauses in the course of a proof would have to take on the same value in\n      each clause, which would be a mistake. Just as arguments to a function can have\n      different values in different recursive calls to the function, so the variables in a clause\n      are allowed to take on different values in different recursive uses. The easiest way to\n      keep variables distinct is just to rename all variables in each clause before it is used.\n      The function rename-vari abl es does this:^\n\n         ^See exercise 11.12 for an alternative approach.\n\f/1.2   IDEA 2: UNIFICATION         OF LOGIC        VARIABLES                                                     363\n\n\n\n                (defun rename-variables (x)\n                  \"Replace a l l v a r i a b l e s in  with new o n e s . \"\n                  ( s u b l i s (mapcar #'(lambda ( v a r ) (cons var (gensym ( s t r i n g v a r ) ) ) )\n                                        (variables-in x))\n                               X))\n\n\n            Rename - variables makes use of gensym, a function that generates a new symbol each\n            time it is called. The symbol is not interned in any package, which means that there\n            is no danger of a programmer typing a symbol of the same name. The predicate\n            vari abl es - i  and its auxiliary function are defined here:\n\n                (defun v a r i a b l e s - i n (exp)\n                  \"Return a l i s t of a l l the v a r i a b l e s in E X P . \"\n                  (unique-find-anywhere-if # * v a r i a b l e - p exp))\n\n                (defun unique-find-anywhere-if (predicate tree\n                                                              �optional f o u n d - s o - f a r )\n                  \"Return a l i s t of leaves of tree s a t i s f y i n g p r e d i c a t e ,\n                  with duplicates removed.\"\n                  ( i f (atom tree)\n                        ( i f (funcall predicate tree)\n                                 (adjoin tree f o u n d - s o - f a r )\n                                 found-so-far)\n                        (unique-find-anywhere-if\n                             predicate\n                             ( f i r s t tree)\n                             (unique-find-anywhere-if predicate ( r e s t tree)\n                                                                 found-so-far))))\n\n\n            Finally, we need a nice interface to the proving functions. We will use ? - as a macro\n            to introduce a query. The query might as well allow a conjunction of goals, so ? - will\n            call prove-all. Together,<- a n d ? - def ine the complete syntax of our Prolog-In-Lisp\n            language.\n\n                (defmacro ? - (&rest g o a l s ) ' ( p r o v e - a l l ' . g o a l s n o - b i n d i n g s ) )\n\n\n            Now we can enter all the clauses given in the prior example:\n\n                �-    (likes     Kim Robin))\n                (<-   (likes     Sandy Lee))\n                (<-   (likes     Sandy Kim))\n                (<-   (likes     Robin c a t s ) )\n                (<-   (likes     Sandy ? x ) ( l i k e s ?x c a t s ) )\n                (<-   (likes     Kim ? x ) ( l i k e s ?x Lee) ( l i k e s ?x Kim))\n                (<-   (likes     ?x ? x ) )\n\f364                                                                             LOGIC   PROGRAMMING\n\n\n\n      To ask whom Sandy Hkes, we would use:\n\n         > ( ? - ( l i k e s Sandy ?who))\n          (((?WHO . LEE))\n           ((?WHO . KIM))\n           ((7X2856 . ROBIN) (?WHO . 7X2856))\n           ((7X2860 . CATS) (7X2857 . CATS) (7X2856 . SANDY) (7WH0 . 7X2856))\n           ((7X2865 . CATS) (7X2856 . 7X2865) (7WH0 . 7X2856))\n           ((7WH0 . SANDY) (7X2867 . SANDY)))\n\n\n      Perhaps surprisingly, there are six answers. The first two answers are Lee and Kim,\n      because of the facts. The next three stem from the clause that Sandy likes everyone\n      who likes cats. First, Robin is an answer because of the fact that Robin likes cats.\n      To see that Robin is the answer, we have to unravel the bindings: ?who is bound to\n      ?x2856, which is in turn bound to Robin.\n          Now we're in for some surprises: Sandy is listed, because of the following reason\n      ing: (1) Sandy likes anyone/thing who likes cats, (2) cats like cats because everyone\n      likes themself, (3) therefore Sandy likes cats, and (4) therefore Sandy likes Sandy.\n      Cats is an answer because of step (2), and finally, Sandy is an answer again, because\n      of the clause about liking oneself. Notice that the result of the query is a list of\n      solutions, where each solution corresponds to a different way of proving the query\n      true. Sandy appears twice because there are two different ways of showing that\n      Sandy likes Sandy. The order in which solutions appear is determined by the order\n      of the search. Prolog searches for solutions in a top-down, left-to-right fashion. The\n      clauses are searched from the top down, so the first clauses entered are the first ones\n      tried. Within a clause, the body is searched left to right. In using the (1 i kes Ki m ?x)\n      clause, Prolog would first try to find an  who likes Lee, and then see if  likes Kim.\n           The output from prove-al 1 is not very pretty. We can fix that by defining a new\n      function, top-level -prove, which calls prove-all as before, but then passes the\n      list of solutions to show-prolog-solutions, which prints them in a more readable\n      format Note thatshow-prolog-solutions returns no values: ( v a l u e s ) . This means\n      the read-eval-print loop will not print anything when (values) is the result of a\n      top-level call.\n\n         (defmacro 7- (&rest g o a l s )\n            *(top-level-prove              *,goals))\n\n         (defun t o p - l e v e l - p r o v e ( g o a l s )\n            \"Prove the g o a l s , and p r i n t v a r i a b l e s readably.\"\n            (show-prolog-solutions\n               (variables-in goals)\n               (prove-all goals n o - b i n d i n g s ) ) )\n\f/1.2   IDEA 2: UNIFICATION       OF LOGIC         VARIABLES                                              365\n\n\n\n                (defun show-prolog-solutions (vars s o l u t i o n s )\n                  \" P r i n t the v a r i a b l e s in each of the s o l u t i o n s . \"\n                  (if   (null    solutions)\n                        (format t       \"-&No.\")\n                        (mapc #'(lambda ( s o l u t i o n ) (show-prolog-vars vars s o l u t i o n ) )\n                                 solutions))\n                  (values))\n\n\n                (defun show-prolog-vars (vars b i n d i n g s )\n                  \" P r i n t each v a r i a b l e with i t s b i n d i n g . \"\n                  (if   (null    vars)\n                        (format t       \"~&Yes\")\n                        ( d o l i s t (var v a r s )\n                           (format t \" \" � ^ a = ~a\" var\n                                        ( s u b s t - b i n d i n g s bindings v a r ) ) ) )\n\n\n                  (princ     \";\"))\n\n\n             Now let's try some queries:\n                > ( ? - ( l i k e s Sandy ?who))\n                ?WHO = LEE;\n                ?WHO = KIM;\n                ?WHO = ROBIN;\n                ?WHO = SANDY;\n                ?WHO = CATS;\n                ?WHO = SANDY;\n\n                > ( ? - ( l i k e s ?who Sandy))\n                ?WHO = SANDY;\n                ?WHO = KIM;\n                ?WHO = SANDY;\n\n\n                > ( ? - ( l i k e s Robin Lee))\n                No.\n\n\n             The first query asks again whom Sandy likes, and the second asks who likes Sandy.\n             The third asks for confirmation of a fact. The answer is \"no,\" because there are no\n             clauses or facts that say Robin likes Lee. Here's another example, a list of pairs of\n             people who are in a mutual liking relation. The last answer has an uninstantiated\n             variable, indicating that everyone likes themselves.\n\f366                                                                              LOGIC   PROGRAMMING\n\n\n\n              > ( ? - ( l i k e s ?x ?y) ( l i k e s ?y ? x ) )\n              ?Y = KIM\n              ?X = SANDY;\n              ?Y = SANDY\n              ?X = SANDY;\n              ?Y = SANDY\n              ?X = SANDY;\n              ?Y = SANDY\n              ?X = KIM;\n              ?Y = SANDY\n              ?X = SANDY;\n              ?Y = 7X3251\n              ?X = 7X3251;\n\n\n           It makes sense in Prolog to ask open-ended queries like \"what lists is 2 a member of?\"\n           or even \"what items are elements of what lists?\"\n\n\n              (7- (member 2 7 1 i s t ) )\n              (7-   (member 7item 7 1 i s t ) )\n\n\n           These queries are valid Prolog and will return solutions, but there will be an infinite\n           number of them. Since our interpreter collects all the solutions into a single list\n           before showing any of them, we will never get to see the solutions. The next section\n           shows how to write a new interpreter that fixes this problem.\n\n\n      El   Exercise 11.1 [m] The representation of relations has been a list whose first element\n           is a symbol. However, for relations with no arguments, some people prefer to write\n           (<-  q r ) rather than ( < - (p) (q) ( r ) ) . Make changes so that either form is\n           acceptable.\n\n\n      SI   Exercise 11.2 [m] Some people find the < - notation difficult to read. Define macros\n           rul e and f a c t so that we can write:\n\n\n              (fact ( l i k e s Robin c a t s ) )\n              ( r u l e ( l i k e s Sandy 7x) i f   ( l i k e s 7x c a t s ) )\n\f/13   IDEA 3: AUTOMATIC      BACKTRACKING                                                        367\n\n\n\n           11.3         Idea 3: Automatic Backtracking\n           The Prolog interpreter implemented in the last section solves problems by returning a\n           list of all possible solutions. We'll call this a batch approach, because the answers are\n           retrieved in one uninterrupted batch of processing. Sometimes that is just what you\n           want, but other times a single solution will do. In real Prolog, solutions are presented\n           one at a time, as they are found. After each solution is printed, the user has the\n           option of asking for more solutions, or stopping. This is an incremental approach.\n           The incremental approach will be faster when the desired solution is one of the first\n           out of many alternatives. The incremental approach will even work when there is an\n           infinite number of solutions. And if that is not enough, the incremental approach can\n           be implemented so that it searches depth-first. This means that at any point it will\n           require less storage space than the batch approach, which must keep all solutions in\n           memory at once.\n                In this section we implement an incremental Prolog interpreter. One approach\n           would be to modify the interpreter of the last section to use pipes rather than lists.\n           With pipes, unnecessary computation is delayed, and even infinite lists can be\n           expressed in a finite amount of time and space. We could change to pipes simply by\n           changing the mapcan in prove and prove-a11 to mappend-pi pe (page 286). The books\n           by Winston and Horn (1988) and by Abelson and Sussman (1985) take this approach.\n           We take a different one.\n                The first step is a version of prove and prove-al 1 that return a single solution\n           rather than a list of all possible solutions. This should be reminiscent of achi eve and\n           achieve-a11 from gps (chapter 4). Unlike gps, recursive subgoals and clobbered\n           siblinggoals are not checked for. However, prove is required to search systematically\n           through all solutions, so it is passed an additional parameter: a list of other goals to\n           achieve after achieving the first goal. This is equivalent to passing a continuation to\n           prove. The result is that if prove ever succeeds, it means the entire top-level goal has\n           succeeded. If it fails, it just means the program is backtracking and trying another\n           sequence of choices. Note that prove relies on the fact that f ai 1 is ni 1, because of\n           the way it uses some.\n\n              (defun p r o v e - a l l (goals b i n d i n g s )\n                \"Find a s o l u t i o n to the conjunction of g o a l s . \"\n                (cond ((eq bindings f a i l ) f a i l )\n                      ( ( n u l l g o a l s ) bindings)\n                      (t (prove ( f i r s t g o a l s ) bindings ( r e s t g o a l s ) ) ) ) )\n\n              (defun prove (goal bindings o t h e r - g o a l s )\n                \"Return a l i s t of p o s s i b l e s o l u t i o n s to g o a l . \"\n                (some #*(lambda (clause)\n                           ( l e t ((new-clause (rename-variables c l a u s e ) ) )\n                               (prove-all\n                                  (append (clause-body new-clause) o t h e r - g o a l s )\n\f368                                                                                LOGIC         PROGRAMMING\n\n\n\n                                      (unify goal (clause-head new-clause)           bindings))))\n                     ( g e t - c l a u s e s (predicate g o a l ) ) ) )\n\n\n      If  rove does succeed, it means a solution has been found. If we want more solutions,\n      we need some way of making the process fail, so that it will backtrack and try again.\n      One way to do that is to extend every query with a goal that will print out the variables,\n      and ask the user if the computation should be continued. If the user says yes, then\n      the goal fails, and backtracking starts. If the user says no, the goal succeeds, and since\n      it is the final goal, the computation ends. This requires a brand new type of goal: one\n      that is not matched against the data base, but rather causes some procedure to take\n      action. In Prolog, such procedures are called primitives, because they are built-in to\n      the language, and new ones may not be defined by the user. The user may, of course,\n      define nonprimitive procedures that call upon the primitives.\n         In our implementation, primitives will be represented as Lisp functions. A\n      predicate can be represented either as a list of clauses (as it has been so far) or as a\n      single primitive. Here is a version of prove that calls primitives when appropriate:\n\n          (defun prove (goal bindings o t h e r - g o a l s )\n            \"Return a l i s t of p o s s i b l e s o l u t i o n s to g o a l . \"\n            ( l e t ( ( c l a u s e s ( g e t - c l a u s e s (predicate g o a l ) ) ) )\n                ( i f ( l i s t p clauses)\n                      (some\n                           #'(lambda (clause)\n                                  ( l e t ((new-clause (rename-variables c l a u s e ) ) )\n                                      (prove-al 1\n                                         (append (clause-body new-clause) o t h e r - g o a l s )\n                                         (unify goal (clause-head new-clause) b i n d i n g s ) ) ) )\n                           clauses)\n                             The p r e d i c a t e ' s \" c l a u s e s \" can be an atom;\n                       ; ; a p r i m i t i v e function to c a l l\n                      (funcall clauses ( r e s t goal) bindings\n                                        other-goals))))\n\n\n      Here is theversionof t o p - l e v e l -provethatadds the primitivegoalshow -prolog-vars\n      totheendofthelistofgoals. Note that this versionneednot call s h o w - p r o l o g - s o l u t i o n s\n      itself, since the printing will be handled by the primitive for show-prol o g - v a r s .\n\n          (defun t o p - l e v e l - p r o v e ( g o a l s )\n            (prove-all ' ( . � g o a l s (show-prolog-vars , � ( v a r i a b l e s - i n   goals)))\n                             no-bindings)\n            (format t \"~&No.\")\n            (values))\n\n\n      Here we define the primitive show-prol og- v a r s . All primitives must be functions of\n\f/13   IDEA 3: AUTOMATIC         BACKTRACKING                                                     369\n\n\n\n           three arguments: a Hst of arguments to the primitive relation (here a list of variables\n           to show), a binding list for these arguments, and a list of pending goals. A primitive\n           should either return f ai 1 or call prove-al 1 to continue.\n\n\n               (defun show-prolog-vars (vars bindings o t h e r - g o a l s )\n                 \" P r i n t each v a r i a b l e with i t s b i n d i n g .\n                 Then ask the user i f more s o l u t i o n s are d e s i r e d . \"\n                 (if   (null v a r s )\n                       (format t \"~&Yes\")\n                       ( d o l i s t (var vars)\n                          (format t \" \" � ^ a = ~a\" var\n                                      ( s u b s t - b i n d i n g s bindings v a r ) ) ) )\n                 (if   (continue-)\n                       fail\n                       (prove-all other-goals bindings)))\n\n\n           Since primitives are represented as entries on the clauses property of predicate\n           symbols, we have to register show- prol og - va rs as a primitive like this:\n\n\n              ( s e t f (get 'show-prolog-vars ' c l a u s e s )            'show-prolog-vars)\n\n\n           Finally, the Lisp predicate conti nue-p asks the user if he or she wants to see more\n           solutions:\n\n\n              (defun continue-p ()\n                 \"Ask user i f we should continue looking for s o l u t i o n s . \"\n                 (case (read-char)\n                   (#\\;    t)\n                   (#\\.    nil)\n                   (#\\newline (continue-p))\n                   (otherwise\n                       (format t \" Type ; to see more or . to s t o p \" )\n                       (continue-p))))\n\n\n           This version works just as well as the previous version on finite problems. The only\n           difference is that the user, not the system, types the semicolons. The advantage is\n           that we can now use the system on infinite problems as well. First, we'll ask what\n           Hsts 2 is a member of:\n\f370                                                                LOGIC       PROGRAMMING\n\n\n\n         > (?-   (member 2 ? l i s t ) )\n         ?LIST   = (2 . 7REST3302);\n         ?LIST   = (7X3303 2 . 7REST3307);\n         7LIST   = (7X3303 7X3308 2 . 7REST3312);\n         7LIST   = (7X3303 7X3308 7X3313 2 . 7REST3317).\n         No.\n\n\n      The answers mean that 2 is a member of any Ust that starts with 2, or whose second\n      element is 2, or whose third element is 2, and so on. The infinite computation was\n      halted when the user typed a period rather than a semicolon. The \"no\" now means\n      that there are no more answers to be printed; it will appear if there are no answers at\n      all, if the user types a period, or if all the answers have been printed.\n          We can ask even more abstract queries. The answer to the next query says that\n      an item is an element of a list when it is the the first element, or the second, or the\n      third, or the fourth, and so on,\n\n         > (7- (member 7item 71ist))\n         7 ITEM = 7ITEM3318\n         7LIST = (7ITEM3318 . 7REST3319);\n         7ITEM = 7ITEM3323\n         7LIST = (7X3320 7ITEM3323 . 7REST3324):\n         7 ITEM = 7ITEM3328\n         7LIST = (7X3320 7X3325 7ITEM3328 . 7REST3329);\n         7 ITEM = 7ITEM3333\n         7LIST = (7X3320 7X3325 7X3330 7ITEM3333 . 7REST3334).\n         No.\n\n\n      Now let's add the definition of the relation 1 ength:\n\n         �-   (length () 0))\n         �-   (length (7x . 7y) (1+ 7n)) (length 7y 7n))\n\n      Here are some queries showing that length can be used to find the second argument,\n      the first, or both:\n\n         > (7- (length ( a b e d ) 7n))\n         7N = (1+ (1+ (1+ (1+ 0 ) ) ) ) ;\n         No.\n\n         > (7- (length 71ist (1+ (1+ 0 ) ) ) )\n         7LIST = (7X3869 7X3872);\n         No.\n\f/1.3   IDEA 3: AUTOMATIC      BACKTRACKING                                                     371\n\n\n\n               > ( ? - (length ? l i s t ? n ) )\n               ?LIST = NIL\n               ?N = 0 ;\n               ?LIST = (?X3918)\n               ?N = (1+ 0 ) ;\n               ? L I S T = (7X3918 7X3921)\n               7N = (1+ (1+ 0 ) ) .\n               No.\n\n\n            The next two queries show the two lists of length two with a as a member. Both\n            queries give the correct answer, a two-element list that either starts or ends with a.\n            However, the behavior after generating these two solutions is quite different.\n\n               > (7- (length 71 (1+ (1+ 0 ) ) ) (member a 71))\n               7L = (A 7X4057);\n               7L = (7Y4061 A ) ;\n               No.\n\n               > (7- (member a 71) (length 71 (1+ (1+ 0 ) ) ) )\n               7L = (A 7X4081);\n               7L = (7Y4085 A ) ; [ A b o r t ]\n\n\n            In the first query, l e n g t h only generates one possible solution, the list with two\n            unbound elements, member takes this solution and instantiates either the first or the\n            second element to a.\n                 In the second query, member keeps generating potential solutions. The first two\n            partial solutions, where a is the first or second member of a list of unknown length,\n            are extended by 1 ength to yield the solutions where the list has length two. After\n            that, member keeps generating longer and longer lists, which 1 ength keeps rejecting.\n            It is implicit in the definition of member that subsequent solutions will be longer, but\n            because that is not explicitly known, they are all generated anyway and then explicitly\n            tested and rejected by 1 ength.\n                 This example reveals the limitations of Prolog as a pure logic-programming lan\n            guage. It turns out the user must be concerned not only about the logic of the problem\n            but also with the flow of control. Prolog is smart enough to backtrack and find all\n            solutions when the search space is small enough, but when it is infinite (or even\n            very large), the programmer still has a responsibility to guide the flow of control.\n            It is possible to devise languages that do much more in terms of automatic flow of\n            control.\"* Prolog is a convenient and efficient middle ground between imperative\n            languages and pure logic.\n\n               ^See the MU-Prolog and NU-Prolog languages (Naish 1986).\n\f372                                                                    LOGIC        PROGRAMMING\n\n\n\n      Approaches to Backtracking\n\n      Suppose you are asked to make a \"small\" change to an existing program. The\n      problem is that some function, f, which was thought to be single-valued, is now\n      known to return two or more vaUd answers in certain circumstances. In other words,\n      f is nondeterministic. (Perhaps f is sqrt, and we now want to deal with negative\n      numbers). What are your alternatives as a programmer? Five possibiUties can be\n      identified:\n\n         � Guess. Choose one possibility and discard the others. This requires a means\n           of making the right guesses, or recovering from wrong guesses.\n\n         � Know. Sometimes you can provide additional information that is enough to\n           decide what the right choice is. This means changing the calling function(s) to\n           provide the additional information.\n\n         � Return a list. This means that the calling function(s) must be changed to expect\n           a list of replies.\n\n         � Return a pipe, as defined in section 9.3. Again, the calling function(s) must be\n           changed to expect a pipe.\n\n         � Guess and save. Choose one possibility and return it, but record enough\n           information to allow computing the other possibilities later. This requires\n           saving the current state of the computation as well as some information on the\n           remaining possibilities.\n\n           The last alternative is the most desirable. It is efficient, because it doesn't require\n      computing answers that are never used. It is unobtrusive, because it doesn't require\n      changing the calling function (and the calling function's calling function) to expect a\n      list or pipe of answers. Unfortunately, it does have one major difficulty: there has\n      to be a way of packaging up the current state of the computation and saving it away\n      so that it can be returned to when the first choice does not work. For our Prolog\n      interpreter, the current state is succinctly represented as a list of goals. In other\n      problems, it is not so easy to summarize the entire state.\n           We will see in section 22.4 that the Scheme dialect of Lisp provides a function,\n      ca 11 - wi th - cu r rent - conti nua t i on, that does exactly what we want: it packages the\n      current state of the computation into a function, which can be stored away and\n      invoked later. Unfortunately, there is no corresponding function in Common Lisp.\n\n\n      Anonymous Variables\n\n      Before moving on, it is useful to introduce the notion of an anonymous variable.\n      This is a variable that is distinct from all others in a clause or query, but which the\n\f/1.4   THE ZEBRA   PUZZLE                                                                            373\n\n\n\n            programmer does not want to bother to name. In real Prolog, the underscore is used\n            for anonymous variables, but we will use a single question mark. The definition of\n            member that follows uses anonymous variables for positions within terms that are not\n            needed within a clause:\n\n                ( < - (member ?item (?item . ? ) ) )\n                ( < - (member ?item ( ? . ? r e s t ) ) (member ?item ? r e s t ) )\n\n\n            However, we also want to allow several anonymous variables in a clause but still be\n            able to keep each anonymous variable distinct from all other variables. One way to\n            do that is to replace each anonymous variable with a unique variable. The function\n            repl ace - ? - va rs uses gensym to do just that. It is installed in the top-level macros < -\n            and ? - so that all clauses and queries get the proper treatment.\n\n                (defmacro < - (&rest clause)\n                  \"Add a clause to the data b a s e . \"\n                  *(add-clause ' . ( r e p l a c e - ? - v a r s c l a u s e ) ) )\n\n                (defmacro ? - (&rest g o a l s )\n                  \"Make a query and p r i n t answers.\"\n                  '(top-level-prove '.(replace-?-vars goals)))\n\n                (defun r e p l a c e - ? - v a r s (exp)\n                  \"Replace any ? within exp with a var of the form ? 1 2 3 . \"\n                  (cond ((eq exp ' ? ) (gensym \" ? \" ) )\n                         ((atom exp) exp)\n                         (t (reuse-cons ( r e p l a c e - ? - v a r s ( f i r s t exp))\n                                                    ( r e p l a c e - ? - v a r s ( r e s t exp))\n                                                    exp))))\n\n\n            A named variable that is used only once in a clause can also be considered an\n            anonymous variable. This is addressed in a different way in section 12.3.\n\n\n\n            11.4          The Zebra Puzzle\n            Here is an example of something Prolog is very good at: a logic puzzle. There are\n            fifteen facts, or constraints, in the puzzle:\n\n               1. There are five houses in a line, each with an owner, a pet, a cigarette, a drink,\n                  and a color.\n\n               2. The Englishman lives in the red house.\n\n               3. The Spaniard owns the dog.\n\f374                                                                                      LOGIC   PROGRAMMING\n\n\n\n        4 . Coffee is drunk in the green house.\n\n        5. The Ukrainian drinks tea.\n\n        6. The green house is immediately to the right of the ivory house.\n\n        7. The Winston smoker owns snails.\n\n        8. Kools are smoked in the yellow house.\n\n        9. Milk is drunk in the middle house.\n\n       1 0 . The Norwegian lives in the first house on the left.\n\n       1 1 . The man who smokes Chesterfields lives next to the man with the fox.\n\n       1 2 . Kools are smoked in the house next to the house with the horse.\n\n       1 3 . The Lucky Strike smoker drinks orange juice.\n\n       1 4 . The Japanese smokes Parliaments.\n\n       1 5 . The Norwegian lives next to the blue house.\n\n         The questions to be answered are: who drinks water and who owns the zebra? To\n      solve this puzzle, we first define the relations nextto (for \"next to\") and i ri ght (for\n      \"immediately to the right of\"). They are closely related to member, which is repeated\n      here.\n\n         (<-    (member ?item (?item . ? r e s t ) ) )\n         (<-    (member ?item ( ? x . ? r e s t ) ) (member ?item ? r e s t ) )\n\n          ( < - (nextto ? x ?y ? l i s t ) ( i r i g h t ? x ? y ? l i s t ) )\n          ( < - (nextto ? x ?y ? l i s t ) ( i r i g h t ?y ? x ? l i s t ) )\n\n          (<- ( i r i g h t ? l e f t ?right ( ? l e f t ? r i g h t . ? r e s t ) ) )\n          (<- ( i r i g h t Tieft ? r i g h t (?x . ? r e s t ) )\n              (iright ?left ?right ?rest))\n\n          �-    (= ?x ? x ) )\n\n\n      We also defined the identity relation, =. It has a single clause that says that any  is\n      equal to itself. One might think that this implements eq or equal. Actually, since\n      Prolog uses unification to see if the two arguments of a goal each unify with ?x, this\n      means that = is unification.\n          Now we are ready to define the zebra puzzle with a single (long) clause. The\n      variable ?h represents the list of five houses, and each house is represented by a term\n      of the form (house nationality pet cigarette drink color). The variable ?w is the water\n      drinker, and ?z is the zebra owner. Each of the 15 constraints in the puzzle is listed\n\f11A   THE ZEBRA   PUZZLE                                                                      375\n\n\n\n           in the body of zebra, ahhough constraints 9 and 10 have been combined into the\n           first one. Consider constraint 2, \"The EngUshman lives in the red house.\" This is\n           interpreted as \"there is a house whose nationality is Englishman and whose color is\n           red, and which is a member of the list of houses\": in other words, (member (house\n           englishman ? ? ? red) ?h). The other constraints are similarly straightforward.\n\n               (<-  (zebra ?h ?w ? z )\n                     Each house i s of the form:\n                     (house n a t i o n a l i t y pet c i g a r e t t e drink house-color)\n                  (= ?h ((house norwegian ? ? ? ? )                                  ;1,10\n                         ?\n                         (house ? ? ? milk ? ) ? ? ) )                            ; 9\n                  (member (house englishman ? ? ? red) ? h )                      ; 2\n                  (member (house S p a n i a r d dog ? ? ? ) ? h )                ; 3\n                  (member (house 111         coffee green) ? h )                  ; 4\n                  (member (house U k r a i n i a n ? ? tea ? ) ? h )              ; 5\n                  (iright (house 1111            ivory)                           ; 6\n                          (house 1111            green) ? h )\n                  (member (house ? s n a i l s winston ? ? ) ? h )                ; 7\n                  (member (house ? ? kools ? yellow) ? h )                        ; 8\n                  (nextto (house ? ? c h e s t e r f i e l d ? ? )                ;11\n                          (house ? fox ? ? ? ) ? h )\n                  (nextto (house ? ? kools ? ? )                                 ;12\n                          (house ? horse ? ? ? ) ? h )\n                  (member (house ? ? l u c k y s t r i k e orange-juice ? ) ? h ) ; 1 3\n                  (member (house Japanese ? parliaments ? ? ) ? h )               ;14\n                  (nextto (house norwegian 1111)                                 ;15\n                          (house 1111            blue) ? h )\n                     Now for the q u e s t i o n s :\n                  (member (house ?w ? ? water ? ) ? h )                          ;Q1\n                  (member (house ? z zebra 111)             ?h))                 ;Q2\n\n\n           Here's the query and solution to the puzzle:\n\n              > ( ? - (zebra ?houses ?water-drinker ?zebra-owner))\n              7H0USES = ((HOUSE NORWEGIAN FOX KOOLS WATER YELLOW)\n                           (HOUSE UKRAINIAN HORSE CHESTERFIELD TEA BLUE)\n                           (HOUSE ENGLISHMAN SNAILS WINSTON MILK RED)\n                           (HOUSE SPANIARD DOG LUCKYSTRIKE ORANGE-JUICE IVORY)\n                           (HOUSE JAPANESE ZEBRA PARLIAMENTS COFFEE GREEN))\n              7WATER-DRINKER = NORWEGIAN\n              7ZEBRA-0WNER = JAPANESE.\n              No.\n\n\n           This took 278 seconds, and profiHng (see page 288) reveals that the function prove was\n           called 12,825 times. A call to prove has been termed a logical inference, so our system\n\f376                                                                   LOGIC    PROGRAMMING\n\n\n      is performing 12825/278 = 46 logical inferences per second, or LIPS. Good Prolog\n      systems perform at 10,000 to 100,000 LIPS or more, so this is barely Hmping along.\n          Small changes to the problem can greatly affect the search time. For example,\n      the relation nextto holds when the first house is immediately right of the second, or\n      when the second is immediately right of the first. It is arbitrary in which order these\n      clauses are listed, and one might think it would make no difference in which order\n      they were listed. In fact, if we reverse the order of these two clauses, the execution\n      time is roughly cut in half.\n\n\n\n      11.5       The Synergy of Backtracking and\n                 Unification\n      Prolog's backward chaining with backtracking is a powerful technique for generating\n      the possible solutions to a problem. It makes it easy to implement a generate-and-test\n      strategy, where possible solutions are considered one at a time, and when a candidate\n      solution is rejected, the next is suggested. But generate-and-test is only feasible when\n      the space of possible solutions is small.\n           In the zebra puzzle, there are five attributes for each of the five houses. Thus\n      there are 5! ^, or over 24 billion candidate solutions, far too many to test one at a time.\n      It is the concept of unification (with the corresponding notion of a logic variable) that\n      makes generate-and-test feasible on this puzzle. Instead of enumerating complete\n      candidate solutions, unification allows us to specify partial candidates. We start out\n      knowing that there are five houses, with the Norwegian living on the far left and\n      the milk drinker in the middle. Rather than generating all complete candidates that\n      satisfy these two constraints, we leave the remaining information vague, by unifying\n      the remaining houses and attributes with anonymous logic variables. The next\n      constraint (number 2) places the Englishman in the red house. Because of the way\n      member is written, this first tries to place the Englishman in the leftmost house. This\n      is rejected, because Englishman and Norwegian fail to unify, so the next possibiUty is\n      considered, and the Englishman is placed in the second house. But no other features\n      of the second house are specified--we didn't have to make separate guesses for the\n      Englishman's house being green, yellow, and so forth. The search continues, filling\n      in only as much as is necessary and backing up whenever a unification fails.\n           For this problem, unification serves the same purpose as the delay macro\n      (page 281). It allows us to delay deciding the value of some attribute as long as\n      possible, but to immediately reject a solution that tries to give two different values\n      to the same attribute. That way, we save time if we end up backtracking before the\n      computation is made, but we are still able to fill in the value later on.\n           It is possible to extend unification so that it is doing more work, and backtracking\n      is doing less work. Consider the following computation:\n\f/1.6   DESTRUCTIVE UNIFICATION                                                                      377\n\n\n\n                 ( ? - (length ?1 4)\n                       (member d ?1) (member a ?1) (member c ? 1 ) (member b ?1)\n                       (= ?1 (a b c d ) ) )\n\n\n             The first two Hnes generate permutations of the Hst ( d a c b ) , and the third line\n             tests for a permutation equal to (a b c d ) . Most of the work is done by backtracking.\n             An alternative is to extend unification to deal with lists, as well as constants and\n             variables. Predicates like 1 ength and member would be primitives that would have to\n             know about the representation of lists. Then the first two lines of the above program\n             would set ?1 to something like # s ( l i s t : l e n g t h 4 :members ( d a c d ) ) . The\n             third line would be a call to the extended unification procedure, which would further\n             specify ?1 to be something like:\n\n                 #s (11st rlength 4 imembers (d a c d) :order ( a b c d ) )\n\n\n             By making the unification procedure more complex, we eliminate the need for back-\n             tracking entirely.\n\n\n       t�3   Exercise 11.3 [s] Would a unification algorithm that delayed member tests be a good\n             idea or a bad idea for the zebra puzzle?\n\n\n\n\n             11.6        Destructive Unification\n             As we saw in section 11.2, keeping track of a binding list of variables is a little tricky.\n             It is also prone to inefficiency if the binding list grows large, because the list must\n             be searched linearly, and because space must be allocated to hold the binding list.\n             An alternative implementation is to change u n i f y to a destructive operation. In\n             this approach, there are no binding lists. Instead, each variable is represented as\n             a structure that includes a field for its binding. When the variable is unified with\n             another expression, the variable's binding field is modified to point to the expression.\n             Such variables will be called v a r s to distinguish them from the implementation of\n             variables as symbols starting with a question mark, v a r s are defined with the\n             following code:\n\n                 (defconstant unbound \"Unbound\")\n\n                 (defstruct var name (binding unbound))\n\n                 (defun bound-p ( v a r ) (not (eq ( v a r - b i n d i n g var) unbound)))\n\n\n             The macro de r e f gets at the binding of a variable, returning its argument when it is an\n\f378                                                                                           LOGIC       PROGRAMMING\n\n\n\n      unbound variable or a nonvariable expression. It includes a loop because a variable\n      can be bound to another variable, which in turn is bound to the ultimate value.\n          Normally, it would be considered bad practice to implement de ref as a macro,\n      since it could be implemented as an inline function, provided the caller was willing\n      to write ( s e t f  ( d e r e f x ) ) instead of (de ref                       x ) . However, de r e f will appear\n      in code generated by some versions of the Prolog compiler that will be presented in\n      the next section. Therefore, to make the generated code look neater, I have allowed\n      myself the luxury of the d e r e f macro.\n\n\n          (defmacro deref (exp)\n            \"Follow pointers f o r bound v a r i a b l e s . \"\n            '(progn (loop while (and ( v a r - p ,exp) (bound-p ,exp))\n                       do ( s e t f ,exp ( v a r - b i n d i n g , e x p ) ) )\n                    ,exp))\n\n\n      The function u n i f y !           below is the destructive version of u n i f y .              It is a predicate\n      that returns true for success and false for failure, and has the side effect of altering\n      variable bindings.\n\n          (defun u n i f y ! (x y )\n            \" D e s t r u c t i v e l y unify two e x p r e s s i o n s \"\n            (cond ((eql (deref x) (deref y ) ) t )\n                       ( ( v a r - p x) ( s e t - b i n d i n g !  y ) )\n                       ((var-p y) (set-binding! y  ) )\n                       ((and (consp  ) (consp y ) )\n                         (and ( u n i f y ! ( f i r s t x ) ( f i r s t y ) )\n                                    ( u n i f y ! ( r e s t x) ( r e s t y ) ) ) )\n                       (t n i l ) ) )\n\n          (defun s e t - b i n d i n g ! (var value)\n            \"Set v a r ' s binding to value. Always succeeds (returns t ) . \"\n            ( s e t f ( v a r - b i n d i n g v a r ) value)\n            t)\n\n\n      To make v a r s easier to read, we can install a : p r i n t - f u n c t i on:\n\n\n          (defstruct (var ( i p r i n t - f u n c t i o n p r i n t - v a r ) )\n               name (binding unbound))\n             (defun p r i n t - v a r (var stream depth)\n               ( i f (or (and (numberp * p r i n t - l e v e l * )\n                               (>= depth * p r i n t - l e v e l * ) )\n                      (var-p (deref v a r ) ) )\n                 (format stream \" ? ~ a \" (var-name v a r ) )\n                 (write var :stream stream)))\n\f/1.6   DESTRUCTIVE      UNIFICATION                                                                                379\n\n\n\n            Thisis the first example of a carefully crafted : p r i n t - f u n c t i on. There are three things\n            to notice about it. First, it explicitly writes to the stream passed as the argument.\n            It does not write to a default stream. Second, it checks the variable depth against\n            * p r i nt - 1 evel *, and prints just the variable name when the depth is exceeded. Third,\n            it uses wr i t e to print the bindings. This is because wr i t e pays attention to the current\n            values of * p r i n t - e s c a p e * , * p r i n t - p r e t t y * , and soon. Other printing functions such\n            as p r i n l or p r i n t do not pay attention to these variables.\n                  N o w , for backtracking purposes, we want to make s e t - b i ndi n g ! keep track of\n            the bindings that were made, so they can be undone later:\n\n                (defvar * t r a i l * (make-array 200 i f i l l - p o i n t e r 0 ladjustable t ) )\n\n                (defun s e t - b i n d i n g ! (var value)\n                  \"Set v a r ' s binding to value, after saving the v a r i a b l e\n                  in the t r a i l . Always returns t.\"\n                  (unless (eq var value)\n                     (vector-push-extend var * t r a i l * )\n                     ( s e t f (var-binding var) value))\n                  t)\n\n                (defun undo-bindings! ( o l d - t r a i l )\n                  \"Undo a l l bindings back to a given point in the t r a i l . \"\n                  (loop u n t i l (= ( f i l l - p o i n t e r n r a i l * ) o l d - t r a i l )\n                     do ( s e t f (var-binding (vector-pop * t r a i l * ) ) unbound)))\n\n\n            N o w we need a way of making new variables, where each one is distinct. That could\n            be done by gensym -ing a new name for each variable, but a quicker solution is just to\n            increment a counter. The constructor function ? is defined to generate a new variable\n            with a name that is a new integer. This is not strictly necessary; we could have just\n            used the automatically provided constructor make-var. However, I thought that the\n            operation of providing new anonymous variable was different enough from providing\n            a named variable that it deserved its own function. Besides, make-var may be less\n            efficient, because it has to process the keyword arguments. The function ? has no\n            arguments; it just assigns the default values specified in the slots of the va r structure.\n\n                (defvar *var-counter* 0)\n\n                (defstruct       (var ( i c o n s t r u c t o r ? ( ) )\n                                        (:print-function print-var))\n                     (name ( i n c f * v a r - c o u n t e r * ) )\n                     (binding unbound))\n\n\n            A reasonable next step would be to use destructive unification to make a more\n            efficient interpreter. This is left as an exercise, however, and instead we put the\n            interpreter aside, and in the next chapter develop a compiler.\n\f380                                                                       LOGIC   PROGRAMMING\n\n\n\n      11.7          Prolog in Prolog\n      As stated at the start of this chapter, Prolog has many of the same features that\n      make Lisp attractive for program development. Just as it is easy to write a Lisp\n      interpreter in Lisp, it is easy to write a Prolog interpreter in Prolog. The following\n      Prolog metainterpreter has three main relations. The relation c1 a use is used to store\n      clauses that make up the rules and facts that are to be interpreted. The relation\n      prove is used to prove a goal. It calls prove-al 1, which attempts to prove a list of\n      goals, prove-al 1 succeeds in two ways: (1) if the list is empty, or (2) if there is some\n      clause whose head matches the first goal, and if we can prove the body of that clause,\n      followed by the remaining goals:\n\n         ( < - (prove ? g o a l ) ( p r o v e - a l l ( ? g o a l ) ) )\n\n         ( < - (prove-all n i l ) )\n         ( < - ( p r o v e - a l l (?goal . ? g o a l s ) )\n               (clause ( < - ?goal . ?body))\n               (concat ?body ? g o a l s ?new-goals)\n               (prove-all ?new-goals))\n\n\n      Now we add two clauses to the data base to define the member relation:\n\n         ( < - (clause ( < - (mem ?x ( ? x . ? y ) ) ) ) )\n         ( < - (clause ( < - (mem ?x ( ? . ? z ) ) (mem ?x ? z ) ) ) )\n\n\n      Finally, we can prove a goal using our interpreter:\n\n         ( ? - (prove (mem ?x ( 1 2 3 ) ) ) )\n         ?X = 1 ;\n         ?X = 2 ;\n         ?X = 3 ;\n         No.\n\n\n\n\n      11.8          Prolog Compared to Lisp\n      Many of the features that make Prolog a succesful language for AI (and for program\n      development in general) are the same as Lisp's features. Let's reconsider the list of\n      features that make Lisp different from conventional languages (see page 25) and see\n      what Prolog has to offer:\n\f/1.8   PROLOG   COMPARED      TO LISP                                                           381\n\n\n\n                � Built-in Support for Lists (and other data types).   New data types can be created\n                  easily using lists or structures (structures are preferred). Support for reading,\n                  printing, and accessing components is provided automatically. Numbers,\n                  symbols, and characters are also supported. However, because logic variables\n                  cannot be altered, certain data structures and operations are not provided. For\n                  example, there is no way to update an element of a vector in Prolog.\n\n                � Automatic Storage Management. The programmer can allocate new objects with\n                  out worrying about reclaiming them. Reclaiming is usually faster in Prolog than\n                  in Lisp, because most data can be stack-allocated instead of heap-allocated.\n\n                � Dynamic Typing. Declarations are not required. Indeed, there is no standard\n                  way to make type declarations, although some implementations allow for them.\n                  Some Prolog systems provide only fixnums, so that eliminates the need for a\n                  large class of declarations.\n\n                � First-Class Functions. Prolog has no equivalent of 1 ambda, but the built-in pred\n                  icate cal 1 allows a term--a piece of data--to be called as a goal. Although\n                  backtracking choice points are not first-class objects, they can be used in a way\n                  very similar to continuations in Lisp.\n\n                � Uniform Syntax. Like Lisp, Prolog has a uniform syntax for both programs and\n                  data. This makes it easy to write interpreters and compilers in Prolog. While\n                  Lisp's prefix-operator list notation is more uniform, Prolog allows infix and\n                  postfix operators, which may be more natural for some applications.\n\n                � Interactive Environment.  Expressions can be immediately evaluated. High-\n                  quality Prolog systems offer both a compiler and interpreter, along with a host\n                  of debugging tools.\n\n                � Extensibility. Prolog syntax is extensible. Because programs and data share\n                  the same format, it is possible to write the equivalent of macros in Prolog and\n                  to define embedded languages. However, it can be harder to ensure that the\n                  resulting code will be compiled efficiently. The details of Prolog compilation\n                  are implementation-dependent.\n\n                To put things in perspective, consider that Lisp is at once one of the highest-level\n            languages available and a universal assembly language. It is a high-level language\n            because it can easily capture data, functional, and control abstractions. It is a good\n            assembly language because it is possible to write Lisp in a style that directly reflects\n            the operations available on modern computers.\n                Prolog is generally not as efficient as an assembly language, but it can be more\n            concise as a specification language, at least for some problems. The user writes\n            specifications: lists of axioms that describe the relationships that can hold in the\n            problem domain. If these specifications are in the right form, Prolog's automatic\n\f382                                                                LOGIC        PROGRAMMING\n\n\n\n      backtracking can find a solution, even though the programmer does not provide an\n      explicit algorithm. For other problems, the search space will be too large or infinite,\n      or Prolog's simple depth-first search with backup will be too inflexible. In this case,\n      Prolog must be used as a programming language rather than a specification language.\n      The programmer must be aware of Prolog's search strategy, using it to implement an\n      appropriate algorithm for the problem at hand.\n          Prolog, like Lisp, has suffered unfairly from some common myths. It has been\n      thought to be an inefficient language because early implementations were inter\n      preted, and because it has been used to write interpreters. But modern compiled\n      Prolog can be quite efficient (see Warren et al. 1977 and Van Roy 1990). There is a\n      temptation to see Prolog as a solution in itself rather than as a programming language.\n      Those who take that view object that Prolog's depth-first search strategy and basis in\n      predicate calculus is too inflexible. This objection is countered by Prolog program\n      mers who use the facilities provided by the language to build more powerful search\n      strategies and representations, just as one would do in Lisp or any other language.\n\n\n\n      11.9       History and References\n      Cordell Green (1968) was the first to articulate the view that mathematical results\n      on theorem proving could be used to make deductions and thereby answer queries.\n      However, the major technique in use at the time, resolution theorem proving (see\n      Robinson 1965), did not adequately constrain search, and thus was not practical.\n      The idea of goal-directed computing was developed in Carl Hewitt's work (1971) on\n      the PLANNER language for robot problem solving. He suggested that the user provide\n      explicit hints on how to control deduction.\n          At about the same time and independently, Alain Colmerauer was developing\n      a system to perform natural language analysis. His approach was to weaken the\n      logical language so that computationally complex statements (such as logical dis\n      junctions) could not be made. Colmerauer and his group implemented the first\n      Prolog interpreter using Algol-W in the summer of 1972 (see Roussel 1975). It was\n      Roussel's wife, Jacqueline, who came up with the name Prolog as an abbreviation\n      for \"programmation en logique.\" The first large Prolog program was their natural\n      language system, also completed that year (Colmerauer et al. 1973). For those who\n      read English better than French, Colmerauer (1985) presents an overview of Prolog.\n      Robert Kowalski is generally considered the coinventer of Prolog. His 1974 article\n      outlines his approach, and his 1988 article is a historical review on the early logic\n      programming work.\n          There are now dozens of text books on Prolog. In my mind, six of these stand\n      out. Clocksin and Mellish's Programming in Prolog (1987) was the first and remains\n      one of the best. Sterling and Shapiro's The Art of Prolog (1986) has more substantial\n      examples but is not as complete as a reference. An excellent overview from a slightly\n\f11.10   EXERCISES                                                                                383\n\n\n\n              more mathematical perspective is Pereira and Shieber's Prolog and Natural-Language\n              Analysis (1987). The book is worthwhile for its coverage of Prolog alone, and it also\n              provides a good introduction to the use of logic programming for language under-\n              standing (see part V for more on this subject). O'Keefe's The Craft of Prolog (1990)\n              shows a number of advanced techinques. O'Keefe is certainly one of the most influ-\n              ential voices in the Prolog community. He has definite views on what makes for good\n              and bad coding style and is not shy about sharing his opinions. The reader is warned\n              that this book evolved from a set of notes on the Clocksin and Mellish book, and the\n              lack of organization shows in places. However, it contains advanced material that\n              can be found nowhere else. Another collection of notes that has been organized into\n              a book is Coelho and Cotta's Prolog by Example. Published in 1988, this is an update\n              of their 1980 book. How to Solve it in Prolog. The earlier book was an underground\n              classic in the field, serving to educate a generation of Prolog programmers. Both\n              versions include a wealth of examples, unfortunately with little documentation and\n              many typos. Finally, Ivan Bratko's Prolog Programming for Artificial Intelligence (1990)\n              covers some introductory AI material from the Prolog perspective.\n                  Maier and Warren's Computing with Logic (1988) is the best reference for those\n              interested in implementing Prolog. It starts with a simple interpreter for a variable-\n              free version of Prolog, and then moves up to the full language, adding improvements\n              to the interpreter along the way. (Note that the second author, David S. Warren of\n              Stonybrook, is different from David H. D. Warren, formerly at Edinburgh and now\n              at Bristol. Both are experts on Prolog.)\n                 Lloyd's Foundations of Logic Programming   (1987) provides a theoretical explanation\n              of the formal semantics of Prolog and related languages. Lassez et al. (1988) and\n              Knight (1989) provide overviews of unification.\n                  There have been many attempts to extend Prolog to be closer to the ideal of Logic\n              Programming. The language MU-Prolog and NU-Prolog (Naish 1986) and Prolog III\n              (Colmerauer 1990) are particularly interesting. The latter includes a systematic\n              treatment of the ^ relation and an interpretation of infinite trees.\n\n\n\n\n              11.10        Exercises\n        @     Exercise 11.4 [m] It is somewhat confusing to see \"no\" printed after one or more\n              valid answers have appeared. Modify the program to print \"no\" only when there are\n              no answers at all, and \"no more\" in other cases.\n\n\n        t�J   Exercise 11.5 [h] At least six books (Abelson and Sussman 1985, Charniak and\n              McDermottl985, Charniaketal. 1986, Hennessey 1989, Wilensky 1986, and Winston\n              and Horn 1988) present unification algorithms with a common error. They all have\n              problems unifying (?x ?y a) with (?y ?x ? x ) . Some of these texts assume that uni fy\n\f384                                                                                                   LOGIC   PROGRAMMING\n\n\n\n            will be called in a context where no variables are shared between the two arguments.\n            However, they are still suspect to the bug, as the following example points out:\n\n               > (unify ' ( f ( ? x ?y a) ( ? y ? x ? x ) ) ' ( f ? z ? z ) )\n               ((?Y . A) (?X . ? Y ) ( ? Z ?X ?Y A ) )\n\n\n            Despite this subtle bug, I highly recommend each of the books to the reader. It is\n            interesting to compare different implementations of the same algorithm. It turns out\n            there are more similarities than differences. This indicates two things: (1) there is a\n            generally agreed-upon style for writing these functions, and (2) good programmers\n            sometimes take advantage of opportunities to look at other's code.\n                The question is: Can you give an informal proof of the correctness of the algorithm\n            presented in this chapter? Start by making a clear statement of the specification.\n            Apply that to the other algorithms, and show where they go wrong. Then see if you\n            can prove that the un i f y function in this chapter is correct. Failing a complete proof,\n            can you at least prove that the algorithm will always terminate? See Norvig 1991 for\n            more on this problem.\n\n\n      t�J   Exercise 11.6 [h] Since logic variables are so basic to Prolog, we would like them\n            to be efficient. In most implementations, structures are not the best choice for small\n            objects. Note that variables only have two slots: the name and the binding. The\n            binding is crucial, but the name is only needed for printing and is arbitrary for most\n            variables. This suggests an alternative implementation. Each variable will be a\n            cons cell of the variable's binding and an arbitrary marker to indicate the type. This\n            marker would be checked by v a r i abl e-p. Variable names can be stored in a hash\n            table that is cleared before each query. Implement this representation for variables\n            and compare it to the structure representation.\n\n\n            Exercise 11.7 [m] Consider the following alternative implementation for anony-\n            mous variables: Leave the macros < - and ?- alone, so that anonymous variables\n            are allowed in assertions and queries. Instead, change uni fy so that it lets anything\n            match against an anonymous variable:\n\n               (defun unify (x y �optional (bindings n o - b i n d i n g s ) )\n                 \"See i f  and y match with given b i n d i n g s . \"\n                 (cond ((eq bindings f a i l ) f a i l )\n                         ((eql  y ) b i n d i n g s )\n                         ((or (eq  * ? ) (eq y ' ? ) ) b i n d i n g s )\n                         ( ( v a r i a b l e - p x) ( u n i f y - v a r i a b l e  y b i n d i n g s ) )\n                         ((variable-p y) (unify-variable y  bindings))\n                         ((and (consp x) (consp y ) )\n                           (unify ( r e s t x) ( r e s t y )\n\f11.10 EXERCISES                                                                                                       385\n\n\n\n                                   (unify ( f i r s t x) ( f i r s t y ) b i n d i n g s ) ) )\n                         (t   fail)))\n\n\n           Is this alternative correct? If so, give an informal proof. If not, give a counterexample.\n\n\n     @     Exercise 11.8 Pi] Write a version of the Prolog interpreter that uses destructive\n           unification instead of binding lists.\n\n\n     C3 Exercise 11.9 [m] Write Prolog rules to express the terms father, mother, son,\n        daughter, and grand- versions of each of them. Also define parent, child, wife,\n        husband, brother, sister, uncle, and aunt. You will need to decide which relations\n        are primitive (stored in the Prolog data base) and which are derived by rules.\n            For example, here's a definition of grandfather that says that G is the grandfather\n        of C if G is the father of some P, who is the parent of C:\n\n              ( < - (grandfather ? g ?c)\n                    (father ? g ? p )\n                    (parent ?p ?c))\n\n\n\n\n     @     Exercise 11.10 [m]      The following problem is presented in Wirth 1976:\n\n                  I married a widow (let's call her W) who has a grown-up                        daughter (call her\n                  D). My father (F), who visited us often, fell in love with my step-daughter and\n                  married her. Hence my father became my son-in-law                      and my step-daughter\n                  became my mother. Some months later, my wife gave birth to a son (Si), who\n                  became the brother-in-law of my father, as well as my uncle. The wife of my\n                  father, that is, my step-daughter, also had a son (S2).\n\n\n              Represent this situation using the predicates defined in the previous exercise,\n          verify its conclusions, and prove that the narrator of this tale is his own grandfather.\n\n\n     @    Exercise 11.11 [d]       Recall the example:\n\n              > ( ? - (length ( a b e d ) ? n ) )\n              ?N = (1+ (1+ (1+ (1+ 0 ) ) ) ) ;\n\n\n          It is possible to produce 4 instead of (1+ (1+ (1+ (1+ 0 ) ) ) ) byextendingthenotion\n          of unification. Ait-Kaci et al. 1987 might give you some ideas how to do this.\n\f386                                                                             LOGIC   PROGRAMMING\n\n\n\n      @   Exercise 11.12 [h] The function rename- vari abl es was necessary to avoid confu\n          sion between the variables in the first argument to u n i f y and those in the second\n          argument. An alternative is to change the uni f y so that it takes two binding lists, one\n          for each argument, and keeps them separate. Implement this alternative.\n\n\n\n\n          11.11          Answers\n\n          Answer 11.9 We will choose as primitives the unary predicates mal e and f emal e\n          and the binary predicates chi 1 d and married. The former takes the child first; the\n          latter takes the husband first. Given these primitives, we can make the following\n          definitions:\n\n             �-     (father ? f ? c )   (male ? f ) (parent ? f ? c ) )\n             ( < - (mother ?m ? c )      (female ?m) (parent ?m ? c ) )\n             ( < - (son ? s ? p )       (male ? s ) (parent ?p ? s ) )\n             ( < - (daughter ? s ? p ) (male ? s ) (parent ?p ? s ) )\n\n             (<-    (grandfather ? g ? c ) (father ? g ? p ) (parent ?p ? c ) )\n             (<-    (grandmother ? g ? c ) (mother ? g ?p) (parent ?p ? c ) )\n             (<-    (grandson ? g s ?gp) (son ? g s ? p ) (parent ?gp ? p ) )\n             (<-    (granddaughter ?gd ?gp) (daughter ?gd ? p ) (parent ?gp ? p ) )\n\n             ( < - (parent ?p ? c )     (child ?c ?p))\n              ( < - (wife ?w ? h )      (married ?h ?w))\n             ( < - (husband ?h ?w) (married ?h ?w))\n\n              (<-   (sibling ?x ? y )   (parent ?p ? x ) (parent ?p ? y ) )\n              (<-   (brother ?b ? x )   (male ? b ) ( s i b l i n g ?b ? x ) )\n              (<-   (sister ?s ?x)      (female ? s ) ( s i b l i n g ? s ? x ) )\n              (<-   (uncle ?u ? n )     (brother ?u ? p ) (parent ?p ? n ) )\n              (<-   (aunt ?a ? n )      ( s i s t e r ?a ? p ) (parent ?p ? n ) )\n\n\n          Note that there is no way in Prolog to express a true definition. We would like to say\n          that \"P is the parent of C if and only if C is the child of P,\" but Prolog makes us express\n          the biconditional in one direction only.\n\f//.//   ANSWERS                                                                                          387\n\n\n\n            Answer 11.10 Because we haven't considered step-relations in the prior defini\n            tions, we have to extend the notion of parent to include step-parents. The definitions\n            have to be written very carefully to avoid infinite loops. The strategy is to structure\n            the defined terms into a strict hierarchy: the four primitives are at the bottom, then\n            pa rent is defined in terms of the primitives, then the other terms are defined in terms\n            of parent and the primitives.\n                We also provide a definition for son-in-law:\n\n                  ( < - (parent ?p ?c)                  (married ?p ?w) ( c h i l d ?c ?w))\n                  ( < - (parent ?p ?c)                  (married ?h ? p ) ( c h i l d ?c ?w))\n                  ( < - ( s o n - i n - l a w ? s ? p ) (parent ?p ?w) (married ? s ?w))\n\n\n            Now we add the information from the story. Note that we only use the four primitives\n            male, female, married, and child:\n\n                  �-    (male I ) )        ( < - (male F)) � - (male S D )           � - (male S 2 ) )\n                  �-    (female W)) ( < - (female D))\n                  (<-   (married I W))\n                  (<-   (married F D))\n                  �-    ( c h i l d D W))\n                  (<-   ( c h i l d I F))\n                  �-    (child S I I ) )\n                  (<-   ( c h i l d S2 F ) )\n\n\n                  Now we are ready to make the queries:\n\n                  > ( ? - (son-in-law F I ) )\n                  Yes.\n\n                  > ( ? - (mother D I ) )\n                  Yes.\n\n                  > ( ? - (uncle S I I ) )\n                  Yes.\n\n                  > ( ? - (grandfather I I ) )\n                  Yes.\n\fCHAPTER                   12\nCompiling Logic\nPrograms\n\n\n\n\nV I 1 he end of chapter 1 1 introduced a new, more efficient representation for logic variables.\n   I     It would be reasonable to build a new version of the Prolog interpreter incorporating\n  JL this representation. However, chapter 9 has taught us that compilers run faster than\ninterpreters and are not that much harder to build. Thus, this chapter will present a Prolog\ncompiler that translates from Prolog to Lisp.\n     Each Prolog predicate will be translated into a Lisp function, and we will adopt the convention\nthat a predicate called with a different number of arguments is a different predicate. If the symbol\n can be called with either one or two arguments, we will need two Lisp functions to implement\nthe two predicates. Following Prolog tradition, these will be called p / 1 and p /2.\n    The next step is to decide what the generated Lisp code should look like. It must unify\nthe head of each clause against the arguments, and if the unification succeeds, it must call the\npredicates in the body. The difficult part is that the choice points have to be remembered. If\na call to a predicate in the first clause fails, we must be able to return to the second clause and\ntry again.\n\fINTRODUCTION                                                                                                      389\n\n\n\n\n                   This can be done by passing in a success continuation as an extra argument to\n               every predicate. This continuation represents the goals that remain unsolved, the\n               other-goal s argument of prove. For each clause in the predicate, if all the goals iri a\n               clause succeed, then we should call the success continuation. If a goal fails, we don't\n               do anything special; we just go on to the next clause. There is one complication: after\n               failing we have to undo any bindings made by uni fy I. Consider an example. The\n               clauses\n\n                   (<-   ( l i k e s Robin c a t s ) )\n                   (<-   ( l i k e s Sandy ? x ) ( l i k e s ? x c a t s ) )\n                   (<-   ( l i k e s Kim ? x ) ( l i k e s ? x Lee) ( l i k e s ? x Kim))\n\n\n               could be compiled into this:\n\n                   (defun l i k e s / 2 ( ? a r g l ?arg2 cont)\n                          First clause:\n                     ( i f (and ( u n i f y ! ? a r g l 'Robin) ( u n i f y ! ?arg2 ' c a t s ) )\n                           (funcall cont))\n                     (undo-bindings)\n                          Second c l a u s e :\n                     ( i f ( u n i f y ! ? a r g l 'Sandy)\n                           ( l i k e s / 2 ?arg2 ' c a t s cont))\n                     (undo-bindings)\n                          Third c l a u s e :\n                     ( i f ( u n i f y ! ? a r g l 'Kim)\n                           ( l i k e s / 2 ?arg2 'Lee\n                                           #'(lambda () ( l i k e s / 2 ?arg2 'Kim c o n t ) ) ) ) ) )\n\n\n               In the first clause, we just check the two arguments and, if the unifications succeed,\n               call the continuation directly, because the first clause has no body. In the second\n               clause, 1 i k e s / 2 is called recursively, to see if ? a r g 2 likes c a t s . If this succeeds, then\n               the original goal succeeds, and the continuation cont is called. In the third clause,\n               we have to call 1 i k e s / 2 recursively again, this time requesting that it check if ? a r g 2\n               likes Lee. If this check succeeds, then the continuation will be called. In this case,\n               the continuation involves another call to 1 i k e s / 2 , to check if ? a r g 2 likes Kim. If this\n               succeeds, then the original continuation, cont, will finally be called.\n                   Recall that in the Prolog interpreter, we had to append the list of pending goals,\n               other-goal s , to the goals in the body of the clause. In the compiler, there is no need\n               to do an append. Instead, the continuation cont represents the other-goals, and the\n               body of the clause is represented by explicit calls to functions.\n\f390                                                                               COMPILING LOGIC PROGRAMS\n\n\n          Note that the code for 1 i kes/2 given before has eUminated some unnecessary\n      calls to un i fy!. The most obvious implementation would have one call to un i fy 1 for\n      each argument. Thus, for the second clause, we would have the code:\n\n          ( i f (and ( u n i f y ! ? a r g l 'Sandy) ( u n i f y l ?arg2 ? x ) )\n                ( l i k e s / 2 ? x ' c a t s cont))\n\n\n      where we would need a suitable 1 e t binding for the variable ?x.\n\n\n\n      12.1           A Prolog Compiler\n      This section presents the compiler summarized in figure 12.1. At the top level is\n      the function prol og-compi 1 e, which takes a symbol, looks at the clauses defined for\n      that symbol, and groups the clauses by arity. Each symbol/arity is compiled into a\n      separate Lisp function by compi 1 e - p r e d i c a t e .\n\n\n          (defun prolog-compile (symbol &optional\n                                                 (clauses ( g e t - c l a u s e s symbol)))\n            \"Compile a symbol; make a separate function f o r each a r i t y . \"\n            (unless (null clauses)\n              ( l e t ( ( a r i t y ( r e l a t i o n - a r i t y (clause-head ( f i r s t c l a u s e s ) ) ) ) )\n                  ; ; Compile the clauses with t h i s a r i t y\n                  (compile-predicate\n                     symbol a r i t y ( c l a u s e s - w i t h - a r i t y clauses # ' = a r i t y ) )\n                  ; ; Compile a l l the clauses with any other a r i t y\n                  (prolog-compile\n                     symbol ( c l a u s e s - w i t h - a r i t y clauses # ' / = a r i t y ) ) ) ) )\n\n\n      Three utility functions are included here:\n\n          (defun c l a u s e s - w i t h - a r i t y (clauses t e s t a r i t y )\n            \"Return a l l clauses whose head has given a r i t y . \"\n            ( f i n d - a l l a r i t y clauses\n                              :key #'(lambda (clause)\n                                            ( r e l a t i o n - a r i t y (clause-head c l a u s e ) ) )\n                              rtest t e s t ) )\n          (defun r e l a t i o n - a r i t y ( r e l a t i o n )\n            \"The number of arguments to a r e l a t i o n .\n            Example: ( r e l a t i o n - a r i t y ' ( p a b c ) ) = > 3 \"\n            (length (args r e l a t i o n ) ) )\n          (defun args (x) \"The arguments of a r e l a t i o n \" ( r e s t x ) )\n\n\n      The next step is to compile the clauses for a given predicate with a fixed arity into a\n\f12.1 A PROLOG COMPILER                                                                      391\n\n\n                                      Top-Level Functions\n         ?-                           Make a query, but compile everything first.\n                                      Special Variables\n        nrail*                        A list of all bindings made so far.\n                                      Data Types\n        var                           A box for a variable; can be destructively modified.\n                                      Major Functions\n        top-level-prove               New version compiles everything first. �\n        run-prolog                    Compile everything and call a Prolog function.\n        pr Ol og-compi 1e -symbols    Compile a list of Prolog symbols.\n        prolog-compile                Compile a symbol; make a separate function for each arity.\n        compile-predicate             Compile all the clauses for a given symbol/arity.\n        compile-clause                Transform away the head and compile the resulting body.\n        compile-body                  Compile the body of a clause.\n        compile-call                  Compile a call to a Prolog predicate.\n        compile-arg                   Generate code for an argument to a goal in the body.\n        compile-unify                 Return code that tests if var and term unify.\n                                      Auxiliary Functions\n        clauses-with-arity            Return all clauses whose head has given arity.\n        relation-arity                The number of arguments to a relation.\n        args                          The arguments of a relation.\n        make-parameters               Build a list of parameters.\n        make-predicate                Build a symbol of the form name/a r i ty.\n        make-=                        Build a unification relation.\n        def-prolog-compi 1er -macro   Define a compiler macro for Prolog.\n        prolog-compi 1er -macro       Fetch the compiler macro for a Prolog predicate.\n        has-variable-p                Is there a variable anywhere in the expression x?\n        proper-listp                  Is X a proper (non-dotted) list?\n        maybe-add-undo-bindings       Undo any bindings that need undoing.\n        bind-unbound-vars             Add a l e t if needed.\n        make-anonymous                Replace variables that are only used once with ?.\n        anonymous-variables-in        A list of anonymous variables.\n        compile-if                    Compile an IF form. No else-part allowed.\n        compile-unify-vari able       Compile the unification of a var.\n        bind-variables-in             Bind all variables in exp to themselves.\n        follow-binding                Get the ultimate binding of var according to bindings.\n        bind-new-variables            Extend bindings to include any unbound variables.\n        ignore                        Do nothing--ignore the arguments.\n                                      Previously Defined Fimctions\n        unify!                        Destructive unification (see section 11.6).\n        undo-bindings!                Use the trail to backtrack, undoing bindings.\n        binding-val                   Pick out the value part of a var/val binding.\n        symbol                        Create or find an interned symbol.\n        new-symbol                    Create a new uninterned symbol.\n        find-anywhere                 Does item occur anywhere in tree?\n\n                            Figure 12.1: Glossary for the Prolog Compiler\n\f392                                                                             COMPILING   LOGIC   PROGRAMS\n\n\n\n      Lisp function. For now, that will be done by compiling each clause indepently and\n      wrapping them in a 1 ambda with the right parameter list.\n\n         (defun compile-predicate (symbol a r i t y c l a u s e s )\n           \"Compile a l l the clauses f o r a given symbol/arity\n           into a s i n g l e LISP f u n c t i o n . \"\n           ( l e t ((predicate (make-predicate symbol a r i t y ) )\n                     (parameters (make-parameters a r i t y ) ) )\n                (compile\n                   (eval\n                     '(defun .predicate (,�parameters cont)\n                         ..(mapcar #*(lambda (clause)\n                                         (compile-clause parameters clause ' c o n t ) )\n                                   clauses))))))\n\n         (defun make-parameters ( a r i t y )\n           \"Return the l i s t ( ? a r g l ?arg2 . . . ? a r g - a r i t y ) \"\n           (loop f o r i from 1 to a r i t y\n                 c o l l e c t (new-symbol ' ? a r g i ) ) )\n\n         (defun make-predicate (symbol a r i t y )\n           \"Return the symbol: symbol/arity\"\n           (symbol symbol V a r i t y ) )\n\n\n      Now for the hard part: we must actually generate the code for a clause. Here again\n      is an example of the code desired for one clause. We'll start by setting as a target the\n      simple code:\n\n         ( < - ( l i k e s Kim ? x ) ( l i k e s ? x Lee) ( l i k e s ? x Kim))\n\n         (defun l i k e s / 2 ( ? a r g l ?arg2 cont)\n\n            (if    (and ( u n i f y ! ? a r g l *Kim) ( u n i f y ! ?arg2 ? x )\n                   ( l i k e s / 2 ?arg2 'Lee\n                                   #'(lambda ( ) ( l i k e s / 2 ? x ' K i m ) ) ) )\n            ...)\n\n\n      but we'll also consider the possibility of upgrading to the improved code:\n\n         (defun l i k e s / 2 ( ? a r g l ?arg2 cont)\n\n            (if    ( u n i f y ! ? a r g l 'Kim)\n                   ( l i k e s / 2 ?arg2 'Lee\n                                   #'(lambda ( ) ( l i k e s / 2 ?arg2       'Kim))))\n            ...)\n\n\n      One approach would be to write two functions, compi 1 e-head and compi 1 e -body.\n\f12.1 A PROLOG        COMPILER                                                                      393\n\n\n\n          and then combine them into the code ( i f head body). This approach could easily\n          generate the prior code. However, let's allow ourselves to think ahead a little. If we\n          eventually want to generate the improved code, we will need some communication\n          between the head and the body. We will have to know that the head decided not\n          to compile the unification of ? a r g 2 and ?x, but because of this, the body will have\n          to substitute ? a r g 2 for ?x. That means that the compi 1 e - head function conceptually\n          returns two values: the code for the head, and an indication of substitutions to\n          perform in the body. This could be handled by explicitly manipulating multiple\n          values, but it seems complicated.\n              An alternate approach is to eliminate compi 1 e - head and just write compi 1 e - body.\n          This is possible if we in effect do a source-code transformation on the clause. Instead\n          of treating the clause as:\n\n\n                �-    ( l i k e s Kim ? x )\n                      ( l i k e s ? x Lee) ( l i k e s ? x Kim))\n\n\n          we transform it to the equivalent:\n\n\n                (<- (likes ?argl        ?arg2)\n                      (= ? a r g l Kim) (= ?arg2 ? x ) ( l i k e s ? x Lee) ( l i k e s ?x Kim))\n\n\n          Now the arguments in the head of the clause match the arguments in the function\n          1 i k e s / 2 , so there is no need to generate any code for the head. This makes things\n          simpler by eliminating compi 1 e -head, and it is a better decomposition for another\n          reason: instead of adding optimizations to compi 1 e-head, we will add them to the\n          code in compi 1 e- body that handles =. That way, we can optimize calls that the user\n          makes to =, in addition to the calls introduced by the source-code transformation.\n               To get an overview, the calling sequence of functions will turn out to be as follows:\n\n\n                prolog-compile\n                  compile-predicate\n                      compile-clause\n                        compile-body\n                           compile-call\n                           compile-arg\n                           compile-unify\n                              compile-arg\n\n\n         where each function calls the ones below it that are indented one level. We have al\n         ready defined the first two functions. Here thenisourfirstversionof compi 1 e - c l ause:\n\f394                                                                   COMPILING        LOGIC        PROGRAMS\n\n\n\n          (defun compile-clause (parms clause cont)\n            \"Transform away the head, and compile the r e s u l t i n g body.\"\n            (compile-body\n               (nconc\n                 (mapcar #'make-= parms (args (clause-head c l a u s e ) ) )\n                 (clause-body c l a u s e ) )\n              cont))\n\n          (defun make-= (x y ) * ( = .x . y ) )\n\n\n      The bulk of the work is in compi 1 e - body, which is a little more complicated. There are\n      three cases. If there is no body, we just call the continuation. If the body starts with\n      a call to =, we compile a call to uni f y ! . Otherwise, we compile a call to a function,\n      passing in the appropriate continuation.\n          However, it is worthwhile to think ahead at this point. If we want to treat =\n      specially now, we will probably want to treat other goals specially later. So instead\n      of explicitly checking for =, we will do a data-driven dispatch, looking for any pred\n      icate that has a prol og-compi 1 er -macro property attached to it. Like Lisp compiler\n      macros, the macro can decline to handle the goal. We will adopt the convenhon that\n      returning .-pass means the macro decided not to handle it, and thus it should be\n      compiled as a normal goal.\n\n         (defun compile-body (body cont)\n           \"Compile the body of a c l a u s e . \"\n           ( i f (null body)\n                 M f u n c a l l .cont)\n                 ( l e t * ((goal ( f i r s t body))\n                            (macro (prolog-compiler-macro (predicate g o a l ) ) )\n                            (macro-val ( i f macro\n                                                  (funcall macro goal ( r e s t body) c o n t ) ) ) )\n                     ( i f (and macro (not (eq macro-val : p a s s ) ) )\n                           macro-val\n                           (compile-cal 1\n                                (make-predicate (predicate goal)\n                                                      (relation-arity goal))\n                                (mapcar #'(lambda ( a r g ) (compile-arg a r g ) )\n                                           (args g o a l ) )\n                                ( i f (null ( r e s t body))\n                                      cont\n                                      '#'(lambda ()\n                                          .(compile-body ( r e s t body) c o n t ) ) ) ) ) ) ) )\n\n         (defun compile-call (predicate args cont)\n           \"Compile a c a l l to a prolog predicate.\"\n           ' ( . p r e d i c a t e .@args .cont))\n\f12.1 A PROLOG      COMPILER                                                                         395\n\n\n\n                (defun prolog-compiler-macro (name)\n                  \"Fetch the compiler macro for a Prolog p r e d i c a t e . \"\n                     Note NAME i s the raw name, not the name/arity\n                  (get name 'prolog-compiler-macro))\n\n                (defmacro def-prolog-compi1er-macro (name a r g l i s t &body body)\n                  \"Define a compiler macro for P r o l o g . \"\n                  ' ( s e t f (get ',name 'prolog-compiler-macro)\n                              #'(lambda . a r g l i s t . . b o d y ) ) )\n\n                (def-prolog-compi1er-macro = (goal body cont)\n                  ( l e t ( ( a r g s (args g o a l ) ) )\n                       ( i f ( / = (length a r g s ) 2)\n                             .-pass\n                             � ( i f .(compile-unify ( f i r s t a r g s ) (second a r g s ) )\n                                     .(compile-body body c o n t ) ) ) ) )\n\n                (defun compile-unify (x y )\n                  \"Return code that t e s t s i f var and term u n i f y . \"\n                  ' ( u n i f y ! .(compile-arg x) .(compile-arg y ) ) )\n\n\n          All that remains is compi 1 e-arg, a function to compile the arguments to goals in the\n          body. There are three cases to consider, as shown in the compilation to the argument\n          of q below:\n\n                1 ( < - (p ? x ) (q ? x ) )                    ( q / 1 ?x cont)\n                2 � - (p ? x ) (q (f a b ) ) )                 ( q / 1 ' ( f a b) cont)\n                3 � - (p ? x ) (q (f ?x b ) ) )                ( q / 1 ( l i s t ' f ?x 'b) cont)\n\n\n          In case 1 , the argument is a variable, and it is compiled as is. In case 2, the argument\n          is a constant expression (one without any variables) that compiles into a quoted\n          expression. In case 3, the argument contains a variable, so we have to generate code\n          that builds up the expression. Case 3 is actually split into two in the list below: one\n          compiles into a call to 1 i s t , and the other a call to cons. It is important to remember\n          that the goal ( q ( f ?x b ) ) does not involve a call to the function f . Rather, it involves\n          the term ( f ?x b ) , which is just a list of three elements.\n\n                (defun compile-arg (arg)\n                  \"Generate code for an argument to a goal in the body.\"\n                  (cond ( ( v a r i a b l e - p arg) arg)\n                        ((not ( h a s - v a r i a b l e - p a r g ) ) \" . a r g )\n                        ( ( p r o p e r - l i s t p arg)\n                           ' ( l i s t ..(mapcar #'compile-arg a r g ) ) )\n                        (t ' ( c o n s .(compile-arg ( f i r s t a r g ) )\n                                              .(compile-arg ( r e s t a r g ) ) ) ) ) )\n\f396                                                                       COMPILING       LOGIC   PROGRAMS\n\n\n\n         (defun h a s - v a r i a b l e - p (x)\n           \" I s there a v a r i a b l e anywhere in the expression x ? \"\n           (find-if-anywhere # ' v a r i a b l e - p x ) )\n\n         (defun p r o p e r - l i s t p (x)\n           \" I s X a proper (non-dotted) l i s t ? \"\n           (or (null x)\n                 (and (consp x) ( p r o p e r - l i s t p ( r e s t   x)))))\n\n\n      Let's see how it works. We will consider the following clauses:\n\n         ( < - ( l i k e s Robin c a t s ) )\n         ( < - ( l i k e s Sandy ? x ) ( l i k e s ?x c a t s ) )\n         ( < - ( l i k e s Kim ? x ) ( l i k e s ? x Lee) ( l i k e s ?x Kim))\n\n         ( < - (member ?item (?item . ? r e s t ) ) )\n         ( < - (member ?item ( ? x . ? r e s t ) ) (member Titem ? r e s t ) )\n\n\n      Here's what prol og-compi 1 e gives us:\n\n         (DEFUN L I K E S / 2 (7ARG1 ?ARG2 CONT)\n           ( I F (UNIFY! ?ARG1 'ROBIN)\n                 ( I F (UNIFY! 7ARG2 'CATS)\n                       (FUNCALL CONT)))\n           ( I F (UNIFY! ?ARG1 'SANDY)\n                 ( I F (UNIFY! ?ARG2 ? X )\n                       ( L I K E S / 2 ?X 'CATS CONT)))\n           ( I F (UNIFY! 7ARG1 ' K I M )\n                 ( I F (UNIFY! ?ARG2 ? X )\n                       ( L I K E S / 2 ?X ' L E E (LAMBDA ()\n                                                     ( L I K E S / 2 ?X 'KIM CONT))))))\n\n         (DEFUN MEMBER/2 (7ARG1 7ARG2 CONT)\n           ( I F (UNIFY! 7ARG1 7ITEM)\n                 ( I F (UNIFY! 7ARG2 (CONS 7ITEM 7REST))\n                       (FUNCALL CONT)))\n           ( I F (UNIFY! 7ARG1 7ITEM)\n                 ( I F (UNIFY! 7ARG2 (CONS 7X 7REST))\n                       (MEMBER/2 7ITEM 7REST CONT))))\n\f12.2   FIXING     THE ERRORS      IN THE COMPILER                                                         397\n\n\n\n\n                12.2         Fixing the Errors in the Compiler\n                There are some problems in this version of the compiler:\n\n                    � We forgot to undo the bindings after each call to uni f y ! .\n\n                    � The definition of undo-bi ndi n g s ! defined previously requires as an argument\n                      an index into the * t r a i 1 * array. So we will have to save the current top of the\n                      trail when we enter each function.\n\n                    � Local variables, such as ?x, were used without being introduced. They should\n                      be bound to new variables.\n\n                    Undoing the bindings is simple: we add a single line to c o m p i l e - p r e d i c a t e ,\n                a call to the function maybe-add-undo-bindings. This function inserts a call to\n                undo-bi ndi n g s ! after every failure. If there is only one clause, no undoing is neces\n                sary, because the predicate higher up in the calling sequence will do it when it fails.\n                If there are multiple clauses, the function wraps the whole function body in a  et\n                that captures the initial value of the trail's fill pointer, so that the bindings can be\n                undone to the right point. Similarly, we can handle the unbound-variable problem\n                by wrapping a call to bind - unbound - va rs around each compiled clause:\n\n                    (defun compile-predicate (symbol a r i t y c l a u s e s )\n                      \"Compile a l l the clauses for a given s y m b o l / a r i t y\n                      into a s i n g l e LISP f u n c t i o n . \"\n                      ( l e t ((predicate (make-predicate symbol a r i t y ) )\n                               (parameters (make-parameters a r i t y ) ) )\n                          (compile\n                             (eval\n                               '(defun .predicate (,�parameters cont)\n                                     (maybe-add-undo-bindings\n                                        (mapcar #*(lambda (clause)\n                                                          (compile-clause parameters\n                                                                          clause ' c o n t ) )\n                                              clauses)))))))\n\n                    (defun compile-clause (parms clause cont)\n                      \"Transform away the head, and compile the r e s u l t i n g body.\"\n                      (bind-unbound-vars\n                        parms\n                        (compi 1 e-body\n                          (nconc\n                             (mapcar #'make-= parms (args (clause-head c l a u s e ) ) )\n                             (clause-body c l a u s e ) )\n                          cont)))\n\f398                                                                                    COMPILING           LOGIC      PROGRAMS\n\n\n\n         (defun maybe-add-undo-bindings (compiled-exps)\n           \"Undo any bindings that need undoing.\n           I f there are any, bind the t r a i l before we s t a r t . \"\n           (if     (length=l compiled-exps)\n                   compiled-exps\n                       �((let ((old-trail (fill-pointer                       nrail*)))\n                             , ( f i r s t compiled-exps)\n                             ,@(loop for exp in ( r e s t              compiled-exps)\n                                          collect '(undo-bindings! o l d - t r a i l )\n                                          collect       exp)))))\n\n\n         (defun bind-unbound-vars (parameters exp)\n           \" I f there are any v a r i a b l e s in exp (besides the parameters)\n           then bind them to new v a r s . \"\n           (let         ((exp-vars ( s e t - d i f f e r e n c e ( v a r i a b l e s - i n   exp)\n                                                                     parameters)))\n                 (if     exp-vars\n                         '(let     .(mapcar #'(lambda (var)                   *(.var     (?)))\n                                                  exp-vars)\n                              ,exp)\n                         exp)))\n\n\n      With these improvements, here's the code we get for 1 i kes and member:\n\n\n         (DEFUN LIKES/2 (?ARG1 ?ARG2 CONT)\n           (LET ((OLD-TRAIL                 (FILL-POINTER * T R A I L * ) ) )\n                 ( I F (UNIFY! ?ARG1 'ROBIN)\n                         ( I F (UNIFY! ?ARG2 'CATS)\n                                 (FUNCALL CONT)))\n                 (UNDO-BINDINGS! OLD-TRAIL)\n                 (LET ( ( ? X ( ? ) ) )\n                       ( I F (UNIFY! ?ARG1 'SANDY)\n                             ( I F (UNIFY! ?ARG2 ? X )\n                                   ( L I K E S / 2 ?X 'CATS CONT))))\n                 (UNDO-BINDINGS! OLD-TRAIL)\n                 (LET ( ( ? X ( ? ) ) )\n                       ( I F (UNIFY! ?ARG1 ' K I M )\n                             ( I F (UNIFY! ?ARG2 ? X )\n                                    ( L I K E S / 2 ?X 'LEE (LAMBDA ()\n                                                                    ( L I K E S / 2 ?X 'KIM C O N T ) ) ) ) ) ) ) )\n\f123   IMPROVING        THE COMPILER                                                                          399\n\n\n\n                  (DEFUN MEMBER/2 (?ARG1 ?ARG2 CONT)\n                    (LET ((OLD-TRAIL (FILL-POINTER * T R A I L * ) ) )\n                       (LET ((?ITEM ( ? ) )\n                                (?RE$T ( ? ) ) )\n                          ( I F (UNIFY! ?ARG1 ?ITEM)\n                                ( I F (UNIFY! ?ARG2 (CONS ?ITEM ?REST))\n                                      (FUNCALL CONT))))\n                       (UNDO-BINDINGS! OLD-TRAIL)\n                       (LET ( ( ? X ( ? ) )\n                                (?ITEM ( ? ) )\n                                (?REST ( ? ) ) )\n                          ( I F (UNIFY! ?ARG1 ?ITEM)\n                                ( I F (UNIFY! ?ARG2 (CONS ?X ?REST))\n                                      (MEMBER/2 ?ITEM ?REST CONT))))))\n\n\n\n\n           12.3            Improving the Compiler\n           This is fairly good, although there is still room for improvement. One minor improve\n           ment is to eliminate unneeded variables. For example, ? r e s t in the first clause of\n           member and ?x in the second clause are bound to new variables--the result of the ( ? )\n           call--and then only used once. The generated code could be made a little tighter by\n           just putting ( ? ) inline, rather than binding it to a variable and then referencing that\n           variable. There are two parts to this change: updating compi 1 e - a r g to compile an\n           anonymous variable inline, and changing the < - macro so that it converts all variables\n           that only appear once in a clause into anonymous variables:\n\n                  (defmacro < - (&rest clause)\n                    \"Add a clause to the data b a s e . \"\n                    ' ( a d d - c l a u s e '.(make-anonymous c l a u s e ) ) )\n                  (defun compile-arg (arg)\n                    \"Generate code for an argument to a goal in the body.\"\n                    (cond ((eq arg ' ? ) ' ( ? ) )\n                                ( ( v a r i a b l e - p arg) arg)\n                                ((not ( h a s - v a r i a b l e - p a r g ) ) \" , a r g )\n                                ( ( p r o p e r - l i s t p arg)\n                                   � ( l i s t ..(mapcar # ' c o m p i l e - a r g a r g ) ) )\n                                (t ' ( c o n s .(compile-arg ( f i r s t a r g ) )\n                                                     .(compile-arg ( r e s t a r g ) ) ) ) ) )\n                  (defun make-anonymous (exp &optional\n                                                            (anon-vars (anonymous-variables-in e x p ) ) )\n                    \"Replace v a r i a b l e s that are only used once with ? . \"\n                    (cond ((consp exp)\n                                   (reuse-cons (make-anonymous ( f i r s t exp) anon-vars)\n\f400                                                                COMPILING       LOGIC       PROGRAMS\n\n\n\n                                (make-anonymous ( r e s t exp) anon-vars)\n                                exp))\n                   ((member exp anon-vars) * ? )\n                   (t exp)))\n\n\n      Finding anonymous variables is tricky. The following function keeps two lists: the\n      variables that have been seen once, and the variables that have been seen twice\n      or more. The local function wal k is then used to walk over the tree, recursively\n      considering the components of each cons cell and updating the two lists as each\n      variable is encountered. This use of local functions should be remembered, as well\n      as an alternative discussed in exercise 12.23 on page 428.\n\n         (defun anonymous-variables-in (tree)\n           \"Return a l i s t of a l l v a r i a b l e s that occur only once i n t r e e . \"\n           ( l e t ((seen-once n i l )\n                       (seen-more n i l ) )\n               ( l a b e l s ((walk ( x )\n                                (cond\n                                  ((variable-p x)\n                                   (cond ((member  seen-once)\n                                              ( s e t f seen-once (delete  seen-once))\n                                              (push  seen-more))\n                                            ((member  seen-more) n i l )\n                                            (t (push  seen-once))))\n                                  ((consp x )\n                                   (walk ( f i r s t x ) )\n                                   (walk ( r e s t x ) ) ) ) ) )\n                    (walk tree)\n                   seen-once)))\n\n\n      Now member compiles into this:\n\n\n         (DEFUN MEMBER/2 (?ARG1 ?ARG2 CONT)\n           (LET ((OLD-TRAIL (FILL-POINTER n R A I L * ) ) )\n              (LET ((?ITEM ( ? ) ) )\n                 ( I F (UNIFY! ?ARG1 ?ITEM)\n                       ( I F (UNIFY! ?ARG2 (CONS ?ITEM ( ? ) ) )\n                             (FUNCALL CONT))))\n              (UNDO-BINDINGS! OLD-TRAIL)\n              (LET ((?ITEM ( ? ) )\n                       (?REST ( ? ) ) )\n                 ( I F (UNIFY! ?ARG1 ?ITEM)\n                       ( I F (UNIFY! ?ARG2 (CONS ( ? ) ?REST))\n                             (MEMBER/2 ?ITEM ?REST CONT))))))\n\f12.4 IMPROVING     THE COMPILATION        OF UNIFICATION                                          401\n\n\n\n          12.4        Improving the Compilation of Unification\n          Now we turn to the improvement of compi 1 e - un i f y . Recall that we want to eliminate\n          certain calls to uni f y ! so that, for example, the first clause of member:\n\n             (<-   (member ?item (?item . ? r e s t ) ) )\n\n\n          compiles into:\n\n             (LET ((?ITEM ( ? ) ) )\n               ( I F (UNIFY! ?ARG1 ?ITEM)\n                     ( I F (UNIFY! ?ARG2 (CONS ?ITEM ( ? ) ) )\n                           (FUNCALL CONT))))\n\n\n         when it could compile to the more efficient:\n\n             ( I F (UNIFY! ?ARG2 (CONS ?ARG1 ( ? ) ) )\n                   (FUNCALL CONT))\n\n\n         Eliminating the unification in one goal has repercussions in other goals later on, so\n         we will need to keep track of expressions that have been unified together. We have\n         a design choice. Either compi 1 e - u n i f y can modify a global state variable, or it can\n         return multiple values. On the grounds that global variables are messy, we make the\n         second choice: compi 1 e- uni f y will take a binding list as an extra argument and will\n         return two values, the actual code and an updated binding list. We will expect that\n         other related functions will have to be modified to deal with these multiple values.\n               When compi l e - u n i f y is first called in our example clause, it is asked to unify\n         ? a r g l and ? i t e m . We want it to return no code (or more precisely, the trivially true\n         test, t). For the second value, it should return a new binding list, with ? i tem bound\n         to ? a r g l . That binding will be used to replace ? i tem with ?argl in subsequent code.\n              How do we know to bind ? i t e m to ?argl rather than the other way around?\n         Because ?argl is already bound to something--the value passed in to member. We\n         don't know what this value is, but we can't ignore it. Thus, the initial binding list will\n         have to indicate that the parameters are bound to something. A simple convention\n         is to bind the parameters to themselves. Thus, the initial binding list will be:\n\n             ((?argl . ?argl) (?arg2 . ? a r g 2 ) )\n\n\n         We saw in the previous chapter (page 354) that binding a variable to itself can lead to\n         problems; we will have to be careful.\n            Besides eliminating unifications of new variables against parameters, there are\n         quite a few other improvements that can be made. For example, unifications involv-\n\f402                                                                           COMPILING       LOGIC          PROGRAMS\n\n\n\n      ing only constants can be done at compile time. The call ( = ( f a) ( f a ) ) always\n      succeeds, while ( = 3 4) always fails. In addition, unification of two cons cells can\n      be broken into components at compile time: ( = ( f ?x) ( f a ) ) reduces to ( = ?x\n      a) and ( = f f ) , where the latter trivially succeeds. We can even do some occm-s\n      checking at compile time: ( = ?x ( f ? x ) ) should fail.\n          The following table lists these improvements, along with a breakdown for the\n      cases of unifying a bound (? a r g 1 ) or unbound (?x) variable agains another expression.\n      The first column is the unification call, the second is the generated code, and the third\n      is the bindings that will be added as a result of the call:\n\n                  Unification                    Code                                 Bindings\n            1     (= 3 3)                        t                                    --\n            2     (= 3 4 )                       nil                                  --\n            3     (= ( f ? x ) ( ? p 3 ) )       t                                    (?x . 3) ( ? p .            f)\n            4     (= ? a r g l ? y )             t                                    (?y .      ?argl)\n            5     (= ? a r g l ? a r g 2 )       (unify!       ?argl     ?arg2)       (?argl      .      ?arg2)\n            6     (=   ? a r g l 3)              (unify!       ? a r g l 3)           (?argl      . 3)\n            7     (=   ?argl (f ?y))             (unify!       ?argl     ...)         (?y . ? y )\n            8     (=   ?x ? y )                  t                                    (?x . ? y )\n            9     (=   ?x 3)                     t                                    ( ? x . 3)\n           10     (=   ?x ( f ? y ) )            (unify!       ?x   ...)              (?y . ? y )\n           11     (=   ?x ( f ? x ) )            nil                                  --\n\n                                                                                      -\n           12     (=   ?x ? )                    t\n\n          From this table we can craft our new version of compi 1 e - u n i fy. The first part\n      is fairly easy. It takes care of the first three cases in this table and makes stue\n      that compi 1 e - u n i f y - v a r i abl e is called with a variable as the first argument for the\n      other cases.\n\n          (defun compile-unify (x y b i n d i n g s )\n            \"Return 2 v a l u e s : code to t e s t i f  and y u n i f y ,\n            and a new binding l i s t . \"\n            (cond\n                     Unify constants and conses:                                                ; Case\n               ((not (or ( h a s - v a r i a b l e - p x) ( h a s - v a r i a b l e - p y ) ) ) ; 1,2\n                 (values (equal  y ) b i n d i n g s ) )\n               ((and (consp x) (consp y ) )                                                     : 3\n                 (multiple-value-bind (codel b i n d i n g s l )\n                          (compile-unify ( f i r s t x) ( f i r s t y ) b i n d i n g s )\n                     (multiple-value-bind (code2 bindings2)\n                              (compile-unify ( r e s t x) ( r e s t y ) b i n d i n g s l )\n                          (values ( c o m p i l e - i f codel code2) b i n d i n g s 2 ) ) ) )\n                     Here  or y i s a v a r i a b l e .       Pick the r i g h t one:\n               ( ( v a r i a b l e - p x) (compi1e-unify-variable  y b i n d i n g s ) )\n               (t                         (compile-unify-variab1e y  b i n d i n g s ) ) ) )\n\f7 2 . 4 IMPROVING     THE COMPILATION                 OF UNIFICATION                                             403\n\n\n\n                (defun c o m p i l e - i f (pred then-part)\n                    \"Compile a Lisp I F form. No e l s e - p a r t allowed.\"\n                    (case pred\n                       ((t)      then-part)\n                       ((nil)       nil)\n                       (otherwise * ( i f         ,pred . t h e n - p a r t ) ) ) )\n\n\n            The function compi 1 e - uni f y - va r i abl e following is one of the most complex we have\n            seen. For each argument, we see if it has a binding (the local variables xb and yb),\n            and then use the bindings to get the value of each argument (xl and y 1). Note that for\n            either an unbound variable or one bound to itself,  will equal x l (and the same for y\n            andyl). If either of the pairs of values is not equal, we should use the new ones (xl or\n            y 1), and the clause commented deref does that. After that point, we just go through\n            the cases, one at a time. It turns out that it was easier to change the order slightly from\n            the preceding table, but each clause is commented with the corresponding number:\n\n                (defun c o m p i l e - u n i f y - v a r i able (x y b i n d i n g s )\n                    \"X i s a v a r i a b l e , and Y may b e . \"\n                    ( l e t * ((xb ( f o l l o w - b i n d i n g  b i n d i n g s ) )\n                                 ( x l ( i f xb (cdr xb) x ) )\n                                 (yb ( i f   (variable-p y) (follow-binding y bindings)))\n                                 ( y l ( i f yb (cdr yb) y ) ) )\n                       (cond                                                                           ; Case:\n                          ((or     (eq  * ? ) (eq y * ? ) ) (values t b i n d i n g s ) )              ; 12\n                          ((not (and (equal  x l ) (equal y y l ) ) )                                  ; deref\n                            (compile-unify x l y l b i n d i n g s ) )\n                          ((find-anywhere x l y l ) (values n i l b i n d i n g s ) )                  ; 11\n                          ((consp y l )                                                                ; 7.10\n                            (values ' ( u n i f y l      . x l .(compile-arg y l b i n d i n g s ) )\n                                           (bind-variables-in yl bindings)))\n                          ((not (null xb))\n                            ;.� i . e . X i s an ?arg v a r i a b l e\n                            (if    (and ( v a r i a b l e - p y l ) (null y b ) )\n                                   (values 't        (extend-bindings y l x l b i n d i n g s ) )      ; 4\n                                   (values ' ( u n i f y ! . x l ,(compile-arg y l b i n d i n g s ) )\n                                                (extend-bindings x l y l b i n d i n g s ) ) ) )       ; 5.6\n                          ((not (null y b ) )\n                            (compile-unify-variable y l xl bindings))\n                          (t (values ' t          (extend-bindings x l y l b i n d i n g s ) ) ) ) ) ) ; 8 . 9\n\n\n            Take some time to understand just how this function works. Then go on to the\n            following auxiliary functions:\n\f404                                                                COMPILING       LOGIC     PROGRAMS\n\n\n\n         (defun b i n d - v a r i a b l e s - i n (exp b i n d i n g s )\n           \"Bind all v a r i a b l e s in exp to themselves, and add that to\n           bindings (except for v a r i a b l e s already bound).\"\n           ( d o l i s t (var ( v a r i a b l e s - i n exp))\n               (unless (get-binding var b i n d i n g s )\n                   ( s e t f bindings (extend-bindings var var b i n d i n g s ) ) ) )\n           bindings)\n\n         (defun follow-binding (var b i n d i n g s )\n           \"Get the ultimate binding of var according to b i n d i n g s . \"\n           ( l e t ((b (get-binding var b i n d i n g s ) ) )\n                ( i f (eq (car b) (cdr b))\n                      b\n                      (or (follow-binding (cdr b) b i n d i n g s )\n                          b))))\n\n\n      Now we need to integrate the new compi 1 e - uni f y into the rest of the compiler. The\n      problem is that the new version takes an extra argument and returns an extra value,\n      so all the functions that call it need to be changed. Let's look again at the calling\n      sequence:\n\n         prolog-compile\n           compile-predicate\n             compile-clause\n               compile-body\n                 compile-call\n                 compile-arg\n                   compile-unify\n                     compile-arg\n\n\n      First, going downward, we see that compi 1 e-arg needs to take a binding Ust as an\n      argument, so that it can look up and substitute in the appropriate values. But it will\n      not alter the binding list, so it still returns one value:\n\n         (defun compile-arg (arg b i n d i n g s )\n           \"Generate code for an argument to a goal in the body.\"\n           (cond ((eq arg * ? ) ' ( ? ) )\n                 ( ( v a r i a b l e - p arg)\n                   ( l e t ((binding (get-binding arg b i n d i n g s ) ) )\n                        ( i f (and (not (null b i n d i n g ) )\n                                           (not (eq arg (binding-val b i n d i n g ) ) ) )\n                             (compile-arg (binding-val binding) b i n d i n g s )\n                             arg)))\n                 ((not (find-if-anywhere # ' v a r i a b l e - p a r g ) ) \" . a r g )\n                 ( ( p r o p e r - l i s t p arg)\n                    � ( l i s t ..(mapcar #*(lambda (a) (compile-arg a b i n d i n g s ) )\n\f12A   IMPROVING    THE COMPILATION            OF UNIFICATION                                                     405\n\n\n\n                                                 arg)))\n                          (t ' ( c o n s ,(compile-arg ( f i r s t arg) b i n d i n g s )\n                                         .(compile-arg ( r e s t arg) b i n d i n g s ) ) ) ) )\n\n\n           Now, going upward, c o m p i l e - b o d y needs to take a binding list and pass it on to\n           various functions:\n\n               (defun compile-body (body cont b i n d i n g s )\n                 \"Compile the body of a c l a u s e . \"\n                 (cond\n                    ( ( n u l l body)\n                      ' ( f u n c a l l .cont))\n                   (t ( l e t * ((goal ( f i r s t body))\n                                       (macro (prolog-compiler-macro (predicate g o a l ) ) )\n                                       (macro-val ( i f macro\n                                                              (funcall macro goal ( r e s t body)\n                                                                       contbindings))))\n                             ( i f (and macro (not (eq macro-val r p a s s ) ) )\n                                   macro-val\n                                   (compile-cal 1\n                                        (make-predicate (predicate g o a l )\n                                                                (relation-arity goal))\n                                        (mapcar #*(lambda ( a r g )\n                                                            (compile-arg arg b i n d i n g s ) )\n                                                     (args g o a l ) )\n                                        ( i f (null ( r e s t body))\n                                              cont\n                                              '#'(lambda ()\n                                                  .(compile-body\n                                                      ( r e s t body) cont\n                                                      (bind-new-variables bindings g o a l ) ) ) ) ) ) ) ) ) )\n\n\n           The function bind -new -variables takes any variables mentioned in the goal that\n           have not been bound yet and binds these variables to themselves. This is because\n           the goal, whatever it is, may bind its arguments.\n\n              (defun bind-new-variables (bindings g o a l )\n                \"Extend bindings to include any unbound v a r i a b l e s i n g o a l . \"\n                ( l e t ( ( v a r i a b l e s (remove-if #'(lambda (v) (assoc  b i n d i n g s ) )\n                                                         (variables-in goal))))\n                    (nconc (mapcar # * s e l f - c o n s v a r i a b l e s ) b i n d i n g s ) ) )\n\n              (defun s e l f - c o n s (x) (cons   ) )\n\n\n           One of the functions that needs to be changed to accept a binding list is the compiler\n           macro for =:\n\f406                                                                         COMPILING         LOGIC      PROGRAMS\n\n\n\n          (def-prolog-compiler-macro = (goal body cont bindings)\n            \"Compile a goal which i s a c a l l to = . \"\n            ( l e t ( ( a r g s (args g o a l ) ) )\n                 ( i f ( / = (length a r g s ) 2)\n                       :pass             decline to handle t h i s goal\n                       ( m u l t i p l e - v a l u e - b i n d (codel b i n d i n g s l )\n                              (compile-unify ( f i r s t a r g s ) (second a r g s ) b i n d i n g s )\n                            (compile-if\n                              codel\n                              (compile-body body cont b i n d i n g s l ) ) ) ) ) )\n\n      The last step upward is to change compi 1 e - c l ause so that it starts everything off by\n      passingin to comp i 1 e - body a binding list with all the parameters bound to themselves:\n\n          (defun compile-clause (parms clause cont)\n            \"Transform away the head, and compile the r e s u l t i n g body.\"\n            (bind-unbound-vars\n              parms\n              (compile-body\n                 (nconc\n                   (mapcar #*make-= parms (args (clause-head c l a u s e ) ) )\n                   (clause-body c l a u s e ) )\n                cont\n\n                  (mapcar # ' s e l f - c o n s   parms))))\n\n      Finally, we can see the fruits of our efforts:\n         (DEFUN MEMBER/2 (?ARG1 ?ARG2 CONT)\n           (LET ((OLD-TRAIL (FILL-POINTER * T R A I L * ) ) )\n              ( I F (UNIFYl ?ARG2 (CONS ?ARG1 ( ? ) ) )\n                      (FUNCALL CONT))\n              (UNDO-BINDINGS! OLD-TRAIL)\n              (LET ((?REST ( ? ) ) )\n                  ( I F (UNIFY! ?ARG2 (CONS ( ? ) ?REST))\n                         (MEI^BER/2 ?ARG1 ?REST CONT)))))\n         (DEFUN LIKES/2 (?ARG1 ?ARG2 CONT)\n           (LET ((OLD-TRAIL (FILL-POINTER * T R A I L * ) ) )\n              ( I F (UNIFY! ?ARG1 'ROBIN)\n                    ( I F (UNIFY! ?ARG2 'CATS)\n                            (FUNCALL CONT)))\n              (UNDO-BINDINGS! OLD-TRAIL)\n              ( I F (UNIFY! ?ARG1 'SANDY)\n                    ( L I K E S / 2 ?ARG2 'CATS CONT))\n              (UNDO-BINDINGS! OLD-TRAIL)\n              ( I F (UNIFY! ?ARG1 ' K I M )\n                    ( L I K E S / 2 ?ARG2 'LEE (LAMBDA ()\n                                                  ( L I K E S / 2 ?ARG2 'KIM CONT))))))\n\f12.5   FURTHER    IMPROVEMENTS               TO UNIFICATION                                                          407\n\n\n\n             12.5           Further Improvements to Unification\n             Could c o m p i l e - u n i f y be improved yet again? If we insist that it call u n i f y l , it\n             seems that it can't be made much better. However, we could improve it by in effect\n             compiling u n i f y ! . This is a key idea in the Warren Abstract Machine, or WAM,\n             which is the most commonly used model for Prolog compilers.\n                 We call uni f y ! in four cases (5, 6, 7, and 10), and in each case the first argument\n             is a variable, and we know something about the second argument. But the first\n             thing uni f y ! does is redundantly test if the first argument is a variable. We could\n             eliminate unnecessary tests by calling more specialized functions rather than the\n             general-purpose function uni f y ! . Consider this call:\n\n                  ( u n i f y ! ?arg2 (cons ? a r g l ( ? ) ) )\n\n\n             If ?arg2 is an unbound variable, this code is appropriate. But if ?arg2 is a constant\n             atom, we should fail immediately, without allowing cons and ? to generate garbage.\n             We could change the test to:\n\n                 (and    ( c o n s p - o r - v a r i a b l e - p ?arg2)\n                         ( u n i f y - f i r s t ! ?arg2 ? a r g l )\n                         ( u n i f y - r e s t ! ?arg2 ( ? ) ) )\n\n\n             with suitable definitions for the functions referenced here. This change should\n             speed execution time and limit the amount of garbage generated. Of course, it makes\n             the generated code longer, so that could slow things down if the program ends up\n             spending too much time bringing the code to the processor.\n\n\n       [�3   Exercise 12.1 [h] Write definitions for c o n s p - o r - v a r i a b l e - p , u n i f y - f i r s t l , and\n             uni f y - r e s t ! , and change the compiler to generate code like that outlined previously.\n             You might want to look at the function c o m p i l e - r u l e in section 9.6, starting on\n             page 300. This function compiled a call to pat-match into individual tests; now we\n             want to do the same thing to uni f y ! . Run some benchmarks to compare the altered\n             compiler to the original version.\n\n\n       @     Exercise 12.2 [h] We can gain some more efficiency by keeping track of which\n             variables have been dereferenced and calling an appropriate unification function:\n             either one that dereferences the argument or one that assumes the argument has\n             already been dereferenced. Implement this approach.\n\n\n       @     Exercise 12.3 [m]            What code is generated for (= ( f ( g ?x) ? y ) ( f ? y ( ? p a ) ) ) ?\n\f408                                                                      COMPILING       LOGIC     PROGRAMS\n\n\n\n          What more efficient code represents the same unification? How easy is it to change\n          the compiler to get this more efficient result?\n\n\n      @   Exercise 12.4 [h] In retrospect, it seems that binding variables to themselves, as\n          in ( ? a r g l . ? a r g l ) , was not such a good idea. It complicates the meaning of\n          bindings, and prohibits us from using existing tools. For example, I had to use\n          find -anywhere instead of occur-check for case 11, because occur-check expects\n          a noncircular binding list. But find -anywhere does not do as complete a job as\n          occur-check. Write a version of compi 1 e - uni f y that returns three values: the code,\n          a noncircular binding list, and a list of variables that are bound to unknown values.\n\n\n      @   Exercise 12.5 [h] An alternative to the previous exercise is not to use binding lists at\n          all. Instead, we could pass in a list of equivalence classes--that is, a list of lists, where\n          each sublist contains one or more elements that have been unified. In this approach,\n          the initial equivalence class Hst would be ( ( ? a r g l ) ( ? a r g 2 ) ) . After unifying ?argl\n          with ? x , ? a r g 2 with ?y, and ?x with 4, the list would be ( ( 4 ?argl ?x) ( ? a r g 2 ? y ) ) .\n          This assumes the convention that the canonical member of an equivalence class (the\n          one that will be substituted for all others) comes first. Implement this approach.\n          What advantages and disadvantages does it have?\n\n\n\n\n          12.6         The User Interface to the Compiler\n          The compiler can translate Prolog to Lisp, but that does us no good unless we can\n          conveniently arrange to compile the right Prolog relations and call the right Lisp\n          functions. In other words, we have to integrate the compiler with the < - and ?\n          macros. Surprisingly, we don't need to change these macros at all. Rather, we\n          will change the functions these macros call. When a new clause is entered, we will\n          enter the clause's predicate in the list *uncompi 1 ed*. This is a one-line addition to\n          add-clause:\n\n\n              (defvar *uncompiled* n i l\n                      \"Prolog symbols that have not been compiled.\")\n\n              (defun add-clause (clause)\n                \"Add a clause to the data base, indexed by head's p r e d i c a t e . \"\n                ; ; The predicate must be a non-variable symbol,\n                ( l e t ((pred (predicate (clause-head c l a u s e ) ) ) )\n                    ( a s s e r t (and (symbolp pred) (not ( v a r i a b l e - p p r e d ) ) ) )\n                    (pushnew pred * d b - p r e d i c a t e s * )\n                    (pushnew pred *uncompiled*)\n                    ( s e t f (get pred ' c l a u s e s )\n\f12,6   THE USER INTERFACE      TO THE COMPILER                                                     409\n\n\n\n                             (nconc ( g e t - c l a u s e s pred) ( l i s t c l a u s e ) ) )\n                    pred))\n\n\n            Now when a query is made, the ?- macro expands into a call to top-level - prove.\n            The Hst of goals in the query, along with the show-prol og-vars goal, is added as the\n            sole clause for the relation top - 1 evel - query. Next, that query, along with any others\n            that are on the uncompiled list, are compiled. Finally, the newly compiled top-level\n            query function is called.\n\n               (defun t o p - l e v e l - p r o v e ( g o a l s )\n                 \"Prove the l i s t of goals by compiling and c a l l i n g i t . \"\n                        F i r s t redefine top-level-query\n                 (clear-predicate ' t o p - l e v e l - q u e r y )\n                 ( l e t ( ( v a r s (delete * ? ( v a r i a b l e s - i n g o a l s ) ) ) )\n                      (add-clause * ( ( t o p - l e v e l - q u e r y )\n                                              ,�goals\n                                              (show-prolog-vars ,(mapcar #'symbol-name v a r s )\n                                                                        .vars))))\n                 ; ; Now run i t\n                 (run-prolog ' t o p - l e v e l - q u e r y / 0 # ' i g n o r e )\n                 (format t \"~&No.\")\n                 (values))\n\n               (defun run-prolog (procedure cont)\n                 \"Run a O-ary prolog procedure with a given c o n t i n u a t i o n . \"\n                      F i r s t compile anything e l s e that needs i t\n                 (prolog-compi 1 e-symbols)\n                 ; ; Reset the t r a i l and the new v a r i a b l e counter\n                 ( s e t f ( f i l l - p o i n t e r n r a i l * ) 0)\n                 ( s e t f * v a r - c o u n t e r * 0)\n                 ; ; F i n a l l y , c a l l the query\n                 (catch ' t o p - l e v e l - p r o v e\n                     (funcall procedure c o n t ) ) )\n\n               (defun prolog-compi 1 e-symbols (&optional (symbols *uncompiled*))\n                 \"Compile a l i s t of Prolog symbols.\n                 By d e f a u l t , the l i s t i s all symbols that need i t . \"\n                 (mapc #'prolog-compile symbols)\n                 ( s e t f *uncompiled* ( s e t - d i f f e r e n c e *uncompiled* symbols)))\n\n               (defun ignore (&rest a r g s )\n                 (declare (ignore a r g s ) )\n                 nil)\n\n\n            Note that at the top level, we don't need the continuation to do anything. Arbitrarily,\n            we chose to pass in the function ignore, which is defined to ignore its arguments.\n\f410                                                                      COMPILING       LOGIC       PROGRAMS\n\n\n\n            This function is useful in a variety of places; some programmers will proclaim it\n            inline and then use a call to i gnore in place of an ignore declaration:\n\n                (defun t h i r d - a r g (x y )\n                  (ignore  y )\n                  )\n\n\n            The compiler's calling convention is different from the interpreter, so the primitives\n            need to be redefined. The old definition of the primitive show-prol og - va r s had three\n            parameters: the list of arguments to the goal, a binding list, and a list of pending\n            goals. The new definition o f s h o w - p r o l o g - v a r s / 2 also has three parameters, but that\n            is just a coincidence. The first two parameters are the two separate arguments to the\n            goal: a list of variable names and a list of variable values. The last parameter is a\n            continuation function. To continue, we call that function, but to fail, we throw to the\n            catch point set up in top- 1 evel - prove.\n\n\n                (defun show-prolog-vars/2 (var-names vars cont)\n                  \" D i s p l a y the v a r i a b l e s , and prompt the user to see\n                  i f we should continue. I f n o t , return to the top l e v e l . \"\n                  ( i f (null v a r s )\n                          (format t \"~&Yes\")\n                          (loop for name in var-names\n                                   for var i n vars do\n                                   (format t \"~&~a = '^a\" name (deref-exp v a r ) ) ) )\n                  ( i f (continue-p)\n                          (funcall cont)\n                          (throw ' t o p - l e v e l - p r o v e n i l ) ) )\n\n                (defun deref-exp (exp)\n                  \" B u i l d something equivalent to EXP with v a r i a b l e s dereferenced.\"\n                  ( i f (atom (deref exp))\n                         exp\n                          (reuse-cons\n                             (deref-exp ( f i r s t exp))\n                             (deref-exp ( r e s t exp))\n                             exp)))\n\n\n            With these definitions in place, we can invoke the compiler automatically just by\n            making a query with the ? - macro.\n\n\n      [�]   Exercise 12.6 [m] Suppose you define a predicate p, which calls q, and then define\n            q. In some implementations of Lisp, when you make a query like (? - ( ? x ) ) , you\n            may get a warning message like \" f uncti on q / 1 undef i ned\" before getting the correct\n\f12,7   BENCHMARKING        THE COMPILER                                                                   411\n\n\n\n            answer. The problem is that each function is compiled separately, so warnings de\n            tected during the compilation of p /1 will be printed right away, even if the function\n            q/1 will be defined later. In ANSI Common Lisp there is a way to delay the printing\n            of warnings until a series of compilations are done: wrap the compilation with the\n            macro wi th - compi 1 at i on - uni t. Even if your implementation does not provide this\n            macro, it may provide the same functionality under a different name. Find out if\n            w i t h - c o m p i l a t i o n - u n i t is already defined in your implementation, or if it can be\n            defined.\n\n\n\n\n            12.7         Benchmarking the Compiler\n            Our compiled Prolog code runs the zebra puzzle in 17.4 seconds, a 16-fold speed-up\n            over the interpreted version, for a rate of 740 LIPS.\n                Another popular benchmark is Lisp's reverse function, which we can code as\n            the rev relation:\n\n                �-    (rev () ( ) ) )\n                �-    (rev (?x . ? a ) ?b) (rev ?a ?c) (concat ?c (?x) ?b))\n\n                (<- (concat () ?1 ?1))\n                (<- (concat (?x . ? a ) ?b (?x . ?c)) (concat ?a ?b ?c))\n\n            rev uses the relation concat, which stands for concatenation, (concat ?a ?b ? c ) i s\n            true when ?a concatenated to ?b yields ?c. This relationlike name is preferred over\n            more procedural names like append. But rev is very similar to the following Lisp\n            definitions:\n\n                (defun rev (1)\n                  ( i f (null 1)\n                        nil\n                        (app (rev (rest 1))\n                             (list (first 1)))))\n\n                (defun app (x y)\n                  ( i f (null X)\n                        y\n                        (cons ( f i r s t x)\n                               (app (rest x) y ) ) ) )\n\n            Both versions are inefficient. It is possible to write an iterative version of reverse\n            that does no extra consing and is tail-recursive:\n\f412                                                                              COMPILING             LOGIC        PROGRAMS\n\n\n\n         ( < - ( i r e v ?1 ? r ) ( i r e v 3 ?1 () ? r ) )\n         ( < - ( i r e v S ( ? x . ? 1 ) ? s o - f a r ? r ) ( i r e v S ?1 ( ? x      ?so-far) ? r ) )\n         ( < - ( i r e v 3 () ? r ? r ) )\n\n\n      The Prolog i rev is equivalent to this Lisp program:\n\n         (defun irev ( l i s t ) ( i r e v 2 l i s t n i l ) )\n\n         (defun irev2 ( l i s t s o - f a r )\n           ( i f (consp l i s t )\n                 ( i r e v 2 ( r e s t l i s t ) (cons ( f i r s t l i s t ) s o - f a r ) )\n                 so-far))\n\n\n      The following table shows times in seconds to execute these routines on lists of length\n      20 and 100, for both Prolog and Lisp, both interpreted and compiled. (Only compiled\n      Lisp could execute rev on a 100 -element list without running out of stack space.)\n      Times for the zebra puzzle are also included, although there is no Lisp version of\n      this program.\n\n                                       Interp.        Comp.                             Interp.         Comp.\n                    Problem            Prolog         Prolog         Speed-up              Lisp           Lisp\n                    zebra             278.000         17.241               16                     --           --\n                    rev 20                4.24          .208               20                  .241       .0023\n                    rev 100                     --            --                 --               --      .0614\n                    irev 20                   .22          .010                22              .028       .0005\n                    irev 100                9.81           .054               181              .139       .0014\n\n          This benchmark is too small to be conclusive, but on these examples the Prolog\n      compiler is 16 to 181 times faster than the Prolog interpreter, slightly faster than\n      interpreted Lisp, but still 17 to 90 times slower than compiled Lisp. This suggests\n      that the Prolog interpreter cannot be used as a practical programming tool, but the\n      Prolog compiler can.\n          Before moving on, it is interesting to note that Prolog provides for optional argu\n      ments automatically. Although there is no special syntax for optional arguments, an\n      often-used convention is to have two versions of a relation, one with  arguments\n      and one with  - 1. A single clause for the  -- 1 case provides the missing, and\n      therefore \"optional,\" argument. In the following example, i r e v / 2 can be considered\n      as a version of i rev /3 where the missing optional argument is ( ) .\n\n         ( < - ( i r e v ?1 ? r ) ( i r e v ?1 ( ) ? r ) )\n         ( < - ( i r e v ( ? x . ? 1 ) ? s o - f a r ? r ) ( i r e v ?1 ( ? x ? s o - f a r ) ? r ) )\n         ( < - ( i r e v () ? r ? r ) )\n\n\n      This is roughly equivalent to the following Lisp verison:\n\f2.8   ADDING   MORE      PRIMITIVES                                                                     413\n\n\n\n               (defun irev ( l i s t �optional ( s o - f a r n i l ) )\n                 ( i f (consp l i s t )\n                       ( i r e v ( r e s t l i s t ) (cons ( f i r s t l i s t ) s o - f a r ) )\n                       so-far))\n\n\n\n\n           12.8          Adding More Primitives\n           Just as a Lisp compiler needs machine instructions to do input/output, arithmetic,\n           and the like, so our Prolog system needs to be able to perform certain primitive actions.\n           For the Prolog interpreter, primitives were implemented by function symbols. When\n           the interpreter went to fetch a list of clauses, if it got a function instead, it called that\n           function, passing it the arguments to the current relation, the current bindings, and\n           a list of unsatisfied goals. For the Prolog compiler, primitives can be installed simply\n           by writing a Lisp function that respects the convention of taking a continuation as\n           the final argument and has a name of the form symbol/arity. For example, here's an\n           easy way to handle input and output:\n\n               (defun read/1 (exp cont)\n                 ( i f ( u n i f y ! exp (read))\n                       (funcall c o n t ) ) )\n\n               (defun w r i t e / 1 (exp cont)\n                 (write (deref-exp exp) :pretty t )\n                 (funcall cont))\n\n\n           Calling ( w r i t e ?x) will always succeed, so the continuation will always be called.\n           Similarly, one could use ( r e a d ?x) to read a value and unify it with ?x. If ?x is\n           unbound, this is the same as assigning the value. However, it is also possible to make\n           a call like ( r e a d (?x + ?y)), which succeeds only if the input is a three-element list\n           with + in the middle. It is an easy extension to define r e a d / 2 and wr i t e / 2 as relations\n           that indicate what stream to use. To make this useful, one would need to define\n           o p e n / 2 as a relation that takes a pathname as one argument and gives a stream back\n           as the other. Other optional arguments could also be supported, if desired.\n                The primitive nl outputs a newline:\n\n               (defun n l / 0 (cont) ( t e r p r i ) (funcall cont))\n\n\n           We provided special support for the unification predicate, =. However, we could\n           have simplified the compiler greatly by having a simple definition for = / 2 :\n\f414                                                                           COMPILING   LOGIC   PROGRAMS\n\n\n\n          (defun = / 2 ( ? a r g l ?arg2 cont)\n               (if   (unify! ?argl       ?arg2)\n                     (funcall c o n t ) ) )\n\n\n      In fact, if we give our compiler the single clause:\n\n          �-     (= ?x ?x))\n\n\n      it produces just this code for the definition of = / 2. There are other equaUty predicates\n      to worry about. The predicate = = / 2 is more like equal in Lisp. It does no unification,\n      but instead tests if two structures are equal with regard to their elements. A variable\n      is considered equal only to itself. Here's an implementation:\n\n          (defun = / 2 ( ? a r g l ?arg2 cont)\n               \"Are the two arguments EQUAL with no u n i f i c a t i o n ,\n            but with dereferencing?               I f s o , succeed.\"\n               (if   (deref-equal ? a r g l     ?arg2)\n                     (funcall c o n t ) ) )\n\n          (defun deref-equal (x y )\n               \"Are the two arguments EQUAL with no u n i f i c a t i o n ,\n            but with dereferencing?\"\n               (or   (eql (deref x) (deref y ) )\n                     (and   (consp x)\n                            (consp y )\n                            (deref-equal ( f i r s t x) ( f i r s t y ) )\n                            (deref-equal ( r e s t x) ( r e s t y ) ) ) ) )\n\n\n      One of the most important primitives is cal 1 . Like f uncal 1 in Lisp, cal 1 allows us\n      to build up a goal and then try to prove it.\n\n          (defun cal 1/1 (goal cont)\n               \"Try to prove goal by c a l l i n g        it.\"\n               (deref goal)\n               (apply (make-predicate ( f i r s t goal)\n                                               (length (args g o a l ) ) )\n                         (append (args goal) ( l i s t c o n t ) ) ) )\n\n\n      This version of cal 1 will give a run-time error if the goal is not instantiated to a list\n      whose first element is a properly defined predicate; one might want to check for that,\n      and fail silently if there is no defined predicate. Here's an example of c a l l where the\n      goal is legal:\n\f12.8 ADDING   MORE      PRIMITIVES                                                                             415\n\n\n\n              > ( ? - (= ?p member) ( c a l l ( ? p ?x (a b c ) ) ) )\n              ?P = MEMBER\n              ?X = A ;\n              ?P = MEMBER\n              ?X = B;\n              ?P = MEMBER\n              ?X = C;\n              No.\n\n          Now that we have ca 11, a lot of new things can be implemented. Here are the logical\n          connectives and and or:\n\n              �-    (or ?a ? b ) ( c a l l ? a ) )\n              �-    (or ?a ? b ) ( c a l l ? b ) )\n\n              ( < - (and ?a ?b) ( c a l l ? a ) ( c a l l ? b ) )\n\n\n          Note that these are only binary connectives, not the n-ary special forms used in Lisp.\n          Also, this definition negates most of the advantage of compilation. The goals inside\n          an and or or will be interpreted by cal 1, rather than being compiled.\n               We can also define n o t , or at least the normal Prolog n o t , which is quite distinct\n          from the logical not. In fact, in some dialects, not is written \\ + , which is supposed to\n          be reminiscent of the logical symbol I/, that is, \"can not be derived.\" The interpretation\n          is that if goal G can not be proved, then ( n o t G ) is true. Logically, there is a difference\n          between ( n o t G ) being true and being unknown, but ignoring that difference makes\n          Prolog a more practical programming language. See Lloyd 1987 for more on the\n          formal semantics of negation in Prolog.\n               Here's an implementation of n o t / L Since it has to manipulate the trail, and we\n          may have other predicates that will want to do the same, we'll package up what was\n          done in m a y b e - a d d - u n d o - b i n d i n g s into the macro w i t h - u n d o - b i n d i n g s :\n\n              (defmacro with-undo-bindings (&body body)\n                \"Undo bindings after each expression i n body except the l a s t . \"\n                ( i f (length=l body)\n                         ( f i r s t body)\n                         '(let ((old-trail (fill-pointer n r a i l * ) ) )\n                                . ( f i r s t body)\n                                .�(loop for exp i n ( r e s t body)\n                                              c o l l e c t *(undo-bindings! o l d - t r a i l )\n                                              collect exp))))\n              (defun n o t / 1 ( r e l a t i o n cont)\n                \"Negation by f a i l u r e : I f you c a n ' t prove G. then (not G) t r u e . \"\n                ; ; Either way. undo the b i n d i n g s ,\n                (with-undo-bindings\n                     ( c a l l / 1 r e l a t i o n #'(lambda () (return-from n o t / 1 n i l ) ) )\n                     (funcall cont)))\n\f416                                                                       COMPILING    LOGIC   PROGRAMS\n\n\n\n      Here's an example where not works fine:\n\n         > ( ? - (member ? x (a b c ) ) (not (= ? x b ) ) )\n         ?X = A ;\n         ?X = C ;\n         No.\n\n\n      Now see what happens when we simply reverse the order of the two goals:\n\n         > ( ? - (not (= ?x b)) (member ? x (a b c ) ) )\n         No.\n\n\n      The first example succeeds unless ?x is bound to b. In the second example, ?x is\n      unbound at the start, so (= ?x b ) succeeds, the not fails, and the member goal is never\n      reached. So our implementation of not has a consistent procedural interpretation,\n      but it is not equivalent to the declarative interpretation usually given to logical nega\n      tion. Normally, one would expect that a and c would be valid solutions to the query,\n      regardless of the order of the goals.\n          One of the fundamental differences between Prolog and Lisp is that Prolog is\n      relational: you can easily express individual relations. Lisp, on the other hand, is\n      good at expressing collections of things as lists. So far we don't have any way of\n      forming a collection of objects that satisfy a relation in Prolog. We can easily iterate\n      over the objects; we just can't gather them together. The primitive bagof is one way\n      of doing the collection. In general, (bagof ?x (p ?x) ?bag) unifies ?bag with a list\n      of all ?x's that satisfy ( ? x ) . If there are no such ?x's, then the call to bagof fails. A\n      bagis an unordered collection with duplicates allowed. For example, the bag { a , 6, a}\n      is the same as the bag { a , a, 6}, but different from { a , 6}. Bags stands in contrast to\n      sets, which are unordered collections with no duplicates. The set { a , 6} is the same\n      as the set {6, a}. Here is an implementation of bagof:\n\n          (defun bagof/3 (exp goal r e s u l t cont)\n               \"Find a l l s o l u t i o n s to GOAL, and for each s o l u t i o n ,\n            c o l l e c t the value of EXP into the l i s t            RESULT.\"\n               ;;    Ex: Assume (p 1) (p 2) (p 3 ) .           Then:\n               ;:          (bagof ? x (p ? x ) ? 1 ) = > ?1 = ( 1 2 3)\n               ( l e t ((answers n i l ) )\n                    ( c a l l / 1 goal #'(lambda ()\n                                            (push (deref-copy exp) answers)))\n                    (if   (and (not (null answers))\n                                 ( u n i f y ! r e s u l t (nreverse answers)))\n                          (funcall c o n t ) ) ) )\n\f12.8 ADDING   MORE    PRIMITIVES                                                                 417\n\n\n\n              (defun deref-copy (exp)\n                \"Copy the e x p r e s s i o n , replacing v a r i a b l e s with new ones.\n                The part without v a r i a b l e s can be returned as i s . \"\n                ( s u b l i s (mapcar #'(lambda ( v a r ) (cons (deref var) ( ? ) )\n                                      (unique-find-anywhere-if # ' v a r - p exp))\n                              exp))\n\n\n          Below we use bagof to collect a list of everyone Sandy likes. Note that the result is a\n          bag, not a set: Sandy appears more than once.\n\n              > ( ? - (bagof ?who ( l i k e s Sandy ?who) ?bag))\n              ?WHO = SANDY\n              ?BAG = (LEE KIM ROBIN SANDY CATS SANDY);\n              No.\n\n\n          In the next example, we form the bag of every list of length three that has A and  as\n          members:\n\n              > ( ? - (bagof ?1 (and (length ?1 (1+ (1+ (1+ 0 ) ) ) )\n                                     (and (member a ?1) (member b ? 1 ) ) )\n                                ?bag))\n              ?L = ( ? 5 ? 8 ?11 ?68 ? 6 6 )\n              ?BAG = ((A  ? 1 7 ) (A ?21 B) (B A ? 3 1 ) ( ? 3 8 A B) (B ?48 A) ( ? 5 2  A ) )\n              No.\n\n          Those who are disappointed with a bag containing multiple versions of the same\n          answer may prefer the primitive s e t o f , which does the same computation as bagof\n          but then discards the duplicates.\n\n              (defun s e t o f / 3 (exp goal r e s u l t cont)\n                \"Find a l l unique s o l u t i o n s to GOAL, and for each s o l u t i o n ,\n                c o l l e c t the value of EXP into the l i s t RESULT.\"\n                ; ; Ex: Assume (p 1) (p 2) (p 3 ) . Then:\n                ;;            ( s e t o f ? x (p ? x ) ?1) = > ?1 = ( 1 2 3)\n                ( l e t ((answers n i l ) )\n                    ( c a l l / 1 goal #'(lambda ()\n                                                (push (deref-copy exp) answers)))\n                    ( i f (and (not (null answers))\n                                      (unify! result (delete-duplicates\n                                                           answers\n                                                           :test #*deref-equal)))\n                            (funcall c o n t ) ) ) )\n\n\n          Prolog supports arithmetic with the operator i s . For example, ( I s ?x (+ ?y 1 ) )\n          unifies ?x with the value of ?y plus one. This expression fails if ?y is unbound, and it\n\f418                                                                                 COMPILING         LOGIC   PROGRAMS\n\n\n\n            gives a run-time error if ?y is not a number. For our version of Prolog, we can support\n            not just arithmetic but any Lisp expression:\n\n               (defun i s / 2 (var exp cont)\n                      Example: ( i s ? x (+ 3 (* ? y (+ ? z 4 ) ) ) )\n                      Or even: ( i s ( ? x ? y ? x ) (cons ( f i r s t ? z ) ? 1 ) )\n                 ( i f (and (not (find-if-anywhere #*unbound-var-p exp))\n                             (unify 1 var (eval (deref-exp e x p ) ) ) )\n                       (funcall c o n t ) ) )\n               (defun unbound-var-p (exp)\n                 \" I s EXP an unbound v a r ? \"\n                 (and (var-p exp) (not (bound-p e x p ) ) ) )\n\n\n            As an aside, we might as well give the Prolog programmer access to the function\n            unbound -var -p. The standard name for this predicate is va r / 1 :\n\n               (defun v a r / 1 ( ? a r g l cont)\n                 \"Succeeds i f ? a r g l i s an uninstantiated v a r i a b l e . \"\n                 ( i f (unbound-var-p ? a r g l )\n                       (funcall c o n t ) ) )\n\n\n            The i s primitive fails if any part of the second argument is unbound. However, there\n            are expressions with variables that can be solved, although not with a direct call to\n            eval. For example, the following goal could be solved by binding ?x to 2:\n\n               (solve (= 12 ( * (+ ?x 1) 4 ) ) )\n\n\n            We might want to have more direct access to Lisp from Prolog. The problem with\n            i s is that it requires a check for unbound variables, and it calls eval to evaluate\n            arguments recursively. In some cases, we just want to get at Lisp's apply, without\n            going through the safety net provided by i s . The primitive l i s p does that. Needless\n            to say, 1 i sp is not a part of standard Prolog.\n\n               (defun l i s p / 2 ( ? r e s u l t exp cont)\n                 \"Apply ( f i r s t exp) to ( r e s t e x p ) , and return the r e s u l t . \"\n                 ( i f (and (consp (deref exp))\n                              ( u n i f y ! ? r e s u l t (apply ( f i r s t exp) ( r e s t e x p ) ) ) )\n                       (funcall c o n t ) ) )\n\n\n\n\n      [�]   Exercise 12.7 [m] Define the primitive s o l v e / 1 , which works like the function\n            sol ve used in student (page 225). Decide if it should take a single equation as\n            argument or a list of equations.\n\f12.8 ADDING    MORE     PRIMITIVES                                                                     419\n\n\n\n     @     Exercise 12.8 [h] A s s u m e w e h a d a g o a l o f the form (solve ( = 12 ( * ( + ?x 1)\n           4 ) ) ) . Rather than manipulate the equation when sol ve/1 is called at run time, we\n           might prefer to do part of the work at compile time, treating the call as if it were\n           (solve (= ?x 2 ) ) . Write a Prolog compiler macro for sol ve. Notice that even when\n           you have defined a compiler macro, you still need the underlying primitive, because\n           the predicate might be invoked through a cal 1 / I. The same thing happens in Lisp:\n           even when you supply a compiler macro, you still need the actual function, in case\n           of a f u n c a l l or apply.\n\n\n     @     Exercise 12.9 [h] Which of the predicates c a l l , and, or, not, or repeat could\n           benefit from compiler macros? Write compiler macros for those predicates that\n           could use one.\n\n\n     ^     Exercise 12.10 [m] You might have noticed that ca 11 / 1 is inefficient in two impor-\n           tant ways. First, it calls make-predi cate, which must build a symbol by appending\n           strings and then look the string up in the Lisp symbol table. Alter make-predi cate\n           to store the predicate symbol the first time it is created, so it can do a faster lookup\n           on subsequent calls. The second inefficiency is the call to append. Change the whole\n           compiler so that the continuation argument comes first, not last, thus eliminating\n           the need for append in cal 1.\n\n\n     @     Exercise 12.11 [s] The primitive t r u e / 0 always succeeds, and f a i 1 /O always fails.\n           Define these primitives. Hint: the first corresponds to a Common Lisp function, and\n           the second is a function already defined in this chapter.\n\n\n     t�J   Exercise 12.12 [s]        Would it be possible to write = = / 2 as a list of clauses rather than\n           as a primitive?\n\n\n     t�3   Exercise 12.13 [m]         Write a version of deref - copy that traverses the argument ex-\n           pression only once.\n\f420                                                          COMPILING     LOGIC      PROGRAMS\n\n\n\n\n      12.9        The Cut\n      In Lisp, it is possible to write programs that backtrack explicitly, although it can\n      be awkward when there are more than one or two backtrack points. In Prolog,\n      backtracking is automatic and implicit, but we don't yet know of any way to avoid\n      backtracking. There are two reasons why a Prolog programmer might want to disable\n      backtracking. First, keeping track of the backtrack points takes up time and space.\n      A programmer who knows that a certain problem has only one solution should be\n      able to speed up the computation by telling the program not to consider the other\n      possible branches. Second, sometimes a simple logical specification of a problem\n      will yield redundant solutions, or even some unintended solutions. It may be that\n      simply pruning the search space to eliminate some backtracking will yield only\n      the desired answers, while restructuring the program to give all and only the right\n      answers would be more difficult. Here's an example. Suppose we wanted to define\n      a predicate, max/3, which holds when the third argument is the maximum of the\n      first two arguments, where the first two arguments will always be instantiated to\n      numbers. The straightforward definition is:\n\n          ( < - (max ?x ?y ? x ) (>= ?x ? y ) )\n          � - (max ?x ?y ? y ) � ?x ? y ) )\n\n\n      Declaratively, this is correct, but procedurally it is a waste of time to compute the <\n      relation if the >= has succeeded: in that case the < can never succeed. The cut symbol,\n      written !, can be used to stop the wasteful computation. We could write:\n\n          ( < - (max ?x ?y ? x ) (>= ?x ? y ) ! )\n          ( < - (max ? x ? y ? y ) )\n\n\n      The cut in the first clause says that if the first clause succeeds, then no other clauses\n      will be considered. So now the second clause can not be interpreted on its own.\n      Rather, it is interpreted as \"if the first clause fails, then the max of two numbers is the\n      second one.\"\n          In general, a cut can occur anywhere in the body of a clause, not just at the end.\n      There is no good declarative interpretation of a cut, but the procedural interpretation\n      is two-fold. First, when a cut is \"executed\" as a goal, it always succeeds. But in\n      addition to succeeding, it sets up a fence that cannot be crossed by subsequent\n      backtracking. The cut serves to cut off backtracking both from goals to the right of\n      the cut (in the same clause) and from clauses below the cut (in the same predicate).\n      Let's look at a more abstract example:\n\n         (<- (p) (q) (r) ! (s) ( t ) )\n         � - (p) is))\n\f12,9 THE CUT                                                                                        421\n\n\n         In processing the first clause of p, backtracking can occur freely while attempting\n         to solve q and r. Once r is solved, the cut is encountered. From that point on,\n         backtracking can occur freely while solving s and t, but Prolog will never backtrack\n         past the cut into r, nor will the second clause be considered. On the other hand, if\n         q or  failed (before the cut is encountered), then Prolog would go on to the second\n         clause.\n           Now that the intent of the cut is clear, let's think of how it should be implemented.\n         We'll look at a slightly more complex predicate, one with variables and multiple cuts:\n\n\n               �-   (p    ?x   a) 1   (q ? x ) )\n\n               ( < - (p   ?x   b)   ( ? x )   ! (s    ?x))\n\n\n\n         We have to arrange it so that as soon as we backtrack into a cut, no more goals\n         are considered. In the first clause, when q / 1 fails, we want to return from p / 2\n         immediately, rather than considering the second clause. Similarly, the first time s / 1\n         fails, we want to return from p / 2 , rather than going on to consider other solutions to\n         r / 1 . Thus, we want code that looks something like this:\n\n\n               (defun p/2 ( a r g l arg2 cont)\n                 ( l e t ( ( o l d - t r a i l ( f i l 1-pointer n r a i l * ) ) )\n                    ( i f ( u n i f y ! arg2 ' a )\n                           (progn ( q / 1 a r g l cont)\n                                      (return-from p/2 n i l ) ) )\n                    (undo-bindings! o l d - t r a i l )\n                    ( i f ( u n i f y ! arg2 ' b )\n                           ( r / 1 a r g l #'(lambda ()\n                                                   (progn ( s / 1 a r g l cont)\n                                                             (return-from p/2 n i l ) ) ) ) ) ) )\n\n\n         We can get this code by making a single change to compi 1 e - body: when the first goal\n         in a body (or what remains of the body) is the cut symbol, then we should generate a\n         progn that contains the code for the rest of the body, followed by a r e t u r n - f r o m the\n         predicate being compiled. Unfortunately, the name of the predicate is not available\n         to compi 1 e-body. We could change c o m p i l e - c l a u s e and compi 1 e - b o d y to take the\n         predicate name as an extra argument, or we could bind the predicate as a special\n         variable in compi 1 e - p r e d i c a t e . I choose the latter:\n\n\n               (defvar ^predicate* n i l\n                 \"The Prolog predicate currently being compiled\")\n\f422                                                                        COMPILING         LOGIC         PROGRAMS\n\n\n\n             (defun compile-predicate (symbol a r i t y c l a u s e s )\n               \"Compile a l l the clauses for a given symbol/arity\n               into a s i n g l e LISP f u n c t i o n . \"\n               ( l e t ((^predicate* (make-predicate symbol a r i t y ) )\n                        (parameters (make-parameters a r i t y ) ) )\n                    (compile\n                      (eval\n                        '(defun , * p r e d i c a t e * (.�parameters cont)\n                              (maybe-add-undo-bindings\n                                 (mapcar #*(lambda ( c l a u s e )\n                                                       (compile-clause parameters\n                                                                       clause *cont))\n                                          clauses)))))))\n\n             (defun compile-body (body cont b i n d i n g s )\n               \"Compile the body of a c l a u s e . \"\n               (cond\n                  ( ( n u l l body)\n                    ' ( f u n c a l l .cont))\n                  ((eq ( f i r s t body)  )\n                    '(progn .(compile-body ( r e s t body) cont b i n d i n g s )\n                                    (return-from . * p r e d i c a t e * n i l ) ) )\n                  (t ( l e t * ((goal ( f i r s t body))\n                                     (macro (prolog-compiler-macro (predicate g o a l ) ) )\n                                     (macro-val ( i f macro\n                                                           (funcall macro goal ( r e s t body)\n                                                                        contbindings))))\n                           ( i f (and macro (not (eq macro-val .-pass)))\n                                 macro-val\n                                  '(.(make-predicate (predicate goal)\n                                                               (relation-arity goal))\n                                     .�(mapcar #'(lambda (arg)\n                                                         (compile-arg arg b i n d i n g s ) )\n                                                   (args g o a l ) )\n                                     . ( i f (null ( r e s t body))\n                                             cont\n                                             '#*(lambda ()\n                                                   .(compile-body\n                                                       ( r e s t body) cont\n                                                       (bind-new-variables bindings g o a l ) ) ) ) ) ) ) ) ) )\n\n\n\n\n      @   Exercise 12.14 [m] Given the definitions below, figure out what a call to t e s t - cut\n          will do, and what it will write:\n\n             ( < - ( t e s t - c u t ) (p a) (p b) ! (p c) (p d))\n             ( < - ( t e s t - c u t ) (p e))\n\f12.9 THE CUT                                                                                   423\n\n\n               � - ( ? x ) (write ( ? x 1 ) ) )\n               ( < - (p ? x ) (write ( ? x 2 ) ) )\n\n\n            Another way to use the cut is in a repeat/fail loop. The predicate repeat is defined\n         with the following two clauses:\n\n               ( < - (repeat))\n               ( < - (repeat) (repeat))\n\n\n         An alternate definition as a primitive is:\n\n               (defun repeat/0 (cont)\n                 (loop (funcall c o n t ) ) )\n\n\n         Unfortunately, repeat is one of the most abused predicates. Several Prolog books\n         present programs like this:\n\n               ( < - (main)\n                     (write \" H e l l o . \" )\n                     (repeat)\n                     (write \"Command: \")\n                     (read ?command)\n                     (process ?command)\n                     (= ?command e x i t )\n                     (write \"Good b y e . \" ) )\n\n\n         The intent is that commands are read one at a time, and then processed. For each\n         command except e x i t , process takes the appropriate action and then fails. This\n         causes a backtrack to the repeat goal, and a new command is read and processed.\n         When the command is ex i t, the procedure returns.\n             There are two reasons why this is a poor program. First, it violates the principle of\n         referential transparency. Things that look alike are supposed to be alike, regardless\n         of the context in which they are used. But here there is no way to tell that four of the six\n         goals in the body comprise a loop, and the other goals are outside the loop. Second,\n         it violates the principle of abstraction. A predicate should be understandable as a\n         separate unit. But here the predicate process can only be understood by considering\n         the context in which it is called: a context that requires it to fail after processing each\n         command. As Richard O'Keefe 1990 points out, the correct way to write this clause\n         is as follows:\n\f424                                                                             COMPILING   LOGIC   PROGRAMS\n\n\n\n         ( < - (main)\n               (write \" H e l l o . \" )\n               (repeat)\n                  (write \"Command: \" )\n                  (read ?command)\n                  (process ?command)\n                  (or (= ?command e x i t )         (fail))\n\n               (write \"Good b y e . \" ) )\n\n\n      The indentation clearly indicates the limits of the repeat loop. The loop is terminated\n      by an explicit test and is followed by a cut, so that a calling program won't accidently\n      backtrack into the loop after it has exited. Personally, I prefer a language like Lisp,\n      where the parentheses make constructs like loops explicit and indentation can be\n      done automatically. But O'Keefe shows that well-structured readable programs can\n      be written in Prolog.\n          The if-then and if-then-else constructions can easily be written as clauses. Note\n      that the if-then-else uses a cut to commit to the then part if the test is satisfied.\n\n         (<- (if     ? t e s t ?then) ( i f   ?then ? e l s e ( f a i l ) ) )\n\n         ( < - ( i f ? t e s t ?then ? e l s e )\n               (call ?test)\n\n               (call    ?then))\n\n         ( < - ( i f ? t e s t ?then ? e l s e )\n               (call ?else))\n\n\n      The cut can be used to implement the nonlogical not. The following two clauses are\n      often given before as the definition of not. Our compiler succesfuUy turns these two\n      clauses into exactly the same code as was given before for the primitive n o t / 1 :\n\n         ( < - (not ?p) ( c a l l ? p ) I ( f a i l ) )\n         ( < - (not ? p ) )\n\n\n\n\n      12.10            '^ear Prolog\n      The Prolog-In-Lisp system developed in this chapter uses Lisp syntax because it is\n      intended to be embedded in a Lisp system. Other Prolog implementations using\n      Lisp syntax include micro-Prolog, Symbolics Prolog, and LMI Prolog.\n\f12.10   ''REAr   PROLOG                                                                        425\n\n\n               However, the majority of Prolog systems use a syntax closer to traditional math\n           ematical notation. The following table compares the syntax of \"standard\" Prolog to\n           the syntax of Prolog-In-Lisp. While there is currently an international committee\n           working on standardizing Prolog, the final report has not yet been released, so dif\n           ferent dialects may have slightly different syntax. However, most implementations\n           follow the notation summarized here. They derive from the Prolog developed at the\n           University of Edinburgh for the DEC-10 by David H. D. Warren and his colleagues.\n           The names for the primitives in the last section are also taken from Edinburgh Prolog.\n\n                                         Prolog              Prolog-In-Lisp\n                          atom            lower              const\n                          variable        Upper              ?var\n                          anonymous       -                  ?\n                          goal            p(Var,const)       (p ? v a r const)\n                          rule            p(X)       q(X).   � - (p ?x) (q ? x ) )\n                          fact            p(a).              (<-    (p a ) )\n                          query           ?- p(X).           (?-    (p ? x ) )\n                          list            [a.b.c]            (a b c )\n                          cons            [a 1 Rest]         (a . ? r e s t )\n                          nil             []                 ()\n                          and            p(X), q(X)          (and (p ?x) (q ? x ) )\n                          or             p(X): q(X)          ( o r (p ?x) (q ? x ) )\n                          not             \\ + p(X)           (not (p ? x ) )\n\n\n\n               We have adopted Lisp's bias toward lists; terms are built out of atoms, variables,\n           and conses of other terms. In real Prolog cons cells are provided, but terms are\n           usually built out of structures, not lists. The Prolog term p ( a , b ) corresponds to the\n           Lisp vector #( p/2 a b ) , not the list ( a b ) . A minority of Prolog implementations\n           use structure sharing. In this approach, every non-atomic term is represented by\n           a skeleton that contains place holders for variables and a header that points to the\n           skeleton and also contains the variables that will fill the place holders. With structure\n           sharing, making a copy is easy: just copy the header, regardless of the size of the\n           skeleton. However, manipulating terms is complicated by the need to keep track of\n           both skeleton and header. See Boyer and Moore 1972 for more on structure sharing.\n               Another major difference is that real Prolog uses the equivalent of failure contin\n           uations, not success continuations. No actual continuation, in the sense of a closure,\n           is built. Instead, when a choice is made, the address of the code for the next choice\n           is pushed on a stack. Upon failure, the next choice is popped off the stack. This is\n           reminiscent of the backtracking approach using Scheme's cal 1 / c c facility outlined\n           on page 772.\n\f426                                                              COMPILING    LOGIC     PROGRAMS\n\n\n\n      t�l   Exercise 12.15 [m] Assuming an approach using a stack of failure continuations\n            instead of success continuations, show what the code for  and member would look\n            like. Note that you need not pass failure continuations around; you can just push\n            them onto a stack that top-1 evel - prove will invoke. How would the cut be imple\n            mented? Did we make the right choice in implementing our compiler with success\n            continuations, or would failure continuations have been better?\n\n\n\n\n            12.11        History and References\n            As described in chapter 11, the idea of logic programming was fairly well understood\n            by the mid-1970s. But because the implementations of that time were slow, logic\n            programming did not catch on. It was the Prolog compiler for the DEC-10 that made\n            logic programming a serious alternative to Lisp and other general-purpose languages.\n            The compiler was developed in 1977 by David H. D. Warren with Fernando Pereira\n            and Luis Pereira. See the paper by Warren (1979) and by all three (1977).\n                Unfortunately, David H. D. Warren's pioneering work on compiling Prolog has\n            never been published in a widely accessible form. His main contribution was the\n            description of the Warren Abstract Machine (WAM), an instruction set for compiled\n            Prolog. Most existing compilers use this instruction set, or a slight modification\n            of it. This can be done either through byte-code interpretation or through macro-\n            expansion to native machine instructions. Ait-Kaci 1991 provides a good tutorial on\n            the WAM, much less terse than the original (Warren 1983). The compiler presented in\n            this chapter does not use the WAM. Instead, it is modeled after Mark Stickel's (1988)\n            theorem prover. A similar compiler is briefly sketched by Jacques Cohen 1985.\n\n\n\n\n            12.12        Exercises\n      @     Exercise 12.16 [m] Change the Prolog compiler to allow implicit c a l l s . That is, if\n            a goal is not a cons cell headed by a predicate, compile it as if it were a cal 1. The\n            clause:\n\n               �-   (p ?x ?y) (?x c) ?y)\n\n            should be compiled as if it were:\n\n               (<- (p ?x ?y) (call (?x c ) ) (call ?y))\n\f12.12 EXERCISES                                                                                       427\n\n\n\n     @      Exercise 12.17 [h]      Here are some standard Prolog primitives:\n\n               � g e t / 1 Read a single character and unify it with the argument.\n\n               � put/1 Print a single character.\n\n               � nonvar/1, / = , / = = T h e o p p o s i t e s o f var, = a n d = = , respectively.\n\n               � i nteger/1 True if the argument is an integer.\n\n               � atom/1 True if the argument is a symbol (like Lisp's symbol p).\n\n               � atomi c / 1 True if the argument is a number or symbol (like Lisp's atom).\n\n               � < , > , = < , > = Arithmetic comparison; succeeds when the arguments are both\n                  instantiated to numbers and the comparison is true.\n\n               � l i s t i n g / 0 Print out the clauses for all defined predicates.\n\n               � 1 i s t i ng/1 Print out the clauses for the argument predicate.\n\n               Implement these predicates. In each case, decide if the predicate should be\n            implemented as a primitive or a list of clauses, and if it should have a compiler\n            macro.\n               There are some naming conflicts that need to be resolved. Terms like atom have\n            one meaning in Prolog and another in Lisp. Also, in Prolog the normal notation is \\ =\n            and \\ = = , not / = and / = = . For Prolog-In-Lisp, you need to decide which notations to\n            use: Prolog's or Lisp's.\n\n\n      [�3   Exercise 12.18 [s] In Lisp, we are used to writing n-ary calls like ( < 1  1 0 ) o r ( =\n             y  ) . Write compiler macros that expand n-ary calls into a series of binary calls.\n            Forexample, (< 1  10) should expand into (and (< 1 n) (<  1 0 ) ) .\n\n\n      @     Exercise 12.19 [m] One feature of Lisp that is absent in Prolog is the quote mech\n            anism. Is there a use for quote? If so, implement it; if not, explain why it is not\n            needed.\n\n\n      [�3   Exercise 12.20 [h] Write a tracing mechanism for Prolog. Add procedures  -1 r a ce\n            and p-untrace to trace and untrace Prolog predicates. Add code to the compiler to\n            generate calls to a printing procedure for goals that are traced. In Lisp, we have to\n            trace procedures when they are called and when they return. In Prolog, there are\n            four cases to consider: the call, successful completion, backtrack into subsequent\n            clauses, and failure with no more clauses. We will call these four cases cal 1, exi t.\n\f428                                                              COMPILING     LOGIC       PROGRAMS\n\n\n\n          redo, and f ai 1 , respectively. If we traced member, we would expect tracing output to\n          look something like this:\n\n             > ( ? - (member ?x (a b c d)) ( f a i l ) )\n                CALL MEMBER: ? 1 (A  C D)\n                 EXIT MEMBER: A (A  C D)\n                 REDO MEMBER: ? 1 (A  C D)\n                     CALL MEMBER: 11 (B C D)\n                     EXIT MEMBER:  (B C D)\n                     REDO MEMBER: ? 1 (B C D)\n                        CALL MEMBER: 11 (C D)\n                        EXIT MEMBER: C (C D)\n                        REDO MEMBER: ? 1 (C D)\n                           CALL MEMBER: 11 (D)\n                           EXIT MEMBER: D (D)\n                           REDO MEMBER: ? 1 (D)\n                              CALL MEMBER: 11 NIL\n                              REDO MEMBER: 11 NIL\n                              FAIL MEMBER: 11 NIL\n                           FAIL MEMBER: 11 (D)\n                        FAIL MEMBER: 11 (C D)\n                     FAIL MEMBER: 11 (B C D)\n                 FAIL MEMBER: ? 1 (A  C D)\n             No.\n\n\n\n\n      @   Exercise 12.21 [m] Some Lisp systems are very slow at compiling functions. KCL\n          is an example; it compiles by translating to C and then calling the C compiler and\n          assembler. In KCL it is best to compile only code that is completely debugged, and\n          run interpreted while developing a program.\n              Alter the Prolog compiler so that calling the Lisp compiler is optional. In all cases,\n          Prolog functions are translated into Lisp, but they are only compiled to machine\n          language when a variable is set.\n\n\n      @   Exercise 12.22 [d] Some Prolog systems provide the predicate freeze to \"freeze\" a\n          goal until its variables are instantiated. For example, the goal (freeze  ( >  0 ) )\n          is interpreted as follows: if x is instantiated, then just evaluate the goal ( >  0 ) , and\n          succeed or fail depending on the result. However, if  is unbound, then succeed and\n          continue the computation, but remember the goal ( >  0) and evaluate it as soon as\n          X becomes instantiated. Implement freeze.\n\n\n      @   Exercise 12.23 [m] Write a recursive version of anonymous - va r i abl es - 1  that does\n          not use a local function.\n\f12.13 ANSWERS                                                                                                    429\n\n\n\n          12.13 Answers\n\n          Answer 12.6           Here 's a version that works for Texas Instruments and Lucid imple\n          mentations:\n\n                (defmacro with-compilation-unit (options &body body)\n                  \"Do the body, but delay compiler warnings u n t i l the e n d . \"\n                      This i s defined i n Common L i s p the Language, 2nd e d .\n                  *(.(read-time-case\n                        #+TI     * compi1 er:compi 1 er-warni ngs-context-bi nd\n                        #+Lucid *with-deferred-warnings\n                                 'progn)\n                     ..body))\n\n                (defun prolog-compile-symbols (&optional (symbols *uncompiled*))\n                  \"Compile a l i s t of Prolog symbols.\n                  By d e f a u l t , the l i s t i s a l l symbols that need i t . \"\n                  (with-compilation-unit ()\n                     (mapc #*prolog-compile symbols)\n                     ( s e t f *uncompiled* ( s e t - d i f f e r e n c e *uncompiled* s y m b o l s ) ) ) )\n\n\n          Answer 12.9 Macros for and and or are very important, since these are commonly\n          used. The macro for and is trivial:\n\n                (def-prolog-compiler-macro and (goal body cont b i n d i n g s )\n                  (compile-body (append (args goal) body) cont b i n d i n g s ) )\n\n\n          The macro for or is trickier:\n\n                (def-prolog-compiler-macro or (goal body cont b i n d i n g s )\n                  ( l e t ( ( d i s j u n c t s (args g o a l ) ) )\n                      (case (length d i s j u n c t s )\n                         (0 f a i l )\n                         (1 (compile-body (cons ( f i r s t d i s j u n c t s ) body) cont b i n d i n g s ) )\n                         (t ( l e t ( ( f n (gensym \" F \" ) ) )\n                                   ' ( f l e t ( ( , f n () ,(compile-body body cont b i n d i n g s ) ) )\n                                          .,(maybe-add-undo-bindings\n                                               (loop for g i n d i s j u n c t s c o l l e c t\n                                                         (compile-body ( l i s t g) * # ' , f n\n                                                                         bindings)))))))))\n\f430                                                                           COMPILING   LOGIC   PROGRAMS\n\n\n\n      Answer 12.11           t r u e / 0 is f uncal 1 : when a goal succeeds, we call the continuation,\n      f a i 1 /O is i g n o r e : when a goal fails, we ignore the continuation. We could also define\n      compiler macros for these primitives:\n\n\n          (def-prolog-compi 1 er-macro true (goal body cont b i n d i n g s )\n            (compile-body body cont b i n d i n g s ) )\n\n          (def-prolog-compiler-macro f a i l (goal body cont b i n d i n g s )\n            (declare (ignore goal body cont b i n d i n g s ) )\n            nil)\n\n\n\n      Answer 12.13\n\n\n         (defun deref-copy (exp)\n            \" B u i l d a copy of the e x p r e s s i o n , which may have v a r i a b l e s .\n            The part without v a r i a b l e s can be returned as i s . \"\n            (let    ((var-alist nil))\n              (labels\n                   ((walk (exp)\n                       (deref exp)\n                       (cond ((consp exp)\n                                  (reuse-cons (walk ( f i r s t exp))\n                                                      (walk ( r e s t exp))\n                                                      exp))\n                                ( ( v a r - p exp)\n                                  (let     ((entry (assoc exp v a r - a l i s t ) ) )\n                                     (if    (not (null        entry))\n                                            (cdr     entry)\n                                            (let     ((var-copy ( ? ) ) )\n                                               (push (cons exp var-copy)           var-alist)\n                                              var-copy))))\n                                (t   exp))))\n                   (walk e x p ) ) ) )\n\f12.13 ANSWERS                                                                                      431\n\n\n\n          Answer 12.14 In the first clause of t e s t - cut, all four calls to  will succeed via the\n          first clause of p. Then backtracking will occur over the calls to ( c ) and ( d). All\n          four combinations of 1 and 2 succeed. After that, backtracking would normally go\n          back to the call to (p b ) . But the cut prevents this, and the whole ( t e s t - c u t ) goal\n          fails, without ever considering the second clause. Here's the actual output:\n\n                (?-     (test-cut))\n                (A 1)(B 1)(C 1)(D 1)\n                Yes;\n                (D 2)\n                Yes;\n                (C 2)(D 1)\n                Yes;\n                (D 2)\n                Yes;\n                No.\n\n\n\n          Answer 12.17 Forexample:\n\n                (defun > / 2 (x y cont)\n                  (if    (and (numberp (deref x ) ) (numberp (deref y ) ) ( >  y ) )\n                         (funcall c o n t ) ) )\n\n                (defun numberp/1 (x cont)\n                  (if    (numberp (deref x ) )\n                         (funcall c o n t ) ) )\n\n\n\n          Answer 12.19 Lisp uses quote in two ways: to distinguish a symbol from the value\n          of the variable represented by that symbol, and to distinguish a literal list from the\n          value that would be returned by evaluating a function call. The first distinction Prolog\n          makes by a lexical convention: variables begin with a question mark in our Prolog,\n          and they are capitalized in real Prolog. The second distinction is not necessary\n          because Prolog is relational rather than functional. An expression is a goal if it is a\n          member of the body of a clause, and is a literal if it is an argument to a goal.\n\f432                                                                                COMPILING   LOGIC   PROGRAMS\n\n\n\n      Answer 12.20             Hint: Here's how member could be augmented with calls to a pro\n      cedure, p r o ! o g - t r a c e , which will print information about the four kinds of tracing\n      events:\n\n\n          (defun member/2 ( ? a r g l ?arg2 cont)\n             (let     ((old-trail (fill-pointer                    nrail*))\n                       (exit-cont #*(lambda ( )\n                                                 (prolog-trace ' e x i t 'member ? a r g l ?arg2 )\n                                                 (funcall        cont))))\n                (prolog-trace ' c a l l 'member ? a r g l ?arg2)\n                (if    ( u n i f y ! ?arg2 (cons ? a r g l ( ? ) ) )\n                       (funcall        exit-cont))\n                (undo-bindings! o l d - t r a i l )\n                (prolog-trace 'redo 'member ? a r g l ?arg2)\n                (let      ((?rest ( ? ) ) )\n                    (if    ( u n i f y ! ?arg2 (cons ( ? ) ? r e s t ) )\n                           (member/2 ? a r g l ? r e s t          exit-cont)))\n                (prolog-trace ' f a i l            'member ? a r g l ? a r g 2 ) ) )\n\n\n      The definition of p r o l o g - t r a c e is:\n\n\n          (defvar * p r o l o g - t r a c e - i n d e n t * 0)\n\n          (defun prolog-trace (kind predicate &rest a r g s )\n             (if    (member kind ' ( c a l l redo))\n               (incf *prolog-trace-indent* 3))\n             (format t \" ~ r v r a ~a:~{ ~a~}\"\n                           * p r o l o g - t r a c e - i n d e n t * kind predicate args)\n             (if    (member kind ' ( f a i l e x i t ) )\n               (decf * p r o l o g - t r a c e - i n d e n t * 3 ) ) )\n\f12.13   ANSWERS                                                                                       433\n\n\n\n            Answer 12.23\n\n                  (defun anonymous-variables-in (tree)\n                    \"Return a l i s t of all v a r i a b l e s that occur only once in t r e e . \"\n                    (values ( a n o n - v a r s - i n tree nil n i l ) ) )\n\n                  (defun a n o n - v a r s - i n (tree seen-once seen-more)\n                    \"Walk the data s t r u c t u r e TREE, returning a l i s t of v a r i a b l e s\n                     seen once, and a l i s t of v a r i a b l e s seen more than once.\"\n                    (cond\n                      ((consp tree)\n                        ( m u l t i p l e - v a l u e - b i n d (new-seen-once new-seen-more)\n                               ( a n o n - v a r s - i n ( f i r s t tree) seen-once seen-more)\n                           ( a n o n - v a r s - i n ( r e s t tree) new-seen-once new-seen-more)))\n                      ((not ( v a r i a b l e - p t r e e ) ) (values seen-once seen-more))\n                      ((member tree seen-once)\n                        (values (delete tree seen-once) (cons tree seen-more)))\n                      ((member tree seen-more)\n                        (values seen-once seen-more))\n                      (t (values (cons tree seen-once) seen-more))))\n\fCHAPTER                     73\n\nObject-Oriented\nProgramming\n\n\n\n\nr I 1 he programs in this book cover a wide range of problems. It is only natural that a\n   I     wide range of programming styles have been introduced to attack these problems. One\n  JL style not yet covered that has gained popularity in recent years is called object-oriented\nprogramming. To understand what object-oriented programming entails, we need to place it in\nthe context of other styles.\n     Historically, the first computer programs were written in an imperative programming style. A\nprogram was construed as a series of instructions, where each instruction performs some action:\nchanging the value of a memory location, printing a result, and so forth. Assembly language is\nan example of an imperative language.\n     As experience (and ambition) grew, programmers looked for ways of controlling the complex\nity of programs. The invention of subroutines marked the algorithmic or procedural programming\nstyle, a subclass of the imperative style. Subroutines are helpful for two reasons: breaking\nup the problem into small pieces makes each piece easier to understand, and it also makes it\npossible to reuse pieces. Examples of procedural languages are FORTRAN, C, Pascal, and Lisp\nwith s e t f .\n\f3.1   OBJECT-ORIENTED    PROGRAMMING                                                           435\n\n\n\n               Subroutines are still dependent on global state, so they are not completely sep\n           arate pieces. The use of a large number of global variables has been criticized as a\n           factor that makes it difficult to develop and maintain large programs. To eliminate\n           this problem, the functional programming style insists that functions access only the\n           parameters that are passed to them, and always return the same result for the same\n           inputs. Functional programs have the advantage of being mathematically clean--it\n           is easy to prove properties about them. However, some applications are more natu\n           rally seen as taking action rather than calculating functional values, and are therefore\n           unnatural to program in a functional style. Examples of functional languages are FP\n           and Lisp without s e t f .\n               In contrast to imperative languages are declarative languages, which attempt to\n           express \"what to do\" rather than \"how to do it.\" One type of declarative programming\n           is rule-based programming, where a set of rules states how to transform a problem\n           into a solution. Examples of rule-based systems are ELIZA and STUDENT.\n               An important kind of declarative programming is logic programming, where axioms\n           are used to describe constraints, and computation is done by a constructive proof of\n           a goal. An example of logic language is Prolog.\n                Object-oriented programming is another way to tame the problem of global state.\n           Instead of prohibiting global state (as functional programming does), object-oriented\n           programming breaks up the unruly mass of global state and encapsulates it into small,\n           manageable pieces, or objects. This chapter covers the object-oriented approach.\n\n\n\n\n            13,1        Object-Oriented Programming\n           Object-oriented programming turns the world of computing on its side: instead\n           of viewing a program primarily as a set of actions which manipulate objects, it is\n           viewed as a set of objects that are manipulated by actions. The state of each object\n           and the actions that manipulate that state are defined once and for all when the\n           object is created. This can lead to modular, robust systems that are easy to use and\n           extend. It also can make systems correspond more closely to the \"real world,\" which\n           we humans perceive more easily as being made up of objects rather than actions.\n           Examples of object-oriented languages are Simula, C++, and CLOS, the Common\n           Lisp Object System. This chapter will first introduce object-oriented programming\n           in general, and then concentrate on the Common Lisp Object System.\n               Many people are promoting object-oriented programming as the solution to the\n           software development problem, but it is hard to get people to agree on just what\n           object-orientation means. Peter Wegner 1987 proposes the following formula as a\n           definition:\n\n               Object-orientation = Objects + Classes + Inheritance\n\f436                                                                      OBJECT-ORIENTED   PROGRAMMING\n\n\n\n      Briefly, objects are modules that encapsulate some data and operations on that data.\n      The idea of information /z/dm^--insulating the representation of that data from opera\n      tions outside of the object--is an important part of this concept. Classes are groups\n      of similar objects with identical behavior. Objects are said to be instances of classes.\n      Inheritance is a means of defining new classes as variants of existing classes. The new\n      class inherits the behavior of the parent class, and the programmer need only specify\n      how the new class is different.\n          The object-oriented style brings with it a new vocabulary, which is summarized in\n      the following glossary. Each term will be explained in more detail when it comes up.\n\n            class: A group of similar objects with identical behavior.\n            class variable: A variable shared by all members of a class.\n            delegation: Passing a message from an object to one of its components.\n            generic function: A function that accepts different types or classes of\n                 arguments.\n            inheritance: A means of defining new classes as variants of existing\n                 classes.\n            instance: An instance of a class is an object.\n            instance variable: A variable encapsulated within an object.\n            message: A name for an action. Equivalent to generic function.\n            method: A means of handling a message for a particular class.\n            multimethod: A method that depends on more than one argument.\n            multiple inheritance: Inheritance from more than one parent class.\n            object: An encapsulation of local state and behavior.\n\n\n\n      13.2         Objects\n      Object-oriented programming, by definition, is concerned with objects. Any datum\n      that can be stored in computer memory can be thought of as an object. Thus, the\n      number 3, the atom x, and the string \"hel 1 o\" are all objects. Usually, however, the\n      term object is used to denote a more complex object, as we shall see.\n          Of course, all programming is concerned with objects, and with procedures\n      operating on those objects. Writing a program to solve a particular problem will\n      necessarily involve writing definitions for both objects and procedures. What dis\n      tinguishes object-oriented programming is that the primary way of decomposing the\n      problem into modules is based on the objects rather than on the procedures. The\n      difference can best be seen with an example. Here is a simple program to create bank\n      accounts and keep track of withdrawals, deposits, and accumulation of interest.\n      First, the program is written in traditional procedural style:\n\n         ( d e f s t r u c t account\n             (name \" \" ) (balance 0 . 0 0 ) ( i n t e r e s t - r a t e . 0 6 ) )\n\f13,2 OBJECTS                                                                                                        437\n\n\n\n               (defun account-withdraw (account amt)\n                 \"Make a withdrawal from t h i s account.\"\n                 ( i f (<= amt (account-balance account))\n                       (decf (account-balance account) amt)\n                       'insufficient-funds))\n\n               (defun account-deposit (account amt)\n                 \"Make a deposit to t h i s account.\"\n                 ( i n c f (account-balance account) amt))\n\n               (defun account-interest (account)\n                 \"Accumulate i n t e r e s t i n t h i s account.\"\n                 ( i n c f (account-balance account)\n                           (* ( a c c o u n t - i n t e r e s t - r a t e account)\n                              (account-balance account))))\n\n\n          We can create new bank accounts with make-a ccount and modify them with\n          account-wi thdraw, a c c o u n t - d e p o s i t , and a c c o u n t - i n t e r e s t . This is a simple prob\n          lem, and this simple solution suffices. Problems appear when we change the spec\n          ification of the problem, or when we envision ways that this implementation could\n          be inadvertently used in error. For example, suppose a programmer looks at the\n          account structure and decides to use ( d e c f ( a c c o u n t - b a l a n c e a c c o u n t ) ) directly\n          instead of going through the account-wi thdraw function. This could lead to negative\n          account balances, which were not intended. Or suppose that we want to create a\n          new kind of account, where only a certain maximum amount can be withdrawn at\n          one time. There would be no way to ensure that account-withdraw would not be\n          applied to this new, limited account.\n             The problem is that once we have created an account, we have no control over\n          what actions are applied to it. The object-oriented style is designed to provide that\n          control. Here is the same program written in object-oriented style (using plain Lisp):\n\n               (defun new-account (name &optional (balance 0 . 0 0 )\n                                             (interest-rate .06))\n                 \"Create a new account that knows the f o l l o w i n g messages:\"\n                 #'(lambda (message)\n                      (case message\n                        (withdraw #*(lambda (amt)\n                                               ( i f (<= amt balance)\n                                                       (decf balance amt)\n                                                       �insufficient-funds)))\n                        (deposit #'(lambda (amt) ( i n c f balance amt)))\n                        (balance #'(lambda ( ) balance))\n                        (name             #'(lambda () name))\n                        ( i n t e r e s t #*(lambda ()\n                                               ( i n c f balance\n                                                         (* i n t e r e s t - r a t e b a l a n c e ) ) ) ) ) ) )\n\f438                                                         OBJECT-ORIENTED             PROGRAMMING\n\n\n\n      The function new-account creates account objects, which are implemented as clo\n      sures that encapsulate three variables: the name, balance, and interest rate of the\n      account. An account object also encapsulates functions to handle the five messages\n      to which the object can respond. An account object can do only one thing: receive a\n      message and return the appropriate function to execute that message. For example,\n      if you pass the message wi thdraw to an account object, it will return a function that,\n      when applied to a single argument (the amount to withdraw), will perform the with\n      drawal action. This function is called the method that implements the message. The\n      advantage of this approach is that account objects are completely encapsulated; the\n      information corresponding to the name, balance, and interest rate is only accessible\n      through the five messages. We have a guarantee that no other code can manipulate\n      the information in the account in any other way.^\n          The function get - method finds the method that implements a message for a given\n      object. The function send gets the method and applies it to a list of arguments. The\n      name send comes from the Flavors object-oriented system, which is discussed in the\n      history section (page 456).\n\n          (defun get-method (object message)\n            \"Return the method that implements message f o r t h i s o b j e c t . \"\n            (funcall object message))\n\n          (defun send (object message &rest a r g s )\n            \"Get the function to implement the message,\n            and apply the function to the a r g s . \"\n            (apply (get-method object message) a r g s ) )\n\n\n      Here is an example of the use of new- account and send:\n\n\n         > ( s e t f acct (new-account \" J . Random Customer\" 1000.00)) =^\n         #<CLOSURE 23652465>\n\n         > (send acct 'withdraw 500.00)            500.0\n\n         > (send acct ' d e p o s i t 123.45) => 623.45\n\n         > (send acct 'name) ^        \" J . Random Customer\"\n\n         > (send acct 'balance) =^ 623.45\n\n\n\n           ^More accurately, we have a guarantee that there is no way to get at the inside of a closure\n      using portable Common Lisp code. Particular implementations may provide debugging tools\n      for getting at this hidden information, such as i spect. So closures are not perfect at hiding\n      information from these tools. Of course, no information-hiding method will be guaranteed\n      against such covert channels--even with the most sophisticated software security measures,\n      it is always possible to, say, wipe a magnet over the computer's disks and alter sensitive data.\n\f13.3 GENERIC FUNCTIONS                                                                             439\n\n\n\n         13.3        Generic Functions\n         The send syntax is awkward, as it is different from the normal Lisp function-calling\n         syntax, and it doesn't fit in with the other Lisp tools. For example, we might like to\n         say (ma pea  ' ba 1 anee accounts), but with messages we would have to write that as:\n\n             (mapcar #*(lambda (acct) (send acct 'balance)) accounts)\n\n\n         We can fix this problem by deiining generic functions that find the right method to\n         execute a message. For example, we could define:\n\n             (defun withdraw (object &rest args)\n               \"Define withdraw as a generic function on o b j e c t s . \"\n               (apply (get-method object 'withdraw) a r g s ) )\n\n\n         and then write (withdraw a c c t ) instead of (send acct 'withdraw x ) . The\n         function wi thdraw is generic because it not only works on account objects but also\n         works on any other class of object that handles the wi thdraw message. For example,\n         we might have a totally unrelated class, army, which also implements a withdraw\n         method. Then we could say (send 5th -army 'withdraw) or (withdraw 5th -army)\n         and have the correct method executed. So object-oriented programming eliminates\n         many problems with name clashes that arise in conventional programs.\n             Many of the built-in Common Lisp functions can be considered generic functions,\n         in that they operate on different types of data. For example, sqrt does one thing\n         when passed an integer and quite another when passed an imaginary number. The\n         sequence functions (like f i n d o r d e l e t e ) operate on lists, vectors, or strings. These\n         functions are not implemented like wi thd raw, but they still act like generic functions.^\n\n\n\n\n         13.4        Classes\n         It is possible to write macros to make the object-oriented style easier to read and\n         write. The macro def i ne - cl ass defines a class with its associated message-handling\n         methods. It also defines a generic function for each message. Finally, it allows the\n         programmer to make a distinction between variables that are associated with each\n         object and those that are associated with a class and are shared by all members of the\n         class. For example, you might want to have all instances of the class account share\n         the same interest rate, but you wouldn't want them to share the same balance.\n\n            ^There is a technical sense of \"generic function\" that is used within CLOS. These functions\n         are not generic according to this technical sense.\n\f440                                                                         OBJECT-ORIENTED                  PROGRAMMING\n\n\n\n          (defmacro d e f i n e - c l a s s ( c l a s s i n s t - v a r s c l a s s - v a r s &body methods)\n            \"Define a c l a s s for object-oriented programming.\"\n                Define constructor and generic functions for methods\n            '(let ,class-vars\n                (mapcar # ' e n s u r e - g e n e r i c - f n \\ ( m a p c a r # ' f i r s t methods))\n                (defun . c l a s s , i n s t - v a r s\n                  #*(lambda (message)\n                       (case message\n                          ,�(mapcar #'make-clause methods))))))\n\n          (defun make-clause (clause)\n            \"Translate a message from d e f i n e - c l a s s into a case c l a u s e . \"\n            ' ( . ( f i r s t clause) #'(lambda .(second clause) . . ( r e s t 2 c l a u s e ) ) ) )\n\n          (defun ensure-generic-fn (message)\n            \"Define an object-oriented dispatch function for a message,\n            unless i t has already been defined as o n e . \"\n            (unless ( g e n e r i c - f n - p message)\n               ( l e t ( ( f n #'(lambda (object &rest a r g s )\n                                    (apply (get-method object message) a r g s ) ) ) )\n                    ( s e t f (symbol-function message) fn)\n                    ( s e t f (get message *generic-fn) f n ) ) ) )\n\n         (defun g e n e r i c - f n - p (fn-name)\n           \" I s t h i s a generic f u n c t i o n ? \"\n           (and (fboundp fn-name)\n                   (eq (get fn-name ' g e n e r i c - f n )          (symbol-function            fn-name))))\n\n\n      Now we define the class account with this macro. We make i n t e r e s t - rate a class\n      variable, one that is shared by all accounts:\n\n         ( d e f i n e - c l a s s account (name �optional (balance 0 . 0 0 ) )\n                                    ((interest-rate .06))\n             (withdraw (amt) ( i f (<= amt balance)\n                                            (decf balance amt)\n                                            'insufficient-funds))\n             (deposit (amt) ( i n c f balance amt))\n             (balance ()                balance)\n             (name               ()     name)\n\n            ( i n t e r e s t ()      ( i n c f balance (* i n t e r e s t - r a t e b a l a n c e ) ) ) )\n\n\n      H e r e w e use the generic functions defined by this macro:\n\n         > ( s e t f acct2 (account \" A . User\" 2000.00))                          #<CL0SURE 24003064>\n\n         > (deposit acct2 42.00) =^ 2042.0\n\n         > ( i n t e r e s t acct2)         2164.52\n\f13.5   DELEGATION                                                                                  44_\n\n\n               > (balance acct2) ^          2164.52\n               > (balance acct) =^ 623.45\n\n\n            In this last line, the generic function bal anee is applied to a c c t , an object that was\n            created before we even defined the account class and the function balance. But\n            bal anee still works properly on this object, because it obeys the message-passing\n            protocol.\n\n\n\n            13.5        Delegation\n            Suppose we want to create a new kind of account, one that requires a password for\n            each action. We can define a new class, password-account, that has two message\n            clauses. The first clause allows for changing the password (if you have the original\n            password), and the second is an otherwi se clause, which checks the password given\n            and, if it is correct, passes the rest of the arguments on to the account that is being\n            protected by the password.\n                  The definition of password-account takes advantage of the internal details of\n            d e f i n e - c l a s s in two ways: it makes use of the fact that otherwise can be used\n            as a catch-all clause in a case form, and it makes use of the fact that the dispatch\n            variable is called message. Usually, it is not a good idea to rely on details about the\n            implementation of a macro, and soon we will see cleaner ways of defining classes.\n            But for now, this simple approach works:\n\n               ( d e f i n e - c l a s s password-account (password acct) ()\n                   (change-password (pass new-pass)\n                                                ( i f (equal pass password)\n                                                      ( s e t f password new-pass)\n                                                      'wrong-password))\n                   (otherwise (pass &rest a r g s )\n                                        ( i f (equal pass password)\n                                              (apply message acct a r g s )\n                                              'wrong-password)))\n\n\n            Now we see how the class password-account can be used to provide protection for\n            an existing account:\n\n               ( s e t f acct3 (password-account \" s e c r e t \" acct2)) => #<CLOSURE 33427277>\n               > (balance acct3 \" s e c r e t \" ) => 2164.52\n               > (withdraw acct3 \"guess\" 2000.00) =^ WRONG-PASSWORD\n               > (withdraw acct3 \" s e c r e t \" 2000.00)        164.52\n\n\n            Now let's try one more example. Suppose we want to have a new class of account\n\f442                                                                OBJECT-ORIENTED          PROGRAMMING\n\n\n\n      where only a limited amount of money can be withdrawn at any time. We could\n      define the class 1 i mi ted - account:\n\n          ( d e f i n e - c l a s s limited-account ( l i m i t acct) ()\n              (withdraw (amt)\n                                   ( i f ( > amt l i m i t )\n                                         'over-limit\n                                         (withdraw acct amt)))\n              (otherwise (&rest args)\n                                   (apply message acct a r g s ) ) )\n\n\n      This definition redefines the wi t hd raw message to check if the limit is exceeded before\n      passing on the message, and it uses the otherwi se clause simply to pass on all other\n      messages unchanged. In the following example, we set up an account with both a\n      password and a limit:\n\n         > ( s e t f acct4 (password-account \" p a s s \"\n                             (limited-account 100.00\n                                (account \" A . T h r i f t y Spender\" 5 0 0 . 0 0 ) ) ) )\n         #<CLOSURE 34136775>\n\n         > (withdraw acct4 \" p a s s \" 200.00) ^           OVER-LIMIT\n\n         > (withdraw acct4 \" p a s s \" 20.00) => 480.0\n\n         > (withdraw acct4 \"guess\" 20.00) =^ WRONG-PASSWORD\n\n\n      Note that functions like wi thdraw are still simple generic functions that just find the\n      right method and apply it to the arguments. The trick is that each class defines a differ\n      ent way to handle the withdraw message. Calling wi thdraw with a c c t 4 as argument\n      results in the following flow of control. First, the method in the password-account\n      class checks that the password is correct. If it is, it calls the method from the\n      1 i mi ted-account class. If the limit is not exceeded, we finally call the method from\n      the account class, which decrements the balance. Passing control to the method of\n      a component is called delegation.\n          The advantage of the object-oriented style is that we can introduce a new class\n      by writing one definition that is localized and does not require changing any existing\n      code. If we had written this in traditional procedural style, we would end up with\n      functions like the following:\n\n         (defun withdraw (acct amt           &optional pass)\n           (cond ((and (typep acct           'password-account)\n                        (not (equal          pass (account-password a c c t ) ) ) )\n                   'wrong-password)\n                 ((and (typep acct            'limited-account)\n\f13.6   INHERITANCE                                                                             443\n\n\n                              (> amt ( a c c o u n t - l i m i t account)))\n                         'over-limit)\n                      ( ( > amt balance)\n                         'insufficient-funds)\n                      (t (decf balance amt))))\n\n\n         There is nothing wrong with this, as an individual function. The problem is that\n         when the bank decides to offer a new kind of account, we will have to change this\n         function, along with all the other functions that implement actions. The \"definition\"\n         of the new account is scattered rather than localized, and altering a bunch of existing\n         functions is usually more error prone than writing a new class definition.\n\n\n\n\n         13.6 Inheritance\n         In the following table, data types (classes) are listed across the horizontal axis, and\n         functions (messages) are listed up and down the vertical axis. A complete program\n         needs to fill in all the boxes, but the question is how to organize the process of filling\n         them in. In the traditional procedural style, we write function definitions that fill in\n         a row at a time. In the object-oriented style, we write class definitions that fill in a\n         column at a time. A third style, the data-dnven or generic style, fills in only one box at\n         a time.\n\n                                          account        limited-        password-\n                                                         account         account\n                          name                                           object\n                          deposit                                        oriented\n                          withdraw        function       oriented\n                          balance\n                          interest         generic\n\n\n\n\n             In this table there is no particular organization to either axis; both messages and\n         classes are listed in random order. This ignores the fact that classes are organized hi\n         erarchically: both Hmited-account and password-account are subclasses of account.\n         This was implicit in the definition of the classes, because both 1 i mi ted - account and\n         password-account contain accounts as components and delegate messages to those\n         components. But it would be cleaner to make this relationship explicit.\n            The d e f s t r u c t mechanism does allow for just this kind of explicit inheritance. If\n         we had defined account as a structure, then we could define 1 i mi ted - account with:\n\f444                                                                     OBJECT-ORIENTED   PROGRAMMING\n\n\n\n              (defstruct (limited-account ( : i n c l u d e account)) l i m i t )\n\n\n          Two things are needed to provide an inheritance facility for classes. First, we should\n          modify d e f i n e - c l a s s so that it takes the name of the class to inherit from as the\n          second argument. This will signal that the new class will inherit all the instance\n          variables, class variables, and methods from the parent class. The new class can, of\n          course, define new variables and methods, or it can shadow the parent's variables and\n          methods. In the form below, we define 1 i ml ted - account to be a subclass of account\n          that adds a new instance variable, 11 mi t , and redefines the wi thdraw method so that\n          it checks for amounts that are over the limit. If the amount is acceptable, then it uses\n          the function cal 1 -next-method (not yet defined) to get at the withdraw method for\n          the parent class, account.\n\n              ( d e f i n e - c l a s s limited-account account ( l i m i t )   ()\n                  (withdraw (amt)\n                                      ( i f ( > amt l i m i t )\n                                            Over-limit\n                                            (call-next-method))))\n\n\n          If inheritance is a good thing, then multiple inheritance is an even better thing. For\n          example, assuming we have defined the classes 1 i mi ted - account and\n          password - account, it is very convenient to define the following class, which inherits\n          from both of them:\n\n              ( d e f i n e - c l a s s limited-account-with-password\n                                        (password-account 1 i mi ted-account))\n\n\n          Notice that this new class adds no new variables or methods. All it does is combine\n          the functionality of two parent classes into one.\n\n\n      [�3 Exercise 13.1 [d]        Define a version of def i ne-cl a s s that handles inheritance and\n          call-next-method.\n\n\n      [�3 Exercise 13.2 [d]        Define a version of def i ne-cl a s s that handles multiple inheri-\n          tance.\n\f13.7 GLOS: THE COMMON        LISP OBJECT SYSTEM                                                     445\n\n\n         13.7         GLOS: The Common Lisp Object System\n         So far, we have developed an object-oriented programming system using a macro,\n         d e f i n e - c l a s s , and a protocol for implementing objects as closures. There have\n         been many proposals for adding object-oriented features to Lisp, some similar to\n         our approach, some quite different. Recently, one approach has been approved to\n         become an official part of Common Lisp, so we will abandon our ad hoc approach\n         and devote the rest of this chapter to CLOS, the Common Lisp Object System. The\n         correspondence between our system and CLOS is summarized here:\n\n                           our system                      CLOS\n                           define-class                    defclass\n                           methods defined in class        defmethod\n                           class-name                      make-instance\n                           call-next-method                call-next-method\n                           ensure-generic-fn               ensure-generic-function\n\n             Like most object-oriented systems, CLOS is primarily concerned with defining\n         classes and methods for them, and in creating instances of the classes. In CLOS the\n         macro def c l a s s defines a class, defmethod defines a method, and make-instance\n         creates an instance of a class--an object. The general form of the macro def cl ass is:\n\n             (def cl ass class-name (superclass...) (slot-specifier...) optional-class-option...)\n\n         The class-options are rarely used, def cl ass can be used to define the class account:\n\n             (defclass account ()\n               ((name :initarg -.name :reader name)\n                 (balance linitarg rbalance linitform 0.00 raccessor balance)\n                 (interest-rate :allocation :class :initform .06\n                                 :reader interest-rate)))\n\n         In the definition of account, we see that the Ust of superclasses is empty, because\n         account does not inherit from any classes. There are three slot specifiers, for the\n         name, bal anee, and i n t e r e s t - rate slots. Each slot name can be followed by optional\n         keyword/value pairs defining how the slot is used. The name slot has an : i ni targ\n         option, which says that the name can be specified when a new account is created\n         with make-instance. The :reader slot creates a method called name to get at the\n         current value of the slot.\n             The balance slot has three options: another : i n i t a r g , saying that the balance\n         can be specified when a new account is made; an rinitform, which says that if\n         the balance is not specified, it defaults to 0.00, and an raccessor, which creates a\n\f446                                                                            OBJECT-ORIENTED           PROGRAMMING\n\n\n\n      method for getting at the slot's value just as : reader does, and also creates a method\n      for updating the slot with s e t f .\n          The i n t e r e s t - rate slot has an : i ni t f orm option to give it a defauh value and an\n       rail ocati on option to say that this slot is part of the class, not of each instance of the\n      class.\n          Here we see the creation of an object, and the application of the automatically\n      defined methods to it.\n\n         > ( s e t f a l (make-instance 'account chalanee 5000.00\n\n                                                     :name \" F r e d \" ) )         #<ACCOUNT 26726272>\n\n         > (name a l ) ^           \"Fred\"\n\n         > (balance a l )               5000.0\n\n         > (interest-rate a l ) ^                0.06\n\n      CLOS differs from most object-oriented systems in that methods are defined sepa\n      rately from classes. To define a method (besides the ones defined automatically by\n      : reader, :writer, or :accessor options) we use the defmethod macro. It is similar\n      to defun in form:\n\n          i�efmetho�method-name                {parameter..:) body...)\n\n      Required parameters to a defmethod can be of the form (var class), meaning that\n      this is a method that applies only to arguments of that class. Here is the method for\n      withdrawing from an account. Note that CLOS does not have a notion of instance\n      variable, only instance slot. So we have to use the method (bal ance a c c t ) rather\n      than the instance variable bal anee:\n\n          (defmethod withdraw ((acct account) amt)\n            ( i f ( < amt (balance a c c t ) )\n                  (decf (balance acct) amt)\n                  'i n s u f f i ci e n t - f u n d s ) )\n\n\n      With CLOS it is easy to define a 1 imited-account as a subclass of account, and to\n      define the wi thd raw method for 11 mi ted - accounts:\n\n          ( d e f c l a s s limited-account (account)\n              ( ( l i m i t : i n i t a r g i l i m i t -.reader l i m i t ) ) )\n\n          (defmethod withdraw ((acct limited-account) amt)\n            ( i f ( > amt ( l i m i t a c c t ) )\n                  Over-limit\n                  (call-next-method)))\n\f13.7   CLOS: THE COMMON            LISP OBJECT SYSTEM                                                 447\n\n\n\n           Note the use of cal 1 -next-method to invoke the withdraw method for the account\n           class. Also note that all the other methods for accounts automatically work on\n           instances of the class limited-account, because it is defined to inherit from account. In\n           the following example, we show that the name method is inherited, that the wi thdraw\n           method for 1 i mi t e d - a c c o u n t is invoked first, and that the withdraw method for\n           account is invoked by the cal 1 -next-method function:\n\n\n               > ( s e t f a2 (make-instance ' l i m i t e d - a c c o u n t\n                                              :name \" A . T h r i f t y Spender\"\n                                              :balance 500.00 : l i m i t 100.00))                ^\n               #<LIMITED-ACCOUNT 24155343>\n\n               > (name a2) ^           \" A . T h r i f t y Spender\"\n\n              > (withdraw a2 200.00) ^                   OVER-LIMIT\n\n              > (withdraw a2 20.00)                     480.0\n\n\n           In general, there may be several methods appropriate to a given message. In that case,\n           all the appropriate methods are gathered together and sorted, most specific first. The\n           most specific method is then called. That is why the method for 1 i mi ted - account is\n           called first rather than the method for account. The function cal 1 -next-method can\n           be used within the body of a method to call the next most specific method.\n                The complete story is actually even more complicated than this. As one example\n           of the complication, consider the class audi ted-a ccount, which prints and keeps\n           a trail of all deposits and withdrawals. It could be defined as follows using a new\n           feature of C L O S , : before and : a f t e r methods:\n\n\n               ( d e f c l a s s audited-account (account)\n                   ( ( a u d i t - t r a i l : i n i t f o r m n i l :accessor   audit-trail)))\n\n               (defmethod withdraw ibefore ( ( a c c t audited-account) amt)\n                 (push ( p r i n t '(withdrawing .amt))\n                       (audit-trail acct)))\n\n               (defmethod withdraw rafter ((acct audited-account) amt)\n                 (push ( p r i n t '(withdrawal (.amt) done))\n                       (audit-trail acct)))\n\n\n           Now a call to withdraw with a a u d i t e d - a c c o u n t as the first argument yields three\n           applicable methods: the primary method from account and the : before and r a f t e r\n           methods. In general, there might be several of each kind of method. In that case,\n           all the : before methods are called in order, most specific first. Then the most\n           specific primary method is called. It may choose to invoke cal 1 - next-method to\n           get at the other methods. (It is an error for a : before or : a f t e r method to use\n           cal 1 -next-method.) Finally, all the r a f t e r methods are called, least specific first.\n\f448                                                     OBJECT-ORIENTED PROGRAMMING\n\n\n      The values from the : before and : a f t e r methods are ignored, and the value from\n      the primary method is returned. Here is an example:\n\n         > ( s e t f a3 (make-instance 'audited-account .-balance 1000.00))\n         #<AUDITED-ACCOUNT 33555607>\n\n         > (withdraw a3 100.00)\n         (WITHDRAWING 100.0)\n         (WITHDRAWAL (100.0) DONE)\n         900.0\n\n         > ( a u d i t - t r a i l a3)\n         ((WITHDRAWAL (100.0) DONE) (WITHDRAWING 1 0 0 . 0 ) )\n\n         > (setf (audit-trail    a3) n i l )\n         NIL\n\n\n      The last interaction shows the biggest flaw in CLOS: it fails to encapsulate informa\n      tion. In order to make the audi t - t r a i 1 accessible to the wi thdraw methods, we had\n      to give it accessor methods. We would like to encapsulate the writer function for\n      a u d i t - t r a i l so that it can only be used with deposit and withdraw. But once the\n      writer function is defined it can be used anywhere, so an unscrupulous outsider can\n      destroy the audit trail, setting it to nil or anything else.\n\n\n\n\n      13.8       A CLOS Example: Searching Tools\n      CLOS is most appropriate whenever there are several types that share related behav\n      ior. A good example of an application that fits this description is the set of searching\n      tools defined in section 6.4. There we defined functions for breadth-first, depth-\n      first, and best-first search, as well as tree- and graph-based search. We also defined\n      functions to search in particular domains, such as planning a route between cities.\n           If we had written the tools in a straightforward procedural style, we would have\n      ended up with dozens of similar functions. Instead, we used higher-order functions\n      to control the complexity. In this section, we see how CLOS can be used to break up\n      the complexity in a slightly different fashion.\n           We begin by defining the class of search problems. Problems will be classified\n      according to their domain (route planning, etc.), their topology (tree or graph) and\n      their search strategy (breadth-first or depth-first, etc.). Each combination of these\n      features results in a new class of problem. This makes it easy for the user to add a new\n      class to represent a new domain, or a new search strategy. The basic class, probl em,\n      contains a single-instance variable to hold the unexplored states of the problem.\n\f13.8 A CLOS EXAMPLE:      SEARCHING          TOOLS                                                 449\n\n\n\n              ( d e f c l a s s problem ()\n                ( ( s t a t e s l i n i t a r g estates :accessor problem-states)))\n\n\n          The function searcher is similar to the function t r e e - s e a r c h of section 6 . 4 . The\n          main difference is that searcher uses generic functions instead of passing around\n          functional arguments.\n\n              (defmethod searcher ((prob problem))\n                \"Find a state that solves the search problem.\"\n                (cond ( ( n o - s t a t e s - p prob)   fail)\n                         ( ( g o a l - p prob) ( c u r r e n t - s t a t e prob))\n                         (t ( l e t ((current (pop-state p r o b ) ) )\n                                ( s e t f (problem-states prob)\n                                          (problem-combiner\n                                             prob\n                                             (problem-successors prob current)\n                                             (problem-states p r o b ) ) ) )\n                             (searcher p r o b ) ) ) )\n\n\n          searcher does not assume that the problem states are organized in a list; rather, it\n          uses the generic function no-states-p to test if there are any states, pop-state to\n          remove and return the first state, and current - s t a t e to access the first state. For the\n          basic probl em class, we will in fact implement the states as a list, but another class of\n          problem is free to use another representation.\n\n              (defmethod c u r r e n t - s t a t e ((prob problem))\n                \"The current state i s the f i r s t of the p o s s i b l e s t a t e s . \"\n                (first    (problem-states p r o b ) ) )\n\n              (defmethod pop-state ((prob problem))\n                \"Remove and return the current s t a t e . \"\n                (pop   (problem-states p r o b ) ) )\n\n              (defmethod n o - s t a t e s - p ((prob problem))\n                \"Are there any more unexplored s t a t e s ? \"\n                (null (problem-states p r o b ) ) )\n\n\n          In t r e e - sea rch, we included a statement to print debugging information. We can do\n          that here, too, but we can hide it in a separate method so as not to clutter up the main\n          definition of searcher. It is a :before method because we want to see the output\n          before carrying out the operation.\n\f450                                                               OBJECT-ORIENTED     PROGRAMMING\n\n\n\n         (defmethod searcher .-before ((prob problem))\n           (dbg 'search \" ~ & ; ; Search: ~a\" (problem-states p r o b ) ) )\n\n\n      The generic functions that remain to be defined are goal -p, probl em-combi ner, and\n      probl em-successors. We will address goal -p first, by recognizing that for many\n      problems we will be searching for a state that is eql to a specified goal state. We\n      define the class eql -probl em to refer to such problems, and specify goal -p for that\n      class. Note that we make it possible to specify the goal when a problem is created,\n      but not to change the goal:\n\n         (defclass eql-problem (problem)\n           ((goal : i n i t a r g :goal :reader problem-goal)))\n\n         (defmethod goal-p ((prob eql-problem))\n           (eql ( c u r r e n t - s t a t e prob) (problem-goal p r o b ) ) )\n\n\n      Now we are ready to specify two search strategies: depth-first search and\n      breadth-first search. We define problem classes for each strategy and specify the\n      probl em- combi ner function:\n\n          ( d e f c l a s s dfs-problem (problem) ( )\n              (:documentation \" D e p t h - f i r s t search problem.\"))\n\n          ( d e f c l a s s bfs-problem (problem) ()\n              (:documentation \" B r e a d t h - f i r s t search problem.\"))\n\n          (defmethod problem-combiner ((prob dfs-problem) new o l d )\n            \" D e p t h - f i r s t search looks at new s t a t e s f i r s t . \"\n            (append new o l d ) )\n          (defmethod problem-combiner ((prob bfs-problem) new o l d )\n            \" D e p t h - f i r s t search looks at old s t a t e s f i r s t . \"\n            (append old new))\n\n\n      While this code will be sufficient for our purposes, it is less than ideal, because it\n      breaks an information-hiding barrier. It treats the set of old states as a list, which is the\n      default for the  r obi em class but is not necessarily the implementation that every class\n      will use. It would have been cleaner to define generic functions add - sta t e s - to - end\n      and a d d - s t a t e s - t o - f r o n t and then define them with append in the default class.\n      But Lisp provides such nice list-manipulation primitives that it is difficult to avoid\n      the temptation of using them directly.\n          Of course, the user who defines a new implementation for probl em-states\n      could just redefine probl em- combi ner for the offending classes, but this is precisely\n      what object-oriented programming is designed to avoid: specializing one abstrac\n      tion (states) should not force us to change anything in another abstraction (search\n      strategy).\n\f13.8 A CLOS EXAMPLE:      SEARCHING             TOOLS                                                      451\n\n\n             The last step is to define a class that represents a particular domain, and define\n          problem-successors for that domain. As the first example, consider the simple\n          binary tree search from section 6.4. Naturally, this gets represented as a class:\n\n             ( d e f c l a s s binary-tree-problem (problem) ( ) )\n\n             (defmethod problem-successors ((prob binary-tree-problem) s t a t e )\n               ( l e t ((n (* 2 s t a t e ) ) )\n                    ( l i s t  (+  1 ) ) ) )\n\n\n          Now suppose we want to solve a binary-tree problem with breadth-first search,\n          searching for a particular goal. Simply create a class that mixes in\n          binary-tree-problem, eql-problem and bfs-problem, create an instance of that\n          class, and call searcher on that instance:\n\n             (defclass binary-tree-eql-bfs-problem\n                        (binary-tree-problem eql-problem bfs-problem)                                ())\n\n             > ( s e t f pi (make-instance ' b i n a r y - t r e e - e q l - b f s - p r o b l e m\n                                             i s t a t e s ' ( 1 ) :goal 12))\n             #<BINARY-TREE-EQL-BFS-PROBLEM 26725536>\n\n             > (searcher p i )\n                Search: (1)\n                Search: (2 3)\n                Search: (3 4 5)\n                Search: (4 5 6 7)\n                Search: (5 6 7 8 9)\n                Search: (6 7 8 9 10 11)\n                Search: (7 8 9 10 11 12 13)\n                Search: (8 9 10 11 12 13 14 15)\n                Search: (9 10 11 12 13 14 15 16 17)\n                Search: (10 11 12 13 14 15 16 17 18 19)\n                Search: (11 12 13 14 15 16 17 18 19 20 21)\n                Search: (12 13 14 15 16 17 18 19 20 21 22 23)\n             12\n\n\n\n\n          Best-First Search\n\n          It should be clear how to proceed to define best-first search: define a class to represent\n          best-first search problems, and then define the necessary methods for that class.\n          Since the search strategy only affects the order in which states are explored, the only\n          method necessary will be for probl em- combi ner.\n\f452                                                               OBJECT-ORIENTED               PROGRAMMING\n\n\n          ( d e f c l a s s best-problem (problem) 0\n              (.�documentation \"A B e s t - f i r s t search problem.\"))\n\n          (defmethod problem-combiner ((prob best-problem) new old)\n            \" B e s t - f i r s t search s o r t s new and old according to c o s t - f n . \"\n            ( s o r t (append new old) # ' <\n                       :key #'(lambda ( s t a t e ) ( c o s t - f n prob s t a t e ) ) ) )\n\n      This introduces the new function cost - f n; naturally it will be a generic function. The\n      following is a cos t - f  that is reasonable for any eq 1 -  rob 1 em dealing with numbers,\n      but it is expected that most domains will specialize this function.\n\n          (defmethod c o s t - f n ((prob eql-problem) s t a t e )\n            (abs (- state (problem-goal p r o b ) ) ) )\n\n      Beam search is a modification of best-first search where all but the best b states are\n      thrown away on each iteration. A beam search problem is represented by a class\n      where the instance variable beam-width holds the parameter b. If this nil, then full\n      best-first search is done. Beam search is implemented by an : a round method on\n      problem-combiner. It calls the next method to get the list of states produced by\n      best-first search, and then extracts the first 6 elements.\n\n         ( d e f c l a s s beam-problem (problem)\n             ((beam-width : i n i t a r g :beam-width : i n i t f o r m n i l\n                                :reader problem-beam-width)))\n\n         (defmethod problem-combiner raround ((prob beam-problem) new old)\n           ( l e t ((combined (call-next-method)))\n                (subseq combined 0 (min (problem-beam-width prob)\n                                         (length combined)))))\n\n      Now we apply beam search to the binary-tree problem. As usual, we have to make\n      up another class to represent this type of problem:\n\n         ( d e f c l a s s binary-tree-eql-best-beam-problem\n             (binary-tree-problem eql-problem best-problem beam-problem)\n             ())\n\n         > ( s e t f p3 (make-instance 'binary-tree-eql-best-beam-problem\n                                       rstates ' ( 1 ) :goal 12 :beam-width 3 ) )\n         #<BINARY-TREE-EQL-BEST-BEAM-PROBLEM 27523251>\n\n         > (searcher p3)\n            Search: (1)\n            Search: (3 2)\n            Search: (7 6 2)\n            Search: (14 15 6)\n            Search: (15 6 28)\n\f13.8 A CLOS EXAMPLE: SEARCHING TOOLS                                                         453\n\n\n                 Search: (6 28 30)\n                 Search: (12 13 28)\n            12\n\n\n        So far the case for CLOS has not been compelling. The code in this section duplicates\n        the functionality of code in section 6.4, but the CLOS code tends to be more verbose,\n        and it is somewhat disturbing that we had to make up so many long class names.\n        However, this verbosity leads to flexibility, and it is easier to extend the CLOS code by\n        adding new specialized classes. It is useful to make a distinction between the systems\n        programmer and the applications programmer. The systems programmer would\n        supply a library of classes like dfs-problem and generic functions like searcher.\n        The applications programmer then just picks what is needed from the library. From\n        the following we see that it is not too difficult to pick out the right code to define a\n        trip-planning searcher. Compare this with the definition of t r i  on page 198 to see\n        if you prefer CLOS in this case. The main difference is that here we say that the cost\n        function is a i r-di stance and the successors are the nei ghbors by defining methods;\n        in t r i  we did it by passing parameters. The latter is a little more succint, but the\n        former may be more clear, especially as the number of parameters grows.\n\n           ( d e f c l a s s trip-problem (binary-tree-eql-best-beam-problem)\n               ((beam-width : i n i t f o r m 1 ) ) )\n\n           (defmethod c o s t - f n ((prob trip-problem) c i t y )\n             ( a i r - d i s t a n c e (problem-goal prob) c i t y ) )\n\n           (defmethod problem-successors ((prob trip-problem) c i t y )\n             (neighbors c i t y ) )\n\n\n        With the definitions in place, it is easy to use the searching tool:\n\n           > ( s e t f p4 (make-instance ' t r i p - p r o b l e m\n                                         estates ( l i s t ( c i t y 'new-york))\n                                         :goal ( c i t y ' s a n - f r a n c i s c o ) ) )\n           #<TRIP-PR�BLEM 31572426>\n\n           > (searcher p4)\n               Search: ((NEW-YORK 73.58 4 0 . 4 7 ) )\n               Search: ((PITTSBURG 79.57 4 0 . 2 7 ) )\n               Search: ((CHICAGO 87.37 4 1 . 5 ) )\n               Search: ((KANSAS-CITY 94.35 3 9 . 0 6 ) )\n               Search: ((DENVER 105.0 3 9 . 4 5 ) )\n           ; ; Search: ((FLAGSTAFF 111.41 3 5 . 1 3 ) )\n               Search: ((RENO 119.49 3 9 . 3 ) )\n           ; : Search: ((SAN-FRANCISCO 122.26 3 7 . 4 7 ) )\n           (SAN-FRANCISCO 122.26 37.47)\n\f454                                                           OBIECT-ORIENTED   PROGRAMMING\n\n\n\n      13.9        Is CLOS Object-Oriented?\n      There is some argument whether CLOS is really object-oriented at all. The arguments\n      are:\n          CLOS IS an object-oriented system because it provides all three of the main criteria\n      for object-orientation: objects with internal state, classes of objects with specialized\n      behavior for each class, and inheritance between classes.\n          CLOS is not an object-oriented system because it does not provide modular\n      objects with information-hiding. In the audi ted-account example, we would like to\n      encapsulate the a u d i t - t r a i l instance variable so that only the withdraw methods\n      can change it. But because methods are written separately from class definitions,\n      we could not do that. Instead, we had to define an accessor for audi t - t r a i 1. That\n      enabled us to write the withdraw methods, but it also made it possible for anyone\n      else to alter the audit trail as well.\n          CLOS is more general than an object-oriented system because it allows for methods\n      that specialize on more than one argument. In true object-oriented systems, methods\n      are associated with objects of a particular class. This association is lexically obvious\n      (and the message-passing metaphor is clear) when we write the methods inside the\n      definition of the class, asinourdef i ne-cl ass macro. The message-passing metaphor\n      is still apparent when we write generic functions that dispatch on the class of their\n      first argument, which is how we've been using CLOS so far.\n          But CLOS methods can dispatch on the class of any required argument, or any\n      combination of them. Consider the following definition of cone, which is like append\n      except that it works for vectors as well as lists. Rather than writing cone using\n      conditional statements, we can use the multimethod dispatch capabilities of CLOS\n      to define the four cases: (1) the first argument is nil, (2) the second argument is nil,\n      (3) both arguments are lists, and (4) both arguments are vectors. Notice that if one of\n      the arguments is nil there will be two applicable methods, but the method for nul 1\n      will be used because the class nul 1 is more specific than the class l i s t .\n\n          (defmethod cone ( ( x n u l l ) y ) y )\n\n          (defmethod cone (x (y n u l l ) ) x)\n\n          (defmethod cone ( ( x l i s t ) (y l i s t ) )\n            (cons ( f i r s t x) (cone ( r e s t x) y ) ) )\n\n          (defmethod cone ( ( x vector) (y v e c t o r ) )\n            ( l e t ((vect (make-array (+ (length x) (length y ) ) ) ) )\n                 (replace vect x)\n                 (replace vect y r s t a r t l (length x ) ) ) )\n\f13.10 ADVANTAGES    OF OBJECT-ORIENTED          PROGRAMMING                                   455\n\n\n\n          Here we see that this definition works:\n\n             > (cone n i l   ' ( a b c ) ) =^ (A  C)\n\n             > (cone ' ( a b c) n i l ) =^ (A  C)\n\n             > (cone ' ( a b c) ' ( d e f ) )     (A  C D  F)\n\n             > (cone ' # ( a b e) ' # ( d e f ) ) =^ #(A  C D  F)\n\n\n          It works, but one might well ask: where are the objects? The metaphor of passing a\n          message to an object does not apply here, unless we consider the object to be the list\n          of arguments, rather than a single privileged argument.\n              It is striking that this style of method definition is very similar to the style used\n          in Prolog. As another example, compare the following two definitions of 1 en, a\n          relation/function to compute the length of a list:\n\n                CLOS                                     %% Prolog\n             (defmethod len ((x n u l l ) ) 0)           len(C].0).\n\n             (defmethod len ((x eons))                   len([XIL].N1) :-\n               (+ 1 (len ( r e s t x ) ) ) )               l e n ( L . N ) . Nl i s N+1.\n\n\n\n\n          13.10         Advantages of Object-Oriented\n                        Programming\n          Bertrand Meyer, in his book on the object-oriented language Eiffel (1988), lists five\n          qualities that contribute to software quality:\n\n             � Correctness. Clearly, a correct program is of the upmost importance.\n\n             � Robustness. Programs should continue to function in a reasonable manner even\n               for input that is beyond the original specifications.\n\n             � Extendability.    Programs should be easy to modify when the specifications\n               change.\n\n             � Reusability. Program components should be easy to transport to new programs,\n               thus amortizing the cost of software development over several projects.\n\n             � Compatibility. Programs should interface well with other programs. For exam\n               ple, a spreadsheet program should not only manipulate numbers correctly but\n               also be compatible with word processing programs, so that spreadsheets can\n               easily be included in documents.\n\f456                                                    OBJECT-ORIENTED         PROGRAMMING\n\n\n\n          Here we list how the object-oriented approach in general and CLOS in particular\n      can effect these measures of quality:\n\n         � Conectness.   Correctness is usually achieved in two stages: correctness of\n           individual modules and correctness of the whole system. The object-oriented\n           approach makes it easier to prove correctness for modules, since they are\n           clearly defined, and it may make it easier to analyze interactions between\n           modules, since the interface is strictly limited. CLOS does not provide for\n           information-hiding the way other systems do.\n\n         � Robustness. Generic functions make it possible for a function to accept, at run\n           time, a class of argument that the programmer did not anticipate at compile\n           time. This is particularly true in CLOS, because multiple inheritance makes it\n           feasible to write default methods that can be used by a wide range of classes.\n\n         � Extendability. Object-oriented systems with inheritance make it easy to define\n           new classes that are slight variants on existing ones. Again, CLOS's multiple\n           inheritance makes extensions even easier than in single-inheritance systems.\n\n         � Reusability. This is the area where the object-oriented style makes the biggest\n           contribution. Instead of writing each new program from scratch, object-\n           oriented programmers can look over a library of classes, and either reuse\n           existing classes as is, or specialize an existing class through inheritance. Large\n           libraries of CLOS classes have not emerged yet. Perhaps they will when the\n           language is more established.\n\n         � Compatibility. The more programs use standard components, the more they will\n           be able to communicate with each other. Thus, an object-oriented program will\n           probably be compatible with other programs developed from the same library\n           of classes.\n\n\n\n      13.11        History and References\n      The first object-oriented language was Simula, which was designed by Ole-Johan\n      Dahl and Krysten Nygaard (1966, Nygaard and Dahl 1981) as an extension of Algol 60.\n      It is still in use today, mostly in Norway and Sweden. Simula provides the ability to\n      define classes with single inheritance. Methods can be inherited from a superclass\n      or overridden by a subclass. It also provides coroutines, class instances that execute\n      continuously, saving local state in instance variables but periodically pausing to let\n      other coroutines run. Although Simula is a general-purpose language, it provides\n      special support for simulation, as the name implies. The built-in class simul a t i o n\n      allows a programmer to keep track of simulated time while running a set of processes\n      as coroutines.\n\f13.11 HISTORY    AND REFERENCES                                                                   457\n\n\n\n              In 1969 Alan Kay was a graduate student at the University of Utah. He became\n          aware of Simula and realized that the object-oriented style was well suited to his\n          research in graphics (Kay 1969). A few years later, at Xerox, he joined with Adele\n          Goldberg and Daniel Ingalls to develop the Smalltalk language (see Goldberg and\n          Robinson 1983). While Simula can be viewed as an attempt to add object-oriented\n          features to strongly typed Algol 60, Smalltalk can be seen as an attempt to use the\n          dynamic, loosely typed features of Lisp, but with methods and objects replacing\n          functions and s-expressions. In Simula, objects existed alongside traditional data\n          types like numbers and strings; in Smalltalk, every datum is an object. This gave\n          Smalltalk the feel of an integrated Lisp environment, where the user can inspect, copy,\n          or edit any part of the environment. In fact, it was not the object-oriented features of\n          Smalltalk per se that have made a lasting impression but rather the then-innovative\n          idea that every user would have a large graphical display and could interact with the\n          system using a mouse and menus rather than by typing commands.\n                Guy Steele's LAMBDA:    The Ultimate Declarative (1976a and b) was perhaps the\n          first paper to demonstrate how object-oriented programming can be done in Lisp. As\n          the title suggests, it was all done using 1 ambda, in a similar way to our def i ne-cl ass\n          example. Steele summarized the approach with the equation \"Actors = Closures\n          (mod Syntax),\" refering to Carl Hewitt's \"Actors\" object-oriented formalism.\n              In 1979, the MIT Lisp Machine group developed the Flavors system based on this\n          approach but offering considerable extensions (Cannon 1980, Weinreb 1980, Moon\n          et al. 1983). \"Flavor\" was a popular jargon word for \"type\" or \"kind\" at MIT, so it was\n          natural that it became the term for what we call classes.\n              The Flavor system was the first to support multiple inheritance. Other languages\n          shunned multiple inheritance because it was too dynamic. With single inheritance,\n          each instance variable and method could be assigned a unique offset number, and\n          looking up a variable or method was therefore trivial. But with multiple inheritance,\n          these computations had to be done at run time. The Lisp tradition enabled pro\n          grammers to accept this dynamic computation, when other languages would not.\n          Once it was accepted, the MIT group soon came to embrace it. They developed\n          complex protocols for combining different flavors into new ones. The concept of\n          mix-ins was developed by programmers who frequented Steve's Ice Cream parlor in\n          nearby Davis Square. Steve's offered a list of ice cream flavors every day but also\n          offered to create new flavors--dynamically--by mixing in various cookies, candies,\n          or fruit, at the request of the individual customer. For example, Steve's did not have\n          chocolate-chip ice cream on the menu, but you could always order vanilla ice cream\n          with chocolate chips mixed in.^\n              This kind of \"flavor hacking\" appealed to the MIT Lisp Machine group, who\n\n             ^Flavor fans will be happy to know that Steve's Ice Cream is now sold nationally in the\n          United States. Alas, it is not possible to create flavors dynamically. Also, be warned that\n          Steve's was bought out by his Teal Square rival, Joey's. The original Steve retired from the\n          business for years, then came back with a new line of stores under his last name, Harrell.\n\f458                                                    OBJECT-ORIENTED          PROGRAMMING\n\n\n\n      adopted the metaphor for their object-oriented programming system. All flavors\n      inherited from the top-most flavor in the hierarchy: vanilla. In the window system, for\n      example, the flavor basi c-wi ndow was defined to support the minimal functionality\n      of all windows, and then new flavors of window were defined by combining mix-in\n      flavors such as s c r o l l -bar-mixin, label -mixin, and border -mixin. These mix-in\n      flavors were used only to define other flavors. Just as you couldn't go into Steve's and\n      order \"crushed Heath bars, hold the ice cream,\" there was a mechanism to prohibit\n      instantiation of mix-ins.\n           A complicated repetoire of method combinations was developed. The default\n      method combination on Flavors was similar to CLOS: first do all the : before meth\n      ods, then the most specific primary method, then the : a f t e r methods. But it was\n      possible to combine methods in other ways as well. For example, consider the\n      i ns i de - wi dth method, which returns the width in pixels of the usuable portion of a\n      window. A programmer could specify that the combined method for i nsi de-wi dth\n      was to be computed by calling all applicable methods and summing them. Then an\n      inside-width method for the basic-window flavor would be defined to return the\n      width of the full window, and each mix-in would have a simple method to say how\n      much of the width it consumed. For example, if borders are 8 pixels wide and scroll\n      bars are 12 pixels wide, then the i nsi de-wi dth method for border -mi xi  returns -8\n      a n d s c r o l l -bar -mixinreturns -12. Thenany window, no matter how many mix-ins\n      it is composed of, automatically computes the proper inside width.\n           In 1981, Symbolics came out with a more efficient implementation of Flavors.\n      Objects were no longer just closures. They were still funcallable, but there was\n      additional hardware support that distinguished them from other functions. After a\n      few years Symbolics abandoned the (send object message) syntax in favor of a new\n      syntax based on generic functions. This system was known as New Flavors. It had a\n      strong influence on the eventual CLOS design.\n           The other strong influence on CLOS was the CommonLoops system developed\n      at Xerox PARC. (See Bobrow 1982, Bobrow et al. 1986, Stefik and Bobrow 1986.)\n      CommonLoops continued the New Flavors trend away from message passing by\n      introducing multimethods: methods that specialize on more than one argument.\n           As of summer 1991, CLOS itself is in a state of limbo. It was legitimitized by its\n      appearance in Common Lisp the Language, 2d edition, but it is not yet official, and an\n      important part, the metaobject protocol, is not yet complete. A tutorial on CLOS is\n      Keenel989.\n         We have seen how easy it is to build an object-oriented system on top of Lisp,\n      using 1 ambda as the primary tool. An interesting alternative is to build Lisp on top of\n      an object-oriented system. That is the approach taken in the Oaklisp system of Lang\n      and Perlmutter (1988). Instead of defining methods using 1 ambda as the primitive,\n      OakHsp has add-method as a primitive and defines 1 ambda as a macro that adds a\n      method to an anonymous, empty operation.\n         Of course, object-oriented systems are thriving outside the Lisp world. With the\n\f13,12 EXERCISES                                                                                459\n\n\n\n          success of UNIX-based workstations, C has become one of the most widely available\n          programming languages. C is a fairly low-level language, so there have been several\n          attempts to use it as a kind of portable assembly language. The most succesful of\n          these attempts is C++, a language developed by Bjarne Stroustrup of AT&T Bell Labs\n          (Stroustrup 1986). C++ provides a number of extensions, including the ability to\n          define classes. However, as an add-on to an existing language, it does not provide as\n          many features as the other languages discussed here. Crucially, it does not provide\n          garbage collection, nor does it support fully generic functions.\n              Eiffel (Meyer 1988) is an attempt to define an object-oriented system from the\n          ground up rather than tacking it on to an existing language. Eiffel supports multiple\n          inheritance and garbage collection and a limited amount of dynamic dispatching.\n              So-called modern languages like Ada and Modula support information-hiding\n          through generic functions and classes, but they do not provide inheritance, and thus\n          can not be classified as true object-oriented languages.\n              Despite these other languages, the Lisp-based object-oriented systems are the\n          only ones since Smalltalk to introduce important new concepts: multiple inheritance\n          and method combination from Flavors, and multimethods from CommonLoops.\n\n\n\n          13.12         Exercises\n     @    Exercise 13.3 [m]    Implement deposit and i n t e r e s t methods for the account class\n          using CLOS.\n\n\n     @    Exercise 13.4 [m] Implement the password-account class using CLOS. Can it be\n          done as cleanly with inheritance as it was done with delegation? Or should you use\n          delegation within CLOS?\n\n\n     @    Exercise 13.5 [h]   Implement graph searching, search paths, and A* searching as\n          classes in CLOS.\n\n\n     @    Exercise 13.6 [h] Implement a priority queue to hold the states of a problem. In\n          stead of a list, the probl em-states will be a vector of lists, each initially null. Each\n          new state will have a priority (determined by the generic function priori ty) which\n          must be an integer between zero and the length of the vector, where zero indicates the\n          highest priority. A new state with priority  is pushed onto element  of the vector,\n          and the state to be explored next is the first state in the first nonempty position. As\n          stated in the text, some of the previously defined methods made the unwarranted\n          assumption that probl em-states would always hold a Hst. Change these methods.\n\fCHAPTER                  14\nKnowledge Representation\nand Reasoning\n\n                                                                                  Knowledge itself is power.\n                                                                           - F r a n c i s B a c o n ( 5 6 1 - 1 6 2 6 )\n\n\n                                                                      The power resides in the knowledge.\n                                                                                      --Edward Feigenbaum\n                                                   Stanford University Heuristic P r o g r a m m i n g Project\n\n\n                                                                 Knowledge is Knowledge, and vice versa.\n                                                                                                         --Tee shirt\n                                                   Stanford University Heuristic Programming Project\n\n\n\n\nI\n    n the 1960s, much of AI concentrated on search techniques. In particular, a lot of w^ork v^as\n    concerned with theorem proving: stating a problem as a small set of axioms and searching for\n    a proof of the problem. The implicit assumption was that the power resided in the inference\nmechanism-if we could just find the right search technique, then all our problems would be\nsolved, and all our theorems would be proved.\n\fINTRODUCTION                                                                                    461\n\n\n\n               Starting in the 1970s, this began to change. The theorem-proving approach failed\n          to live up to its promise. AI workers slowly began to realize that they were not going\n          to solve NP-hard problems by conung up with a clever inference algorithm. The\n          general inferencing mechanisms that worked on toy examples just did not scale up\n          when the problem size went into the thousands (or sometimes even into the dozens).\n              The expert-system approach offered an alternative. The key to solving hard prob\n          lems was seen to be the acquisition of special-case rules to break the problem into\n          easier problems. According to Feigenbaum, the lesson learned from expert systems\n          like MYCIN (which we will see in chapter 16) is that the choice of inferencing mech\n          anism is not as important as having the right knowledge. In this view it doesn't\n          matter very much if MYCIN uses forward- or backward-chaining, or if it uses certainty\n          factors, probabilities, or fuzzy set theory. What matters crucially is that we know\n          Pseudomonas is a gram-negative, rod-shaped organism that can infect patients with\n          compromised immune systems. In other words, the key problem is acquiring and\n          representing knowledge.\n               While the expert system approach had some successes, it also had failiu-es, and\n          researchers were interested in learning the limits of this new technology and under\n          standing exactly how it works. Many found it troublesome that the meaning of the\n          knowledge used in some systems was never clearly defined. For example, does the\n          assertion ( c o l o r appl e red) mean that a particular apple is red, that all apples are\n          red, or that some/most apples are red? The field of knowledge representation concen\n          trated on providing clear semantics for such representations, as well as providing\n          algorithms for manipulating the knowledge. Much of the emphasis was on finding a\n          good trade-off between expressiveness and efficiency. An efficient language is one for\n          which all queries (or at least the average query) can be answered quickly. If we want\n          to guarantee that queries will be answered quickly, then we have to limit what can\n          be expressed in the language.\n              In the late 1980s, a series of results shed doubt on the hopes of finding an efficient\n          language with any reasonable degree of expressiveness at all. Using mathematical\n          techniques based on worst-case analysis, it was shown that even seemingly trivial\n          languages were intractable--in the worst case, it would take an exponential amount of\n          time to answer a simple query.\n              Thus, in the 1990s the emphasis has shifted to knowledge representation and reason\n          ing, a field that encompasses both the expressiveness and efficiency of languages but\n          recognizes that the average case is more important than the worst case. No amount\n          of knowledge can help solve an intractable problem in the worse case, but in practice\n          the worst case rarely occurs.\n\f462                                     KNOWLEDGE      REPRESENTATION     AND       REASONING\n\n\n\n      14.1       A Taxonomy of Representation Languages\n      AI researchers have investigated hundreds of knowledge representation languages,\n      trying to find languages that are convenient, expressive, and efficient. The languages\n      can be classified into four groups, depending on what the basic unit of representation\n      is. Here are the four categories, with some examples:\n\n         � Logical Formulae (Prolog)\n\n         � Networks (semantic nets, conceptual graphs)\n\n         � Objects (scripts, frames)\n\n         � Procedures (Lisp, production systems)\n\n          We have already dealt with logic-based languages like Prolog.\n          Network-based languages can be seen as a syntactic variation on logical languages.\n      A link L between nodes A and  is just another way of expressing the logical rela\n      tion       B), The difference is that network-based languages take their links more\n      seriously: they are intended to be implemented directly by pointers in the computer,\n      and inference is done by traversing these pointers. So placing a link L between A\n      and  not only asserts that L(A, B) is true, but it also says something about how the\n      knowledge base is to be searched.\n          Object-oriented languages can also be seen as syntactic variants of predicate cal\n      culus. Here is a statement in a typical slot-filler frame language:\n\n         (a person\n            (name = Jan)\n            (age = 32))\n\n\n      This is equivalent to the logical formula:\n\n         3 p: person(p)  name(p,Jan)  age(p,32)\n\n      The frame notation has the advantage of being easier to read, in some people's\n      opinion. However, the frame notation is less expressive. There is no way to say that\n      the person's name is either Jan or John, or that the person's age is not 34. In predicate\n      calculus, of course, such statements can be easily made.\n          Finally, procedural languages are to be contrasted with representation languages:\n      procedural languages compute answers without explicit representation of knowl\n      edge.\n          There are also hybrid representation languages that use different methods to\n      encode different kinds of knowledge. The KL-ONE family of languages uses both\n      logical formulae and objects arranged into a network, for example. Many frame\n\f14.2 PREDICATE   CALCULUS   AND ITS PROBLEMS                                                    463\n\n\n\n          languages allow procedural attachment, a technique that uses arbitrary procedures to\n          compute values for expressions that are inconvenient or impossible to express in the\n          frame language itself.\n\n\n\n          14.2        Predicate Calculus and its Problems\n          So far, many of our representations have been based on predicate calculus, a notation\n          with a distinguished position in AI: it serves as the universal standard by which other\n          representations are defined and evaluated. The previous section gave an example\n          expression from a frame language. The frame language may have many merits in\n          terms of the ease of use of its syntax or the efficiency of its internal representation of\n          data. However, to understand what expressions in the language mean, there must be\n          a clear definition. More often than not, that definition is given in terms of predicate\n          calculus.\n               A predicate calculus representation assumes a universe of individuals, with re\n          lations and functions on those individuals, and sentences formed by combining\n          relations with the logical connectives and, or, and not. Philosophers and psycholo\n          gists will argue the question of how appropriate predicate calculus is as a model of\n          human thought, but one point stands clear: predicate calculus is sufficient to repre\n          sent anything that can be represented in a digital computer. This is easy to show:\n          assuming the computer's memory has  bits, and the equation hi = 1 means that bit\n          i is on, then the entire state of the computer is represented by a conjunction such as:\n\n                              (6o = 0)  (6i = 0)  (62 = 1)      ...    {bn = 0)\n              Once we can represent a state of the computer, it becomes possible to represent\n          any computer program in predicate calculus as a set of axioms that map one state onto\n          another. Thus, predicate calculus is shown to be a sufficientlangaage for representing\n          anything that goes on inside a computer--it can be used as a tool for analyzing any\n          program from the outside.\n              This does not prove that predicate calculus is an appropriate tool for all applica\n          tions. There are good reasons why we may want to represent knowledge in a form\n          that is quite different from predicate calculus, and manipulate the knowledge with\n          procedures that are quite different from logical inference. But we should still be able\n          to describe our system in terms of predicate calculus axioms, and prove theorems\n          about it. To do any less is to be sloppy. For example, we may want to manipulate\n          numbers inside the computer by using the arithmetic instructions that are built into\n          the CPU rather than by manipulating predicate calculus axioms, but when we write\n          a square-root routine, it had better satisfy the axiom:\n\n                                           y/x = y=^yxy      =x\n\f464                                      KNOWLEDGE      REPRESENTATION      AND      REASONING\n\n\n\n           Predicate calculus also serves another purpose: as a tool that can be used by a\n      program rather than on a program. All programs need to manipulate data, and some\n      programs will manipulate data that is considered to be in predicate calculus notation.\n      It is this use that we will be concerned with.\n           Predicate calculus makes it easy to start writing down facts about a domain. But\n      the most straightforward version of predicate calculus suffers from a number of\n      serious limitations:\n\n         � Decidability--^ven a set of axioms and a goal, it may be that neither the goal nor\n           its negation can be derived from the axioms.\n\n         � Tractability--even when a goal is provable, it may take too long to find the proof\n           using the available inferencing mechanisms.\n\n         � Uncertainty--it can be inconvenient to deal with relations that are probable to a\n           degree but not known to be definitely true or false.\n\n         � Monotonicity--in pure predicate calculus, once a theorem is proved, it is true\n           forever. But we would like a way to derive tentative theorems that rely on\n           assumptions, and be able to retract them when the assumptions prove false.\n\n         � Consistency--pure predicate calculus admits no contradictions. If by accident\n           both  and -� are derived, then any theorem can be proved. In effect, a single\n           contradiction corrupts the entire data base.\n\n         � Omniscience--it can be difficult to distinguish what is provable from what should\n           be proved. This can lead to the unfounded assumption that an agent believes\n           all the consequences of the facts it knows.\n\n         � Expressiveness--the first-order predicate calculus makes it awkward to talk\n           about certain things, such as the relations and propositions of the language\n           itself.\n\n          The view held predominantly today is that it is best to approach these problems\n      with a dual attack that is both within and outside of predicate calculus. It is considered\n      a good idea to invent new notations to address the problems--both for convenience\n      and to facilitate special-purpose reasoners that are more efficient than a general-\n      purpose theorem prover. However, it is also important to define scrupulously the\n      meaning of the new notation in terms of familiar predicate-calculus notation. As\n      Drew McDermott put it, \"No notation without denotation!\" (1978).\n          In this chapter we show how new notations (and their corresponding meanings)\n      can be used to extend an existing representation and reasoning system. Prolog is\n      chosen as the language to extend. This is not meant as an endorsement for Prolog as\n      the ultimate knowledge representation language. Rather, it is meant solely to give us\n      a clear and familiar foundation from which to build.\n\f14.3 A LOGICAL     LANGUAGE:   PROLOG                                                                465\n\n\n\n          14.3          A Logical Language: Prolog\n          Prolog has been proposed as the answer to the problem of programming in logic. Why\n          isn't it accepted as the universal representation language? Probably because Prolog\n          is a compromise between a representation language and a programming language.\n          Given two specifications that are logically equivalent, one can be an efficient Prolog\n          program, while the other is not. Kowalski's famous equation \"algonthm = logic +\n          control\" expresses the limits of logic alone: logic = algorithm - control Many problems\n          (especially in AI) have large or infinite search spaces, and if Prolog is not given some\n          advice on how to search that space, it will not come up with the answer in any\n          reasonable length of time.\n              Prolog's problems fall into three classes. First, in order to make the language\n          efficient, its expressiveness was restricted. It is not possible to assert that a person's\n          name is either Jan or John in Prolog (although it is possible to ask if the person's\n          name is one of those). Similarly, it is not possible to assert that a fact is false;\n          Prolog does not distinguish between false and unknown. Second, Prolog's inference\n          mechanism is neither sound nor complete. Because it does not check for circular\n          unification, it can give incorrect answers, and because it searches depth-first it can\n          miss correct answers. Third, Prolog has no good way of adding control information\n          to the underlying logic, making it inefficient on certain problems.\n\n\n\n\n          14.4          Problems with Prolog's Expressiveness\n          If Prolog is programming in logic, it is not the full predicate logic we are familiar with.\n          The main problem is that Prolog can't express certain kinds of indefinite facts. It can\n          represent definite facts: the capital of Rhode Island is Providence. It can represent\n          conjunctions of facts: the capital of Rhode Island is Providence and the capital of\n          California is Sacramento. But it can not represent disjunctions or negations: that the\n          capital of California is not Los Angeles, or that the capital of New York is either New\n          York City or Albany. We could try this:\n\n                 ( < - (not (capital LA CA)))\n                 � - (or (capital Albany NY) (capital NYC NY)))\n\n\n          but note that these last two facts concern the relation n o t and o r , not the relation\n          c a p i t a l . Thus, they will not be considered when we ask a query about c a p i t a l . For\n          tunately, the assertion \"Either NYC or Albany is the capital of NY\" can be rephrased\n          as two assertions: \"Albany is the capital of NY if NYC is not\" and \"NYC is the capital\n          of NY if Albany is not:\"\n\f466                                         KNOWLEDGE      REPRESENTATION       AND       REASONING\n\n\n\n         ( < - (capital Albany NY) (not (capital NYC NY)))\n         ( < - (capital NYC NY) (not (capital Albany NY)))\n\n\n      Unfortunately, Prolog's not is different from logic's not. When Prolog answers \"no\"\n      to a query, it means the query cannot be proven from the known facts. If everything\n      is known, then the query must be false, but if there are facts that are not known, the\n      query may in fact be true. This is hardly surprising; we can't expect a program to\n      come up with answers using knowledge it doesn't have. But in this case, it causes\n      problems. Given the previous two clauses and the query ( capi t a l ?c NY ), Prolog\n      will go into an infinite loop. If we remove the first clause, Prolog would fail to prove\n      that Albany is the capital, and hence conclude that NYC is. If we remove the second\n      clause, the opposite conclusion would be drawn.\n          The problem is that Prolog equates \"not proven\" with \"false.\" Prolog makes what\n      is called the closed world assumption--it assumes that it knows everything that is true.\n      The closed world assumption is reasonable for most programs, because the program\n      mer does know all the relevant information. But for knowledge representation in\n      general, we would like a system that does not make the closed world assumption\n      and has three ways to answer a query: \"yes,\" \"no,\" or \"unknown.\" In this example,\n      we would not be able to conclude that the capital of NY is or is not NYC, hence we\n      would not be able to conclude anything about Albany.\n          As another example, consider the clauses:\n\n          ( < - (damned) (do))\n          ( < - (damned) (not ( d o ) ) )\n\n\n      With these rules, the query (? (damned)) should logically be answered \"yes.\"\n      Furthermore, it should be possible to conclude ( damned ) without even investigating\n      if ( do ) is provable or not. What Prolog does is first try to prove ( d o ) . If this succeeds,\n      then ( damned ) is proved. Either way, Prolog then tries again to prove ( d o ) , and this\n      time if the proof fails, then (damned) is proved. So Prolog is doing the same proof\n      twice, when it is unnecessary to do the proof at all. Introducing negation wrecks\n      havoc on the simple Prolog evaluation scheme. It is no longer sufficient to consider\n      a single clause at a time. Rather, multiple clauses must be considered together if we\n      want to derive all the right answers.\n           Robert Moore 1982 gives a good example of the power of disjunctive reasoning.\n      His problem concerned three colored blocks, but we will update it to deal with three\n      countries. Suppose that a certain Eastern European country, E, has just decided if it\n      will remain under communist rule or become a democracy, but we do not know the\n      outcome of the decision.  is situated between the democracy D and the communist\n      country C:\n\n                                      I     D ^\n                                              1      �     ^\n                                                           1     c    I\n\f14A   PROBLEMS         WITH PROLOG'S            EXPRESSIVENESS                                    467\n\n\n\n                The question is: Is there a communist country next to a democracy? Moore points\n           out that the answer is \"yes,\" but discovering this requires reasoning by cases. If  is\n           a democracy then it is next to C and the answer is yes. But if  is communist then\n           it is next to D and the answer is still yes. Since those are the only two possibilities,\n           the answer must be yes in any case. Logical reasoning gives us the right answer, but\n           Prolog can not. We can describe the problem with the following seven assertions\n           and one query, but Prolog can not deal with the or in the final assertion.\n\n                 (<-    (next-to D E))             ( < - (next-to  D))\n                 (<-    (next-to   )               ( < - (next-to C E))\n                 (<-    (democracy D))             ( < - (communist O )\n                 (<-    (or (democracy E) (communist E ) ) )\n\n                 ( ? - (next-to ?A ? B ) (democracy ?A) (communist ? B ) )\n\n\n           We have seen that Prolog is not very good at representing disjunctions and negations.\n           It also has difficulty representing existentials. Consider the following statement in\n           English, logic, and Prolog:\n\n                 Jan likes everyone.\n                 V X person(x) => likesQan,x)\n                 (<-    ( l i k e s Jan ? x ) (person ? x ) )\n\n\n           The Prolog translation is faithful. But there is no good translation for \"Jan likes\n           someone.\" The closest we can get is:\n\n                 Jan likes someone.\n                 3 X person(x) =^ likesQan,x)\n                 (<-    ( l i k e s Jan p D )\n                 (<-    (person p D )\n\n\n           Here we have invented a new symbol, pi, to represent the unknown person that Jan\n           likes, and have asserted that pi is a person. Notice that pi is a constant, not a variable.\n           This use of a constant to represent a specific but unknown entity is called a Skolem\n           constant, after the logician Thoralf Skolem (1887-1963). The intent is that pi may be\n           equal to some other person that we know about. If we find out that Adrian is the\n           person Jan likes, then in logic we can just add the assertion p i = Adrian. But that does\n           not work in Prolog, because Prolog implicitly uses the unique name assumption--d\\\\\n           atoms represent distinct individuals.\n               A Skolem constant is really just a special case of a Skolem function--an unknown\n           entity that depends on one or more variable. For example, to represent \"Everyone\n           likes someone\" we could use:\n\f468                                                  KNOWLEDGE    REPRESENTATION   AND   REASONING\n\n\n\n         Everyone likes someone.\n         V 2/ 3 X person(3:) =^ likes (y, x)\n         ( < - ( l i k e s ?y (p2 ? y ) ) )\n         ( < - (person (p2 ? y ) ) )\n\n\n      Here 2 is a Skolem function that depends on the variable ?y. In other words,\n      everyone likes some person, but not necessarily the same person.\n\n\n\n      14.5           Problems with Predicate Calculus's\n                     Expressiveness\n      In the previous section we saw that Prolog has traded some expressiveness for\n      efficiency. This section explores the limits of predicate calculus's expressiveness.\n          Suppose we want to assert that lions, tigers, and bears are kinds of animals. In\n      predicate calculus or in Prolog we could write an impHcation for each case:\n\n          ( < - (animal ? x ) ( l i o n ? x ) )\n          ( < - (animal ? x ) ( t i g e r ? x ) )\n          ( < - (animal ? x ) (bear ? x ) )\n\n\n      These implications allow us to prove that any known lion, tiger, or bear is in fact\n      an animal. However, they do not allow us to answer the question \"What kinds of\n      animals are there?\" It is not hard to imagine extending Prolog so that the query\n\n          ( ? - ( < - (animal ? x ) ? p r o p o s i t i o n ) )\n\n\n      would be legal. However, this happens not to be valid Prolog, and it is not even\n      valid first-order predicate calculus (or FOPC). In FOPC the variables must range over\n      constants in the language, not over relations or propositions. Higher-order predicate\n      calculus removes this limitation, but it has a more complicated proof theory.\n          It is not even clear what the values of ?propos i t i on should be in the query above.\n      Surely (1 ion ?x) would be a valid answer, but so would (animal ? x ) , (or ( t i g e r\n      ?x) (bea r ? x ) ) , and an infinite number of other propositions. Perhaps we should\n      have two types of queries, one that asks about \"kinds,\" and another that asks about\n      propositions.\n          There are other questions that we might want to ask about relations. Just as it is\n      useful to declare the types of parameters to a Lisp function, it can be useful to declare\n      the types of the parameters of a relation, and later query those types. For example,\n      we might say that the 1 i kes relation holds between a person and an object.\n          In general, a sentence in the predicate calculus that uses a relation or sentence as\n      a term is called a higher-order sentence. There are some quite subtle problems that\n\f14.6 PROBLEMS    WITH COMPLETENESS                                                            469\n\n\n\n         come into play when we start to allow higher-order expressions. Allowing sentences\n         in the calculus to talk about the truth of other sentences can lead to a paradox: is the\n         sentence \"This sentence is false\" true or false?\n              Predicate calculus is defined in terms of a universe of individuals and their\n         properties and relations. Thus it is well suited for a model of the world that picks out\n         individuals and categorizes them--a person here, a building there, a sidewalk between\n         them. But how well does predicate calculus fare in a world of continuous substances?\n         Consider a body of water consisting of an indefinite number of subconstituents that\n         are all water, with some of the water evaporating into the air and rising to form clouds.\n         It is not at all obvious how to define the individuals here. However, Patrick Hayes\n         has shown that when the proper choices are made, predicate calculus can describe\n         this kind of situation quite well. The details are in Hayes 1985.\n             The need to define categories is a more difficult problem. Predicate calculus\n         works very well for crisp, mathematical categories:  is a triangle if and only if  is\n         a polygon with three sides. Unfortunately, most categories that humans deal with\n         in everyday life are not defined so rigorously. The category friend refers to someone\n         you have mostly positive feelings for, whom you can usually trust, and so on. This\n         \"definition\" is not a set of necessary and sufficient conditions but rather is an open-\n         ended list of ill-defined qualities that are highly correlated with the category friend.\n         We have a prototype for what an ideal friend should be, but no clear-cut boundaries\n         that separate friend from, say, acquaintance. Furthermore, the boundaries seem to\n         vary from one situation to another: a person you describe as a good friend in your\n         work place might be only an acquaintance in the context of your home life.\n             There are versions of predicate calculus that admit quantifiers like \"most\" in\n         addition to \"for all\" and \"there exists,\" and there have been attempts to define\n         prototypes and measure distances from them. However, there is no consensus on\n         the way to approach this problem.\n\n\n\n\n         14.6         Problems with Completeness\n         Because Prolog searches depth-first, it can get caught in one branch of the search\n         space and never examine the other branches. This problem can show up, for example,\n         in trying to define a commutative relation, like si bl i ng:\n\n            ( < - ( s i b l i n g lee kirn))\n            �-    ( s i b l i n g ?x ? y ) ( s i b l i n g ?y ? x ) )\n\n\n         With these clauses, we expect to be able to conclude that Lee is Kim's sibling, and\n         Kim is Lee's. Let's see what happens:\n\f470                                                    KNOWLEDGE                REPRESENTATION   AND   REASONING\n\n\n\n         > ( ? - ( s i b l i n g ?x ? y ) )\n         ?X = LEE\n         ?Y = KIM;\n         ?X = KIM\n         ?Y = LEE;\n         ?X = LEE\n         ?Y = KIM;\n         ?X = KIM\n         ?Y = LEE.\n         No.\n\n\n      We get the expected conclusions, but they are deduced repeatedly, because the\n      commutative clause for siblings is applied over and over again. This is annoying, but\n      not critical. Far worse is when we ask ( ? - ( s i b l i n g fred ? x ) ) . This query loops\n      forever. Happily, this particular type of example has an easy fix: just introduce two\n      predicates, one for data-base level facts, and one at the level of axioms and queries:\n\n          ( < - ( s i b l i n g - f a c t lee kim))\n          ( < - ( s i b l i n g ?x ? y ) ( s i b l i n g - f a c t ?x ? y ) )\n          ( < - ( s i b l i n g ?x ? y ) ( s i b l i n g - f a c t ?y ? x ) )\n\n\n      Another fix would be to change the interpreter to fail when a repeated goal was de\n      tected. This was the approach taken in G P S . However, even if we eliminated repeated\n      goals, Prolog can still get stuck in one branch of a depth-first search. Consider the\n      example:\n\n          (<- (natural 0 ) )\n          (<- (natural (1-�- ? n ) ) (natural ? n ) )\n\n      These rules define the natural numbers (the non-negative integers). We can use\n      the rules either to confirm queries like (natural (1+ (1-�- (1-�- 0 ) ) ) ) or to generate\n      the natural numbers, as in the query (natural ?n). So far, everything is fine. But\n      suppose we wanted to define all the integers. One approach would be this:\n\n          (<- (integer 0 ) )\n          (<- (integer ?n) (integer (1+ ? n ) ) )\n          (<- (integer a+ ? n ) ) (integer ? n ) )\n\n      These rules say that 0 is an integer, and any  is an integer if  - f 1 is, and  -h 1 is\n      if  is. While these rules are correct in a logical sense, they don't work as a Prolog\n      program. Asking ( i n t e g e r x) will result in an endless series of ever-increasing\n      queries: ( i n t e g e r (1+ x)), ( i n t e g e r (1+ (1+   and so on. Each goal is\n      different, so no check can stop the recursion.\n\f14,6   PROBLEMS         WITH COMPLETENESS                                                       471\n\n\n\n                The occurs check may or may not introduce problems into Prolog, depending on\n            your interpretation of infinite trees. Most Prolog systems do not do the occurs check.\n            The reasoning is that unifying a variable with some value is the Prolog equivalent of\n            assigning a value to a variable, and programmers expect such a basic operation to be\n            fast. With the occurs check turned off, it will in fact be fast. With checking on, it\n            takes time proportional to the size of the value, which is deemed unacceptable.\n               With occurs checking off, the programmer gets the benefit of fast unification but\n            can run into problems with circular structures. Consider the following clauses:\n\n\n                  (<-    (parent ?x (mother-of ? x ) ) )\n                  ( < - (parent ? x ( f a t h e r - o f ? x ) ) )\n\n\n            These clauses say that, for any person, the mother of that person and the father of\n            that person are parents of that person. Now let us ask if there is a person who is his\n            or her own parent:\n\n\n                  > ( ? (parent ?y ? y ) )\n                  ?Y = [Abort]\n\n\n            The system has found an answer, where ?y = (mother-of ?y). The answer can't be\n            printed, though, because deref (or subst-bindings in the interpreter) goes into an\n            infinite loop trying to figure out what ?y is. Without the printing, there would be no\n            infinite loop:\n\n\n                  ( < - ( s e l f - p a r e n t ) (parent ?y ? y ) )\n\n\n                  > (? (self-parent))\n                  Yes;\n                  Yes;\n                  No.\n\n\n            The sel f-parent query succeeds twice, once with the mother clause and once with\n            the father clause. Has Prolog done the right thing here? It depends on your interpre\n            tation of infinite circular trees. If you accept them as valid objects, then the answer\n            is consistent. If you don't, then leaving out the occurs check makes Prolog unsound:\n            it can come up with incorrect answers.\n               The same problem comes up if we ask if there are any sets that include themselves\n            as members. The query (member ? s e t ? s e t ) will succeed, but we will not be able to\n            print the value of ? s e t .\n\f472                                     KNOWLEDGE      REPRESENTATION     AND       REASONING\n\n\n\n      14.7         Problems with Efficiency: Indexing\n      Our Prolog compiler is designed to handle \"programlike\" predicates--predicates\n      with a small number of rules, perhaps with complex bodies. The compiler does\n      much worse on \"tablelike\" predicates-predicates with a large number of simple\n      facts. Consider the predicate pb, which encodes phone-book facts in the form:\n\n         (pb    (name Jan Doe) (num 415 555 1212))\n\n\n      Suppose we have a few thousand entries of this kind. A typical query for this data\n      base would be:\n\n          (pb   (name Jan Doe) ?num)\n\n\n      It would be inefficient to search through the facts linearly, matching each one against\n      the query. It would also be inefficient to recompile the whole pb /2 predicate every\n      time a new entry is added. But that is just what our compiler does.\n          The solutions to the three problems--expressiveness, completeness, and index-\n      ing-will be considered in reverse order, so that the most difficult one, expressiveness,\n      will come last.\n\n\n\n\n      14.8        A Solution to the Indexing Problem\n      A better solution to the phone-book problem is to index each phone-book entry in\n      some kind of table that makes it easy to add, delete, and retrieve entries. That is what\n      we will do in this section. We will develop an extension of the trie or discrimination\n      tree data structure built in section 10.5 (page 344).\n          Making a discrimination tree for Prolog facts is complicated by the presence of\n      variables in both the facts and the query. Either facts with variables in them will have\n      to be indexed in several places, or queries with variables will have to look in several\n      places, or both. We also have to decide if the discrimination tree itself will handle\n      variable binding, or if it will just return candidate matches which are then checked by\n      some other process. It is not clear what to store in the discrimination tree: copies of\n      the fact, functions that can be passed continuations, or something else. More design\n      choices will come up as we proceed.\n          It is difficult to make design choices when we don't know exactly how the system\n      will be used. We don't know what typical facts will look like, nor typical queries.\n      Therefore, we will design a fairly abstract tool, forgetting for the moment that it will\n      be used to index Prolog facts.\n\f14,8 A SOLUTION        TO THE INDEXING   PROBLEM                                                473\n\n\n\n              We will address the problem of a discrimination tree where both the keys and\n          queries are predicate structures with wild cards. A wild card is a variable, but with\n          the understanding thatjhere is no variable binding; each instance of a variable can\n          match anything. A predicate structure is a list whose first element is a nonvariable\n          symbol. The discrimination tree supports three operations:\n\n              � i ndex--add a key/value pair to the tree\n\n              � fetch--find all values that potentially match a given key\n\n              � uni ndex--remove all key/value pairs that match a given key\n\n              To appreciate the problems, we need an example. Suppose we have the following\n          six keys to index. For simplicity, the value of each key will be the key itself:\n\n             1    (p   a b)\n             2    (p   a c)\n             3    (p   a ?x)\n             4    (p   b c)\n             5    (p   b (f c))\n             6    (p   a (f . ? x ) )\n\n\n          Now assume the query ( ?y c ) . This should match keys 2, 3, and 4. How could\n          we efficiently arrive at this set? One idea is to list the key/value pairs under every\n          atom that they contain. Thus, all six would be listed under the atom p, while 2,\n          4, and 5 would be listed under the atom c. A unification check could eliminate 5,\n          but we still would be missing 3. Key 3 (and every key with a variable in it) could\n          potentially contain the atom c. So to get the right answers under this approach,\n          we will need to index every key that contains a variable under every atom--not an\n          appealing situation.\n              An alternative is to create indices based on both atoms and their position. So now\n          we would be retrieving all the keys that have a c in the second argument position: 2\n          and 4, plus the keys that have a variable as the second argument: 3. This approach\n          seems to work much better, at least for the example shown. To create the index, we\n          essentially superimpose the list structure of all the keys on top of each other, to arrive\n          at one big discrimination tree. At each position in the tree, we create an index of the\n          keys that have either an atom or a variable at that position. Figure 14.1 shows the\n          discrimination tree for the six keys.\n              Consider the query ( ?y c ) . Either the  or the c could be used as an index.\n          The  in the predicate position retrieves all six keys. But the c in the second argument\n          position retrieves only three keys: 2 and 4, which are indexed under c itself, and 3,\n          which is indexed under the variable in that position.\n              Now consider the query ( ?y ( f ? z ) ) . Again, the  serves as an index to all\n          six keys. The f serves as an index to only three keys: the 5 and 6, which are indexed\n\f474                                     KNOWLEDGE       REPRESENTATION      AND      REASONING\n\n\n\n\n                                   A\n              ( A )                ( A )\n              (PAC)                (PAC)\n              (PA?)                (PA?)\n              (PBC)                ( A (F.?))                                     \n              ( 8 (FC))                                        ( A (F.?))         (  (FC))\n                                   \n              ( A (F.?))\n                                   (PBC)\n                                   (  (FC))            (  (F C))\n                                                       (PA(F.?))\n\n                                                       \n\n                                                       (  )\n\n                                                       C\n                                                       (PAC)\n                                                       (PBC)\n                                                       ?\n                                                       (PA?)\n\n\n                         Figure 14.1: Discrimination Tree with Six Keys\n\n\n      directly under f in that position, and 3, which is indexed under the variable in a\n      position along the path that lead to f. In general, all the keys indexed under variables\n      along the path must be considered.\n          The retrieval mechanism can overretrieve. Given the query ( a ( f ? x ) ) , t h e\n      atom  will again retrieve all six keys, the atom a retrieves 1 , 2 , 3 , and 6, and f again\n      retrieves 5, 6, and 3. So f retrieves the shortest list, and hence it will be used to\n      determine the final result. But key 5 is ( b ( f c ) ) , which does not match the query\n      (pa ( f ? x ) ) .\n          We could eliminate this problem by intersecting all the lists instead of just taking\n      the shortest list. It is perhaps feasible to do the intersection using bit vectors, but\n      probably too slow and wasteful of space to do it using lists. Even if we did intersect\n      keys, we would still overretrieve, for two reasons. First, we don't use  i 1 as an index,\n      so we are ignoring the difference between ( f ?x) and ( f . ? x ) . Second, we are\n      using wild-card semantics, so the query ( ?x ?x) would retrieve all six keys, when\n\f14.8 A SOLUTION      TO THE INDEXING    PROBLEM                                                 475\n\n\n\n          it should only retrieve three. Because of these problems, we make a design choice:\n          we will first build a data base retrieval function that retrieves potential matches, and\n          later worry about the unification process that will eliminate mismatches.\n              We are ready for a more complete specification of the indexing strategy:\n\n             � The value will be indexed under each non-nil nonvariable atom in the key, with\n               a separate index for each position. For example, given the preceding data base,\n               the atom a in the first argument position would index values 1,2,3, and 6, while\n               the atom b in the second argument position would index value 4 and 5. The\n               atom  in the predicate position would index all six values.\n\n                  In addition, we will maintain a separate index for variables at each position. For\n                  example, value 3 would be stored under the index \"variable in second argument\n                  position.\"\n\n             � \"Position\" does not refer solely to the linear position in the top-level list. For\n               example, value 5 would be indexed under atom f in the caaddr position.\n\n             � It follows that a key with  atoms will be indexed in  different ways.\n\n             For retrieval, the strategy is:\n\n             � For each non-nil nonvariable atom in the retrieval key, generate a list of possible\n               matches. Choose the shortest such list.\n\n             � Each list of possible matches will have to be augmented with the values indexed\n               under a variable at every position \"above.\" For example, f in the ca add r position\n               retrieves value 5, but it also must retrieve value 3, because the third key has a\n                  variable in the caddr position, and caddr is \"above\" caaddr.\n\n             � The discrimination tree may return values that are not valid matches. The\n               purpose of the discrimination tree is to reduce the number of values we will\n               have to unify against, not to determine the exact set of matches.\n\n              It is important that the retrieval function execute quickly. If it is slow, we might\n         just as well match against every key in the table linearly. Therefore, we will take\n         care to implement each part efficiently. Note that we will have to compare the length\n         of lists to choose the shortest possibility. Of course, it is trivial to compare lengths\n         using 1 e n g t h , but 1 ength requires traversing the whole list. We can do better if we\n         store the length of the list explicitly. A list with its length will be called an nl 1 s t .\n         It will be implemented as a cons cell containing the number of elements and a list\n         of the elements themselves. An alternative would be to use extensible vectors with\n         fill pointers.\n\f476                                          KNOWLEDGE         REPRESENTATION         AND     REASONING\n\n\n\n            An n l i s t i s implemented as a (count . elements) p a i r :\n         (defun make-empty-nlist ( )\n           \"Create a new, empty n l i s t . \"\n           (cons 0 n i l ) )\n\n         (defun n l i s t - n (x) \"The number of elements in an n l i s t . \" ( c a r x ) )\n         (defun n l i s t - l i s t (x) \"The elements in an n l i s t . \" (cdr x ) )\n\n         (defun n l i s t - p u s h (item n l i s t )\n           \"Add a new element to an n l i s t . \"\n           ( i n c f (car n l i s t ) )\n           (push item (cdr n l i s t ) )\n           nlist)\n\n\n      Now we need a place to store these nlists. We will build the data base out of\n      discrimination tree nodes called dtree nodes. Each dtree node has a field to hold\n      the variable index, the atom indices, and pointers to two subnodes, one for the f i r s t\n      and one for the r e s t . We implement dtrees as vectors for efficiency, and because we\n      will never need a dtree- predicate.\n\n         ( d e f s t r u c t (dtree (:type v e c t o r ) )\n             ( f i r s t n i l ) ( r e s t n i l ) (atoms n i l ) (var (make-empty-nlist)))\n\n\n      A separate dtree will be stored for each predicate. Since the predicates must be\n      symbols, it is possible to store the dtrees on the predicate's property list. In most\n      implementations, this will be faster than alternatives such as hash tables.\n\n         ( l e t ((predicates n i l ) )\n\n            (defun get-dtree (predicate)\n              \"Fetch (or make) the dtree for t h i s p r e d i c a t e . \"\n              (cond ( ( g e t predicate ' d t r e e ) )\n                    (t (push predicate predicates)\n                          ( s e t f (get predicate ' d t r e e ) (make-dtree)))))\n\n            (defun c l e a r - d t r e e s ()\n              \"Remove a l l the dtrees for a l l the p r e d i c a t e s . \"\n              ( d o l i s t (predicate predicates)\n                  ( s e t f (get predicate ' d t r e e ) n i l ) )\n              ( s e t f predicates n i l ) ) )\n\n\n      The function i ndex takes a relation as key and stores it in the dtree for the predicate\n      of the relation. It calls dtree - i ndex to do all the work of storing a value under the\n      proper indices for the key in the proper dtree node.\n          The atom indices are stored in an association Ust. Property lists would not\n      work, because they are searched using eq and atoms can be numbers, which are not\n\f14.8 A SOLUTION    TO THE INDEXING           PROBLEM                                                            477\n\n\n\n          necessarily eq. Association lists are searched using eql by default. An alternative\n          would be to use hash tables for the index, or even to use a scheme that starts with\n          association lists and switches to a hash table when the number of entries gets large. I\n          use 1 ookup to look up the value of a key in a property list. This function, and its s e t f\n          method, are defined on page 896.\n\n              (defun index (key)\n                \"Store key in a dtree node. Key must be (predicate . a r g s ) ;\n                i t i s stored i n the p r e d i c a t e ' s d t r e e . \"\n                (dtree-index key key (get-dtree (predicate k e y ) ) ) )\n\n              (defun dtree-index (key value dtree)\n                \"Index value under a l l atoms of key i n d t r e e . \"\n                (cond\n                   ((consp key)                                   ; index on both f i r s t and r e s t\n                     (dtree-index ( f i r s t key) value\n                                            (or ( d t r e e - f i r s t dtree)\n                                                ( s e t f ( d t r e e - f i r s t dtree) (make-dtree))))\n                     (dtree-index ( r e s t key) value\n                                            (or ( d t r e e - r e s t dtree)\n                                                ( s e t f ( d t r e e - r e s t dtree) (make-dtree)))))\n                   ( ( n u l l key))                               ; d o n ' t index on n i l\n                   ( ( v a r i a b l e - p key)                    ; index a v a r i a b l e\n                     ( n l i s t - p u s h value (dtree-var d t r e e ) ) )\n                   (t           Make sure there i s an n l i s t for t h i s atom, and add to              it\n                     ( n l i s t - p u s h value (lookup-atom key d t r e e ) ) ) ) )\n\n              (defun lookup-atom (atom dtree)\n                \"Return (or create) the n l i s t for t h i s atom i n d t r e e . \"\n                (or (lookup atom (dtree-atoms dtree))\n                    ( l e t ((new (make-empty-nlist)))\n                         (push (cons atom new) (dtree-atoms dtree))\n                        new)))\n\n\n          Now we define a function to test the indexing routine. Compare the output with\n          figure 14.1.\n\n              (defun t e s t - i n d e x ()\n                ( l e t ((props ' ( ( p a b) (p a c) (p a ? x ) (p b c)\n                                        (p b (f c ) ) (p a (f . ? x ) ) ) ) )\n                     (clear-dtrees)\n                     (mapc #*index props)\n                     (write ( l i s t props (get-dtree '  ) )\n                              i c i r c l e t rarray t :pretty t )\n                    (values)))\n\f478                                        KNOWLEDGE        REPRESENTATION       AND     REASONING\n\n\n\n         > (test-index)\n         ((#1=(P A B)\n           #2=(P A C)\n           #3=(P A ? X )\n           #4=(P  C)\n           #5=(P  (F O )\n           #6=(P A (F . ? X ) ) )\n          #(#(NIL NIL (P (6 #6# #5# #4# #3# #2# # ! # ) ) ( 0 ) )\n            #(#(NIL NIL (B (2 #5# #4#) A (4 #6# #3# #2# # ! # ) ) ( 0 ) )\n              #(#(#(NIL NIL (F (2 #6# #5#)) ( 0 ) )\n                   #(#(NIL NIL (C (1 #5#)) ( 0 ) )\n                         #(NIL NIL NIL ( 0 ) ) NIL ( 1 #6#))\n                    (C (2 #4# #2#)  ( 1 # ! # ) )\n                    (1 #3#))\n                 #(NIL NIL NIL ( 0 ) )\n                 NIL ( 0 ) )\n               NIL ( 0 ) )\n             NIL ( 0 ) ) )\n\n\n      The next step is to fetch matches from the dtree data base. The function fetch takes\n      a query, which must be a valid relation, as its argument, and returns a list of possible\n      matches. It calls d t r e e - f e t c h to do the work:\n\n          (defun fetch (query)\n            \"Return a l i s t of buckets p o t e n t i a l l y matching the query,\n            which must be a r e l a t i o n of form (predicate . a r g s ) . \"\n            (dtree-fetch query (get-dtree (predicate query))\n                            nil 0 nil most-positive-fixnum))\n\n\n      d t r e e - f e t c h must be passed the query and the dtree, of course, but it is also passed\n      four additional arguments. First, we have to accumulate matches indexed under\n      variables as we are searching through the dtree. So two arguments are used to pass\n      the actual matches and a count of their total number. Second, we want dtree - fetch\n      to return the shortest possible index, so we pass it the shortest answer found so far,\n      and the size of the shortest answer. That way, as it is making its way down the tree,\n      accumulating values indexed under variables, it can be continually comparing the\n      size of the evolving answer with the best answer found so far.\n            We could use nlists to pass around count/values pairs, but nlists only support a\n      push operation, where one new item is added. We need to append together lists of\n      values coming from the variable indices with values indexed under an atom. Append\n      is expensive, so instead we make a list-of-lists and keep the count in a separate\n      variable. When we are done, d t r e e - f e t c h and hence fetch does a multiple-value\n      return, yielding the list-of-lists and the total count.\n\f14.8 A SOLUTION     TO THE INDEXING               PROBLEM                                                                      479\n\n\n\n              There are four cases to consider in dtree-fetch. If the dtree is null or the query\n          pattern is either null or a variable, then nothing will be indexed, so we should just\n          return the best answer found so far. Otherwise, we bind var- and var- 1 i s t to\n          the count and list-of-lists of variable matches found so far, including at the current\n          node. If the count var- is greater than the best count so far, then there is no\n          sense continuing, and we return the best answer found. Otherwise we look at the\n          query pattern. If it is an atom, we use dtree-atom-f etch to return either the current\n          index (along with the accumulated variable index) or the accumulated best answer,\n          whichever is shorter. If the query is a cons, then we use d t r e e - f e t c h on the first\n          part of the cons, yielding a new best answer, which is passed along to the call of\n          dtree-fetch on the rest of the cons.\n\n              (defun dtree-fetch (pat dtree v a r - l i s t - i n v a r - n - i n b e s t - l i s t best-n)\n                \"Return two v a l u e s : a l i s t - o f - l i s t s of p o s s i b l e matches to pat.\n                and the number of elements in the l i s t - o f - l i s t s . \"\n                ( i f (or (null dtree) (null pat) ( v a r i a b l e - p pat))\n                      (values b e s t - l i s t best-n)\n                      ( l e t * ( ( v a r - n l i s t (dtree-var dtree))\n                                  (var-n (+ v a r - n - i n ( n l i s t - n v a r - n l i s t ) ) )\n                                  ( v a r - l i s t ( i f (null ( n l i s t - l i s t v a r - n l i s t ) )\n                                                             var- 1 i s t - i \n                                                             (cons ( n l i s t - l i s t v a r - n l i s t )\n                                                                        var-list-in))))\n                          (cond\n                              ((>= var-n best-n) (values b e s t - l i s t b e s t - n ) )\n                              ((atom pat) (dtree-atom-fetch pat dtree v a r - l i s t var-n\n                                                                                    b e s t - l i s t best-n))\n                              (t ( m u l t i p l e - v a l u e - b i n d ( l i s t l n l )\n                                         (dtree-fetch ( f i r s t pat) ( d t r e e - f i r s t dtree)\n                                                                  v a r - l i s t var-n b e s t - l i s t best-n)\n                                      (dtree-fetch ( r e s t pat) ( d t r e e - r e s t dtree)\n                                                              v a r - l i s t var-n l i s t l n l ) ) ) ) ) ) )\n\n              (defun dtree-atom-fetch (atom dtree v a r - l i s t var-n b e s t - l i s t best-n)\n                \"Return the answers indexed at t h i s atom (along with the v a r s ) ,\n                or return the previous best answer, i f i t i s b e t t e r . \"\n                ( l e t ( ( a t o m - n l i s t (lookup atom (dtree-atoms d t r e e ) ) ) )\n                     (cond\n                       ((or (null a t o m - n l i s t ) (null ( n l i s t - l i s t a t o m - n l i s t ) ) )\n                         (values v a r - l i s t v a r - n ) )\n                       ((and a t o m - n l i s t ( < ( i n c f var-n ( n l i s t - n a t o m - n l i s t ) ) b e s t - n ) )\n                         (values (cons ( n l i s t - l i s t a t o m - n l i s t ) v a r - l i s t ) v a r - n ) )\n                       (t (values b e s t - l i s t b e s t - n ) ) ) ) )\n\n\n          Here we see a call to fetch on the data base created by t e s t - i ndex. It returns two\n          values: a list-of-lists of facts, and the total number of facts, three.\n\f480                                               KNOWLEDGE           REPRESENTATION     AND       REASONING\n\n\n\n         > (fetch ' (  ? c ) )\n         (((   ( A  )\n           ((  ?  ) ) )\n         3\n\n\n      Now let's stop and see what we have accomplished. The functions fetch and\n      d t r e e - f e t c h fulfill their contract of returning potential matches. However, we still\n      need to integrate the dtree facility with Prolog. We need to go through the potential\n      matches and determine which candidates are actual matches. For simplicity we will\n      use the version of u  i f y with binding lists defined in section 11.2. (It is also possible to\n      construct a more efficient version that uses the compiler and the destructive function\n      unifyl.)\n            The function mapc- r e t r i eve calls fetch to get a Ust-of-Usts of potential matches\n      and then calls uni fy to see if the match is a true one. If the match is true, it calls\n      the supplied function with the binding list that represents the unification as the\n      argument, mapc-retri eve is proclaimed inl ine so that functions passed to it can\n      also be compiled in place.\n\n          (proclaim ' ( i n l i n e mapc-retrieve))\n\n          (defun mapc-retrieve (fn query)\n            \"For every fact that matches the query,\n            apply the function to the binding l i s t . \"\n            ( d o l i s t (bucket (fetch query))\n               ( d o l i s t (answer bucket)\n                    ( l e t ( ( b i n d i n g s ( u n i f y query answer)))\n                         (unless (eq bindings f a i l )\n                           (funcall fn b i n d i n g s ) ) ) ) ) )\n\n\n      There are many ways to use this retriever. The function r e t r i eve returns a list of the\n      matching binding hsts, and r e t r i eve-matches substitutes each binding hst into the\n      original query so that the result is a list of expressions that unify with the query.\n\n          (defun r e t r i e v e (query)\n            \"Find a l l f a c t s that match query. Return a l i s t of b i n d i n g s . \"\n            ( l e t ((answers n i l ) )\n                (mapc-retrieve #'(lambda ( b i n d i n g s ) (push bindings answers))\n                                    query)\n                answers))\n\n          (defun retrieve-matches (query)\n            \"Find a l l f a c t s that match query.\n            Return a l i s t of expressions that match the query.\"\n            (mapcar #'(lambda ( b i n d i n g s ) ( s u b s t - b i n d i n g s bindings query))\n                       (retrieve query)))\n\f14.8 A SOLUTION          TO THE INDEXING         PROBLEM                                              481\n\n\n\n          There is one further complication to consider. Recall that in our original Prolog\n          interpreter, the function prove had to rename the variables in each clause as it\n          retrieved it from the data base. This was to insure that there was no conflict between\n          the variables in the query and the variables in the clause. We could do that in\n          r e t r i e v e . However, if we assume that the expressions indexed in discrimination\n          trees are tablelike rather than rulelike and thus are not recursive, then we can get\n          away with renaming the variables only once, when they are entered into the data\n          base. This is done by changing i ndex:\n\n\n              (defun index (key)\n                   \"Store key i n a dtree node.               Key must be (predicate . a r g s ) ;\n                   i t i s stored i n the p r e d i c a t e ' s d t r e e . \"\n                   (dtree-index key (rename-variables key)                      ; store unique vars\n                                      (get-dtree (predicate k e y ) ) ) )\n\n\n          With the new i ndex in place, and after calling t e s t - i ndex to rebuild the data base,\n          we are now ready to test the retrieval mechanism:\n\n\n              > (fetch ' ( p ?x c ) )\n              (((P  C) (P A O )\n                  ((PA     7X3408)))\n              3\n\n             > (retrieve '(p ?x c))\n              (((7X3408 . C) (7X . A ) )\n                  ((7X    . A))\n                  ((7X    . B)))\n\n             > (retrieve-matches ' ( p 7x c ) )\n              ((P A C) (P A C) (P   )\n\n             > (retrieve-matches *(p 7x (7fn c ) ) )\n              ((P A (7FN O ) (P A (F O ) (P  (F C ) ) )\n\n\n          Actually, it is better to use m a p c - r e t r i e v e when possible, since it doesn't cons up\n          answers the way r e t r i e v e and retrieve-matches do. The macro query-bind is\n          provided as a nice interface to mapc - r e t r i eve. The macro takes as arguments a list of\n          variables to bind, a query, and one or more forms to apply to each retrieved answer.\n          Within this list of forms, the variables will be bound to the values that satisfy the\n          query. The syntax was chosen to be the same as mul t i pi e - va 1 ue - bi nd. Here we see\n          a typical use of query - bi nd, its result, and its macro-expansion:\n\f482                                                      KNOWLEDGE               REPRESENTATION                 AND      REASONING\n\n\n\n         > (query-bind ( ? x ? f n ) ' ( p ? x ( ? f n c ) )\n             (format t \"~&P holds between ~a and ~a of c . \" ? x ? f n ) ) =\n          holds between  and F of c .\n          holds between A and F of c .\n          holds between A and ?FN of c .\n         NIL\n\n         = (mapc-retrieve\n            #'(lambda (#:bindings6369)\n                 ( l e t ( ( ? x ( s u b s t - b i n d i n g s #:bindings6369 ' ?  ) )\n                           ( ? f n ( s u b s t - b i n d i n g s #:bindings6369 ' ? f n ) ) )\n                     (format t \"~&P holds between ~a and ~a of c . \" ? x ? f n ) ) )\n            '(p ? x ( ? f n c ) ) )\n\n\n      Here is the implementation:\n\n         (defmacro query-bind ( v a r i a b l e s query &body body)\n           \"Execute the body for each match to the query.\n           Within the body, bind each v a r i a b l e . \"\n           ( l e t * ( ( b i n d i n g s (gensym \"BINDINGS\"))\n                       (vars-and-vals\n                            (mapcar\n                               #'(lambda ( v a r )\n                                       ( l i s t var ' ( s u b s t - b i n d i n g s . b i n d i n g s ' , v a r ) ) )\n                               variables)))\n               '(mapc-retrieve\n                    #'(lambda ( . b i n d i n g s )\n                            (let ,vars-and-vals\n                                .�body))\n                    .query)))\n\n\n\n\n      14.9           A Solution to the Completeness Problem\n      We saw in chapter 6 that iterative deepening is an efficient way to cover a search\n      space without falling into an infinite loop. Iterative deepening can also be used to\n      guide the search in Prolog. It will insiu-e that all valid answers are found eventually,\n      but it won't turn an infinite search space into a finite one.\n          In the interpreter, iterative deepening is implemented by passing an extra argu\n      ment to prove and prove-a 11 to indicate the depth remaining to be searched. When\n      that argument is zero, the search is cut off, and the proof fails. On the next iteration\n      the bounds will be increased and the proof may succeed. If the search is never cut off\n      by a depth bound, then there is no reason to go on to the next iteration, because all\n\f14.9   A SOLUTION         TO THE COMPLETENESS                   PROBLEM                                            483\n\n\n\n            proofs have already been found. The special variable *sea r ch - cut - off* keeps track\n            of this.\n\n\n                (defvar * s e a r c h - c u t - o f f * n i l    \"Has the search been stopped?\")\n\n\n                (defun p r o v e - a l l (goals bindings depth)\n                    \"Find a s o l u t i o n to the conjunction of g o a l s . \"\n                          This v e r s i o n j u s t passes the depth on to PROVE,\n                    (cond ((eq bindings f a i l )               fail)\n                              ((null goals) bindings)\n                              (t (prove ( f i r s t g o a l s ) bindings ( r e s t g o a l s ) d e p t h ) ) ) )\n\n\n                (defun prove (goal bindings o t h e r - g o a l s depth)\n                    \"Return a l i s t of p o s s i b l e s o l u t i o n s to g o a l . \"\n                    : ; Check i f the depth bound has been exceeded\n                    (if    (= depth 0)\n                           (progn ( s e t f * s e a r c h - c u t - o f f * t )\n                                      fail)\n                           (let     ( ( c l a u s e s ( g e t - c l a u s e s (predicate g o a l ) ) ) )\n                              (if    ( l i s t p clauses)\n                                     (some\n                                        #'(lambda (clause)\n                                               (let    ((new-clause (rename-variables c l a u s e ) ) )\n                                                  (prove-al 1\n                                                      (append (clause-body new-clause) o t h e r - g o a l s )\n                                                      (unify goal (clause-head new-clause) b i n d i n g s )\n                                                      (- depth 1 ) ) ) )\n                                        clauses)\n                                          The p r e d i c a t e ' s \" c l a u s e s \" can be an atom:\n                                     ; ; a p r i m i t i v e function to c a l l\n                                     ( f u n c a l l clauses ( r e s t g o a l ) bindings\n                                                    other-goals depth)))))\n\n\n            prove and  rove - a 11 now implement search cutoff, but we need something to control\n            the iterative deepening of the search. First we define parameters to control the\n            iteration: one for the initial depth, one for the maximum depth, and one for the\n            increment between iterations. Setting the initial and increment values to one will\n            make the results come out in strict breadth-first order, but will duplicate more effort\n            than a slightly larger value.\n\f484                                                  KNOWLEDGE             REPRESENTATION              AND   REASONING\n\n\n\n          (defparameter * d e p t h - s t a r t * 5\n            \"The depth of the f i r s t round of i t e r a t i v e s e a r c h . \" )\n          (defparameter * d e p t h - i n c r * 5\n            \"Increase each i t e r a t i o n of the search by t h i s amount.\")\n          (defparameter *depth-max* m o s t - p o s i t i v e - f i x n u m\n            \"The deepest we w i l l ever s e a r c h . \" )\n\n      A new version of t o p - l e v e l - prove will be used to control the iteration.                        It calls\n      prove-al 1 for all depths from the starting depth to the maximum depth, increasing\n      by the increment. However, it only proceeds to the next iteration if the search was\n      cut off at some point in the previous iteration.\n\n          (defun t o p - l e v e l - p r o v e ( g o a l s )\n            (let ((all-goals\n                       *(,�goals (show-prolog-vars , @ ( v a r i a b l e s - i n g o a l s ) ) ) ) )\n               (loop f o r depth from * d e p t h - s t a r t * to *depth-max* by * d e p t h - i n c r *\n                      while ( l e t ( ( * s e a r c h - c u t - o f f * n i l ) )\n                                       ( p r o v e - a l l a l l - g o a l s no-bindings depth)\n                                       *search-cut-off*)))\n            (format t \"~&No.\")\n            (values))\n\n      There is one final complication. When we increase the depth of search, we may\n      find some new proofs, but we will also find all the old proofs that were found on the\n      previous iteration. We can modify show-prol o g - v a r s to only print proofs that are\n      found with a depth less than the increment--that is, those that were not found on the\n      previous iteration.\n\n          (defun show-prolog-vars (vars bindings o t h e r - g o a l s depth)\n            \" P r i n t each v a r i a b l e with i t s b i n d i n g .\n            Then ask the user i f more s o l u t i o n s are d e s i r e d . \"\n            ( i f ( > depth * d e p t h - i n c r * )\n                    fail\n                    (progn\n                       ( i f (null v a r s )\n                             (format t \"~&Yes\")\n                             ( d o l i s t (var vars)\n                                 (format t \"~&~a = ~a\" var\n                                                ( s u b s t - b i n d i n g s bindings v a r ) ) ) )\n                       ( i f (continue-p)\n                             fail\n                             ( p r o v e - a l l o t h e r - g o a l s bindings d e p t h ) ) ) ) )\n\n\n      To test that this works, try setting *depth-max* to 5 and running the following\n      assertions and query. The infinite loop is avoided, and the first four solutions\n      are found.\n\f14.10 SOLUTIONS       TO THE EXPRESSIVENESS      PROBLEMS                                     485\n\n\n\n              ( < - (natural 0 ) )\n              ( < - (natural (1+ ? n ) ) (natural ? n ) )\n\n             > ( ? - (natural ? n ) )\n             ?N = 0;\n             ?N = (1+ 0 ) ;\n             ?N = (1+ (1+ 0 ) ) ;\n             ?N = (1+ (1+ (1+ 0 ) ) ) ;\n             No.\n\n\n\n\n          14.10           Solutions to the Expressiveness Problems\n          In this section we present solutions to three of the limitations described above:\n\n              � Treatment of (limited) higher-order predications.\n\n              � Introduction of a frame-based syntax.\n\n              � Support for possible worlds, negation, and disjunction.\n\n             We also introduce a way to attach functions to predicates to do forward-chaining\n          and error detection, and we discuss ways to extend unification to handle Skolem\n          constants and other problems.\n\n\n          Higher-Order        Predications\n\n          First we will tackle the problem of answering questions like \"What kinds of animals\n          are there?\" Paradoxically, the key to allowing more expressiveness in this case is to\n          invent a new, more limited language and insist that all assertions and queries are\n          made in that language. That way, queries that would have been higher-order in the\n          original language become first-order in the restricted language.\n              The language admits three types of objects: categones, relations, and individuals.\n          A category corresponds to a one-place predicate, a relation to a two-place predicate,\n          and an individual to constant, or zero-place predicate. Statements in the language\n          musthaveoneof five primitive operators: sub, r e l , i n d . v a l , and and. They have\n          the following form:\n\n              (sub     subcategorysupercategory)\n              (rel    relation domain-category range-category)\n              (i nd   individual category)\n              (val    relation individual value)\n              (and     assertion...)\n\f486                                         KNOWLEDGE        REPRESENTATION   AND   REASONING\n\n\n\n      The following table gives some examples, along with English translations:\n\n\n       (sub     dog animal)                   Dog is a kind of animal.\n       (rel     birthday animal date)         The birthday relation holds between each animal\n                                                and some date.\n       (ind fido dog)                         The individual Fido is categorized as a dog.\n       (val birthday fido j u l y - 1 )       The birthday of Fido is July-1.\n       (and AB)                               Both A and Bare true.\n           For those who feel more comfortable with predicate calculus, the following table\n      gives the formal definition of each primitive. The most complicated definition is for\n      rel . The form ( r e l RAB) means that every R holds between an individual of A\n      and an individual of B, and furthermore that every individual of A participates in at\n      least one R relation.\n                            (sub   AB)         Va:: A(x) D\n                            (rel   RAB)        \"rfx^y: R{x,y) D A{x) A B{y)\n                                                 A\\/xA{x) D 3y : R{x, y)\n                            (ind   IC)         C{I)\n                            (val   RIV)          R{I,V)\n                            (and   PQ...)           PAQ.,.\n\n          Queries in the language, not surprisingly, have the same form as assertions,\n      except that they may contain variables as well as constants. Thus, to find out what\n      kinds of animals there are, use the query (sub ?kind animal ). To find out what\n      individual animals there are, use the query (ind ?x animal ). To find out what\n      individual animals of what kinds there are, use:\n\n         (and    (sub ?kind animal) (ind ? x ? k i n d ) )\n\n\n      The implemention of this new language can be based directly on the previous im\n      plementation of dtrees. Each assertion is stored as a fact in a dtree, except that\n      the components of an and assertion are stored separately. The function add-fact\n      does this:\n\n         (defun add-fact ( f a c t )\n           \"Add the fact to the data b a s e . \"\n           ( i f (eq (predicate f a c t ) 'and)\n                 (mapc #*add-fact (args f a c t ) )\n                 (index f a c t ) ) )\n\n\n      Querying this new data base consists of querying the dtree just as before, but with\n      a special case for conjunctive (and) queries. Conceptually, the function to do this,\n      r e t r i eve -fact, should be as simple as the following:\n\f14.10 SOLUTIONS        TO THE EXPRESSIVENESS               PROBLEMS                                                  487\n\n\n\n                 (defun r e t r i e v e - f a c t (query)\n                   \"Find a l l f a c t s that match query. Return a l i s t of b i n d i n g s .\n                   Warning!! t h i s version i s incomplete.\"\n                   ( i f (eq (predicate query) 'and)\n                         ( r e t r i e v e - c o n j u n c t i o n (args query))\n                         ( r e t r i e v e query b i n d i n g s ) ) )\n\n\n          Unfortunately, there are some complications. Think about what must be done in\n          r e t r i e v e - c o n j u n c t i o n . It is passed a list of conjuncts and must return a list of\n          binding lists, where each binding list satisfies the query. For example, to find out\n          what people were born on July 1st, we could use the query:\n\n                 (and (val birthday ?p j u l y - 1 ) ( i n d ?p person))\n\n\n          r e t r i e v e - c o n j u n c t i o n could solve this problem by first calling r e t r i e v e - f a c t on\n          (val     b i r t h d a y ?p j u l y - 1 ) . Once that is done, there is only one conjunct remaining,\n          but in general there could be several, so we need to call r e t r i eve - con j unct i on recur\n          sively with two arguments: theremainingconjuncts,andtheresultthat r e t r i e v e - f a c t\n          gave for the first solution. Since r e t r i e v e - f a c t returns a list of binding lists, it will\n          be easiest if r e t r i e v e - c o n j u n c t i on accepts such a list as its second argument. Fur\n          thermore, when it comes time to call r e t r i eve - f a c t on the second conjunct, we will\n          want to respect the bindings set up by the first conjunct. So r e t r i e v e - f a c t must\n          accept a binding list as its second argument. Thus we have:\n\n                 (defun r e t r i e v e - f a c t (query &optional (bindings n o - b i n d i n g s ) )\n                   \"Find a l l f a c t s that match query. Return a l i s t of b i n d i n g s . \"\n                   ( i f (eq (predicate query) 'and)\n                         ( r e t r i e v e - c o n j u n c t i o n (args query) ( l i s t b i n d i n g s ) )\n                         ( r e t r i e v e query b i n d i n g s ) ) )\n\n                 (defun r e t r i e v e - c o n j u n c t i o n (conjuncts b i n d i n g s - l i s t s )\n                   \"Return a l i s t of binding l i s t s s a t i s f y i n g the c o n j u n c t s . \"\n                   (mapcan\n                     #'(lambda ( b i n d i n g s )\n                          (cond ((eq bindings f a i l ) n i l )\n                                      ( ( n u l l conjuncts) ( l i s t b i n d i n g s ) )\n                                      (t ( r e t r i e v e - c o n j u n c t i o n\n                                                ( r e s t conjuncts)\n                                                (retrieve-fact\n                                                    ( s u b s t - b i n d i n g s bindings ( f i r s t conjuncts))\n                                                    bindings)))))\n                     bindings-lists))\n\n\n          Notice that r e t r i e v e and therefore m a p c - r e t r i e v e now also must accept a binding\n          list. The changes to them are shown in the following. In each case the extra argument\n\f488                                                KNOWLEDGE            REPRESENTATION          AND   REASONING\n\n\n\n      is made optional so that previously written functions that call these functions without\n      passing in the extra argument will still work.\n\n\n          (defun mapc-retrieve (fn query �optional (bindings n o - b i n d i n g s ) )\n            \"For every fact that matches the query,\n            apply the function to the binding l i s t . \"\n            ( d o l i s t (bucket (fetch query))\n               ( d o l i s t (answer bucket)\n                    ( l e t ((new-bindings (unify query answer b i n d i n g s ) ) )\n                         (unless (eq new-bindings f a i l )\n                           (funcall fn n e w - b i n d i n g s ) ) ) ) ) )\n\n          (defun retrieve (query �optional (bindings n o - b i n d i n g s ) )\n            \"Find a l l facts that match query. Return a l i s t of b i n d i n g s . \"\n            ( l e t ((answers n i l ) )\n                 (mapc-retrieve #'(lambda ( b i n d i n g s ) (push bindings   ansviers))\n                                  query bindings)\n                answers))\n\n\n      Now add - f a c t and r e t r i eve - f a c t comprise all we need to implement the language.\n      Here is a short example where a d d - f a c t is used to add facts about bears and dogs,\n      both as individuals and as species:\n\n\n         >   (add-fact     *(sub dog animal)) =^ \n         >   (add-fact     ' ( s u b bear animal)) =^ \n         >   (add-fact     ' ( i n d Fido dog)) =^ \n         >   (add-fact     ' ( i n d Yogi bear))    \n         >   (add-fact     ' ( v a l color Yogi brown)) => \n         >   (add-fact     ' ( v a l color Fido golden))           \n         >   (add-fact     ' ( v a l latin-name bear u r s i d a e ) ) => \n         >   (add-fact     ' ( v a l latin-name dog c a n i s - f a m i l i a r i s ) )   => \n\n\n      Now r e t r i e v e - f a c t is used to answer three questions: What kinds of animals are\n      there? What are the Latin names of each kind of animal? and What are the colors of\n      each individual bear?\n\n\n         > ( r e t r i e v e - f a c t ' ( s u b ?kind animal))\n         (((?KIND . DOG))\n          ((?KIND . BEAR)))\n\n         > ( r e t r i e v e - f a c t '(and (sub ?kind animal)\n                                             (val latin-name ?kind ? l a t i n ) ) )\n         (((7LATIN . CANIS-FAMILIARIS) (7KIND . DOG))\n          ((7LATIN . URSIDAE) (7KIND . BEAR)))\n\f14.10 SOLUTIONS     TO THE EXPRESSIVENESS             PROBLEMS                                                489\n\n\n\n              > ( r e t r i e v e - f a c t '(and (ind ?x bear) (val color ?x ? c ) ) )\n              ( ( ( ? C . BROWN) (?X . YOGI)))\n\n\n\n\n          Improvements\n\n          There are quite a few improvements that can be made to this system. One direction\n          is to provide different kinds of answers to queries. The following two functions\n          are similar to r e t r i eve -matches in that they return lists of solutions that match the\n          query, rather than lists of possible bindings:\n\n              (defun retrieve-bagof (query)\n                \"Find a l l facts that match query.\n                Return a l i s t of queries with bindings f i l l e d i n . \"\n                (mapcar #'(lambda ( b i n d i n g s ) ( s u b s t - b i n d i n g s bindings query))\n                          ( r e t r i e v e - f a c t query)))\n\n              (defun r e t r i e v e - s e t o f (query)\n                \"Find a l l facts that match query.\n                Return a l i s t of unique queries with bindings f i l l e d i n . \"\n                (remove-duplicates (retrieve-bagof query) : t e s t # ' e q u a l ) )\n\n\n          Another direction to take is to provide better error checking. The current system\n          does not complain if a fact or query is ill-formed. It also relies on the user to input all\n          facts, even those that could be derived automatically from the semantics of existing\n          facts. Forexample, the semantics of sub imply that if (sub bear a n i m a l ) and ( s u b\n          p o l a r - b e a r bear) are true, then ( s u b p o l a r - b e a r a n i m a l ) must also be true. This\n          kind of implication can be handled in two ways. The typical Prolog approach would\n          be to write rules that derive the additional sub facts by backward-chaining. Then\n          every query would have to check if there were rules to run. The alternative is to use\n          a forward-chaining approach, which caches each new sub fact by adding it to the data\n          base. This latter alternative takes more storage, but because it avoids rederiving the\n          same facts over and over again, it tends to be faster.\n                The following version of a d d - f a c t does error checking, and it automatically\n          caches facts that can be derived from existing facts. Both of these things are done by\n          a set of functions that are attached to the primitive operators. It is done in a data-\n          driven style to make it easier to add new primitives, should that become necessary.\n                The function a d d - f a c t checks that each argument to a primitive relation is a\n          nonvariable atom, and it also calls f a c t - p r e s e n t - p to check if the fact is already\n          present in the data base. If not, it indexes the fact and calls r u n - a t t a c h e d - f  to do\n          additional checking and caching:\n\n              (defparameter ^ p r i m i t i v e s *   ' ( a n d sub ind rel v a l ) )\n\f490                                                      KNOWLEDGE           REPRESENTATION      AND      REASONING\n\n\n\n          (defun add-fact             (fact)\n             \"Add the fact to the data b a s e . \"\n             (cond ((eq (predicate f a c t )                 *and)\n                         (mapc #*add-fact (args                  fact)))\n                        ((or (not (every #*atom (args                     fact)))\n                                (some # ' v a r i a b l e - p (args       fact))\n                                (not (member (predicate f a c t )              *primitives*)))\n                         (error \"111 -formed f a c t : ~ a \" f a c t ) )\n                        ((not ( f a c t - p r e s e n t - p f a c t ) )\n                         (index f a c t )\n                         (run-attached-fn              fact)))\n             t)\n\n          (defun f a c t - p r e s e n t - p ( f a c t )\n             \" I s t h i s fact present i n the data base?\"\n             (retrieve         fact))\n\n\n      The attached functions are stored on the operator's property list under the indicator\n      attached-fn:\n\n\n          (defun run-attached-fn ( f a c t )\n             \"Run the function associated with the predicate of t h i s                          fact.\"\n             (apply (get (predicate f a c t )                  'attached-fn) (args     fact)))\n\n\n          (defmacro def-attached-fn (pred args &body body)\n             \"Define the attached function f o r a p r i m i t i v e . \"\n             ' ( s e t f (get ' . p r e d 'attached-fn)\n                         #'(lambda ,args . . b o d y ) ) )\n\n\n      The attached functions for i n d and v a l are fairly simple. If w e know ( s u b bear\n      ani m a l ) , then when ( i nd Y o g i bea r ) i s asserted, w e have to also assert ( i nd Y o g i\n      a n i m a l ) . Similarly, the values in a val assertion must be individuals of the categories\n      in the relation's r e l assertion. That is, if ( r e l b i r t h d a y animal d a t e ) is a fact and\n      ( v a l b i r t h d a y Lee j u 1 y - l ) is added, then we can conclude ( i n d Lee a n i m a l ) and\n      ( i n d j u l y - 1 d a t e ) . The followingfunctions add the appropriate facts:\n\n\n          (def-attached-fn ind ( i n d i v i d u a l category)\n                   Cache f a c t s about inherited categories\n             (query-bind (?super) ' ( s u b .category ?super)\n                  (add-fact ' ( i n d . i n d i v i d u a l      .?super))))\n\f14,10   SOLUTIONS      TO THE EXPRESSIVENESS             PROBLEMS                                          491\n\n\n\n                (def-attached-fn val ( r e l a t i o n i n d i ind2)\n                     Make sure the i n d i v i d u a l s are the r i g h t kinds\n                  (query-bind ( ? c a t l ?cat2) ' ( r e l . r e l a t i o n ? c a t l ?cat2)\n                    (add-fact *(ind , i n d l . ? c a t l ) )\n                    (add-fact ' ( i n d .ind2 . ? c a t 2 ) ) ) )\n\n\n            The attached function for r e l simply runs the attached function for any individual of\n            the given relation. Normally one would make all r e l assertions before i nd assertions,\n            so this will have no effect at all. But we want to be sure the data base stays consistent\n            even if facts are asserted in an unusual order.\n\n                (def-attached-fn rel ( r e l a t i o n c a t l cat2)\n                     Run attached function for any I N D ' s of t h i s r e l a t i o n\n                  (query-bind ( ? a ? b ) ' ( i n d . r e l a t i o n ?a ? b )\n                    (run-attached-fn ' ( i n d . r e l a t i o n . ? a . ? b ) ) ) )\n\n\n            The most complicated attached function is for sub. Adding a fact such as ( s u b bear\n            a n i m a l ) causes the following to happen:\n\n                � All of a n i m a l ' s supercategories (such as 1 i v i n g - t h i n g ) become supercate-\n                    gories of all of bea r's subcategories (such as pol a r - bea r ) .\n\n                � animal itself becomes a supercategory all of b e a r ' s subcategories.\n\n                � bear itself becomes a subcategory of all of a n i m a l ' s supercategories.\n\n                � All of the individuals of bear become individuals of animal and its supercate\n                    gories.\n\n               The following accomplishes these four tasks. It does it with four calls to\n            i n d e x - n e w - f a c t , which is used instead of a d d - f a c t because we don't need to run\n            the attached function on the new facts. We do, however, need to make sure that we\n            aren't indexing the same fact twice.\n\n                (def-attached-fn sub (subcat supercat)\n                     Cache SUB facts\n                  (query-bind (?super-super) ' ( s u b .supercat ?super-super)\n                    (index-new-fact ' ( s u b .subcat . ? s u p e r - s u p e r ) )\n                    (query-bind (?sub-sub) ' ( s u b ?sub-sub .subcat)\n                       (index-new-fact ' ( s u b . ? s u b - s u b . ? s u p e r - s u p e r ) ) ) )\n                  (query-bind ( ? s u b - s u b ) ' ( s u b ?sub-sub .subcat)\n                    (index-new-fact ' ( s u b . ? s u b - s u b . s u p e r c a t ) ) )\n                     Cache IND facts\n                  (query-bind (?super-super) ' ( s u b .subcat ?super-super)\n                    (query-bind ( ? s u b - s u b ) ' ( s u b ?sub-sub .supercat)\n                       (query-bind ( ? i n d ) ' ( i n d ? i n d . ? s u b - s u b )\n                          (index-new-fact ' ( i n d . ? i n d . ? s u p e r - s u p e r ) ) ) ) ) )\n\f492                                      KNOWLEDGE       REPRESENTATION        AND       REASONING\n\n\n\n         (defun index-new-fact ( f a c t )\n           \"Index the fact in the data base unless i t       i s already t h e r e . \"\n           (unless ( f a c t - p r e s e n t - p f a c t )\n              (index f a c t ) ) )\n\n\n      The following function tests the attached functions. It shows that adding the single\n      fact (sub bea r ani mal) to the given data base causes 18 new facts to be added.\n\n         (defun t e s t - b e a r s ()\n           (clear-dtrees)\n           (mapc # ' a d d - f a c t\n                   ' ( ( s u b animal l i v i n g - t h i n g )\n                        (sub l i v i n g - t h i n g t h i n g ) (sub polar-bear bear)\n                        (sub g r i z z l y bear) (ind Yogi bear) (ind Lars polar-bear)\n                        (ind Helga g r i z z l y ) ) )\n           (trace index)\n           (add-fact ' ( s u b bear animal))\n           (untrace index))\n\n         >    (test-bears)\n         (1    ENTER INDEX: (SUB BEAR ANIMAL))\n         (1    EXIT INDEX: T)\n         (1    ENTER INDEX: (SUB BEAR THING))\n         (1    EXIT INDEX: T)\n         (1    ENTER INDEX: (SUB GRIZZLY THING))\n         (1    EXIT INDEX: T)\n         (1    ENTER INDEX: (SUB POLAR-BEAR THING))\n         (1    EXIT INDEX: T)\n         (1    ENTER INDEX: (SUB BEAR LIVING-THING))\n         (1    EXIT INDEX: T)\n         (1    ENTER INDEX: (SUB GRIZZLY LIVING-THING))\n         (1    EXIT INDEX: T)\n         (1    ENTER INDEX: (SUB POLAR-BEAR LIVING-THING))\n         (1    EXIT INDEX: T)\n         (1    ENTER INDEX: (SUB GRIZZLY ANIMAL))\n         (1    EXIT INDEX: T)\n         (1    ENTER INDEX: (SUB POLAR-BEAR ANIMAL))\n         (1    EXIT INDEX: T)\n         (1    ENTER INDEX: (IND LARS LIVING-THING))\n         (1    EXIT INDEX: T)\n         (1    ENTER INDEX: (IND HELGA LIVING-THING))\n         (1    EXIT INDEX: T)\n         (1    ENTER INDEX: (IND YOGI LIVING-THING))\n         (1    EXIT INDEX: T)\n         (1    ENTER INDEX: (IND LARS THING))\n         (1    EXIT INDEX: T)\n         (1    ENTER INDEX: (IND HELGA THING))\n\f14.10   SOLUTIONS    TO THE EXPRESSIVENESS        PROBLEMS                                      493\n\n\n\n                (1 EXIT INDEX: T)\n                (1 ENTER INDEX: (IND YOGI THING))\n                (1 EXIT INDEX: T)\n                (1 ENTER INDEX: (IND LARS ANIMAD)\n                (1 EXIT INDEX: )\n                (1 ENTER INDEX: (IND HELGA ANIMAD)\n                (1 EXIT INDEX: )\n                (1 ENTER INDEX: (IND YOGI ANIMAD)\n                (1 EXIT INDEX: )\n                (INDEX)\n\n\n\n\n            A Frame Language\n\n            Another direction we can take is to provide an alternative syntax that will be easier\n            to read and write. Many representation languages are based on the idea of frames,\n            and their syntax reflects this. A frame is an object with slots. We will continue to use\n            the same data base in the same format, but we will provide an alternative syntax that\n            considers the individuals and categories as frames, and the relations as slots.\n                Here is an example of the frame syntax for individuals, which uses the operator\n            a. Note that it is more compact than the equivalent notation using the primitives.\n\n                (a person (name Joe) (age 27)) =\n\n                (and (ind personl person)\n                     (val name personl Joe)\n                     (val age personl 27))\n\n\n             The syntax also allows for nested expressions to appear as the values of slots. Notice\n             that the Skolem constant personl was generated automatically; an alternative is\n             to supply a constant for the individual after the category name. For example, the\n             following says that Joe is a person of age 27 whose best friend is a person named Fran\n             who is 28 and whose best friend is Joe:\n\n                (a person pi (name Joe) (age 27)\n                   ( b e s t - f r i e n d (a person (name Fran) (age 28)\n                                              (best-friend p i ) ) ) ) =\n\n                (and (ind   pi person) (val name p i joe) (val age pi 27)\n                     (ind   person2 person) (val name person2 f r a n )\n                     (val   age person2 28) (val b e s t - f r i e n d person2 p i )\n                     (val   b e s t - f r i e n d p i person2))\n\f494                                                  KNOWLEDGE             REPRESENTATION              AND       REASONING\n\n\n\n      The frame syntax for categories uses the operator each. For example:\n\n          (each person ( i s a animal) (name person-name) (age i n t e g e r ) ) =\n\n          (and (sub person animal)\n               (rel name person person-name)\n               (rel age person i n t e g e r ) )\n\n\n      The syntax for queries is the same as for assertions, except that variables are used\n      instead of the Skolem constants. This is true even when the Skolem constants are\n      automatically generated, as in the following query:\n\n          (a person (age 2 7 ) ) = (AND (IND ? 3 PERSON) (VAL AGE ? 3 2 7 ) )\n\n\n      To support the frame notation, we define the macros a and each to make assertions\n      and ?? to make queries.\n\n          (defmacro a (&rest args)\n            \"Define a new i n d i v i d u a l and a s s e r t f a c t s about i t i n the data b a s e . \"\n            *(add-fact \\ ( t r a n s l a t e - e x p (cons *a a r g s ) ) ) )\n\n          (defmacro each (&rest args)\n            \"Define a new category and a s s e r t f a c t s about i t i n the data b a s e . \"\n            '(add-fact   ( t r a n s � a t e - e x p (cons 'each a r g s ) ) ) )\n\n          (defmacro ? ? (&rest queries)\n            \"Return a l i s t of answers s a t i s f y i n g the query or q u e r i e s . \"\n            *(retrieve-setof\n               ' . ( t r a n s l a t e - e x p (maybe-add 'and ( r e p l a c e - ? - v a r s q u e r i e s ) )\n                                               rquery)))\n\n\n      All three of these macros call on t r a n s ! ate - exp to translate from the frame syntax to\n      the primitive syntax. Note that an a or ea ch expression is computing a conjunction of\n      primitive relations, but it is also computing a term when it is used as the nested value\n      of a slot. It would be possible to do this by returning multiple values, but it is easier to\n      build t r a n s � ate - exp as a set of local functions that construct facts and push them on\n      the local variable con j u n c t s . At the end, the list of con j u n c t s is returned as the value\n      of the translation. The local functions t r a n s ! a t e - a and t r a n s ! a t e - e a c h return the\n      atom that represents the term they are translating. The local function t r a n s l a t e\n      translates any kind of expression, t r a n s ! ate - s ! ot handles a slot, and co!! e c t - f a c t\n      is responsible for pushing a fact onto the list of conjuncts. The optional argument\n      query-mode-p tells what to do if the individual is not provided in an a expression. If\n      query-mode-p is true, the individual will be represented by a variable; otherwise it\n      will be a Skolem constant.\n\f14.10   SOLUTIONS    TO THE EXPRESSIVENESS                 PROBLEMS                                                      495\n\n\n\n                (defun t r a n s l a t e - e x p (exp &optional query-mode-p)\n                  \"Translate exp into a conjunction of the four p r i m i t i v e s . \"\n                  ( l e t ((conjuncts n i l ) )\n                       (labels\n                         ( ( c o l l e c t - f a c t (&rest terms) (push terms conjuncts))\n\n                        ( t r a n s l a t e (exp)\n                                  Figure out what kind of expression t h i s i s\n                             (cond\n                                ((atom exp) exp)\n                                ((eq ( f i r s t exp) *a) ( t r a n s l a t e - a ( r e s t exp)))\n                                ((eq ( f i r s t exp) 'each) ( t r a n s l a t e - e a c h ( r e s t exp)))\n                                 (t (apply # ' c o l l e c t - f a c t exp) exp)))\n\n                        (translate-a (args)\n                                 t r a n s l a t e (A category Cind] (rel f i l l e r ) * )\n                           ( l e t * ((category (pop a r g s ) )\n                                           ( s e l f (cond ((and args (atom ( f i r s t a r g s ) ) )\n                                                                  (pop a r g s ) )\n                                                                 (query-mode-p (gentemp \" ? \" ) )\n                                                                 (t (gentemp ( s t r i n g c a t e g o r y ) ) ) ) ) )\n                               ( c o l l e c t - f a c t ' i n d s e l f category)\n                               ( d o l i s t (slot args)\n                                    ( t r a n s l a t e - s l o t 'val s e l f s l o t ) )\n                               self))\n\n                        (translate-each (args)\n                           ; ; t r a n s l a t e (EACH category [ ( i s a c a t * ) ] ( s l o t             cat)*)\n                           ( l e t * ((category (pop a r g s ) ) )\n                               (when (eq (predicate ( f i r s t a r g s ) ) ' i s a )\n                                   ( d o l i s t (super ( r e s t (pop a r g s ) ) )\n                                        ( c o l l e c t - f a c t ' s u b category s u p e r ) ) )\n                               ( d o l i s t (slot args)\n                                   ( t r a n s l a t e - s l o t ' r e l category s l o t ) )\n                               category))\n\n                        (translate-slot (primitive self slot)\n                                t r a n s l a t e ( r e l a t i o n value) into a REL or SUB\n                           ( a s s e r t (= (length s l o t ) 2 ) )\n                           (collect-fact primitive ( f i r s t slot) s e l f\n                                                    ( t r a n s l a t e (second s l o t ) ) ) ) )\n\n                              Body of t r a n s l a t e - e x p :\n                       ( t r a n s l a t e exp)       B u i l d up the l i s t of conjuncts\n                       (maybe-add 'and (nreverse c o n j u n c t s ) ) ) ) )\n\f496                                          KNOWLEDGE          REPRESENTATION        AND         REASONING\n\n\n\n      The auxiliary functions maybe - add and repl ace - ? - va r s are shown in the following:\n\n         (defun maybe-add (op exps �optional i f - n i l )\n           \"For example, (maybe-add 'and exps t ) returns\n           t i f exps i s n i l , ( f i r s t exps) i f there i s only one.\n           and (and expl e x p 2 . . . ) i f there are several e x p s . \"\n           (cond ( ( n u l l exps) i f - n i l )\n                  ( ( l e n g t h = l exps) ( f i r s t exps))\n                  (t (cons op e x p s ) ) ) )\n\n          (defun length=l (x)\n            \" I s X a l i s t of length 1 ? \"\n            (and (consp x) (null (cdr x ) ) ) )\n\n          (defun r e p l a c e - ? - v a r s (exp)\n            \"Replace each ? i n exp with a temporary v a r : 7123\"\n            (cond ((eq exp ' 7 ) (gentemp \" 7 \" ) )\n                   ((atom exp) exp)\n                   (t (reuse-cons (replace-7-vars ( f i r s t exp))\n                                               (replace-7-vars ( r e s t exp))\n                                              exp))))\n\n\n\n\n      Possible Worlds: Truth, Negation, and Disjunction\n\n      In this section we address four problems: distinguishing unknown from f al se, rep\n      resenting negations, representing disjunctions, and representing multiple possible\n      states of affairs. It turns out that all four problems can be solved by introducing\n      two new techniques: possible worlds and negated predicates. The solution is not\n      completely general, but it is practical in a wide variety of applications.\n          There are two basic ways to distinguish unknown from false. The first possibility\n      is to store a truth value-- true or f al se--along with each proposition. The second\n      possibility is to include the truth value as part of the proposition. There are several\n      syntactic variations on this theme. The following table shows the possibilities for\n      the propositions \"Jan likes Dean is true\" and \"Jan likes Ian is false:\"\n\n            Approach        True Prop.                            False Prop.\n            (1)             ( l i k e s Jan Dean) - - t r u e     ( l i k e s Jan I a n ) - -   false\n            (2a)            ( l i k e s t r u e Jan Dean)         ( l i k e s f a l s e Jan I a n )\n            {2b)            ( l i k e s Jan Dean)                 (not    ( l i k e s Jan Dean))\n            (2c)            ( l i k e s Jan Dean)                 (~likes     Jan Dean)\n\n         The difference between (1) and (2) shows up when we want to make a query.\n      With (1), we make the single query (1 i kes Jan Dean ) (or perhaps (1 i kes Jan ?x)),\n      and the answers will tell us who Jan does and does not like. With (2), we make one\n\f14.10 SOLUTIONS TO THE EXPRESSIVENESS PROBLEMS                                             497\n\n\n        query to find out what liking relationships are true, and another to find out which\n        ones are false. In either approach, if there are no responses then the answer is truly\n        unknown.\n             Approach (1) is better for applications where most queries are of the form \"Is\n        this sentence true or false?\" But applications that include backward-chaining rules\n        are not like this. The typical backward-chaining rule says \"Conclude X is true if Y is\n        true.\" Thus, most queries will be of the type \"Is Y true?\" Therefore, some version of\n        approach (2) is preferred.\n             Representing true and false opens the door to a host of possible extensions. First,\n        we could add multiple truth values beyond the simple \"true\" and \"false.\" These\n        could be symbolic values like \"probably-true\" or \"false-by-default\" or they could be\n        numeric values representing probabilities or certainty factors.\n             Second, we could introduce the idea of possible worlds. That is, the truth of a\n        proposition could be unknown in the current world, but true if we assume p, and\n        false if we assume q. In the possible world approach, this is handled by calling the\n        current world W, and then creating a new world VFi, which is just like W except\n        that  is true, and w2, which is just like W except that q is true. By doing reasoning\n        in different worlds we can make predictions about the future, resolve ambiguitites\n        about the current state, and do reasoning by cases.\n             For example, possible worlds allow us to solve Moore's communism/democracy\n        problem (page 466). We create two new possible worlds, one where is a democracy\n        and one where it is communist. In each world it is easy to derive that there is\n        a democracy next to a communist country. The trick is to realize then that the\n        two worlds form a partition, and that therefore the assertion holds in the original\n        \"real\" world as well. This requires an interaction between the Prolog-based tactical\n        reasoning going on within a world and the planning-based strategic reasoning that\n        decides which worlds to consider.\n             We could also add a truth maintenance system (or TMS) to keep track of the as\n        sumptions or justifications that lead to each fact being considered true. A truth\n        maintenance system can lessen the need to backtrack in a search for a global solu\n        tion. Although truth maintenance systems are an important part of AI programming,\n        they will not be covered in this book.\n             In this section we extend the dtree facility (section 14.8) to handle truth values\n        and possible worlds. With so many options, it is difficult to make design choices. We\n        will choose a fairly simple system, one that remains close to the simplicity and speed\n        of Prolog but offers additional functionality when needed. We will adopt approach\n        (2c) to truth values, using negated predicates. For example, the negated predicate of\n        1 i kes is ~1 i kes, which is pronounced \"not likes.\"\n             We will also provide minimal support for possible worlds. Assume that there is\n        always a current world, W, and that there is a way to create alternative worlds and\n        change the current world to an alternative one. Assertions and queries will always be\n        made with respect to the current world. Each fact is indexed by the atoms it contains.\n\f498                                                     KNOWLEDGE                REPRESENTATION   AND           REASONING\n\n\n\n      just as before. The difference is that the facts are also indexed by the current world.\n      To support this, we need to modify the notion of the numbered list, or n l i s t , to\n      include a numbered association list, or nal i s t . The following is an nal i s t showing\n      six facts indexed under three different worlds: WO, Wl, and W2:\n\n          (6 (WO #1# #2# #3#) (Wl #4#) (W2 #5# #6#))\n\n\n      The fetching routine will remain unchanged, but the postfetch processing will have\n      to sort through the nalists to find only the facts in the current world. It would also be\n      possible for fetch to do this work, but the reasoning is that most facts will be indexed\n      under the \"real world,\" and only a few facts will exist in alternative, hypothetical\n      worlds. Therefore, we should delay the effort of sorting through the answers to\n      eliminate those answers in the wrong world--it may be that the first answer fetched\n      will suffice, and then it would have been a waste to go through and eliminate other\n      answers. The following changes to i ndex and dtree - i ndex add support for worlds:\n\n          (defvar *world* *W0 \"The current world used by index and f e t c h . \" )\n\n          (defun index (key &optional (world * w o r l d * ) )\n            \"Store key i n a dtree node.                      Key must be (predicate . a r g s ) ;\n            it    i s stored i n the dtree, indexed by the w o r l d . \"\n            (dtree-index key key world (get-dtree (predicate k e y ) ) ) )\n\n          (defun dtree-index (key value world dtree)\n            \"Index value under a l l atoms of key in d t r e e . \"\n            (cond\n                 ((consp key)                                   ; index on both f i r s t and r e s t\n                  (dtree-index ( f i r s t key) value world\n                                        (or     ( d t r e e - f i r s t dtree)\n                                                ( s e t f ( d t r e e - f i r s t dtree) (make-dtree))))\n                  (dtree-index ( r e s t key) value world\n                                        (or     ( d t r e e - r e s t dtree)\n                                                ( s e t f ( d t r e e - r e s t dtree) (make-dtree)))))\n                 ( ( n u l l key))                              ; d o n ' t index on n i l\n\n\n\n                 ( ( v a r i a b l e - p key)                   ; index a v a r i a b l e\n                  ( n a l i s t - p u s h world value (dtree-var d t r e e ) ) )\n                 (t ; ; Make sure there i s an n l i s t for t h i s atom, and add to                      it\n                  ( n a l i s t - p u s h world value (lookup-atom key d t r e e ) ) ) ) )\n\n\n      The new function n a l i s t - p u s h adds a value to an nalist, either by inserting the value\n      in an existing key's list or by adding a new key/value list:\n\f14.10 SOLUTIONS       TO THE EXPRESSIVENESS                   PROBLEMS                               499\n\n\n\n              (defun n a l i s t - p u s h (key val n a l i s t )\n                   \"Index val under key in a numbered al i s t . \"\n                   ; ; An n a l i s t i s of the form (count (key v a l * ) * )\n                       Ex: (6 (nums 1 2 3) ( l e t t e r s a b c ) )\n                   ( i n c f (car n a l i s t ) )\n                   ( l e t ( ( p a i r (assoc key (cdr n a l i s t ) ) ) )\n                      ( i f pair\n                            (push val (cdr p a i r ) )\n                            (push ( l i s t key v a l ) (cdr n a l i s t ) ) ) ) )\n\n\n          In the following, fetch is used on the same data base created by t e s t - i ndex, indexed\n          under the world WO. This time the result is a list-of-lists of world/values a-lists. The\n          count, 3, is the same as before.\n\n             > (fetch ' ( p ?x c ) )\n              (((WO (P  C) (P A C ) ) )\n                  ((WO (P A ? X ) ) ) )\n              3\n\n\n          So far, worlds have been represented as symbols, with the implication that different\n          symbols represent completely distinct worlds. That doesn't make worlds very easy\n          to use. We would like to be able to use worlds to explore alternatives--create a\n          new hypothetical world, make some assumptions (by asserting them as facts in the\n          hypothetical world), and see what can be derived in that world. It would be tedious\n          to have to copy all the facts from the real world into each hypothetical world.\n              An alternative is to establish an inheritance hierarchy among worlds. Then a fact\n          is considered true if it is indexed in the current world or in any world that the current\n          world inherits from.\n              To support inheritance, we will implement worlds as structures with a name field\n          and a field for the list of parents the world inherits from. Searching through the\n          inheritance lattice could become costly, so we will do it only once each time the user\n          changes worlds, and mark all the current worlds by setting the current field on or\n          off. Here is the definition for the world structure:\n\n              ( d e f s t r u c t (world ( : p r i n t - f u n c t i o n p r i n t - w o r l d ) )\n                   name parents current)\n\n\n          We will need a way to get from the name of a world to the world structure. Assuming\n          names are symbols, we can store the structure on the name's property list. The\n          function get-worl d gets the structure for a name, or builds a new one and stores it.\n          get - wor 1 d can also be passed a world instead of a name, in which case it just returns\n          the world. We also include a definition of the default initial world.\n\f500                                               KNOWLEDGE            REPRESENTATION   AND   REASONING\n\n\n\n          (defun get-world (name &optional current (parents ( l i s t * w o r l d * ) ) )\n            \"Look up or create the world with t h i s name.\n            I f the world i s new, g i v e i t the l i s t of p a r e n t s . \"\n            (cond ((world-p name) name) ; ok i f i t already i s a world\n                    ((get name ' w o r l d ) )\n                    (t ( s e t f (get name 'world)\n                                 (make-world rname name .-parents parents\n                                                    .�current c u r r e n t ) ) ) ) )\n\n         (defvar *world* (get-world 'WO n i l n i l )\n            \"The current world used by index and f e t c h . \" )\n\n\n      The function use-worl d is used to switch to a new world. It first makes the current\n      world and all its parents no longer current, and then makes the new chosen world and\n      all its parents current. The function use-new-worl d is more efficient in the common\n      case where you want to create a new world that inherits from the current world. It\n      doesn't have to turn any worlds off; it j ust creates the new world and makes it current.\n\n\n         (defun use-world (world)\n            \"Make t h i s world c u r r e n t . \"\n            ; ; I f passed a name, look up the world i t names\n            ( s e t f world (get-world world))\n            (unless (eq world *world*)\n                  Turn the o l d w o r l d ( s ) o f f and the new one(s) o n ,\n              ; ; unless we are already using the new world\n              (set-world-current *world* n i l )\n              (set-world-current world t )\n              ( s e t f *world* w o r l d ) ) )\n\n         (defun use-new-world ( )\n           \"Make up a new world and use i t .\n           The world i n h e r i t s from the current w o r l d . \"\n           ( s e t f *world* (get-world (gensym \"W\")))\n           ( s e t f (world-current *world*) t )\n           *world*)\n\n         (defun set-world-current (world o n / o f f )\n           \"Set the current f i e l d of world and i t s parents on or o f f . \"\n                 nil i s o f f , anything e l s e i s o n .\n            ( s e t f (world-current world) o n / o f f )\n            ( d o l i s t (parent (world-parents world))\n                (set-world-current parent o n / o f f ) ) )\n\n\n      We also add a print function for worlds, which just prints the world's name.\n\f14.10   SOLUTIONS      TO THE EXPRESSIVENESS                   PROBLEMS                                              501\n\n\n\n                (defun print-world (world &optional (stream t ) depth)\n                  (declare (ignore depth))\n                  ( p r i n l (world-name world) stream))\n\n\n            The format of the dtree data base has changed to include worlds, so we need\n            new retrieval functions to search through this new format. Here the functions\n            m a p c - r e t r i e v e , r e t r i e v e , and r e t r i e v e - b a g o f are modified to give new versions\n            that treat worlds. To reflect this change, the new functions all have names ending in\n            -in-world:\n\n\n                (defun mapc-retrieve-in-world (fn query)\n                  \"For every fact i n the current world that matches the query,\n                  apply the function to the binding l i s t . \"\n                  ( d o l i s t (bucket (fetch query))\n                      ( d o l i s t ( w o r l d / e n t r i e s bucket)\n                          (when (world-current ( f i r s t w o r l d / e n t r i e s ) )\n                              ( d o l i s t (answer ( r e s t w o r l d / e n t r i e s ) )\n                                  ( l e t ( ( b i n d i n g s (unify query answer)))\n                                       (unless (eq bindings f a i l )\n                                          (funcall fn b i n d i n g s ) ) ) ) ) ) ) )\n\n                (defun r e t r i e v e - i n - w o r l d (query)\n                  \"Find a l l f a c t s that match query. Return a l i s t of b i n d i n g s . \"\n                  ( l e t ((answers n i l ) )\n                       (mapc-retrieve-in-world\n                         #'(lambda ( b i n d i n g s ) (push bindings answers))\n                         query)\n                      answers))\n\n                 (defun r e t r i e v e - b a g o f - i n - w o r l d (query)\n                   \"Find a l l f a c t s i n the current world that match query.\n                   Return a l i s t of queries with bindings f i l l e d i n . \"\n                   (mapcar #'(lambda ( b i n d i n g s ) ( s u b s t - b i n d i n g s bindings query))\n                               (retrieve-in-world query)))\n\n\n            Now let's see how these worlds work.                                  First, in WO we see that the facts from\n            t e s t - i ndex are still in the data base:\n\n\n                > *world* ^ WO\n\n                > ( r e t r i e v e - b a g o f - i n - w o r l d *(p ? z c ) )    ^\n                ((P A C) (P A C) (P   )\n\f502                                     KNOWLEDGE      REPRESENTATION     AND      REASONING\n\n\n\n      Now we create and use a new world that inherits from WO. Two new facts are added\n      to this new world:\n\n         > (use-new-world)      W7031\n\n         > (index *(p new c ) ) => \n         > (index ' C p b b)) =^ \n\n      We see that the two new facts are accessible in this world:\n\n         > (retrieve-bagof-in-world ' ( p ?z c ) )\n         ((P A C) (P A C) (P  C) (P NEW O )\n\n         > (retrieve-bagof-in-world ' ( ^ p ?x ?y)) ^\n         ((~P   ) )\n\n\n      Now we create another world as an alternative to the current one by first switching\n      back to the original WO, then creating the new world, and then adding some facts:\n\n         > (use-world *W0) WO\n         > (use-new-world)      W7173\n\n         > (index *(p newest c ) ) ^ \n         > (index '(~p c newest))       \n\n      Here we see that the facts entered in W7031 are not accessible, but the facts in the new\n      world and in WO are:\n\n         > (retrieve-bagof-in-world ' ( p ?z c ) ) =^\n         ((P A C) (P A C) (P  C) (P NEWEST O )\n\n         > (retrieve-bagof-in-world ' ( ^ p ?x ?y))\n         ir?   C NEWEST))\n\n\n\n\n      Unification, Equality, Types, and Skolem Constants\n\n      The lesson of the zebra puzzle in section 11.4 was that unification can be used to\n      lessen the need for backtracking, because an uninstantiated logic variable or partially\n      instantiated term can stand for a whole range of possible solutions. However, this\n      advantage can quickly disappear when the representation forces the problem solver\n      to enumerate possible solutions rather than treating a whole range of solutions as one.\n      For example, consider the following query in the frame language and its expansion\n      into primitives:\n\f14.11   HISTORY    AND REFERENCES                                                              503\n\n\n\n                  (a person (name Fran))\n                  = (and (ind ?p person) (val name ?p f r a n ) )\n\n\n            The way to answer this query is to enumerate all individuals ?p of type person and\n            then check the name slot of each such person. It would be more efficient if ( i nd ?p\n            person) did not act as an enumeration, but rather as a constraint on the possible\n            values of ?p. This would be possible if we changed the definition of variables (and\n            of the unification function) so that each variable had a type associated with it. In\n            fact, there are at least three sources of information that have been implemented as\n            constraints on variables terms:\n\n                  � The type or category of the term.\n\n                  � The members or size of a term considered as a set or list.\n\n                  � Other terms this term is equal or not equal to.\n\n                Note that with a good solution to the problem of equality, we can solve the problem\n            of Skolem constants. The idea is that a regular constant unifies with itself but no\n            other regular constant. On the other hand, a Skolem constant can potentially unify\n            with any other constant (regular or Skolem). The equality mechanism is used to keep\n            track of each Skolem variable's possible bindings.\n\n\n\n            14.11          History and References\n            Brachman and Levesque (1985) collect thirty of the key papers in knowledge repre\n            sentation. Included are some early approaches to semantic network based (Quillian\n            1967) and logic-based (McCarthy 1968) representation. Two thoughtful critiques\n            of the ad hoc use of representations without defining their meaning are by Woods\n            (1975) and McDermott (1978). It is interesting to contrast the latter with McDermott\n            1987, which argues that logic by itself is not sufficient to solve the problems of AI.\n            This argument should not be surprising to those who remember the slogan logic =\n            algonthm -    control.\n                Genesereth and Nilsson's textbook (1987) cover the predicate-calculus-based ap\n            proach to knowledge representation and AI in general. Ernest Davis (1990) presents\n            a good overview of the field that includes specialized representations for time, space,\n            qualitative physics, propositional attitudes, and the interaction between agents.\n                Many representation languages focus on the problem of defining descriptions for\n            categories of objects. These have come to be known as term-subsumption languages.\n            Examples include KL-ONE (Schm�lze and Lipkis 1983) and KRYPTON (Brachman,\n            Fikes, and Levesque 1983). See Lakoff 1987 for much more on the problem of\n            categories and prototypes.\n\f504                                          KNOWLEDGE      REPRESENTATION     AND      REASONING\n\n\n\n              Hector Levesque (1986) points out that the areas Prolog has difficulty with--\n          disjunction, negation, and existentials--all involve a degree of vagueness. In his\n          term, they lack vividness.     A vivid proposition is one that could be represented\n          directly in a picture: the car is blue; she has a martini in her left hand; Albany is the\n          capital of New York. Nonvivid propositions cannot be so represented: the car is not\n          blue; she has a martini in one hand; either Albany or New York City is the capital\n          of New York. There is interest in separating vivid from nonvivid reasoning, but no\n          current systems are actually built this way.\n              The possible world approach of section 14.10 was used in the MRS system (Russell\n          1985). More recent knowledge representation systems tend to use truth maintenance\n          systems instead of possible worlds. This approach was pioneered by Doyle (1979)\n          and McAllester (1982). Doyle tried to change the name to \"reason maintenance,\" in\n          (1983), but it was too late. The version in widest used today is the assumption-based\n          truth maintenance system, or ATMS, developed by de Kleer (1986a,b,c). Charniak\n          et al. (1987) present a complete Common Lisp implementation of a McAllester-\n          styleTMS.\n              There is little communication between the logic programming and knowledge\n          representation communities, even though they cover overlapping territory. Colmer-\n          auer (1990) and Cohen (1990) describe Logic Programming languages that address\n          some of the issues covered in this chapter. Key papers in equality reasoning include\n          Caller and Fisher 1974, Kornfeld 1983,^ Jaffar, Lassez, and Maher 1984, and van\n          Emden and Yukawa 1987. H�Udobler's book (1987) includes an overview of the area.\n          Papers on extending unification in ways other than equality include Ait-Kaci et al.\n          1987 and Staples and Robinson 1988. Finally, papers on extending Prolog to cover\n          disjunction and negation (i.e., non-Horn clauses) include Loveland 1987, Plaisted\n          1988, and Stickell988.\n\n\n\n\n          14.12         Exercises\n      @   Exercise 14.1 [m]     Arrange to store dtrees in a hash table rather than on the property\n          list of predicates.\n\n\n      (�3 Exercise 14.2 [m] Arrange to store the dtree-atoms in a hash table rather than in\n          an association list.\n\n\n      @   Exercise 14.3 [m] Change the dtree code so that  i 1 is used as an atom index. Time\n          the performance on an application and see if the change helps or hurts.\n\n             ^ A commentary on this paper appears in Elcock and Hoddinott 1986.\n\f14.12 EXERCISES                                                                                   505\n\n\n\n     @     Exercise 14.4 [m] Consider the query ( a b c d e f g). If the index under a\n           returns only one or two keys, then it is probably a waste of time for d t r e e - f e t c h\n           to consider the other keys in the hope of finding a smaller bucket. It is certainly\n           a waste if there are no keys at all indexed under a. Make appropriate changes to\n           dtree-fetch.\n\n\n     @     Exercise 14.5 [h]   Arrange to delete elements from a dtree.\n\n\n     @     Exercise 14.6 [h] Implement iterative-deepening search in the Prolog compiler.\n           You will have to change each function to accept the depth as an extra argument, and\n           compile in checks for reaching the maximum depth.\n\n\n           Exercise 14.7 [d] Integrate the Prolog compiler with the dtree data base. Use\n           the dtrees for predicates with a large number of clauses, and make sure that each\n           predicate that is implemented as a dtree has a Prolog primitive accessing the dtree.\n\n\n     [�J   Exercise 14.8 [d] Add support for possible worlds to the Prolog compiler with\n           dtrees. This support has already been provided for dtrees, but you will have to\n           provide it for ordinary Prolog rules.\n\n\n     @     Exercise 14.9 [h] Integrate the language described in section 14.10 and the frame\n           syntax from section 14.10 with the extended Prolog compiler from the previous\n           exercise.\n\n\n     @     Exercise 14.10 [d] Build a strategic reasoner that decides when to create a possible\n           world and does reasoning by cases over these worlds. Use it to solve Moore's problem\n           (page 466).\n\f506                                         KNOWLEDGE REPRESENTATION AND REASONING\n\n\n\n      14.13         Answers\n      Answer 14.1\n\n         (let   ((dtrees (make-hash-table : t e s t # ' e q ) ) )\n\n            (defun get-dtree (predicate)\n              \"Fetch (or make) the dtree for t h i s p r e d i c a t e . \"\n              ( s e t f (gethash predicate dtrees)\n                        (or (gethash predicate dtrees)\n                            (make-dtree))))\n\n            (defun c l e a r - d t r e e s ()\n              \"Remove all the dtrees for a l l the p r e d i c a t e s . \"\n              (clrhash dtrees)))\n\n\n      Answer 14.5 Hint: here is the code for nl i s t - del e t e . Now figure out how to find\n      all the nlists that an item is indexed under.\n\n         (defun n l i s t - d e l e t e (item n l i s t )\n           \"Remove an element from an n l i s t .\n           Assumes that item i s present exactly once.\"\n           (decf (car n l i s t ) )\n           ( s e t f (cdr n l i s t ) (delete item (cdr n l i s t ) rcount D )\n           nlist)\n\f"}